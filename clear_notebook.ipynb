{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 14:11:09.875271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSet2.csv\", sep=\";\")#, parse_dates=['Timestamp']) #, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "df = data.groupby(data.index // K).mean() #усреднение\n",
    "df_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError, MeanAbsolutePercentageError\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mase = MeanAbsoluteScaledError(multioutput='raw_values')\n",
    "mase_uni = MeanAbsoluteScaledError(multioutput='uniform_average')\n",
    "mape = MeanAbsolutePercentageError(multioutput='raw_values')\n",
    "# mae = MeanAbsoluteError()\n",
    "\n",
    "\n",
    "#if ‘raw_values’, returns a full set of errors in case of multioutput input. If ‘uniform_average’, errors of all outputs are averaged with uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 67)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_np[:, :]\n",
    "# dataset = np.concatenate((dataset[:, :8], dataset[:, 9:]), axis=1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**__Отбор признаков на минималках__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удаление константных\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(0.001)\n",
    "dataset1 = selector.fit_transform(dataset) \n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 14}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(range(67)) - set(selector.get_feature_names_out(input_features=np.arange(dataset.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset[:, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(dataset[:, 8], color=\"green\")\n",
    "plt.plot(np.concatenate((dataset[:32714, 8], dataset[32717:, 8])))\n",
    "plt.title(\"consumption_09\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00292  0.00733  0.754974 1.658794 1.956544]\n",
      "[32714, 375379, 1, 1, 1]\n",
      "Изменение только в [[32713]\n",
      " [32714]\n",
      " [32715]\n",
      " [32716]]\n"
     ]
    }
   ],
   "source": [
    "values = np.unique(dataset[:, 8])\n",
    "print(values)\n",
    "print([len(np.argwhere(dataset[:, 8] == val)) for val in values])\n",
    "print(f\"Изменение только в {np.argwhere(dataset[1:, 8] - dataset[:-1, 8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Эти датчики пока выкинем из-за константности: ** \n",
    "\n",
    "8: consumption_09\n",
    "\n",
    "14 : consumption_07 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('consumption_07', 'consumption_09')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[15], columns[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7effcfc36820>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset[7])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import correlate\n",
    "# a = np.array([np.sin(x + 1) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 2) for x in range(10)])\n",
    "# c = correlate(a, b, mode=\"full\") #mode='same'\n",
    "# plt.plot(a, label=\"a\")\n",
    "# plt.plot(b, label=\"b\")\n",
    "# plt.plot(c, label=\"correlation\")\n",
    "# plt.legend()\n",
    "# c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "#еще не поняла до конца\n",
    "from sklearn.feature_selection import f_regression\n",
    "for i in range(1):\n",
    "    X = np.concatenate((dataset[:, :i], dataset[:, i + 1:]), axis=1)\n",
    "    y = dataset[:, i]\n",
    "    res = f_regression(X, y)\n",
    "    print(res[0].shape)\n",
    "    # plt.plot(res[0], label=\"f_statistics\")\n",
    "    # # plt.plot(res[1], label=\"p_values\")\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([np.sin(x) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 1) + 1 for x in range(10)])\n",
    "# c = np.array([np.sin(x + 0.1) for x in range(10)])\n",
    "\n",
    "# f_regression(a[:, None], b), f_regression(a[:, None], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прогнозирование**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "window_sizes_for_clustering = 10\n",
    "# X, y = dataset[:-window_sizes_for_clustering, ...], dataset[window_sizes_for_clustering:, ...]\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "n_split = round(0.2 * dataset.shape[0])\n",
    "dataset_train, dataset_test = dataset[:-n_split, ...], dataset[-n_split:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((326477, 65), (81619, 65))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes_for_clustering = [5, 10, 15] #1, 3\n",
    "Ns_clusters = [7, 9, 11] #2, 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns_clusters = [11]\n",
    "# window_sizes_for_clustering = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_windows.shape=(326472, 5, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=396, result_data[0].shape=(6, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "FAIL - test_X.shape=(1, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(2, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=232, result_data[0].shape=(261, 65)\n",
      "Before prediction: train_X.shape=(151, 10, 65), train_y.shape=(151, 65), test_X.shape=(50, 10, 65), test_y.shape=(50, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.3912 - val_loss: 0.3267\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3902 - val_loss: 0.3261\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3892 - val_loss: 0.3255\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3883 - val_loss: 0.3249\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3874 - val_loss: 0.3244\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3865 - val_loss: 0.3238\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3856 - val_loss: 0.3233\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.3848 - val_loss: 0.3227\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3839 - val_loss: 0.3222\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.3831 - val_loss: 0.3216\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.3823 - val_loss: 0.3211\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3815 - val_loss: 0.3206\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.3807 - val_loss: 0.3201\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.3799 - val_loss: 0.3196\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.3791 - val_loss: 0.3191\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.3783 - val_loss: 0.3186\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.3776 - val_loss: 0.3181\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3768 - val_loss: 0.3176\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3761 - val_loss: 0.3171\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3754 - val_loss: 0.3167\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=31, result_data[0].shape=(68, 65)\n",
      "Before prediction: train_X.shape=(35, 10, 65), train_y.shape=(35, 65), test_X.shape=(12, 10, 65), test_y.shape=(12, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5615 - val_loss: 0.4720\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5597 - val_loss: 0.4713\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5579 - val_loss: 0.4707\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5562 - val_loss: 0.4700\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5544 - val_loss: 0.4694\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5527 - val_loss: 0.4688\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5510 - val_loss: 0.4682\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5493 - val_loss: 0.4675\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5476 - val_loss: 0.4669\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5459 - val_loss: 0.4663\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5443 - val_loss: 0.4657\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5427 - val_loss: 0.4651\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5410 - val_loss: 0.4645\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5395 - val_loss: 0.4639\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5379 - val_loss: 0.4632\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5364 - val_loss: 0.4626\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5349 - val_loss: 0.4620\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5334 - val_loss: 0.4614\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5319 - val_loss: 0.4608\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5305 - val_loss: 0.4602\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=54, result_data[0].shape=(306, 65)\n",
      "Before prediction: train_X.shape=(178, 10, 65), train_y.shape=(178, 65), test_X.shape=(59, 10, 65), test_y.shape=(59, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7199 - val_loss: 0.5737\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7183 - val_loss: 0.5729\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7168 - val_loss: 0.5721\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7154 - val_loss: 0.5713\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7140 - val_loss: 0.5706\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7126 - val_loss: 0.5698\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7113 - val_loss: 0.5691\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7100 - val_loss: 0.5684\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7088 - val_loss: 0.5677\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7075 - val_loss: 0.5670\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7064 - val_loss: 0.5663\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7052 - val_loss: 0.5657\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7041 - val_loss: 0.5650\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7029 - val_loss: 0.5644\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.7018 - val_loss: 0.5638\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.7007 - val_loss: 0.5632\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6997 - val_loss: 0.5626\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.6986 - val_loss: 0.5620\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6975 - val_loss: 0.5614\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6965 - val_loss: 0.5608\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=134, result_data[0].shape=(145, 65)\n",
      "Before prediction: train_X.shape=(81, 10, 65), train_y.shape=(81, 65), test_X.shape=(27, 10, 65), test_y.shape=(27, 65)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4035 - val_loss: 0.4929\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4026 - val_loss: 0.4923\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4018 - val_loss: 0.4917\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4010 - val_loss: 0.4911\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4003 - val_loss: 0.4906\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3995 - val_loss: 0.4901\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3988 - val_loss: 0.4895\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3981 - val_loss: 0.4890\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3975 - val_loss: 0.4886\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3968 - val_loss: 0.4881\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3962 - val_loss: 0.4877\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3956 - val_loss: 0.4872\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3950 - val_loss: 0.4868\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3944 - val_loss: 0.4864\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3938 - val_loss: 0.4860\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3932 - val_loss: 0.4856\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3926 - val_loss: 0.4852\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3921 - val_loss: 0.4848\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3916 - val_loss: 0.4844\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3910 - val_loss: 0.4840\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(9935, 65)\n",
      "Before prediction: train_X.shape=(5955, 10, 65), train_y.shape=(5955, 65), test_X.shape=(1985, 10, 65), test_y.shape=(1985, 65)\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0691 - val_loss: 0.0469\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0631 - val_loss: 0.0436\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0596 - val_loss: 0.0414\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0571 - val_loss: 0.0396\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0551 - val_loss: 0.0381\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0534 - val_loss: 0.0368\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0520 - val_loss: 0.0357\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0508 - val_loss: 0.0348\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0499 - val_loss: 0.0340\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0490 - val_loss: 0.0333\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0482 - val_loss: 0.0327\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0476 - val_loss: 0.0322\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0470 - val_loss: 0.0318\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0465 - val_loss: 0.0314\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0460 - val_loss: 0.0310\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0456 - val_loss: 0.0307\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0452 - val_loss: 0.0304\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0448 - val_loss: 0.0301\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0298\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0442 - val_loss: 0.0296\n",
      "63/63 [==============================] - 1s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=521, result_data[0].shape=(11, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(1, 10, 65)\n",
      "dataset_windows.shape=(326472, 5, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=3, result_data[0].shape=(46, 65)\n",
      "Before prediction: train_X.shape=(22, 10, 65), train_y.shape=(22, 65), test_X.shape=(7, 10, 65), test_y.shape=(7, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7555 - val_loss: 0.4138\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7533 - val_loss: 0.4128\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7512 - val_loss: 0.4118\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7490 - val_loss: 0.4109\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7469 - val_loss: 0.4100\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7449 - val_loss: 0.4091\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7428 - val_loss: 0.4081\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7408 - val_loss: 0.4072\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7388 - val_loss: 0.4063\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7368 - val_loss: 0.4054\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7349 - val_loss: 0.4045\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7330 - val_loss: 0.4037\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7311 - val_loss: 0.4028\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7292 - val_loss: 0.4019\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7274 - val_loss: 0.4010\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7255 - val_loss: 0.4001\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7237 - val_loss: 0.3993\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7219 - val_loss: 0.3984\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7202 - val_loss: 0.3975\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7184 - val_loss: 0.3966\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=199, result_data[0].shape=(170, 65)\n",
      "Before prediction: train_X.shape=(96, 10, 65), train_y.shape=(96, 65), test_X.shape=(32, 10, 65), test_y.shape=(32, 65)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.3782 - val_loss: 0.3492\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3774 - val_loss: 0.3488\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3767 - val_loss: 0.3485\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3761 - val_loss: 0.3482\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3754 - val_loss: 0.3479\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3747 - val_loss: 0.3475\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3741 - val_loss: 0.3472\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3734 - val_loss: 0.3469\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3728 - val_loss: 0.3466\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3722 - val_loss: 0.3463\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3716 - val_loss: 0.3460\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3710 - val_loss: 0.3457\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3704 - val_loss: 0.3454\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3698 - val_loss: 0.3452\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3692 - val_loss: 0.3449\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3687 - val_loss: 0.3446\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3681 - val_loss: 0.3443\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3676 - val_loss: 0.3440\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3670 - val_loss: 0.3438\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3665 - val_loss: 0.3435\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=11, result_data[0].shape=(3247, 65)\n",
      "Before prediction: train_X.shape=(1942, 10, 65), train_y.shape=(1942, 65), test_X.shape=(647, 10, 65), test_y.shape=(647, 65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1181 - val_loss: 0.0937\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1124 - val_loss: 0.0919\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1079 - val_loss: 0.0906\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.1041 - val_loss: 0.0895\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.1007 - val_loss: 0.0886\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0978 - val_loss: 0.0880\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0953 - val_loss: 0.0874\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0930 - val_loss: 0.0870\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0910 - val_loss: 0.0866\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0891 - val_loss: 0.0862\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0874 - val_loss: 0.0860\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0859 - val_loss: 0.0858\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0845 - val_loss: 0.0855\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0832 - val_loss: 0.0853\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0820 - val_loss: 0.0851\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0808 - val_loss: 0.0849\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0798 - val_loss: 0.0847\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0788 - val_loss: 0.0845\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0779 - val_loss: 0.0843\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0770 - val_loss: 0.0841\n",
      "21/21 [==============================] - 0s 15ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=37, result_data[0].shape=(24, 65)\n",
      "Before prediction: train_X.shape=(8, 10, 65), train_y.shape=(8, 65), test_X.shape=(3, 10, 65), test_y.shape=(3, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4672 - val_loss: 0.4840\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4647 - val_loss: 0.4824\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4623 - val_loss: 0.4807\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4599 - val_loss: 0.4791\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4576 - val_loss: 0.4775\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4554 - val_loss: 0.4758\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4532 - val_loss: 0.4743\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4510 - val_loss: 0.4727\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4489 - val_loss: 0.4712\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4468 - val_loss: 0.4697\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4448 - val_loss: 0.4682\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4428 - val_loss: 0.4667\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4408 - val_loss: 0.4653\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4389 - val_loss: 0.4638\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4370 - val_loss: 0.4624\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4352 - val_loss: 0.4611\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4334 - val_loss: 0.4598\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4316 - val_loss: 0.4585\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4299 - val_loss: 0.4573\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4281 - val_loss: 0.4562\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=463, result_data[0].shape=(5, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=515, result_data[0].shape=(13, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "FAIL - test_X.shape=(1, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(2, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=172, result_data[0].shape=(156, 65)\n",
      "Before prediction: train_X.shape=(88, 10, 65), train_y.shape=(88, 65), test_X.shape=(29, 10, 65), test_y.shape=(29, 65)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.4425 - val_loss: 0.5346\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4416 - val_loss: 0.5341\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4408 - val_loss: 0.5337\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4400 - val_loss: 0.5332\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4391 - val_loss: 0.5328\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4384 - val_loss: 0.5323\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4376 - val_loss: 0.5319\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4369 - val_loss: 0.5315\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4362 - val_loss: 0.5310\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4354 - val_loss: 0.5306\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4347 - val_loss: 0.5302\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4341 - val_loss: 0.5298\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4334 - val_loss: 0.5294\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4328 - val_loss: 0.5291\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4322 - val_loss: 0.5287\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4315 - val_loss: 0.5283\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4309 - val_loss: 0.5279\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4303 - val_loss: 0.5276\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4297 - val_loss: 0.5272\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4292 - val_loss: 0.5269\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=40, result_data[0].shape=(299, 65)\n",
      "Before prediction: train_X.shape=(173, 10, 65), train_y.shape=(173, 65), test_X.shape=(58, 10, 65), test_y.shape=(58, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7509 - val_loss: 0.5994\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7496 - val_loss: 0.5989\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7483 - val_loss: 0.5985\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7472 - val_loss: 0.5980\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7459 - val_loss: 0.5976\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7448 - val_loss: 0.5971\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7436 - val_loss: 0.5967\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.7425 - val_loss: 0.5963\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7414 - val_loss: 0.5958\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7403 - val_loss: 0.5954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7392 - val_loss: 0.5950\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7382 - val_loss: 0.5946\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7372 - val_loss: 0.5941\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7361 - val_loss: 0.5937\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7351 - val_loss: 0.5933\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7341 - val_loss: 0.5929\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7331 - val_loss: 0.5925\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7322 - val_loss: 0.5921\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7312 - val_loss: 0.5917\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7303 - val_loss: 0.5913\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=252, result_data[0].shape=(5, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6794 - val_loss: 0.4281\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6772 - val_loss: 0.4270\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6751 - val_loss: 0.4260\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6730 - val_loss: 0.4249\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6709 - val_loss: 0.4240\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6688 - val_loss: 0.4230\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6667 - val_loss: 0.4220\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6646 - val_loss: 0.4211\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6626 - val_loss: 0.4201\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6605 - val_loss: 0.4192\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6585 - val_loss: 0.4183\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6565 - val_loss: 0.4174\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6545 - val_loss: 0.4166\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6525 - val_loss: 0.4158\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6505 - val_loss: 0.4150\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6485 - val_loss: 0.4142\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6466 - val_loss: 0.4133\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6447 - val_loss: 0.4125\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6428 - val_loss: 0.4117\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6410 - val_loss: 0.4109\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "dataset_windows.shape=(326472, 5, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=595, result_data[0].shape=(4, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "FAIL - test_X.shape=(1, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(2, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=576, result_data[0].shape=(9, 65)\n",
      "Before prediction: train_X.shape=(5, 10, 65), train_y.shape=(5, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9897 - val_loss: 9.1949\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9868 - val_loss: 9.1953\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9838Restoring model weights from the end of the best epoch: 1.\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9838 - val_loss: 9.1956\n",
      "Epoch 3: early stopping\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=186, result_data[0].shape=(4, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(1, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(9935, 65)\n",
      "Before prediction: train_X.shape=(5955, 10, 65), train_y.shape=(5955, 65), test_X.shape=(1985, 10, 65), test_y.shape=(1985, 65)\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0684 - val_loss: 0.0462\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0624 - val_loss: 0.0428\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0590 - val_loss: 0.0406\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0564 - val_loss: 0.0388\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0544 - val_loss: 0.0375\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0527 - val_loss: 0.0364\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0514 - val_loss: 0.0354\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0503 - val_loss: 0.0346\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0493 - val_loss: 0.0338\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0485 - val_loss: 0.0331\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0478 - val_loss: 0.0325\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0471 - val_loss: 0.0319\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0466 - val_loss: 0.0314\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0461 - val_loss: 0.0310\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0456 - val_loss: 0.0306\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0452 - val_loss: 0.0303\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0448 - val_loss: 0.0300\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0445 - val_loss: 0.0298\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0442 - val_loss: 0.0295\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0439 - val_loss: 0.0293\n",
      "63/63 [==============================] - 1s 14ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=366, result_data[0].shape=(14, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3717 - val_loss: 0.3211\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3697 - val_loss: 0.3211\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3678Restoring model weights from the end of the best epoch: 1.\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3678 - val_loss: 0.3211\n",
      "Epoch 3: early stopping\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=30, result_data[0].shape=(27, 65)\n",
      "Before prediction: train_X.shape=(10, 10, 65), train_y.shape=(10, 65), test_X.shape=(3, 10, 65), test_y.shape=(3, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4068 - val_loss: 0.4141\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4061 - val_loss: 0.4141\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4054 - val_loss: 0.4140\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4048 - val_loss: 0.4139\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4041 - val_loss: 0.4139\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4035 - val_loss: 0.4138\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4028 - val_loss: 0.4137\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4022 - val_loss: 0.4137\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4015 - val_loss: 0.4136\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4009 - val_loss: 0.4136\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4003 - val_loss: 0.4135\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3997 - val_loss: 0.4134\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3991 - val_loss: 0.4134\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3984 - val_loss: 0.4133\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3978 - val_loss: 0.4133\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3972 - val_loss: 0.4132\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3966 - val_loss: 0.4132\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3961 - val_loss: 0.4131\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3955 - val_loss: 0.4131\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3949 - val_loss: 0.4130\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=77, result_data[0].shape=(309, 65)\n",
      "Before prediction: train_X.shape=(179, 10, 65), train_y.shape=(179, 65), test_X.shape=(60, 10, 65), test_y.shape=(60, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7420 - val_loss: 0.6000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7405 - val_loss: 0.5994\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7392 - val_loss: 0.5988\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7380 - val_loss: 0.5982\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7367 - val_loss: 0.5976\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7354 - val_loss: 0.5970\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7343 - val_loss: 0.5964\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7330 - val_loss: 0.5959\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7319 - val_loss: 0.5953\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7307 - val_loss: 0.5948\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7296 - val_loss: 0.5942\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7284 - val_loss: 0.5937\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7273 - val_loss: 0.5931\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7262 - val_loss: 0.5926\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7251 - val_loss: 0.5921\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7241 - val_loss: 0.5916\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.7230 - val_loss: 0.5911\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7220 - val_loss: 0.5906\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.7210 - val_loss: 0.5901\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7199 - val_loss: 0.5897\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=33, result_data[0].shape=(26, 65)\n",
      "Before prediction: train_X.shape=(10, 10, 65), train_y.shape=(10, 65), test_X.shape=(3, 10, 65), test_y.shape=(3, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4410 - val_loss: 0.5220\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4385 - val_loss: 0.5202\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4360 - val_loss: 0.5185\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4336 - val_loss: 0.5168\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4312 - val_loss: 0.5151\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4289 - val_loss: 0.5135\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4266 - val_loss: 0.5119\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4243 - val_loss: 0.5103\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4222 - val_loss: 0.5087\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4200 - val_loss: 0.5072\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4179 - val_loss: 0.5056\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4159 - val_loss: 0.5041\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4139 - val_loss: 0.5027\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4119 - val_loss: 0.5013\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4099 - val_loss: 0.4999\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4080 - val_loss: 0.4986\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4061 - val_loss: 0.4972\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4042 - val_loss: 0.4959\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4023 - val_loss: 0.4946\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4005 - val_loss: 0.4933\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=144, result_data[0].shape=(141, 65)\n",
      "Before prediction: train_X.shape=(79, 10, 65), train_y.shape=(79, 65), test_X.shape=(26, 10, 65), test_y.shape=(26, 65)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3802 - val_loss: 0.4673\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3795 - val_loss: 0.4668\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3789 - val_loss: 0.4664\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3783 - val_loss: 0.4659\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3777 - val_loss: 0.4655\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3771 - val_loss: 0.4651\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3765 - val_loss: 0.4647\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3760 - val_loss: 0.4643\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3754 - val_loss: 0.4639\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3749 - val_loss: 0.4635\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3743 - val_loss: 0.4631\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3738 - val_loss: 0.4627\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3733 - val_loss: 0.4623\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3728 - val_loss: 0.4620\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3723 - val_loss: 0.4616\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3718 - val_loss: 0.4612\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3713 - val_loss: 0.4608\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3708 - val_loss: 0.4605\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3703 - val_loss: 0.4601\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3699 - val_loss: 0.4597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=354, result_data[0].shape=(5, 65)\n",
      "Before prediction: train_X.shape=(18, 10, 65), train_y.shape=(18, 65), test_X.shape=(6, 10, 65), test_y.shape=(6, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3524 - val_loss: 0.3734\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3519 - val_loss: 0.3733\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3515 - val_loss: 0.3732\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3511 - val_loss: 0.3731\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3507 - val_loss: 0.3730\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3502 - val_loss: 0.3729\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3498 - val_loss: 0.3728\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3494 - val_loss: 0.3727\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3490 - val_loss: 0.3726\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3486 - val_loss: 0.3725\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3482 - val_loss: 0.3724\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3478 - val_loss: 0.3723\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3474 - val_loss: 0.3722\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3470 - val_loss: 0.3721\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3466 - val_loss: 0.3720\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3463 - val_loss: 0.3719\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3459 - val_loss: 0.3718\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3455 - val_loss: 0.3717\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3451 - val_loss: 0.3717\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3448 - val_loss: 0.3716\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=152, result_data[0].shape=(6, 65)\n",
      "Before prediction: train_X.shape=(11, 10, 65), train_y.shape=(11, 65), test_X.shape=(4, 10, 65), test_y.shape=(4, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2340 - val_loss: 0.3816\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2334 - val_loss: 0.3815\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2329 - val_loss: 0.3814\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2323 - val_loss: 0.3813\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2318 - val_loss: 0.3812\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2312 - val_loss: 0.3811\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2307 - val_loss: 0.3810\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2302 - val_loss: 0.3809\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2297 - val_loss: 0.3808\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2292 - val_loss: 0.3808\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2287 - val_loss: 0.3807\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2282 - val_loss: 0.3807\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2277 - val_loss: 0.3806\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2272 - val_loss: 0.3806\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2267 - val_loss: 0.3805\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2263 - val_loss: 0.3805\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2258 - val_loss: 0.3805\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2253 - val_loss: 0.3804\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2249 - val_loss: 0.3804\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2244 - val_loss: 0.3804\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "dataset_windows.shape=(326467, 10, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=42, result_data[0].shape=(308, 65)\n",
      "Before prediction: train_X.shape=(179, 10, 65), train_y.shape=(179, 65), test_X.shape=(60, 10, 65), test_y.shape=(60, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.7061 - val_loss: 0.5577\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7047 - val_loss: 0.5571\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7033 - val_loss: 0.5565\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7020 - val_loss: 0.5559\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7007 - val_loss: 0.5553\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6994 - val_loss: 0.5547\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6982 - val_loss: 0.5541\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6970 - val_loss: 0.5536\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6958 - val_loss: 0.5530\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6946 - val_loss: 0.5524\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6934 - val_loss: 0.5519\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5514\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6911 - val_loss: 0.5508\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6899 - val_loss: 0.5503\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6888 - val_loss: 0.5498\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6877 - val_loss: 0.5492\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6866 - val_loss: 0.5487\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6856 - val_loss: 0.5482\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6845 - val_loss: 0.5477\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6834 - val_loss: 0.5471\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=9, result_data[0].shape=(9940, 65)\n",
      "Before prediction: train_X.shape=(5958, 10, 65), train_y.shape=(5958, 65), test_X.shape=(1986, 10, 65), test_y.shape=(1986, 65)\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0702 - val_loss: 0.0486\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0644 - val_loss: 0.0454\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0611 - val_loss: 0.0432\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0586 - val_loss: 0.0414\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0566 - val_loss: 0.0399\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0549 - val_loss: 0.0385\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0535 - val_loss: 0.0373\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0523 - val_loss: 0.0363\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0513 - val_loss: 0.0354\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0504 - val_loss: 0.0346\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0496 - val_loss: 0.0340\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0489 - val_loss: 0.0334\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0483 - val_loss: 0.0329\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0478 - val_loss: 0.0324\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0474 - val_loss: 0.0320\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0469 - val_loss: 0.0316\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0465 - val_loss: 0.0313\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0462 - val_loss: 0.0310\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0459 - val_loss: 0.0307\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0456 - val_loss: 0.0305\n",
      "63/63 [==============================] - 1s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=299, result_data[0].shape=(11, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=102, result_data[0].shape=(150, 65)\n",
      "Before prediction: train_X.shape=(84, 10, 65), train_y.shape=(84, 65), test_X.shape=(28, 10, 65), test_y.shape=(28, 65)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.4007 - val_loss: 0.4933\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4000 - val_loss: 0.4929\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3993 - val_loss: 0.4926\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3985 - val_loss: 0.4922\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3979 - val_loss: 0.4919\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3972 - val_loss: 0.4915\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3966 - val_loss: 0.4912\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3960 - val_loss: 0.4908\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3953 - val_loss: 0.4905\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3947 - val_loss: 0.4902\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3941 - val_loss: 0.4899\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3936 - val_loss: 0.4895\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3930 - val_loss: 0.4892\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3924 - val_loss: 0.4889\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3919 - val_loss: 0.4886\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3913 - val_loss: 0.4883\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3908 - val_loss: 0.4880\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3903 - val_loss: 0.4878\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3898 - val_loss: 0.4875\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3893 - val_loss: 0.4872\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=25, result_data[0].shape=(75, 65)\n",
      "Before prediction: train_X.shape=(39, 10, 65), train_y.shape=(39, 65), test_X.shape=(13, 10, 65), test_y.shape=(13, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5618 - val_loss: 0.4940\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5596 - val_loss: 0.4928\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5575 - val_loss: 0.4916\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5554 - val_loss: 0.4904\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5533 - val_loss: 0.4892\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5513 - val_loss: 0.4881\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5493 - val_loss: 0.4869\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5472 - val_loss: 0.4858\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5452 - val_loss: 0.4847\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5433 - val_loss: 0.4836\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5413 - val_loss: 0.4826\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5394 - val_loss: 0.4815\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5375 - val_loss: 0.4805\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5356 - val_loss: 0.4795\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5337 - val_loss: 0.4786\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5319 - val_loss: 0.4776\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5300 - val_loss: 0.4767\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5282 - val_loss: 0.4757\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5264 - val_loss: 0.4748\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5247 - val_loss: 0.4739\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=409, result_data[0].shape=(16, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6384 - val_loss: 0.3691\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6358 - val_loss: 0.3675\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6331 - val_loss: 0.3660\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6305 - val_loss: 0.3644\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6279 - val_loss: 0.3628\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6253 - val_loss: 0.3612\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6227 - val_loss: 0.3597\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6201 - val_loss: 0.3581\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6175 - val_loss: 0.3565\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6151 - val_loss: 0.3549\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6126 - val_loss: 0.3533\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6101 - val_loss: 0.3517\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6076 - val_loss: 0.3501\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6052 - val_loss: 0.3486\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6028 - val_loss: 0.3471\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6004 - val_loss: 0.3456\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5981 - val_loss: 0.3441\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5958 - val_loss: 0.3427\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5935 - val_loss: 0.3413\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5913 - val_loss: 0.3401\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=189, result_data[0].shape=(263, 65)\n",
      "Before prediction: train_X.shape=(152, 10, 65), train_y.shape=(152, 65), test_X.shape=(51, 10, 65), test_y.shape=(51, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.3731 - val_loss: 0.3146\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3723 - val_loss: 0.3140\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3715 - val_loss: 0.3135\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3707 - val_loss: 0.3129\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3699 - val_loss: 0.3124\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3692 - val_loss: 0.3118\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3685 - val_loss: 0.3113\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3678 - val_loss: 0.3108\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3671 - val_loss: 0.3103\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3664 - val_loss: 0.3098\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3658 - val_loss: 0.3094\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3651 - val_loss: 0.3089\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3644 - val_loss: 0.3084\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3638 - val_loss: 0.3080\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3631 - val_loss: 0.3075\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3625 - val_loss: 0.3070\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3619 - val_loss: 0.3066\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3613 - val_loss: 0.3062\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3607 - val_loss: 0.3057\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3601 - val_loss: 0.3053\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "dataset_windows.shape=(326467, 10, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=27, result_data[0].shape=(74, 65)\n",
      "Before prediction: train_X.shape=(38, 10, 65), train_y.shape=(38, 65), test_X.shape=(13, 10, 65), test_y.shape=(13, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5278 - val_loss: 0.4820\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5259 - val_loss: 0.4810\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5240 - val_loss: 0.4801\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5222 - val_loss: 0.4791\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5203 - val_loss: 0.4782\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5185 - val_loss: 0.4773\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5167 - val_loss: 0.4765\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5149 - val_loss: 0.4756\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5132 - val_loss: 0.4747\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5114 - val_loss: 0.4739\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5097 - val_loss: 0.4730\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5080 - val_loss: 0.4722\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5064 - val_loss: 0.4714\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5047 - val_loss: 0.4705\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5031 - val_loss: 0.4697\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5015 - val_loss: 0.4689\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4999 - val_loss: 0.4681\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4983 - val_loss: 0.4673\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4967 - val_loss: 0.4666\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.4658\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=230, result_data[0].shape=(11, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=399, result_data[0].shape=(17, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5591 - val_loss: 0.3680\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5564 - val_loss: 0.3670\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5538 - val_loss: 0.3660\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5512 - val_loss: 0.3650\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5487 - val_loss: 0.3640\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5462 - val_loss: 0.3632\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5437 - val_loss: 0.3624\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5413 - val_loss: 0.3616\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5389 - val_loss: 0.3607\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5365 - val_loss: 0.3599\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5341 - val_loss: 0.3591\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5317 - val_loss: 0.3584\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5293 - val_loss: 0.3577\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5269 - val_loss: 0.3571\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5246 - val_loss: 0.3564\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5222 - val_loss: 0.3557\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5199 - val_loss: 0.3550\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5175 - val_loss: 0.3544\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5152 - val_loss: 0.3537\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5130 - val_loss: 0.3530\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=31, result_data[0].shape=(302, 65)\n",
      "Before prediction: train_X.shape=(175, 10, 65), train_y.shape=(175, 65), test_X.shape=(58, 10, 65), test_y.shape=(58, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7254 - val_loss: 0.5843\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7240 - val_loss: 0.5835\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7227 - val_loss: 0.5826\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7214 - val_loss: 0.5818\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7201 - val_loss: 0.5810\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7189 - val_loss: 0.5803\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7177 - val_loss: 0.5795\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7165 - val_loss: 0.5787\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7153 - val_loss: 0.5780\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7141 - val_loss: 0.5772\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7130 - val_loss: 0.5765\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7119 - val_loss: 0.5757\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7107 - val_loss: 0.5750\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7097 - val_loss: 0.5743\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7086 - val_loss: 0.5736\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7075 - val_loss: 0.5729\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.7065 - val_loss: 0.5723\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7054 - val_loss: 0.5716\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.7044 - val_loss: 0.5710\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7034 - val_loss: 0.5704\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=1, result_data[0].shape=(2622, 65)\n",
      "Before prediction: train_X.shape=(1567, 10, 65), train_y.shape=(1567, 65), test_X.shape=(522, 10, 65), test_y.shape=(522, 65)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2452 - val_loss: 0.2832\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2339 - val_loss: 0.2728\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2256 - val_loss: 0.2650\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2191 - val_loss: 0.2587\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2139 - val_loss: 0.2533\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.2094 - val_loss: 0.2487\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.2055 - val_loss: 0.2446\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2020 - val_loss: 0.2408\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1989 - val_loss: 0.2373\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1959 - val_loss: 0.2341\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1932 - val_loss: 0.2311\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.1906 - val_loss: 0.2284\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.1882 - val_loss: 0.2258\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.1860 - val_loss: 0.2234\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1839 - val_loss: 0.2212\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1819 - val_loss: 0.2191\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1801 - val_loss: 0.2172\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1784 - val_loss: 0.2154\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1769 - val_loss: 0.2138\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.1756 - val_loss: 0.2123\n",
      "17/17 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(3251, 65)\n",
      "Before prediction: train_X.shape=(1945, 10, 65), train_y.shape=(1945, 65), test_X.shape=(648, 10, 65), test_y.shape=(648, 65)\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1185 - val_loss: 0.0931\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1130 - val_loss: 0.0911\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1086 - val_loss: 0.0899\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.1049 - val_loss: 0.0889\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.1017 - val_loss: 0.0881\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0989 - val_loss: 0.0875\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0965 - val_loss: 0.0870\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0944 - val_loss: 0.0866\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0924 - val_loss: 0.0862\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0907 - val_loss: 0.0860\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0891 - val_loss: 0.0857\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0876 - val_loss: 0.0855\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0863 - val_loss: 0.0852\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0851 - val_loss: 0.0850\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0839 - val_loss: 0.0848\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0829 - val_loss: 0.0847\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0819 - val_loss: 0.0845\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0809 - val_loss: 0.0844\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0800 - val_loss: 0.0843\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0792 - val_loss: 0.0842\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=157, result_data[0].shape=(261, 65)\n",
      "Before prediction: train_X.shape=(151, 10, 65), train_y.shape=(151, 65), test_X.shape=(50, 10, 65), test_y.shape=(50, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3387 - val_loss: 0.2844\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.3377 - val_loss: 0.2838\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.3369 - val_loss: 0.2832\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3360 - val_loss: 0.2827\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3352 - val_loss: 0.2821\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3344 - val_loss: 0.2816\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3336 - val_loss: 0.2810\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3328 - val_loss: 0.2805\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3320 - val_loss: 0.2800\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3312 - val_loss: 0.2795\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3305 - val_loss: 0.2791\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3298 - val_loss: 0.2786\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3290 - val_loss: 0.2781\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3283 - val_loss: 0.2777\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3276 - val_loss: 0.2772\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3269 - val_loss: 0.2768\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3263 - val_loss: 0.2763\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3256 - val_loss: 0.2759\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3249 - val_loss: 0.2755\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3243 - val_loss: 0.2750\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=114, result_data[0].shape=(160, 65)\n",
      "Before prediction: train_X.shape=(90, 10, 65), train_y.shape=(90, 65), test_X.shape=(30, 10, 65), test_y.shape=(30, 65)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4100 - val_loss: 0.4843\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4090 - val_loss: 0.4839\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4081 - val_loss: 0.4835\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4072 - val_loss: 0.4831\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4063 - val_loss: 0.4827\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4055 - val_loss: 0.4824\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4047 - val_loss: 0.4820\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4039 - val_loss: 0.4817\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4031 - val_loss: 0.4813\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4023 - val_loss: 0.4810\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4016 - val_loss: 0.4807\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4009 - val_loss: 0.4804\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4002 - val_loss: 0.4801\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3995 - val_loss: 0.4798\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3988 - val_loss: 0.4795\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3982 - val_loss: 0.4792\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3975 - val_loss: 0.4789\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3969 - val_loss: 0.4787\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3963 - val_loss: 0.4784\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3957 - val_loss: 0.4781\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=411, result_data[0].shape=(10, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "FAIL - test_X.shape=(1, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(2, 10, 65)\n",
      "dataset_windows.shape=(326467, 10, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=82, result_data[0].shape=(18, 65)\n",
      "Before prediction: train_X.shape=(5, 10, 65), train_y.shape=(5, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4485 - val_loss: 0.5334\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4473 - val_loss: 0.5329\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4461 - val_loss: 0.5324\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4450 - val_loss: 0.5319\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4439 - val_loss: 0.5315\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4427 - val_loss: 0.5310\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4416 - val_loss: 0.5306\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4406 - val_loss: 0.5302\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4395 - val_loss: 0.5298\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4384 - val_loss: 0.5294\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4374 - val_loss: 0.5290\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4363 - val_loss: 0.5285\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4353 - val_loss: 0.5281\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4342 - val_loss: 0.5277\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4332 - val_loss: 0.5273\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4322 - val_loss: 0.5269\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4312 - val_loss: 0.5265\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4301 - val_loss: 0.5261\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4291 - val_loss: 0.5257\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4281 - val_loss: 0.5254\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=534, result_data[0].shape=(9, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=1, result_data[0].shape=(2622, 65)\n",
      "Before prediction: train_X.shape=(1567, 10, 65), train_y.shape=(1567, 65), test_X.shape=(522, 10, 65), test_y.shape=(522, 65)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.2462 - val_loss: 0.2876\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2366 - val_loss: 0.2782\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2289 - val_loss: 0.2706\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2227 - val_loss: 0.2640\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2174 - val_loss: 0.2584\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.2128 - val_loss: 0.2534\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.2087 - val_loss: 0.2490\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2051 - val_loss: 0.2448\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2017 - val_loss: 0.2411\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1986 - val_loss: 0.2376\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1957 - val_loss: 0.2343\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1930 - val_loss: 0.2313\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1905 - val_loss: 0.2285\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.1882 - val_loss: 0.2259\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1859 - val_loss: 0.2234\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1839 - val_loss: 0.2211\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1819 - val_loss: 0.2189\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1801 - val_loss: 0.2170\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1784 - val_loss: 0.2151\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1768 - val_loss: 0.2134\n",
      "17/17 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(3251, 65)\n",
      "Before prediction: train_X.shape=(1945, 10, 65), train_y.shape=(1945, 65), test_X.shape=(648, 10, 65), test_y.shape=(648, 65)\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1179 - val_loss: 0.0924\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1127 - val_loss: 0.0906\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1084 - val_loss: 0.0894\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.1049 - val_loss: 0.0884\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.1018 - val_loss: 0.0877\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0991 - val_loss: 0.0872\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0967 - val_loss: 0.0867\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0945 - val_loss: 0.0863\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0925 - val_loss: 0.0859\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0908 - val_loss: 0.0857\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0891 - val_loss: 0.0854\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0876 - val_loss: 0.0851\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0862 - val_loss: 0.0849\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0849 - val_loss: 0.0846\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 41ms/step - loss: 0.0837 - val_loss: 0.0845\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0826 - val_loss: 0.0843\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0816 - val_loss: 0.0841\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0806 - val_loss: 0.0839\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0797 - val_loss: 0.0838\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0789 - val_loss: 0.0836\n",
      "21/21 [==============================] - 0s 13ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=30, result_data[0].shape=(36, 65)\n",
      "Before prediction: train_X.shape=(16, 10, 65), train_y.shape=(16, 65), test_X.shape=(5, 10, 65), test_y.shape=(5, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5331 - val_loss: 0.7597\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5324 - val_loss: 0.7595\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5317 - val_loss: 0.7593\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5311 - val_loss: 0.7591\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5304 - val_loss: 0.7589\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5298 - val_loss: 0.7588\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5291 - val_loss: 0.7586\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5285 - val_loss: 0.7584\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5278 - val_loss: 0.7583\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5272 - val_loss: 0.7581\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5266 - val_loss: 0.7580\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5259 - val_loss: 0.7578\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5253 - val_loss: 0.7577\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5247 - val_loss: 0.7575\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5241 - val_loss: 0.7574\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5235 - val_loss: 0.7572\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5229 - val_loss: 0.7571\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5223 - val_loss: 0.7569\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5217 - val_loss: 0.7568\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5211 - val_loss: 0.7567\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=28, result_data[0].shape=(31, 65)\n",
      "Before prediction: train_X.shape=(13, 10, 65), train_y.shape=(13, 65), test_X.shape=(4, 10, 65), test_y.shape=(4, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4595 - val_loss: 0.6494\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4571 - val_loss: 0.6476\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4547 - val_loss: 0.6457\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4524 - val_loss: 0.6439\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4501 - val_loss: 0.6422\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4479 - val_loss: 0.6405\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4456 - val_loss: 0.6388\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4435 - val_loss: 0.6371\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4413 - val_loss: 0.6356\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4392 - val_loss: 0.6340\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4371 - val_loss: 0.6325\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4351 - val_loss: 0.6310\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4331 - val_loss: 0.6296\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4311 - val_loss: 0.6282\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4292 - val_loss: 0.6268\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4273 - val_loss: 0.6255\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4254 - val_loss: 0.6241\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4236 - val_loss: 0.6229\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4218 - val_loss: 0.6216\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4200 - val_loss: 0.6204\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=86, result_data[0].shape=(15, 65)\n",
      "Before prediction: train_X.shape=(3, 10, 65), train_y.shape=(3, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1452 - val_loss: 0.1712\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1445 - val_loss: 0.1710\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1439 - val_loss: 0.1709\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1432 - val_loss: 0.1708\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1425 - val_loss: 0.1706\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1418 - val_loss: 0.1705\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1412 - val_loss: 0.1704\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1406 - val_loss: 0.1703\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1400 - val_loss: 0.1702\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1394 - val_loss: 0.1701\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1389 - val_loss: 0.1700\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1384 - val_loss: 0.1700\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1378 - val_loss: 0.1699\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1374 - val_loss: 0.1699\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1369 - val_loss: 0.1699\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1364 - val_loss: 0.1699\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1359 - val_loss: 0.1699\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1354 - val_loss: 0.1699\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1349Restoring model weights from the end of the best epoch: 17.\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1349 - val_loss: 0.1699\n",
      "Epoch 19: early stopping\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=240, result_data[0].shape=(30, 65)\n",
      "Before prediction: train_X.shape=(12, 10, 65), train_y.shape=(12, 65), test_X.shape=(4, 10, 65), test_y.shape=(4, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3309 - val_loss: 0.4102\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3302 - val_loss: 0.4100\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3295 - val_loss: 0.4098\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3288 - val_loss: 0.4096\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3280 - val_loss: 0.4095\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3273 - val_loss: 0.4093\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3266 - val_loss: 0.4091\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3259 - val_loss: 0.4089\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3252 - val_loss: 0.4088\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3245 - val_loss: 0.4086\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3238 - val_loss: 0.4084\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3231 - val_loss: 0.4082\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3225 - val_loss: 0.4081\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3218 - val_loss: 0.4079\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3212 - val_loss: 0.4077\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3205 - val_loss: 0.4075\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3199 - val_loss: 0.4074\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3193 - val_loss: 0.4072\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3187 - val_loss: 0.4070\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3181 - val_loss: 0.4069\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=304, result_data[0].shape=(10, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=470, result_data[0].shape=(14, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5953 - val_loss: 0.4601\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5920 - val_loss: 0.4575\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5887 - val_loss: 0.4552\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5855 - val_loss: 0.4529\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5823 - val_loss: 0.4506\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5791 - val_loss: 0.4483\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5760 - val_loss: 0.4460\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5729 - val_loss: 0.4439\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5699 - val_loss: 0.4417\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5669 - val_loss: 0.4396\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5640 - val_loss: 0.4376\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5611 - val_loss: 0.4356\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5583 - val_loss: 0.4339\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5556 - val_loss: 0.4322\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5530 - val_loss: 0.4305\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5504 - val_loss: 0.4289\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5477 - val_loss: 0.4273\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5451 - val_loss: 0.4258\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5425 - val_loss: 0.4243\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5400 - val_loss: 0.4229\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=113, result_data[0].shape=(27, 65)\n",
      "Before prediction: train_X.shape=(10, 10, 65), train_y.shape=(10, 65), test_X.shape=(3, 10, 65), test_y.shape=(3, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4093 - val_loss: 0.3648\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4085 - val_loss: 0.3647\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4078 - val_loss: 0.3645\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4071 - val_loss: 0.3644\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4064 - val_loss: 0.3643\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4057 - val_loss: 0.3642\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4050 - val_loss: 0.3640\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4043 - val_loss: 0.3639\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4036 - val_loss: 0.3638\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4030 - val_loss: 0.3637\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4023 - val_loss: 0.3636\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4016 - val_loss: 0.3635\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4010 - val_loss: 0.3634\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4003 - val_loss: 0.3633\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3997 - val_loss: 0.3632\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3991 - val_loss: 0.3631\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3984 - val_loss: 0.3630\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3978 - val_loss: 0.3629\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3972 - val_loss: 0.3628\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3966 - val_loss: 0.3627\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "dataset_windows.shape=(326462, 15, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=1, result_data[0].shape=(2628, 65)\n",
      "Before prediction: train_X.shape=(1571, 10, 65), train_y.shape=(1571, 65), test_X.shape=(524, 10, 65), test_y.shape=(524, 65)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2427 - val_loss: 0.2802\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2319 - val_loss: 0.2706\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2242 - val_loss: 0.2633\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.2183 - val_loss: 0.2574\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2134 - val_loss: 0.2522\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2090 - val_loss: 0.2477\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2051 - val_loss: 0.2436\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2016 - val_loss: 0.2398\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1984 - val_loss: 0.2362\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1954 - val_loss: 0.2329\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.1926 - val_loss: 0.2298\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.1899 - val_loss: 0.2270\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1875 - val_loss: 0.2244\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1852 - val_loss: 0.2219\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1831 - val_loss: 0.2198\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1813 - val_loss: 0.2178\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1795 - val_loss: 0.2160\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1780 - val_loss: 0.2142\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.1765 - val_loss: 0.2127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1752 - val_loss: 0.2112\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=289, result_data[0].shape=(18, 65)\n",
      "Before prediction: train_X.shape=(5, 10, 65), train_y.shape=(5, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6763 - val_loss: 0.7430\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6743 - val_loss: 0.7418\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6723 - val_loss: 0.7406\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6703 - val_loss: 0.7394\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6684 - val_loss: 0.7382\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6665 - val_loss: 0.7370\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6645 - val_loss: 0.7358\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6626 - val_loss: 0.7346\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6607 - val_loss: 0.7334\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6588 - val_loss: 0.7322\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6569 - val_loss: 0.7310\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6551 - val_loss: 0.7298\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6532 - val_loss: 0.7286\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6514 - val_loss: 0.7274\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6496 - val_loss: 0.7262\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6479 - val_loss: 0.7250\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6461 - val_loss: 0.7238\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6444 - val_loss: 0.7227\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6426 - val_loss: 0.7215\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6409 - val_loss: 0.7203\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=83, result_data[0].shape=(101, 65)\n",
      "Before prediction: train_X.shape=(55, 10, 65), train_y.shape=(55, 65), test_X.shape=(18, 10, 65), test_y.shape=(18, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3934 - val_loss: 0.3919\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3929 - val_loss: 0.3918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3924 - val_loss: 0.3917\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3919 - val_loss: 0.3916\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3914 - val_loss: 0.3914\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3909 - val_loss: 0.3913\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3904 - val_loss: 0.3912\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3899 - val_loss: 0.3910\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.3895 - val_loss: 0.3909\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3890 - val_loss: 0.3908\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3885 - val_loss: 0.3907\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3881 - val_loss: 0.3906\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3876 - val_loss: 0.3904\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3871 - val_loss: 0.3903\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3867 - val_loss: 0.3902\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3862 - val_loss: 0.3901\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3858 - val_loss: 0.3900\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3854 - val_loss: 0.3898\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3850 - val_loss: 0.3897\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3846 - val_loss: 0.3896\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=29, result_data[0].shape=(84, 65)\n",
      "Before prediction: train_X.shape=(44, 10, 65), train_y.shape=(44, 65), test_X.shape=(15, 10, 65), test_y.shape=(15, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5496 - val_loss: 0.7638\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5480 - val_loss: 0.7633\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5464 - val_loss: 0.7628\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5448 - val_loss: 0.7623\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5432 - val_loss: 0.7617\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5417 - val_loss: 0.7612\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5401 - val_loss: 0.7607\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5386 - val_loss: 0.7602\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5371 - val_loss: 0.7598\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5356 - val_loss: 0.7593\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5341 - val_loss: 0.7588\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5326 - val_loss: 0.7583\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5311 - val_loss: 0.7579\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5297 - val_loss: 0.7574\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5282 - val_loss: 0.7570\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5268 - val_loss: 0.7565\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5254 - val_loss: 0.7561\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5240 - val_loss: 0.7556\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5226 - val_loss: 0.7552\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5212 - val_loss: 0.7548\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=29, result_data[0].shape=(321, 65)\n",
      "Before prediction: train_X.shape=(187, 10, 65), train_y.shape=(187, 65), test_X.shape=(62, 10, 65), test_y.shape=(62, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6740 - val_loss: 0.7000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6726 - val_loss: 0.6989\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6713 - val_loss: 0.6979\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6701 - val_loss: 0.6969\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6689 - val_loss: 0.6960\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6677 - val_loss: 0.6950\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6665 - val_loss: 0.6940\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6654 - val_loss: 0.6931\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6643 - val_loss: 0.6922\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6632 - val_loss: 0.6913\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6621 - val_loss: 0.6904\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6610 - val_loss: 0.6895\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6600 - val_loss: 0.6887\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6589 - val_loss: 0.6878\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6579 - val_loss: 0.6870\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6569 - val_loss: 0.6862\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6559 - val_loss: 0.6854\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6549 - val_loss: 0.6847\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6540 - val_loss: 0.6839\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6530 - val_loss: 0.6832\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(3255, 65)\n",
      "Before prediction: train_X.shape=(1947, 10, 65), train_y.shape=(1947, 65), test_X.shape=(649, 10, 65), test_y.shape=(649, 65)\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.1206 - val_loss: 0.0919\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1153 - val_loss: 0.0897\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1111 - val_loss: 0.0882\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1076 - val_loss: 0.0872\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1046 - val_loss: 0.0863\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.1019 - val_loss: 0.0857\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0996 - val_loss: 0.0852\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0975 - val_loss: 0.0848\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0956 - val_loss: 0.0845\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0938 - val_loss: 0.0842\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0922 - val_loss: 0.0839\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0907 - val_loss: 0.0837\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0894 - val_loss: 0.0835\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0881 - val_loss: 0.0833\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0870 - val_loss: 0.0831\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0859 - val_loss: 0.0830\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.0849 - val_loss: 0.0829\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0840 - val_loss: 0.0827\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0831 - val_loss: 0.0826\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0823 - val_loss: 0.0825\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=259, result_data[0].shape=(274, 65)\n",
      "Before prediction: train_X.shape=(158, 10, 65), train_y.shape=(158, 65), test_X.shape=(53, 10, 65), test_y.shape=(53, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.4853 - val_loss: 0.4035\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4841 - val_loss: 0.4028\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4830 - val_loss: 0.4020\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4818 - val_loss: 0.4013\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4808 - val_loss: 0.4006\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.4798 - val_loss: 0.3999\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.4787 - val_loss: 0.3993\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.4777 - val_loss: 0.3986\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.4767 - val_loss: 0.3979\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.4757 - val_loss: 0.3973\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4748 - val_loss: 0.3967\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4738 - val_loss: 0.3961\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.4728 - val_loss: 0.3955\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4719 - val_loss: 0.3949\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4710 - val_loss: 0.3943\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.4701 - val_loss: 0.3937\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.4693 - val_loss: 0.3931\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.4684 - val_loss: 0.3926\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.4676 - val_loss: 0.3920\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4667 - val_loss: 0.3915\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "dataset_windows.shape=(326462, 15, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=142, result_data[0].shape=(263, 65)\n",
      "Before prediction: train_X.shape=(152, 10, 65), train_y.shape=(152, 65), test_X.shape=(51, 10, 65), test_y.shape=(51, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3436 - val_loss: 0.2881\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3427 - val_loss: 0.2876\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3419 - val_loss: 0.2871\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3411 - val_loss: 0.2866\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3403 - val_loss: 0.2861\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3396 - val_loss: 0.2856\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3388 - val_loss: 0.2852\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3380 - val_loss: 0.2847\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3373 - val_loss: 0.2843\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3366 - val_loss: 0.2838\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3359 - val_loss: 0.2834\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3352 - val_loss: 0.2830\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3345 - val_loss: 0.2826\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3338 - val_loss: 0.2822\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3332 - val_loss: 0.2817\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3325 - val_loss: 0.2813\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3319 - val_loss: 0.2810\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3313 - val_loss: 0.2806\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3306 - val_loss: 0.2802\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3300 - val_loss: 0.2798\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=23, result_data[0].shape=(82, 65)\n",
      "Before prediction: train_X.shape=(43, 10, 65), train_y.shape=(43, 65), test_X.shape=(14, 10, 65), test_y.shape=(14, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5405 - val_loss: 0.8371\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5387 - val_loss: 0.8362\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5369 - val_loss: 0.8353\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5352 - val_loss: 0.8345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5334 - val_loss: 0.8336\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5317 - val_loss: 0.8328\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5300 - val_loss: 0.8320\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5284 - val_loss: 0.8311\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5267 - val_loss: 0.8303\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5251 - val_loss: 0.8295\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5234 - val_loss: 0.8287\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5218 - val_loss: 0.8279\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5202 - val_loss: 0.8270\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5187 - val_loss: 0.8262\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5171 - val_loss: 0.8255\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5155 - val_loss: 0.8247\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5140 - val_loss: 0.8239\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5124 - val_loss: 0.8231\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5109 - val_loss: 0.8223\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5094 - val_loss: 0.8216\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=35, result_data[0].shape=(295, 65)\n",
      "Before prediction: train_X.shape=(171, 10, 65), train_y.shape=(171, 65), test_X.shape=(57, 10, 65), test_y.shape=(57, 65)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.7736 - val_loss: 0.5926\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7722 - val_loss: 0.5920\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7709 - val_loss: 0.5914\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7697 - val_loss: 0.5908\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.7684 - val_loss: 0.5902\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7672 - val_loss: 0.5897\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7660 - val_loss: 0.5891\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.7648 - val_loss: 0.5886\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7636 - val_loss: 0.5881\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7625 - val_loss: 0.5875\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7613 - val_loss: 0.5870\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7601 - val_loss: 0.5864\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7590 - val_loss: 0.5859\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7579 - val_loss: 0.5854\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7567 - val_loss: 0.5849\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7556 - val_loss: 0.5843\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7546 - val_loss: 0.5838\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7534 - val_loss: 0.5833\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7524 - val_loss: 0.5828\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7513 - val_loss: 0.5823\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=1, result_data[0].shape=(2628, 65)\n",
      "Before prediction: train_X.shape=(1571, 10, 65), train_y.shape=(1571, 65), test_X.shape=(524, 10, 65), test_y.shape=(524, 65)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2498 - val_loss: 0.2915\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2390 - val_loss: 0.2813\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2308 - val_loss: 0.2732\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.2244 - val_loss: 0.2665\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.2190 - val_loss: 0.2608\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2144 - val_loss: 0.2559\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2105 - val_loss: 0.2515\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2069 - val_loss: 0.2476\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2036 - val_loss: 0.2439\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2006 - val_loss: 0.2406\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1978 - val_loss: 0.2374\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1951 - val_loss: 0.2345\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1926 - val_loss: 0.2318\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1902 - val_loss: 0.2291\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1880 - val_loss: 0.2266\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1858 - val_loss: 0.2242\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.1838 - val_loss: 0.2219\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.1819 - val_loss: 0.2199\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1801 - val_loss: 0.2179\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1784 - val_loss: 0.2161\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=299, result_data[0].shape=(16, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7194 - val_loss: 0.8481\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7164 - val_loss: 0.8457\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7136 - val_loss: 0.8433\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7107 - val_loss: 0.8410\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7078 - val_loss: 0.8386\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7049 - val_loss: 0.8362\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7021 - val_loss: 0.8339\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6994 - val_loss: 0.8316\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6967 - val_loss: 0.8292\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6941 - val_loss: 0.8269\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6915 - val_loss: 0.8247\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6889 - val_loss: 0.8225\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6863 - val_loss: 0.8204\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6837 - val_loss: 0.8183\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6812 - val_loss: 0.8163\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6786 - val_loss: 0.8144\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6761 - val_loss: 0.8124\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6736 - val_loss: 0.8104\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6710 - val_loss: 0.8085\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6686 - val_loss: 0.8065\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=101, result_data[0].shape=(18, 65)\n",
      "Before prediction: train_X.shape=(5, 10, 65), train_y.shape=(5, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8015 - val_loss: 0.6799\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7992 - val_loss: 0.6792\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7969 - val_loss: 0.6786\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7947 - val_loss: 0.6778\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7925 - val_loss: 0.6771\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7905 - val_loss: 0.6763\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7885 - val_loss: 0.6755\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7864 - val_loss: 0.6746\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7844 - val_loss: 0.6737\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7825 - val_loss: 0.6727\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7805 - val_loss: 0.6718\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7786 - val_loss: 0.6709\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7767 - val_loss: 0.6701\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7749 - val_loss: 0.6693\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7730 - val_loss: 0.6685\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7711 - val_loss: 0.6678\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7692 - val_loss: 0.6670\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7673 - val_loss: 0.6663\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7654 - val_loss: 0.6656\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7636 - val_loss: 0.6649\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(3255, 65)\n",
      "Before prediction: train_X.shape=(1947, 10, 65), train_y.shape=(1947, 65), test_X.shape=(649, 10, 65), test_y.shape=(649, 65)\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.1215 - val_loss: 0.0910\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1163 - val_loss: 0.0892\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1120 - val_loss: 0.0880\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1084 - val_loss: 0.0871\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.1053 - val_loss: 0.0864\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.1025 - val_loss: 0.0859\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1001 - val_loss: 0.0855\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0979 - val_loss: 0.0851\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0959 - val_loss: 0.0848\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0940 - val_loss: 0.0845\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0924 - val_loss: 0.0843\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0908 - val_loss: 0.0841\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0894 - val_loss: 0.0838\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0881 - val_loss: 0.0836\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0869 - val_loss: 0.0834\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.0858 - val_loss: 0.0832\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0847 - val_loss: 0.0831\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0837 - val_loss: 0.0829\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0828 - val_loss: 0.0827\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0819 - val_loss: 0.0826\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=89, result_data[0].shape=(192, 65)\n",
      "Before prediction: train_X.shape=(109, 10, 65), train_y.shape=(109, 65), test_X.shape=(36, 10, 65), test_y.shape=(36, 65)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.4157 - val_loss: 0.4810\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4149 - val_loss: 0.4805\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4141 - val_loss: 0.4800\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4134 - val_loss: 0.4796\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.4127 - val_loss: 0.4792\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4120 - val_loss: 0.4787\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.4113 - val_loss: 0.4783\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4106 - val_loss: 0.4779\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4100 - val_loss: 0.4775\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4093 - val_loss: 0.4771\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4087 - val_loss: 0.4767\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4081 - val_loss: 0.4763\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4075 - val_loss: 0.4759\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4069 - val_loss: 0.4755\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4063 - val_loss: 0.4751\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4058 - val_loss: 0.4747\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4052 - val_loss: 0.4743\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4046 - val_loss: 0.4740\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4041 - val_loss: 0.4736\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4036 - val_loss: 0.4732\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=376, result_data[0].shape=(21, 65)\n",
      "Before prediction: train_X.shape=(7, 10, 65), train_y.shape=(7, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5148 - val_loss: 0.4070\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5125 - val_loss: 0.4063\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5102 - val_loss: 0.4057\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5079 - val_loss: 0.4050\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5056 - val_loss: 0.4044\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5033 - val_loss: 0.4038\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5011 - val_loss: 0.4032\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4989 - val_loss: 0.4027\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4967 - val_loss: 0.4022\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4946 - val_loss: 0.4017\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4925 - val_loss: 0.4012\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4904 - val_loss: 0.4008\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4884 - val_loss: 0.4004\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4864 - val_loss: 0.4000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4844 - val_loss: 0.3997\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4825 - val_loss: 0.3993\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4807 - val_loss: 0.3989\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4788 - val_loss: 0.3986\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4770 - val_loss: 0.3982\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4752 - val_loss: 0.3979\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "dataset_windows.shape=(326462, 15, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=27, result_data[0].shape=(40, 65)\n",
      "Before prediction: train_X.shape=(18, 10, 65), train_y.shape=(18, 65), test_X.shape=(6, 10, 65), test_y.shape=(6, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5575 - val_loss: 0.9179\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5569 - val_loss: 0.9175\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5562 - val_loss: 0.9172\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5555 - val_loss: 0.9169\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5549 - val_loss: 0.9166\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5542 - val_loss: 0.9162\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5536 - val_loss: 0.9159\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5529 - val_loss: 0.9156\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5523 - val_loss: 0.9152\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5516 - val_loss: 0.9149\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5510 - val_loss: 0.9146\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5504 - val_loss: 0.9142\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5498 - val_loss: 0.9139\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5492 - val_loss: 0.9135\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5485 - val_loss: 0.9132\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5479 - val_loss: 0.9129\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5473 - val_loss: 0.9125\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5467 - val_loss: 0.9122\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5461 - val_loss: 0.9119\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5456 - val_loss: 0.9116\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=99, result_data[0].shape=(30, 65)\n",
      "Before prediction: train_X.shape=(12, 10, 65), train_y.shape=(12, 65), test_X.shape=(4, 10, 65), test_y.shape=(4, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3964 - val_loss: 0.3482\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3481\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3952 - val_loss: 0.3481\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3945 - val_loss: 0.3480\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3939 - val_loss: 0.3479\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3933 - val_loss: 0.3479\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3927 - val_loss: 0.3478\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3920 - val_loss: 0.3477\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3914 - val_loss: 0.3477\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3908 - val_loss: 0.3476\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3902 - val_loss: 0.3475\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3896 - val_loss: 0.3475\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3890 - val_loss: 0.3474\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3884 - val_loss: 0.3474\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3878 - val_loss: 0.3473\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3872 - val_loss: 0.3473\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.3472\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3861 - val_loss: 0.3472\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3856 - val_loss: 0.3471\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3850 - val_loss: 0.3471\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=464, result_data[0].shape=(14, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6498 - val_loss: 0.7503\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6472 - val_loss: 0.7487\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6446 - val_loss: 0.7472\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6420 - val_loss: 0.7456\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6396 - val_loss: 0.7441\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6371 - val_loss: 0.7427\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6346 - val_loss: 0.7412\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6322 - val_loss: 0.7398\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6297 - val_loss: 0.7384\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6272 - val_loss: 0.7370\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6247 - val_loss: 0.7356\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6223 - val_loss: 0.7342\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6198 - val_loss: 0.7328\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6174 - val_loss: 0.7313\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6149 - val_loss: 0.7299\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6125 - val_loss: 0.7284\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6100 - val_loss: 0.7270\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6076 - val_loss: 0.7256\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6051 - val_loss: 0.7243\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6028 - val_loss: 0.7230\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=72, result_data[0].shape=(14, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4271 - val_loss: 0.4203\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4255 - val_loss: 0.4197\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4239 - val_loss: 0.4192\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4223 - val_loss: 0.4186\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4207 - val_loss: 0.4181\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4191 - val_loss: 0.4176\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4175 - val_loss: 0.4171\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4160 - val_loss: 0.4166\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4146 - val_loss: 0.4162\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4131 - val_loss: 0.4157\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4116 - val_loss: 0.4154\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4102 - val_loss: 0.4150\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4087 - val_loss: 0.4147\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4073 - val_loss: 0.4143\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4059 - val_loss: 0.4140\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4045 - val_loss: 0.4136\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4032 - val_loss: 0.4133\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4018 - val_loss: 0.4129\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4004 - val_loss: 0.4126\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3990 - val_loss: 0.4123\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=24, result_data[0].shape=(36, 65)\n",
      "Before prediction: train_X.shape=(16, 10, 65), train_y.shape=(16, 65), test_X.shape=(5, 10, 65), test_y.shape=(5, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4663 - val_loss: 0.6854\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4640 - val_loss: 0.6842\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4617 - val_loss: 0.6829\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4594 - val_loss: 0.6817\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4571 - val_loss: 0.6804\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4549 - val_loss: 0.6792\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4527 - val_loss: 0.6780\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4505 - val_loss: 0.6767\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4483 - val_loss: 0.6755\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4462 - val_loss: 0.6743\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4441 - val_loss: 0.6731\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4421 - val_loss: 0.6719\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4400 - val_loss: 0.6707\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4380 - val_loss: 0.6695\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4360 - val_loss: 0.6684\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4340 - val_loss: 0.6672\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4320 - val_loss: 0.6661\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4301 - val_loss: 0.6649\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4283 - val_loss: 0.6638\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4265 - val_loss: 0.6627\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=399, result_data[0].shape=(19, 65)\n",
      "Before prediction: train_X.shape=(5, 10, 65), train_y.shape=(5, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5656 - val_loss: 0.3498\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5629 - val_loss: 0.3482\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5603 - val_loss: 0.3467\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5576 - val_loss: 0.3452\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5550 - val_loss: 0.3437\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5523 - val_loss: 0.3423\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5497 - val_loss: 0.3409\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5471 - val_loss: 0.3395\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5446 - val_loss: 0.3381\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5420 - val_loss: 0.3368\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5395 - val_loss: 0.3354\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5370 - val_loss: 0.3341\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5345 - val_loss: 0.3328\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5321 - val_loss: 0.3316\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5297 - val_loss: 0.3304\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5272 - val_loss: 0.3293\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5248 - val_loss: 0.3283\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5224 - val_loss: 0.3272\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5200 - val_loss: 0.3261\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5176 - val_loss: 0.3251\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(3255, 65)\n",
      "Before prediction: train_X.shape=(1947, 10, 65), train_y.shape=(1947, 65), test_X.shape=(649, 10, 65), test_y.shape=(649, 65)\n",
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.1237 - val_loss: 0.0920\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1180 - val_loss: 0.0902\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1135 - val_loss: 0.0890\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1097 - val_loss: 0.0880\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1065 - val_loss: 0.0872\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.1036 - val_loss: 0.0866\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.1010 - val_loss: 0.0861\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0987 - val_loss: 0.0858\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0966 - val_loss: 0.0854\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0947 - val_loss: 0.0851\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0930 - val_loss: 0.0848\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.0914 - val_loss: 0.0846\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0900 - val_loss: 0.0844\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0887 - val_loss: 0.0842\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0875 - val_loss: 0.0840\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0864 - val_loss: 0.0838\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0853 - val_loss: 0.0837\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0844 - val_loss: 0.0835\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0835 - val_loss: 0.0834\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0827 - val_loss: 0.0833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=202, result_data[0].shape=(38, 65)\n",
      "Before prediction: train_X.shape=(17, 10, 65), train_y.shape=(17, 65), test_X.shape=(6, 10, 65), test_y.shape=(6, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3337 - val_loss: 0.3753\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3330 - val_loss: 0.3750\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3324 - val_loss: 0.3747\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3317 - val_loss: 0.3744\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3310 - val_loss: 0.3742\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3304 - val_loss: 0.3739\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3298 - val_loss: 0.3736\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3291 - val_loss: 0.3734\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3285 - val_loss: 0.3731\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3279 - val_loss: 0.3728\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3272 - val_loss: 0.3726\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3266 - val_loss: 0.3723\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3260 - val_loss: 0.3720\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3254 - val_loss: 0.3718\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3248 - val_loss: 0.3715\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3242 - val_loss: 0.3712\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3236 - val_loss: 0.3710\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3230 - val_loss: 0.3707\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3224 - val_loss: 0.3705\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3219 - val_loss: 0.3702\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=73, result_data[0].shape=(17, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1569 - val_loss: 0.2119\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1565 - val_loss: 0.2117\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1561 - val_loss: 0.2115\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1556 - val_loss: 0.2112\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1552 - val_loss: 0.2110\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1548 - val_loss: 0.2108\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1544 - val_loss: 0.2105\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1540 - val_loss: 0.2103\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1536 - val_loss: 0.2100\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1531 - val_loss: 0.2098\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1528 - val_loss: 0.2096\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1524 - val_loss: 0.2095\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1520 - val_loss: 0.2093\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1516 - val_loss: 0.2091\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1512 - val_loss: 0.2089\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1508 - val_loss: 0.2087\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1505 - val_loss: 0.2086\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1501 - val_loss: 0.2084\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1497 - val_loss: 0.2082\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1494 - val_loss: 0.2080\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=1, result_data[0].shape=(2628, 65)\n",
      "Before prediction: train_X.shape=(1571, 10, 65), train_y.shape=(1571, 65), test_X.shape=(524, 10, 65), test_y.shape=(524, 65)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2525 - val_loss: 0.2947\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2409 - val_loss: 0.2835\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2319 - val_loss: 0.2744\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2247 - val_loss: 0.2668\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.2186 - val_loss: 0.2603\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2135 - val_loss: 0.2548\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2091 - val_loss: 0.2500\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2053 - val_loss: 0.2458\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2019 - val_loss: 0.2420\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1988 - val_loss: 0.2387\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1960 - val_loss: 0.2355\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1934 - val_loss: 0.2326\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.1910 - val_loss: 0.2300\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1888 - val_loss: 0.2275\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1866 - val_loss: 0.2251\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1846 - val_loss: 0.2230\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1828 - val_loss: 0.2210\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.1811 - val_loss: 0.2191\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.1794 - val_loss: 0.2174\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1779 - val_loss: 0.2158\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=268, result_data[0].shape=(16, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6353 - val_loss: 0.5634\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6322 - val_loss: 0.5615\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6293 - val_loss: 0.5596\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6263 - val_loss: 0.5577\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6235 - val_loss: 0.5558\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6206 - val_loss: 0.5540\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6177 - val_loss: 0.5523\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6149 - val_loss: 0.5507\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6121 - val_loss: 0.5492\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6094 - val_loss: 0.5477\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6067 - val_loss: 0.5463\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6042 - val_loss: 0.5448\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6016 - val_loss: 0.5434\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5991 - val_loss: 0.5420\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5968 - val_loss: 0.5407\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5944 - val_loss: 0.5393\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5921 - val_loss: 0.5380\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5898 - val_loss: 0.5366\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5875 - val_loss: 0.5353\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5852 - val_loss: 0.5340\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"N_clusters\":Ns_clusters, \"window_size_for_clustering\":window_sizes_for_clustering, \"dif\":True}\n",
    "models, model_mase = Forecasting.try_parameters(parameters, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [<keras.engine.sequential.Sequential at 0x7eff4049ddc0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7efe806a18e0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7efe82172f40>,\n",
       "  <keras.engine.sequential.Sequential at 0x7efe8212b100>,\n",
       "  <keras.engine.sequential.Sequential at 0x7efe81f8baf0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7efe81f7a8e0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7efe81dd30a0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7efe81eb8c70>,\n",
       "  <keras.engine.sequential.Sequential at 0x7efe82963a30>],\n",
       " 'scalers': [<Forecasting.MyStandardScaler at 0x7efe82ef2790>,\n",
       "  <Forecasting.MyStandardScaler at 0x7efe82823eb0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7efe82109ee0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7efe81080e50>,\n",
       "  <Forecasting.MyStandardScaler at 0x7efe81fa2b80>,\n",
       "  <Forecasting.MyStandardScaler at 0x7efe81eb3280>,\n",
       "  <Forecasting.MyStandardScaler at 0x7efe81e554c0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7efe81df70a0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7efe81c83100>],\n",
       " 'clusters_model': KMeans(init='random', max_iter=50, n_clusters=9)}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736527557.522011"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_model = models[\"clusters_model\"]\n",
    "forecasting_models = models['models']\n",
    "scalers = models['scalers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.shape=(81619, 65), dataset_windows.shape=(81604, 975), cluster_nums.shape=(81604,), 15\n",
      "After pad: dataset.shape=(81619, 65), cluster_nums.shape=(81619,)\n",
      "dataset_windows.shape=(81609, 1, 11, 65)\n",
      "cluster_nums.shape=(81609,)\n",
      "cur_windows.shape=(1032, 11, 65)\n",
      "N=0, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=1032, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(1032, 10, 65)\n",
      "cur_windows.shape=(713, 11, 65)\n",
      "N=1, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=713, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(713, 10, 65)\n",
      "cur_windows.shape=(47696, 11, 65)\n",
      "N=4, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=47696, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(47696, 10, 65)\n",
      "cur_windows.shape=(692, 11, 65)\n",
      "N=5, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=692, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(692, 10, 65)\n",
      "cur_windows.shape=(2129, 11, 65)\n",
      "N=6, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=2129, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(2129, 10, 65)\n",
      "cur_windows.shape=(29347, 11, 65)\n",
      "N=8, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=29347, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(29347, 10, 65)\n"
     ]
    }
   ],
   "source": [
    "window_sizes_for_clustering = clusters_model.cluster_centers_.shape[-1] // dataset_test.shape[-1]\n",
    "y_pred = Forecasting.predict_through_clusters(dataset_test, clusters_model, forecasting_models, scalers, window_size_clustering=window_sizes_for_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81609, 65)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape=(81609, 65), dataset_test.shape=(81619, 65)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{y_pred.shape=}, {dataset_test.shape=}\")\n",
    "y_true = dataset_test[-y_pred.shape[0]:]\n",
    "cur_mase = Forecasting.my_mase(y_true, y_pred, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"50% best MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_mape = mape(y_true, y_pred)\n",
    "plt.plot(cur_mape[cur_mape < np.percentile(cur_mape, 55)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"55% best MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mape[cur_mape <= np.percentile(cur_mape,100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 67), dtype=float32, numpy=\n",
       "array([[ 8.25200696e-04, -2.52360152e-03,  1.24429585e-03,\n",
       "         5.61252143e-03,  2.41480279e-03,  6.91283401e-03,\n",
       "        -1.55929942e-04,  5.05245430e-03, -3.45375156e-03,\n",
       "         2.31756223e-03, -5.02947718e-03,  5.21133933e-03,\n",
       "         2.63487943e-03, -1.15680450e-03, -8.61713605e-04,\n",
       "        -4.27721906e-03,  1.65054473e-04,  1.98029215e-03,\n",
       "         1.16372411e-03, -6.18001819e-03,  1.38662616e-03,\n",
       "        -3.87507980e-03, -5.78831602e-03, -4.70064487e-03,\n",
       "        -4.91938740e-03, -9.45061352e-03, -6.37044199e-03,\n",
       "        -1.24200690e-03, -2.50279880e-03,  6.26629405e-03,\n",
       "         7.07075465e-03,  4.37504100e-03,  8.11321661e-06,\n",
       "         6.27311785e-03, -2.45433138e-03,  6.55709300e-04,\n",
       "         1.01655931e-03,  3.92863574e-03, -7.48858880e-03,\n",
       "        -3.09383660e-03, -3.60715576e-03,  3.58439516e-04,\n",
       "         5.01208124e-04,  4.94992966e-03,  4.09077760e-03,\n",
       "        -1.00721011e-03, -6.26226794e-03, -6.27841754e-03,\n",
       "         5.10353828e-03,  4.80458234e-03, -2.42970185e-03,\n",
       "         3.23574082e-03,  4.15166654e-03,  1.97961787e-03,\n",
       "         2.42814887e-03, -2.23055086e-03, -2.55294633e-03,\n",
       "        -3.07056517e-03, -7.46782962e-03,  4.13405150e-03,\n",
       "         4.82963771e-03,  6.89104025e-04, -1.09297456e-04,\n",
       "         3.91600234e-03, -8.97214864e-04, -1.08612701e-03,\n",
       "         4.65779193e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.zeros(67 * 10).reshape(1, 10, 67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=2, 2, 22, (30608, 67)\n",
      "Before prediction: train_X.shape=(18358, 10, 67), train_y.shape=(18358, 67), test_X.shape=(6119, 10, 67), test_y.shape=(6119, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3112 - val_loss: 0.3270\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2915 - val_loss: 0.3111\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2761 - val_loss: 0.2987\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2646 - val_loss: 0.2898\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2564 - val_loss: 0.2830\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2504 - val_loss: 0.2777\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2456 - val_loss: 0.2732\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2415 - val_loss: 0.2694\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2378 - val_loss: 0.2660\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2345 - val_loss: 0.2630\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2314 - val_loss: 0.2603\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2286 - val_loss: 0.2579\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2262 - val_loss: 0.2559\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2241 - val_loss: 0.2541\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2222 - val_loss: 0.2526\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2206 - val_loss: 0.2513\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2191 - val_loss: 0.2500\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2179 - val_loss: 0.2489\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2167 - val_loss: 0.2478\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2156 - val_loss: 0.2470\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2147 - val_loss: 0.2461\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2138 - val_loss: 0.2453\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2129 - val_loss: 0.2444\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2122 - val_loss: 0.2439\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2115 - val_loss: 0.2432\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2109 - val_loss: 0.2427\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2103 - val_loss: 0.2421\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2097 - val_loss: 0.2416\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2092 - val_loss: 0.2410\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2087 - val_loss: 0.2407\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2082 - val_loss: 0.2401\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2397\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2073 - val_loss: 0.2394\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2069 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2065 - val_loss: 0.2386\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2062 - val_loss: 0.2382\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2058 - val_loss: 0.2380\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2055 - val_loss: 0.2376\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2052 - val_loss: 0.2373\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2049 - val_loss: 0.2370\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6119, 67), test_y.shape=(6119, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1578.0531622950014, my average MASE = 2807.2183134542065\n",
      "Cluster 0, 1578.0531622950014\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4317 - val_loss: 1.2280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4299 - val_loss: 1.2276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4282 - val_loss: 1.2273\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4264 - val_loss: 1.2269\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4247 - val_loss: 1.2266\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 1.2263\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 1.2259\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4198 - val_loss: 1.2256\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4182 - val_loss: 1.2253\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4166 - val_loss: 1.2251\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4151 - val_loss: 1.2248\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4135 - val_loss: 1.2245\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4120 - val_loss: 1.2242\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4105 - val_loss: 1.2239\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4089 - val_loss: 1.2236\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4074 - val_loss: 1.2233\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4060 - val_loss: 1.2229\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4045 - val_loss: 1.2226\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 1.2223\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4017 - val_loss: 1.2220\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4004 - val_loss: 1.2216\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3990 - val_loss: 1.2213\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3977 - val_loss: 1.2210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3964 - val_loss: 1.2207\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3951 - val_loss: 1.2204\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3938 - val_loss: 1.2201\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3926 - val_loss: 1.2198\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3914 - val_loss: 1.2195\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3901 - val_loss: 1.2192\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3889 - val_loss: 1.2189\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3877 - val_loss: 1.2186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3866 - val_loss: 1.2184\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 1.2181\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3842 - val_loss: 1.2178\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3831 - val_loss: 1.2175\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 1.2173\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3809 - val_loss: 1.2170\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3798 - val_loss: 1.2167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3787 - val_loss: 1.2165\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3776 - val_loss: 1.2162\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 708619678.5307182, my average MASE = 1911068024.4320867\n",
      "Cluster 1, 708619678.5307182\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=5, 5, 1026, (269, 67)\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5683 - val_loss: 0.4789\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5669 - val_loss: 0.4779\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5656 - val_loss: 0.4770\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5643 - val_loss: 0.4760\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5631 - val_loss: 0.4751\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5619 - val_loss: 0.4743\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5607 - val_loss: 0.4734\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5595 - val_loss: 0.4726\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5584 - val_loss: 0.4718\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5573 - val_loss: 0.4710\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5562 - val_loss: 0.4702\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5552 - val_loss: 0.4694\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5542 - val_loss: 0.4687\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5532 - val_loss: 0.4679\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5522 - val_loss: 0.4672\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5512 - val_loss: 0.4665\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5502 - val_loss: 0.4658\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5493 - val_loss: 0.4651\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5483 - val_loss: 0.4644\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5474 - val_loss: 0.4637\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5465 - val_loss: 0.4630\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5456 - val_loss: 0.4624\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5447 - val_loss: 0.4617\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5438 - val_loss: 0.4611\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5429 - val_loss: 0.4605\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5421 - val_loss: 0.4598\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5412 - val_loss: 0.4592\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5404 - val_loss: 0.4586\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5396 - val_loss: 0.4579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5388 - val_loss: 0.4573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5379 - val_loss: 0.4567\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5371 - val_loss: 0.4561\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5363 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5355 - val_loss: 0.4549\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5348 - val_loss: 0.4543\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5340 - val_loss: 0.4538\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5332 - val_loss: 0.4532\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5324 - val_loss: 0.4526\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5317 - val_loss: 0.4521\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5309 - val_loss: 0.4515\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.40868807431647, my average MASE = 112470179.11258063\n",
      "Cluster 0, 139.40868807431647\n",
      "Before prediction: train_X.shape=(31, 10, 67), train_y.shape=(31, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3364 - val_loss: 0.3469\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3360 - val_loss: 0.3468\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3355 - val_loss: 0.3468\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3350 - val_loss: 0.3467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3346 - val_loss: 0.3466\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3341 - val_loss: 0.3465\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3337 - val_loss: 0.3464\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3332 - val_loss: 0.3463\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3328 - val_loss: 0.3463\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3323 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3319 - val_loss: 0.3461\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3315 - val_loss: 0.3460\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3310 - val_loss: 0.3459\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3306 - val_loss: 0.3458\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3302 - val_loss: 0.3457\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3298 - val_loss: 0.3457\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3294 - val_loss: 0.3456\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3290 - val_loss: 0.3455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3286 - val_loss: 0.3454\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3282 - val_loss: 0.3453\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3278 - val_loss: 0.3453\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3274 - val_loss: 0.3452\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3270 - val_loss: 0.3451\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3267 - val_loss: 0.3450\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3263 - val_loss: 0.3450\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3259 - val_loss: 0.3449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3255 - val_loss: 0.3448\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3252 - val_loss: 0.3448\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3248 - val_loss: 0.3447\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3245 - val_loss: 0.3446\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3242 - val_loss: 0.3445\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3238 - val_loss: 0.3445\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3235 - val_loss: 0.3444\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3231 - val_loss: 0.3443\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3228 - val_loss: 0.3443\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3225 - val_loss: 0.3442\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3222 - val_loss: 0.3441\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3440\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3216 - val_loss: 0.3440\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3213 - val_loss: 0.3439\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3523641.3982873675, my average MASE = 66808534.66599488\n",
      "Cluster 1, 3523641.3982873675\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1130 - val_loss: 0.1021\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1076 - val_loss: 0.1000\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1032 - val_loss: 0.0984\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0995 - val_loss: 0.0974\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0964 - val_loss: 0.0968\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0912 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0889 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0869 - val_loss: 0.0951\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0834 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0804 - val_loss: 0.0940\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0791 - val_loss: 0.0938\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0936\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0934\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0757 - val_loss: 0.0933\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0748 - val_loss: 0.0931\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0739 - val_loss: 0.0930\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0730 - val_loss: 0.0929\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0722 - val_loss: 0.0927\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0926\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0707 - val_loss: 0.0925\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0701 - val_loss: 0.0924\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0694 - val_loss: 0.0923\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0922\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0922\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0677 - val_loss: 0.0922\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0672 - val_loss: 0.0921\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0921\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0663 - val_loss: 0.0920\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0919\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0656 - val_loss: 0.0919\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0918\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0918\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0646 - val_loss: 0.0917\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0638 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0635 - val_loss: 0.0915\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 869790828.2820631, my average MASE = 17262168691.962505\n",
      "Cluster 2, 869790828.2820631\n",
      "Before prediction: train_X.shape=(2219, 10, 67), train_y.shape=(2219, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5462 - val_loss: 0.4045\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5391 - val_loss: 0.4010\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5333 - val_loss: 0.3979\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5281 - val_loss: 0.3951\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5234 - val_loss: 0.3925\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5190 - val_loss: 0.3900\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5147 - val_loss: 0.3877\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5107 - val_loss: 0.3856\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5068 - val_loss: 0.3835\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5031 - val_loss: 0.3816\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4996 - val_loss: 0.3797\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4961 - val_loss: 0.3780\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4928 - val_loss: 0.3763\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4896 - val_loss: 0.3747\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4865 - val_loss: 0.3732\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4835 - val_loss: 0.3717\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4806 - val_loss: 0.3704\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4778 - val_loss: 0.3691\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4750 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4723 - val_loss: 0.3666\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4697 - val_loss: 0.3655\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4672 - val_loss: 0.3644\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4647 - val_loss: 0.3633\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4623 - val_loss: 0.3624\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4600 - val_loss: 0.3614\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4577 - val_loss: 0.3605\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4556 - val_loss: 0.3596\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4535 - val_loss: 0.3588\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4515 - val_loss: 0.3580\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4495 - val_loss: 0.3572\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4476 - val_loss: 0.3564\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4458 - val_loss: 0.3557\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4440 - val_loss: 0.3551\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4423 - val_loss: 0.3544\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4406 - val_loss: 0.3538\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4390 - val_loss: 0.3532\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4374 - val_loss: 0.3525\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4359 - val_loss: 0.3519\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4343 - val_loss: 0.3514\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4329 - val_loss: 0.3508\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 408.78828000932964, my average MASE = 1218.6998180420371\n",
      "Cluster 3, 408.78828000932964\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5668 - val_loss: 0.4468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5648 - val_loss: 0.4459\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5628 - val_loss: 0.4451\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5609 - val_loss: 0.4443\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5589 - val_loss: 0.4435\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5570 - val_loss: 0.4427\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5551 - val_loss: 0.4419\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5533 - val_loss: 0.4412\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5514 - val_loss: 0.4404\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5496 - val_loss: 0.4397\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5478 - val_loss: 0.4389\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5460 - val_loss: 0.4382\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5442 - val_loss: 0.4374\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5425 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5408 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5391 - val_loss: 0.4352\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5374 - val_loss: 0.4344\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5358 - val_loss: 0.4337\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5342 - val_loss: 0.4329\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.4322\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5310 - val_loss: 0.4315\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5295 - val_loss: 0.4308\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5280 - val_loss: 0.4300\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5264 - val_loss: 0.4293\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5250 - val_loss: 0.4286\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5235 - val_loss: 0.4279\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5221 - val_loss: 0.4273\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5207 - val_loss: 0.4266\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5193 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5179 - val_loss: 0.4254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5165 - val_loss: 0.4248\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5151 - val_loss: 0.4241\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5138 - val_loss: 0.4235\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5125 - val_loss: 0.4229\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5112 - val_loss: 0.4223\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5099 - val_loss: 0.4217\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5086 - val_loss: 0.4212\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5073 - val_loss: 0.4206\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5061 - val_loss: 0.4200\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5048 - val_loss: 0.4194\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2631402082.882854, my average MASE = 5288471031.0194235\n",
      "Cluster 4, 2631402082.882854\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=7, 7, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1149 - val_loss: 0.1029\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1092 - val_loss: 0.1008\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1047 - val_loss: 0.0992\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1009 - val_loss: 0.0980\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0972\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0947 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0922 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0899 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0878 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0859 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0842 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0826 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0812 - val_loss: 0.0939\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0799 - val_loss: 0.0936\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0934\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0775 - val_loss: 0.0931\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0929\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0755 - val_loss: 0.0928\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0746 - val_loss: 0.0926\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0737 - val_loss: 0.0924\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0923\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0922\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0921\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0708 - val_loss: 0.0920\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0919\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0696 - val_loss: 0.0918\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0690 - val_loss: 0.0917\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0685 - val_loss: 0.0916\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0680 - val_loss: 0.0916\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0675 - val_loss: 0.0915\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0670 - val_loss: 0.0915\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0666 - val_loss: 0.0915\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0662 - val_loss: 0.0914\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0658 - val_loss: 0.0914\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0654 - val_loss: 0.0913\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0651 - val_loss: 0.0913\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0648 - val_loss: 0.0912\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0645 - val_loss: 0.0912\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0642 - val_loss: 0.0911\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0911\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 1397145651.915293, my average MASE = 8779028319.064796\n",
      "Cluster 0, 1397145651.915293\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4446 - val_loss: 0.4248\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.4440 - val_loss: 0.4245\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4434 - val_loss: 0.4242\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4429 - val_loss: 0.4239\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4423 - val_loss: 0.4236\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4418 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4413 - val_loss: 0.4231\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4408 - val_loss: 0.4228\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4403 - val_loss: 0.4226\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4398 - val_loss: 0.4223\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4393 - val_loss: 0.4221\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4388 - val_loss: 0.4219\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4383 - val_loss: 0.4216\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4378 - val_loss: 0.4214\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4212\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4369 - val_loss: 0.4209\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4364 - val_loss: 0.4207\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4360 - val_loss: 0.4205\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4355 - val_loss: 0.4202\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4351 - val_loss: 0.4200\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4346 - val_loss: 0.4198\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4342 - val_loss: 0.4195\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.4193\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4333 - val_loss: 0.4191\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4329 - val_loss: 0.4189\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4325 - val_loss: 0.4187\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4321 - val_loss: 0.4184\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4317 - val_loss: 0.4182\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4313 - val_loss: 0.4180\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4309 - val_loss: 0.4178\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4305 - val_loss: 0.4176\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4301 - val_loss: 0.4175\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4297 - val_loss: 0.4173\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4293 - val_loss: 0.4171\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4289 - val_loss: 0.4169\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4286 - val_loss: 0.4167\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4282 - val_loss: 0.4165\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4278 - val_loss: 0.4163\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4274 - val_loss: 0.4161\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4271 - val_loss: 0.4159\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 86.00366340249806, my average MASE = 69691247.07168306\n",
      "Cluster 1, 86.00366340249806\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9826 - val_loss: 1.3468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9801 - val_loss: 1.3460\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9776 - val_loss: 1.3453\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9751 - val_loss: 1.3446\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9726 - val_loss: 1.3439\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9701 - val_loss: 1.3432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9677 - val_loss: 1.3425\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9653 - val_loss: 1.3419\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9628 - val_loss: 1.3413\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9604 - val_loss: 1.3408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9580 - val_loss: 1.3402\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9556 - val_loss: 1.3396\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9532 - val_loss: 1.3390\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9508 - val_loss: 1.3384\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9486 - val_loss: 1.3379\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9463 - val_loss: 1.3374\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9440 - val_loss: 1.3368\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9418 - val_loss: 1.3363\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9397 - val_loss: 1.3358\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9375 - val_loss: 1.3352\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9353 - val_loss: 1.3347\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9331 - val_loss: 1.3341\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9309 - val_loss: 1.3337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9287 - val_loss: 1.3332\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9266 - val_loss: 1.3328\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9245 - val_loss: 1.3324\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9224 - val_loss: 1.3321\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9203 - val_loss: 1.3317\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9183 - val_loss: 1.3314\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9162 - val_loss: 1.3311\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9141 - val_loss: 1.3308\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9120 - val_loss: 1.3305\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9100 - val_loss: 1.3303\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9079 - val_loss: 1.3300\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9059 - val_loss: 1.3298\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9039 - val_loss: 1.3295\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9019 - val_loss: 1.3293\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9000 - val_loss: 1.3291\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8981 - val_loss: 1.3288\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8963 - val_loss: 1.3286\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1.6636413128548868, my average MASE = 8.526439257891766\n",
      "Cluster 2, 1.6636413128548868\n",
      "Before prediction: train_X.shape=(177, 10, 67), train_y.shape=(177, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7327 - val_loss: 0.5966\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7311 - val_loss: 0.5956\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7296 - val_loss: 0.5946\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7281 - val_loss: 0.5936\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7266 - val_loss: 0.5927\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7252 - val_loss: 0.5918\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7239 - val_loss: 0.5909\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7225 - val_loss: 0.5901\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7212 - val_loss: 0.5892\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7199 - val_loss: 0.5884\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7186 - val_loss: 0.5875\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7174 - val_loss: 0.5867\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7162 - val_loss: 0.5859\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7150 - val_loss: 0.5852\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7138 - val_loss: 0.5844\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7127 - val_loss: 0.5837\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7116 - val_loss: 0.5829\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7104 - val_loss: 0.5822\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7093 - val_loss: 0.5815\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7082 - val_loss: 0.5808\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7071 - val_loss: 0.5801\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7061 - val_loss: 0.5794\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7050 - val_loss: 0.5788\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7040 - val_loss: 0.5781\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7030 - val_loss: 0.5775\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7020 - val_loss: 0.5768\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7010 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7000 - val_loss: 0.5756\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6990 - val_loss: 0.5750\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6981 - val_loss: 0.5744\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6971 - val_loss: 0.5738\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6962 - val_loss: 0.5732\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6953 - val_loss: 0.5726\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6944 - val_loss: 0.5721\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6935 - val_loss: 0.5715\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6925 - val_loss: 0.5710\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6917 - val_loss: 0.5704\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6908 - val_loss: 0.5699\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6899 - val_loss: 0.5694\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6890 - val_loss: 0.5688\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 148.95203283848892, my average MASE = 195949093.5023566\n",
      "Cluster 3, 148.95203283848892\n",
      "Before prediction: train_X.shape=(59, 10, 67), train_y.shape=(59, 67), test_X.shape=(20, 10, 67), test_y.shape=(20, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4242 - val_loss: 0.4717\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4237 - val_loss: 0.4716\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4715\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4228 - val_loss: 0.4714\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4223 - val_loss: 0.4713\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4219 - val_loss: 0.4712\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4214 - val_loss: 0.4711\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4210 - val_loss: 0.4710\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.4709\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4201 - val_loss: 0.4708\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4197 - val_loss: 0.4707\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4193 - val_loss: 0.4706\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4189 - val_loss: 0.4705\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.4705\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4180 - val_loss: 0.4704\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4176 - val_loss: 0.4703\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4702\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4168 - val_loss: 0.4701\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4164 - val_loss: 0.4700\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4160 - val_loss: 0.4699\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4157 - val_loss: 0.4698\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4153 - val_loss: 0.4698\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4149 - val_loss: 0.4697\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4145 - val_loss: 0.4696\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4141 - val_loss: 0.4695\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4138 - val_loss: 0.4694\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4134 - val_loss: 0.4694\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4130 - val_loss: 0.4693\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4127 - val_loss: 0.4692\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4123 - val_loss: 0.4691\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4119 - val_loss: 0.4690\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4116 - val_loss: 0.4690\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4112 - val_loss: 0.4689\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.4688\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4105 - val_loss: 0.4687\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4101 - val_loss: 0.4687\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4098 - val_loss: 0.4686\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4094 - val_loss: 0.4685\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4091 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4087 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(20, 67), test_y.shape=(20, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 138.4214035546147, my average MASE = 76438634.40084383\n",
      "Cluster 4, 138.4214035546147\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4144 - val_loss: 0.4072\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4116 - val_loss: 0.4056\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4089 - val_loss: 0.4039\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4061 - val_loss: 0.4022\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4034 - val_loss: 0.4005\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4008 - val_loss: 0.3988\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3982 - val_loss: 0.3971\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3957 - val_loss: 0.3954\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3932 - val_loss: 0.3937\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3908 - val_loss: 0.3920\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3885 - val_loss: 0.3903\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3861 - val_loss: 0.3887\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3838 - val_loss: 0.3870\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3816 - val_loss: 0.3854\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3795 - val_loss: 0.3838\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3775 - val_loss: 0.3822\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3755 - val_loss: 0.3807\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3735 - val_loss: 0.3793\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3716 - val_loss: 0.3779\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3697 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3679 - val_loss: 0.3751\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3661 - val_loss: 0.3737\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3644 - val_loss: 0.3723\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3710\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3611 - val_loss: 0.3697\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3594 - val_loss: 0.3684\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3578 - val_loss: 0.3672\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3562 - val_loss: 0.3659\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3547 - val_loss: 0.3646\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3533 - val_loss: 0.3634\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.3621\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3506 - val_loss: 0.3608\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3493 - val_loss: 0.3596\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3481 - val_loss: 0.3583\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3468 - val_loss: 0.3571\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3456 - val_loss: 0.3558\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3443 - val_loss: 0.3546\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3431 - val_loss: 0.3534\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3419 - val_loss: 0.3521\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3407 - val_loss: 0.3509\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 697989181.1057402, my average MASE = 1714132782.1928625\n",
      "Cluster 5, 697989181.1057402\n",
      "Before prediction: train_X.shape=(95, 10, 67), train_y.shape=(95, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3944 - val_loss: 0.3555\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3937 - val_loss: 0.3552\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3930 - val_loss: 0.3549\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3924 - val_loss: 0.3546\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3917 - val_loss: 0.3543\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3910 - val_loss: 0.3540\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3904 - val_loss: 0.3537\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3898 - val_loss: 0.3534\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3892 - val_loss: 0.3532\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3886 - val_loss: 0.3529\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3880 - val_loss: 0.3526\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3874 - val_loss: 0.3523\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3868 - val_loss: 0.3520\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3863 - val_loss: 0.3518\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3857 - val_loss: 0.3515\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3852 - val_loss: 0.3512\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3846 - val_loss: 0.3510\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3841 - val_loss: 0.3507\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3835 - val_loss: 0.3504\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3830 - val_loss: 0.3502\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3825 - val_loss: 0.3499\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3820 - val_loss: 0.3496\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3815 - val_loss: 0.3494\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3810 - val_loss: 0.3491\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3805 - val_loss: 0.3489\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3799 - val_loss: 0.3486\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3795 - val_loss: 0.3484\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3790 - val_loss: 0.3481\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3785 - val_loss: 0.3479\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.3476\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3776 - val_loss: 0.3474\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3771 - val_loss: 0.3471\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3767 - val_loss: 0.3469\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3762 - val_loss: 0.3466\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3758 - val_loss: 0.3464\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3753 - val_loss: 0.3461\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3749 - val_loss: 0.3459\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3745 - val_loss: 0.3456\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3740 - val_loss: 0.3454\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3736 - val_loss: 0.3451\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 265.33452450872096, my average MASE = 56598015.30805221\n",
      "Cluster 6, 265.33452450872096\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=9, 9, 1486, (3, 67)\n",
      "Before prediction: train_X.shape=(97, 10, 67), train_y.shape=(97, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4153 - val_loss: 0.4398\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.4396\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4138 - val_loss: 0.4393\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4131 - val_loss: 0.4391\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4124 - val_loss: 0.4388\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4118 - val_loss: 0.4386\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4111 - val_loss: 0.4383\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4105 - val_loss: 0.4381\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4099 - val_loss: 0.4378\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4093 - val_loss: 0.4376\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4087 - val_loss: 0.4374\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4081 - val_loss: 0.4371\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.4369\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4069 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4064 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4058 - val_loss: 0.4362\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.4360\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4047 - val_loss: 0.4358\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4042 - val_loss: 0.4356\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4037 - val_loss: 0.4353\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4032 - val_loss: 0.4351\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4349\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4022 - val_loss: 0.4347\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4017 - val_loss: 0.4345\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4012 - val_loss: 0.4343\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4007 - val_loss: 0.4341\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4003 - val_loss: 0.4339\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3998 - val_loss: 0.4337\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3993 - val_loss: 0.4335\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3989 - val_loss: 0.4334\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3984 - val_loss: 0.4332\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3980 - val_loss: 0.4330\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3976 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3967 - val_loss: 0.4324\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3963 - val_loss: 0.4322\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4320\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3955 - val_loss: 0.4318\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3950 - val_loss: 0.4316\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.4314\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 106.62824359839709, my average MASE = 181907103.45341906\n",
      "Cluster 0, 106.62824359839709\n",
      "Before prediction: train_X.shape=(1415, 10, 67), train_y.shape=(1415, 67), test_X.shape=(472, 10, 67), test_y.shape=(472, 67)\n",
      "Epoch 1/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.1435 - val_loss: 0.0272\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1388 - val_loss: 0.0264\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1347 - val_loss: 0.0256\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1311 - val_loss: 0.0250\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1278 - val_loss: 0.0244\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1249 - val_loss: 0.0239\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1221 - val_loss: 0.0234\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1196 - val_loss: 0.0231\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.1173 - val_loss: 0.0227\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.1151 - val_loss: 0.0224\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1132 - val_loss: 0.0221\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1113 - val_loss: 0.0220\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1096 - val_loss: 0.0217\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1080 - val_loss: 0.0216\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1065 - val_loss: 0.0214\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1051 - val_loss: 0.0212\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1038 - val_loss: 0.0211\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1026 - val_loss: 0.0209\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1014 - val_loss: 0.0208\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1004 - val_loss: 0.0206\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0993 - val_loss: 0.0206\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0983 - val_loss: 0.0205\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0974 - val_loss: 0.0204\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0965 - val_loss: 0.0202\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0957 - val_loss: 0.0201\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0949 - val_loss: 0.0200\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0941 - val_loss: 0.0200\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0934 - val_loss: 0.0199\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0927 - val_loss: 0.0198\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0920 - val_loss: 0.0197\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0914 - val_loss: 0.0197\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0907 - val_loss: 0.0196\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0902 - val_loss: 0.0195\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0896 - val_loss: 0.0195\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0890 - val_loss: 0.0195\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0885 - val_loss: 0.0194\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0880 - val_loss: 0.0194\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0875 - val_loss: 0.0193\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0871 - val_loss: 0.0194\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0867 - val_loss: 0.0193\n",
      "15/15 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(472, 67), test_y.shape=(472, 67)\n",
      "average MASE = 484561401.3912065, my average MASE = 2109803098.5295365\n",
      "Cluster 1, 484561401.3912065\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4184 - val_loss: 0.4085\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4174 - val_loss: 0.4084\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4165 - val_loss: 0.4083\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4155 - val_loss: 0.4082\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4146 - val_loss: 0.4082\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4136 - val_loss: 0.4081\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4127 - val_loss: 0.4080\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4118 - val_loss: 0.4079\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4109 - val_loss: 0.4078\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4100 - val_loss: 0.4077\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4091 - val_loss: 0.4077\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4083 - val_loss: 0.4076\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4074 - val_loss: 0.4075\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4066 - val_loss: 0.4074\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4057 - val_loss: 0.4074\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4049 - val_loss: 0.4073\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4041 - val_loss: 0.4072\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4033 - val_loss: 0.4071\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4025 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4017 - val_loss: 0.4069\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4009 - val_loss: 0.4069\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4001 - val_loss: 0.4068\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3994 - val_loss: 0.4067\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3986 - val_loss: 0.4066\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3979 - val_loss: 0.4065\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3971 - val_loss: 0.4065\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3964 - val_loss: 0.4064\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3957 - val_loss: 0.4063\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3949 - val_loss: 0.4062\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3942 - val_loss: 0.4062\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3936 - val_loss: 0.4061\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3929 - val_loss: 0.4060\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3922 - val_loss: 0.4059\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4058\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3909 - val_loss: 0.4058\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3902 - val_loss: 0.4057\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3896 - val_loss: 0.4056\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3889 - val_loss: 0.4055\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3883 - val_loss: 0.4055\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3877 - val_loss: 0.4054\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 146.41485105295615, my average MASE = 90287364.09726365\n",
      "Cluster 2, 146.41485105295615\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5429 - val_loss: 0.4489\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5408 - val_loss: 0.4477\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5388 - val_loss: 0.4466\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5367 - val_loss: 0.4454\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5348 - val_loss: 0.4443\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5328 - val_loss: 0.4432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5308 - val_loss: 0.4421\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5289 - val_loss: 0.4410\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5270 - val_loss: 0.4399\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5251 - val_loss: 0.4389\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5232 - val_loss: 0.4378\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5214 - val_loss: 0.4368\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5195 - val_loss: 0.4357\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5177 - val_loss: 0.4347\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5159 - val_loss: 0.4336\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5140 - val_loss: 0.4326\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5123 - val_loss: 0.4316\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5105 - val_loss: 0.4306\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5087 - val_loss: 0.4296\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5069 - val_loss: 0.4287\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5052 - val_loss: 0.4277\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5034 - val_loss: 0.4268\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5017 - val_loss: 0.4258\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5000 - val_loss: 0.4249\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4983 - val_loss: 0.4240\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4967 - val_loss: 0.4230\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4950 - val_loss: 0.4221\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4934 - val_loss: 0.4212\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4918 - val_loss: 0.4204\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4903 - val_loss: 0.4195\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4887 - val_loss: 0.4186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.4177\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4857 - val_loss: 0.4169\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4843 - val_loss: 0.4161\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4828 - val_loss: 0.4152\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4814 - val_loss: 0.4144\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4800 - val_loss: 0.4136\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4786 - val_loss: 0.4127\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4772 - val_loss: 0.4119\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4758 - val_loss: 0.4111\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1177081/3287276626.py:67: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 10))\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3556660081.750684, my average MASE = 7865462670.190711\n",
      "Cluster 3, 3556660081.750684\n",
      "Before prediction: train_X.shape=(173, 10, 67), train_y.shape=(173, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7286 - val_loss: 0.5747\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7270 - val_loss: 0.5740\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7256 - val_loss: 0.5733\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7243 - val_loss: 0.5725\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7229 - val_loss: 0.5718\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7216 - val_loss: 0.5712\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7203 - val_loss: 0.5705\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7190 - val_loss: 0.5698\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7178 - val_loss: 0.5692\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7166 - val_loss: 0.5686\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7154 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7142 - val_loss: 0.5673\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7130 - val_loss: 0.5667\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7119 - val_loss: 0.5662\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7108 - val_loss: 0.5656\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7096 - val_loss: 0.5650\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7086 - val_loss: 0.5645\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7075 - val_loss: 0.5639\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7064 - val_loss: 0.5634\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7054 - val_loss: 0.5629\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7044 - val_loss: 0.5624\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7034 - val_loss: 0.5619\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5614\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7014 - val_loss: 0.5609\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7004 - val_loss: 0.5604\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6995 - val_loss: 0.5599\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6986 - val_loss: 0.5595\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6976 - val_loss: 0.5590\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6967 - val_loss: 0.5585\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6958 - val_loss: 0.5581\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6949 - val_loss: 0.5576\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6940 - val_loss: 0.5571\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6931 - val_loss: 0.5567\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5562\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6914 - val_loss: 0.5558\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6905 - val_loss: 0.5553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6896 - val_loss: 0.5549\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6887 - val_loss: 0.5545\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6879 - val_loss: 0.5540\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5536\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 122.19340890523425, my average MASE = 115345826.80728418\n",
      "Cluster 4, 122.19340890523425\n",
      "Before prediction: train_X.shape=(1562, 10, 67), train_y.shape=(1562, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2392 - val_loss: 0.2772\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2287 - val_loss: 0.2673\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2207 - val_loss: 0.2595\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2144 - val_loss: 0.2534\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2094 - val_loss: 0.2481\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2050 - val_loss: 0.2435\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2013 - val_loss: 0.2394\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1978 - val_loss: 0.2357\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1947 - val_loss: 0.2322\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1919 - val_loss: 0.2289\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1892 - val_loss: 0.2259\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1867 - val_loss: 0.2231\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2204\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1821 - val_loss: 0.2179\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1800 - val_loss: 0.2156\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1761 - val_loss: 0.2114\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1743 - val_loss: 0.2096\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1727 - val_loss: 0.2078\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1712 - val_loss: 0.2062\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1698 - val_loss: 0.2047\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2033\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1672 - val_loss: 0.2020\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1661 - val_loss: 0.2007\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1650 - val_loss: 0.1996\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1640 - val_loss: 0.1985\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1631 - val_loss: 0.1974\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1622 - val_loss: 0.1964\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1614 - val_loss: 0.1954\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1598 - val_loss: 0.1936\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1578 - val_loss: 0.1912\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1572 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1566 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1560 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1554 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1549 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1544 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 151.79409601094594, my average MASE = 3866050940.760538\n",
      "Cluster 5, 151.79409601094594\n",
      "Before prediction: train_X.shape=(83, 10, 67), train_y.shape=(83, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4279 - val_loss: 0.5018\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4270 - val_loss: 0.5012\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4262 - val_loss: 0.5006\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4254 - val_loss: 0.5000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4246 - val_loss: 0.4995\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4239 - val_loss: 0.4989\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4231 - val_loss: 0.4984\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4224 - val_loss: 0.4978\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4217 - val_loss: 0.4973\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4968\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4203 - val_loss: 0.4962\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4197 - val_loss: 0.4958\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4191 - val_loss: 0.4953\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4184 - val_loss: 0.4948\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4178 - val_loss: 0.4943\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4939\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4167 - val_loss: 0.4934\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4161 - val_loss: 0.4930\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4155 - val_loss: 0.4926\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4150 - val_loss: 0.4921\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4144 - val_loss: 0.4917\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4139 - val_loss: 0.4913\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4133 - val_loss: 0.4908\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4128 - val_loss: 0.4904\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4123 - val_loss: 0.4900\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4118 - val_loss: 0.4895\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4113 - val_loss: 0.4891\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4107 - val_loss: 0.4887\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4103 - val_loss: 0.4883\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4098 - val_loss: 0.4879\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4093 - val_loss: 0.4875\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4088 - val_loss: 0.4871\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4083 - val_loss: 0.4867\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4079 - val_loss: 0.4863\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4074 - val_loss: 0.4859\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4069 - val_loss: 0.4855\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4065 - val_loss: 0.4851\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4061 - val_loss: 0.4848\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4056 - val_loss: 0.4844\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4052 - val_loss: 0.4840\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 155.68618683798326, my average MASE = 97738271.39222205\n",
      "Cluster 6, 155.68618683798326\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2911 - val_loss: 0.2917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2907 - val_loss: 0.2915\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2902 - val_loss: 0.2913\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2897 - val_loss: 0.2911\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2892 - val_loss: 0.2909\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2888 - val_loss: 0.2907\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2883 - val_loss: 0.2905\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2878 - val_loss: 0.2903\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2874 - val_loss: 0.2901\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2869 - val_loss: 0.2899\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2865 - val_loss: 0.2898\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2861 - val_loss: 0.2896\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2856 - val_loss: 0.2894\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2852 - val_loss: 0.2892\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2848 - val_loss: 0.2890\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2844 - val_loss: 0.2889\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2840 - val_loss: 0.2887\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2836 - val_loss: 0.2885\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2832 - val_loss: 0.2883\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2828 - val_loss: 0.2882\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2824 - val_loss: 0.2880\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2820 - val_loss: 0.2878\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2816 - val_loss: 0.2877\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2812 - val_loss: 0.2875\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2808 - val_loss: 0.2874\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2804 - val_loss: 0.2872\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2800 - val_loss: 0.2870\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2796 - val_loss: 0.2869\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2793 - val_loss: 0.2867\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2789 - val_loss: 0.2865\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2785 - val_loss: 0.2864\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2781 - val_loss: 0.2862\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2778 - val_loss: 0.2861\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2774 - val_loss: 0.2859\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2770 - val_loss: 0.2858\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2767 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2763 - val_loss: 0.2855\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2759 - val_loss: 0.2853\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2756 - val_loss: 0.2852\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2752 - val_loss: 0.2851\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 112.24086700274312, my average MASE = 119826311.76187374\n",
      "Cluster 8, 112.24086700274312\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=11, 11, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1118 - val_loss: 0.1019\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1064 - val_loss: 0.0996\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1022 - val_loss: 0.0982\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0987 - val_loss: 0.0973\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0956 - val_loss: 0.0966\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0930 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0885 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0866 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0848 - val_loss: 0.0949\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0832 - val_loss: 0.0946\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0818 - val_loss: 0.0944\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0804 - val_loss: 0.0941\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0792 - val_loss: 0.0939\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0780 - val_loss: 0.0937\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0769 - val_loss: 0.0936\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0759 - val_loss: 0.0934\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0749 - val_loss: 0.0933\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0740 - val_loss: 0.0932\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0732 - val_loss: 0.0931\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0724 - val_loss: 0.0929\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0716 - val_loss: 0.0928\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0927\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0926\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0696 - val_loss: 0.0926\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0690 - val_loss: 0.0925\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0924\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0923\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0674 - val_loss: 0.0923\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0922\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0921\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0662 - val_loss: 0.0921\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0658 - val_loss: 0.0920\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0919\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0651 - val_loss: 0.0919\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0648 - val_loss: 0.0918\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0645 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0642 - val_loss: 0.0917\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0637 - val_loss: 0.0916\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 876211806.5152007, my average MASE = 21477700395.128197\n",
      "Cluster 0, 876211806.5152007\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7012 - val_loss: 0.5689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7001 - val_loss: 0.5688\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6990 - val_loss: 0.5687\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6979 - val_loss: 0.5686\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6968 - val_loss: 0.5685\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6958 - val_loss: 0.5684\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6947 - val_loss: 0.5683\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6936 - val_loss: 0.5682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6926 - val_loss: 0.5681\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6916 - val_loss: 0.5680\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6906 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6896 - val_loss: 0.5678\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6887 - val_loss: 0.5677\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6877 - val_loss: 0.5676\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6868 - val_loss: 0.5675\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6859 - val_loss: 0.5674\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6849 - val_loss: 0.5673\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6840 - val_loss: 0.5672\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6831 - val_loss: 0.5671\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6822 - val_loss: 0.5670\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6813 - val_loss: 0.5669\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6805 - val_loss: 0.5668\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6796 - val_loss: 0.5667\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6787 - val_loss: 0.5666\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6779 - val_loss: 0.5665\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6771 - val_loss: 0.5665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6762 - val_loss: 0.5664\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6754 - val_loss: 0.5663\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6746 - val_loss: 0.5662\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6738 - val_loss: 0.5661\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6730 - val_loss: 0.5660\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6722 - val_loss: 0.5659\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6715 - val_loss: 0.5658\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6707 - val_loss: 0.5657\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6699 - val_loss: 0.5656\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6691 - val_loss: 0.5655\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6684 - val_loss: 0.5654\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6676 - val_loss: 0.5653\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6668 - val_loss: 0.5652\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6661 - val_loss: 0.5651\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1104923.1929255812, my average MASE = 35973487.14565515\n",
      "Cluster 1, 1104923.1929255812\n",
      "Before prediction: train_X.shape=(134, 10, 67), train_y.shape=(134, 67), test_X.shape=(45, 10, 67), test_y.shape=(45, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4388 - val_loss: 0.7635\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4381 - val_loss: 0.7630\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4375 - val_loss: 0.7625\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4369 - val_loss: 0.7620\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4363 - val_loss: 0.7616\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4358 - val_loss: 0.7611\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4353 - val_loss: 0.7607\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4348 - val_loss: 0.7603\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4343 - val_loss: 0.7598\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4338 - val_loss: 0.7594\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4333 - val_loss: 0.7590\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4328 - val_loss: 0.7585\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4323 - val_loss: 0.7581\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4318 - val_loss: 0.7576\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4314 - val_loss: 0.7572\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4309 - val_loss: 0.7568\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4305 - val_loss: 0.7564\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4301 - val_loss: 0.7561\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4296 - val_loss: 0.7557\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4292 - val_loss: 0.7554\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4288 - val_loss: 0.7550\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4284 - val_loss: 0.7546\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4280 - val_loss: 0.7543\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4276 - val_loss: 0.7539\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4272 - val_loss: 0.7535\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4268 - val_loss: 0.7532\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4264 - val_loss: 0.7528\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4260 - val_loss: 0.7525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4257 - val_loss: 0.7521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4253 - val_loss: 0.7517\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4249 - val_loss: 0.7514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4245 - val_loss: 0.7511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4242 - val_loss: 0.7508\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4238 - val_loss: 0.7505\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4235 - val_loss: 0.7502\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4231 - val_loss: 0.7499\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4228 - val_loss: 0.7496\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4225 - val_loss: 0.7492\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4221 - val_loss: 0.7489\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4218 - val_loss: 0.7486\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(45, 67), test_y.shape=(45, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 134.01886625392066, my average MASE = 180554408.61752364\n",
      "Cluster 2, 134.01886625392066\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3365 - val_loss: 0.4571\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3346 - val_loss: 0.4566\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3328 - val_loss: 0.4560\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.4555\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3293 - val_loss: 0.4550\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.4544\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3260 - val_loss: 0.4539\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.4534\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3229 - val_loss: 0.4528\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3213 - val_loss: 0.4523\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3197 - val_loss: 0.4518\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3182 - val_loss: 0.4512\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3166 - val_loss: 0.4507\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3152 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3137 - val_loss: 0.4496\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3123 - val_loss: 0.4490\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3109 - val_loss: 0.4485\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3095 - val_loss: 0.4479\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3082 - val_loss: 0.4473\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3070 - val_loss: 0.4468\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3058 - val_loss: 0.4462\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3045 - val_loss: 0.4456\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.4450\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3021 - val_loss: 0.4444\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3009 - val_loss: 0.4438\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2998 - val_loss: 0.4432\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2986 - val_loss: 0.4426\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2974 - val_loss: 0.4420\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2963 - val_loss: 0.4414\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2952 - val_loss: 0.4407\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2940 - val_loss: 0.4401\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2929 - val_loss: 0.4395\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.4389\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2907 - val_loss: 0.4384\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2896 - val_loss: 0.4379\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2885 - val_loss: 0.4373\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2875 - val_loss: 0.4369\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2865 - val_loss: 0.4364\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2854 - val_loss: 0.4359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2844 - val_loss: 0.4355\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.28495017155315366, my average MASE = 0.3992586255016426\n",
      "Cluster 3, 0.28495017155315366\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6320 - val_loss: 1.0222\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6307 - val_loss: 1.0218\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 1.0214\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6284 - val_loss: 1.0211\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6273 - val_loss: 1.0208\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6262 - val_loss: 1.0205\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6252 - val_loss: 1.0201\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6241 - val_loss: 1.0198\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6231 - val_loss: 1.0195\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6221 - val_loss: 1.0192\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6212 - val_loss: 1.0188\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6202 - val_loss: 1.0185\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6193 - val_loss: 1.0182\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6183 - val_loss: 1.0179\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6174 - val_loss: 1.0176\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6166 - val_loss: 1.0172\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6157 - val_loss: 1.0169\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6148 - val_loss: 1.0166\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6139 - val_loss: 1.0162\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6131 - val_loss: 1.0159\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6122 - val_loss: 1.0155\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6114 - val_loss: 1.0152\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6106 - val_loss: 1.0148\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6097 - val_loss: 1.0145\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6089 - val_loss: 1.0141\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6081 - val_loss: 1.0138\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6073 - val_loss: 1.0134\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6066 - val_loss: 1.0131\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6057 - val_loss: 1.0127\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6050 - val_loss: 1.0124\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6042 - val_loss: 1.0121\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6035 - val_loss: 1.0118\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6027 - val_loss: 1.0114\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6020 - val_loss: 1.0111\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6013 - val_loss: 1.0108\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6005 - val_loss: 1.0104\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5998 - val_loss: 1.0101\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5991 - val_loss: 1.0098\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5984 - val_loss: 1.0094\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5977 - val_loss: 1.0091\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 98.33747704062574, my average MASE = 204772160.73570046\n",
      "Cluster 4, 98.33747704062574\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4785 - val_loss: 0.4645\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4760 - val_loss: 0.4629\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4734 - val_loss: 0.4612\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4709 - val_loss: 0.4596\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4684 - val_loss: 0.4580\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4661 - val_loss: 0.4564\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4638 - val_loss: 0.4548\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4615 - val_loss: 0.4532\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4593 - val_loss: 0.4516\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4572 - val_loss: 0.4500\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4551 - val_loss: 0.4484\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4530 - val_loss: 0.4468\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4509 - val_loss: 0.4453\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4489 - val_loss: 0.4438\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4469 - val_loss: 0.4422\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4449 - val_loss: 0.4407\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4429 - val_loss: 0.4393\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4410 - val_loss: 0.4380\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4391 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4371 - val_loss: 0.4354\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4353 - val_loss: 0.4343\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4335 - val_loss: 0.4332\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4317 - val_loss: 0.4322\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4300 - val_loss: 0.4311\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4282 - val_loss: 0.4301\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4265 - val_loss: 0.4291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4248 - val_loss: 0.4281\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 0.4270\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4197 - val_loss: 0.4250\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4181 - val_loss: 0.4240\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4165 - val_loss: 0.4229\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4149 - val_loss: 0.4218\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4134 - val_loss: 0.4208\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4118 - val_loss: 0.4197\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4103 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4088 - val_loss: 0.4176\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.4167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4060 - val_loss: 0.4157\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4046 - val_loss: 0.4148\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 931833756.986838, my average MASE = 2420970654.4710827\n",
      "Cluster 5, 931833756.986838\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4346 - val_loss: 0.4628\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4334 - val_loss: 0.4625\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4323 - val_loss: 0.4621\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4312 - val_loss: 0.4618\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4301 - val_loss: 0.4615\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4290 - val_loss: 0.4612\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4280 - val_loss: 0.4609\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4269 - val_loss: 0.4605\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4259 - val_loss: 0.4602\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4249 - val_loss: 0.4599\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4239 - val_loss: 0.4596\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4228 - val_loss: 0.4593\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4218 - val_loss: 0.4590\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4208 - val_loss: 0.4587\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4198 - val_loss: 0.4584\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4188 - val_loss: 0.4582\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4179 - val_loss: 0.4579\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4169 - val_loss: 0.4576\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4160 - val_loss: 0.4573\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4151 - val_loss: 0.4570\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4141 - val_loss: 0.4567\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4132 - val_loss: 0.4564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4123 - val_loss: 0.4561\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4114 - val_loss: 0.4558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4106 - val_loss: 0.4555\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4097 - val_loss: 0.4552\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4089 - val_loss: 0.4549\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4080 - val_loss: 0.4546\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4072 - val_loss: 0.4544\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4063 - val_loss: 0.4541\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4055 - val_loss: 0.4538\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4047 - val_loss: 0.4536\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4039 - val_loss: 0.4533\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4031 - val_loss: 0.4531\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4023 - val_loss: 0.4529\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4015 - val_loss: 0.4527\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4007 - val_loss: 0.4526\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3999 - val_loss: 0.4524\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3991 - val_loss: 0.4522\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3983 - val_loss: 0.4520\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 806621.4868706047, my average MASE = 27017424.126969155\n",
      "Cluster 6, 806621.4868706047\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8616 - val_loss: 0.8556\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8588 - val_loss: 0.8539\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8561 - val_loss: 0.8522\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8534 - val_loss: 0.8505\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8508 - val_loss: 0.8489\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8484 - val_loss: 0.8472\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8459 - val_loss: 0.8456\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8435 - val_loss: 0.8440\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8412 - val_loss: 0.8424\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8389 - val_loss: 0.8408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8366 - val_loss: 0.8392\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8343 - val_loss: 0.8376\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8320 - val_loss: 0.8361\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8298 - val_loss: 0.8345\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8276 - val_loss: 0.8329\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8254 - val_loss: 0.8314\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8232 - val_loss: 0.8298\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8210 - val_loss: 0.8283\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 0.8267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8168 - val_loss: 0.8253\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8146 - val_loss: 0.8238\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8125 - val_loss: 0.8224\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8104 - val_loss: 0.8210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8084 - val_loss: 0.8197\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8064 - val_loss: 0.8184\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8045 - val_loss: 0.8170\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8025 - val_loss: 0.8157\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8006 - val_loss: 0.8143\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7987 - val_loss: 0.8129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7969 - val_loss: 0.8115\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7950 - val_loss: 0.8102\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7932 - val_loss: 0.8089\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7913 - val_loss: 0.8077\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7894 - val_loss: 0.8065\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7876 - val_loss: 0.8053\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7857 - val_loss: 0.8041\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7839 - val_loss: 0.8030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7821 - val_loss: 0.8019\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7803 - val_loss: 0.8008\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7785 - val_loss: 0.7997\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 964635493.0745914, my average MASE = 2107611139.389815\n",
      "Cluster 7, 964635493.0745914\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3952 - val_loss: 0.3689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3946 - val_loss: 0.3689\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3941 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3935 - val_loss: 0.3687\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3930 - val_loss: 0.3687\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3924 - val_loss: 0.3686\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3919 - val_loss: 0.3685\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3914 - val_loss: 0.3685\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3909 - val_loss: 0.3684\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3903 - val_loss: 0.3684\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3898 - val_loss: 0.3683\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3893 - val_loss: 0.3682\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3888 - val_loss: 0.3682\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3883 - val_loss: 0.3681\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3878 - val_loss: 0.3680\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3873 - val_loss: 0.3680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3869 - val_loss: 0.3679\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3864 - val_loss: 0.3679\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3855 - val_loss: 0.3677\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3850 - val_loss: 0.3677\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3845 - val_loss: 0.3676\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3841 - val_loss: 0.3676\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3836 - val_loss: 0.3675\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3832 - val_loss: 0.3674\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3828 - val_loss: 0.3674\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3823 - val_loss: 0.3673\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3819 - val_loss: 0.3673\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3815 - val_loss: 0.3672\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3811 - val_loss: 0.3672\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3806 - val_loss: 0.3671\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3802 - val_loss: 0.3670\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3798 - val_loss: 0.3670\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.3669\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3790 - val_loss: 0.3669\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3786 - val_loss: 0.3668\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3782 - val_loss: 0.3668\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3778 - val_loss: 0.3667\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3774 - val_loss: 0.3666\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3770 - val_loss: 0.3666\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 51.171495934252626, my average MASE = 30811708.472042836\n",
      "Cluster 8, 51.171495934252626\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4416 - val_loss: 0.4387\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4409 - val_loss: 0.4386\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4402 - val_loss: 0.4384\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4395 - val_loss: 0.4383\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4388 - val_loss: 0.4381\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4382 - val_loss: 0.4380\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4375 - val_loss: 0.4379\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4368 - val_loss: 0.4377\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4362 - val_loss: 0.4376\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4355 - val_loss: 0.4375\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4348 - val_loss: 0.4373\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4342 - val_loss: 0.4372\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4335 - val_loss: 0.4371\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4329 - val_loss: 0.4370\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4323 - val_loss: 0.4368\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4316 - val_loss: 0.4367\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4310 - val_loss: 0.4366\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4304 - val_loss: 0.4365\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4298 - val_loss: 0.4364\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4292 - val_loss: 0.4363\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4286 - val_loss: 0.4362\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4280 - val_loss: 0.4361\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4274 - val_loss: 0.4359\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4268 - val_loss: 0.4358\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4262 - val_loss: 0.4357\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4256 - val_loss: 0.4356\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4250 - val_loss: 0.4355\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4245 - val_loss: 0.4354\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4239 - val_loss: 0.4353\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4352\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4227 - val_loss: 0.4351\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4221 - val_loss: 0.4350\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.4349\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4348\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4204 - val_loss: 0.4347\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4199 - val_loss: 0.4346\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4193 - val_loss: 0.4345\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4187 - val_loss: 0.4345\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4182 - val_loss: 0.4344\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4176 - val_loss: 0.4343\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 67.68630348587587, my average MASE = 34346224.36796317\n",
      "Cluster 9, 67.68630348587587\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=2, 2, 18, (30610, 67)\n",
      "Before prediction: train_X.shape=(18359, 10, 67), train_y.shape=(18359, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3046 - val_loss: 0.3213\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2853 - val_loss: 0.3058\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2698 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2588 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2516 - val_loss: 0.2788\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2460 - val_loss: 0.2736\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2412 - val_loss: 0.2691\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2371 - val_loss: 0.2652\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2335 - val_loss: 0.2618\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2301 - val_loss: 0.2588\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2271 - val_loss: 0.2562\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2243 - val_loss: 0.2538\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2219 - val_loss: 0.2516\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2199 - val_loss: 0.2498\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2181 - val_loss: 0.2483\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2166 - val_loss: 0.2469\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2153 - val_loss: 0.2458\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2142 - val_loss: 0.2448\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2122 - val_loss: 0.2430\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2114 - val_loss: 0.2422\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2106 - val_loss: 0.2414\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2099 - val_loss: 0.2407\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2092 - val_loss: 0.2401\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2086 - val_loss: 0.2395\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2080 - val_loss: 0.2389\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2074 - val_loss: 0.2385\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2069 - val_loss: 0.2380\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2064 - val_loss: 0.2376\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2059 - val_loss: 0.2370\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2054 - val_loss: 0.2367\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2050 - val_loss: 0.2362\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2046 - val_loss: 0.2359\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2042 - val_loss: 0.2356\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2038 - val_loss: 0.2351\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2034 - val_loss: 0.2349\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2031 - val_loss: 0.2345\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2021 - val_loss: 0.2337\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1675.644817755528, my average MASE = 2652.7812514268226\n",
      "Cluster 0, 1675.644817755528\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4228 - val_loss: 1.1321\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4209 - val_loss: 1.1320\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4191 - val_loss: 1.1319\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4173 - val_loss: 1.1318\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 1.1317\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4139 - val_loss: 1.1315\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4122 - val_loss: 1.1314\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4106 - val_loss: 1.1313\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4090 - val_loss: 1.1311\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4075 - val_loss: 1.1310\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4059 - val_loss: 1.1308\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4044 - val_loss: 1.1306\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4030 - val_loss: 1.1304\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4015 - val_loss: 1.1302\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4001 - val_loss: 1.1300\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 1.1298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3973 - val_loss: 1.1296\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3960 - val_loss: 1.1294\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3946 - val_loss: 1.1292\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3933 - val_loss: 1.1290\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 1.1288\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3907 - val_loss: 1.1286\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3895 - val_loss: 1.1283\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3883 - val_loss: 1.1281\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3871 - val_loss: 1.1279\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 1.1277\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3847 - val_loss: 1.1275\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3836 - val_loss: 1.1272\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3825 - val_loss: 1.1270\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3814 - val_loss: 1.1268\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3803 - val_loss: 1.1266\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3792 - val_loss: 1.1264\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3781 - val_loss: 1.1262\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3771 - val_loss: 1.1259\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3761 - val_loss: 1.1257\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3750 - val_loss: 1.1255\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3740 - val_loss: 1.1253\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 1.1251\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3721 - val_loss: 1.1249\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3711 - val_loss: 1.1247\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 993839931.13901, my average MASE = 2723871222.022616\n",
      "Cluster 1, 993839931.13901\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=5, 5, 75, (319, 67)\n",
      "Before prediction: train_X.shape=(185, 10, 67), train_y.shape=(185, 67), test_X.shape=(62, 10, 67), test_y.shape=(62, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6944 - val_loss: 0.6444\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6929 - val_loss: 0.6434\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6914 - val_loss: 0.6425\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6901 - val_loss: 0.6415\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6887 - val_loss: 0.6406\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6874 - val_loss: 0.6397\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6860 - val_loss: 0.6388\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6847 - val_loss: 0.6380\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6834 - val_loss: 0.6372\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6822 - val_loss: 0.6363\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6810 - val_loss: 0.6355\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6798 - val_loss: 0.6347\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.6340\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6775 - val_loss: 0.6332\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.6325\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6753 - val_loss: 0.6318\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6742 - val_loss: 0.6310\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6732 - val_loss: 0.6303\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6721 - val_loss: 0.6296\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6711 - val_loss: 0.6289\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6701 - val_loss: 0.6283\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6692 - val_loss: 0.6276\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6682 - val_loss: 0.6270\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6672 - val_loss: 0.6263\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6663 - val_loss: 0.6257\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6654 - val_loss: 0.6251\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.6244\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6636 - val_loss: 0.6238\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6627 - val_loss: 0.6232\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6618 - val_loss: 0.6226\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6610 - val_loss: 0.6220\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6601 - val_loss: 0.6214\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6593 - val_loss: 0.6208\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6584 - val_loss: 0.6202\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6576 - val_loss: 0.6196\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6568 - val_loss: 0.6191\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6559 - val_loss: 0.6185\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6551 - val_loss: 0.6179\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6543 - val_loss: 0.6173\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6535 - val_loss: 0.6167\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(62, 67), test_y.shape=(62, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 141.38884780958514, my average MASE = 173942620.82410374\n",
      "Cluster 0, 141.38884780958514\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0665 - val_loss: 0.0455\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0607 - val_loss: 0.0424\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0575 - val_loss: 0.0402\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0551 - val_loss: 0.0384\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0531 - val_loss: 0.0370\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0515 - val_loss: 0.0358\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0502 - val_loss: 0.0347\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0491 - val_loss: 0.0338\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0481 - val_loss: 0.0331\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0473 - val_loss: 0.0324\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0466 - val_loss: 0.0319\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0460 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0454 - val_loss: 0.0311\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0449 - val_loss: 0.0307\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0304\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0301\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0437 - val_loss: 0.0299\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0433 - val_loss: 0.0297\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0294\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0292\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0424 - val_loss: 0.0290\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0422 - val_loss: 0.0288\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0420 - val_loss: 0.0287\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0418 - val_loss: 0.0285\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0416 - val_loss: 0.0284\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0414 - val_loss: 0.0283\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0412 - val_loss: 0.0281\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0411 - val_loss: 0.0280\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0279\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0278\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0278\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0277\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0276\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0403 - val_loss: 0.0276\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0275\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0401 - val_loss: 0.0274\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0274\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0273\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0273\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0272\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1157555182.6490364, my average MASE = 73085160895.13536\n",
      "Cluster 1, 1157555182.6490364\n",
      "Before prediction: train_X.shape=(37, 10, 67), train_y.shape=(37, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5516 - val_loss: 0.5380\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5498 - val_loss: 0.5365\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5480 - val_loss: 0.5350\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5462 - val_loss: 0.5335\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5444 - val_loss: 0.5321\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5427 - val_loss: 0.5306\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5410 - val_loss: 0.5292\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5393 - val_loss: 0.5278\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5376 - val_loss: 0.5264\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5360 - val_loss: 0.5250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5343 - val_loss: 0.5237\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5328 - val_loss: 0.5223\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5312 - val_loss: 0.5210\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5297 - val_loss: 0.5197\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5281 - val_loss: 0.5184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5266 - val_loss: 0.5171\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5252 - val_loss: 0.5158\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5237 - val_loss: 0.5146\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5223 - val_loss: 0.5133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5208 - val_loss: 0.5121\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5194 - val_loss: 0.5109\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5181 - val_loss: 0.5098\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5167 - val_loss: 0.5086\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5154 - val_loss: 0.5075\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5141 - val_loss: 0.5063\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5128 - val_loss: 0.5052\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5115 - val_loss: 0.5041\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5103 - val_loss: 0.5031\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5091 - val_loss: 0.5020\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5078 - val_loss: 0.5010\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.5000\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5055 - val_loss: 0.4990\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5043 - val_loss: 0.4980\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5031 - val_loss: 0.4970\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5020 - val_loss: 0.4961\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5008 - val_loss: 0.4952\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.4943\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4986 - val_loss: 0.4934\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4975 - val_loss: 0.4926\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4964 - val_loss: 0.4917\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4324881186.205308, my average MASE = 10393885205.318085\n",
      "Cluster 2, 4324881186.205308\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4066 - val_loss: 0.3845\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4060 - val_loss: 0.3840\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.3836\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4048 - val_loss: 0.3831\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4042 - val_loss: 0.3826\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4036 - val_loss: 0.3822\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 0.3817\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4025 - val_loss: 0.3812\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4019 - val_loss: 0.3808\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4014 - val_loss: 0.3803\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3799\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4003 - val_loss: 0.3795\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3791\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3992 - val_loss: 0.3787\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 0.3783\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3982 - val_loss: 0.3779\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3977 - val_loss: 0.3775\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.3772\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3966 - val_loss: 0.3768\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3764\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3956 - val_loss: 0.3761\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3757\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3946 - val_loss: 0.3754\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3942 - val_loss: 0.3751\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3937 - val_loss: 0.3747\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3932 - val_loss: 0.3744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3927 - val_loss: 0.3741\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3922 - val_loss: 0.3738\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3918 - val_loss: 0.3735\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3913 - val_loss: 0.3732\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3908 - val_loss: 0.3729\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3903 - val_loss: 0.3726\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.3723\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3894 - val_loss: 0.3720\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3890 - val_loss: 0.3718\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3885 - val_loss: 0.3715\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3881 - val_loss: 0.3712\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3877 - val_loss: 0.3709\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3872 - val_loss: 0.3706\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3868 - val_loss: 0.3704\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n",
      "average MASE = 1110146.2653270473, my average MASE = 43278995.990564056\n",
      "Cluster 3, 1110146.2653270473\n",
      "Before prediction: train_X.shape=(25, 10, 67), train_y.shape=(25, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5208 - val_loss: 0.4711\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5196 - val_loss: 0.4707\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5184 - val_loss: 0.4702\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5173 - val_loss: 0.4698\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5161 - val_loss: 0.4694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5150 - val_loss: 0.4690\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4686\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5127 - val_loss: 0.4682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5116 - val_loss: 0.4678\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5105 - val_loss: 0.4675\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5094 - val_loss: 0.4671\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5084 - val_loss: 0.4667\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5073 - val_loss: 0.4664\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5063 - val_loss: 0.4660\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5052 - val_loss: 0.4657\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5042 - val_loss: 0.4654\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5031 - val_loss: 0.4651\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4648\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5011 - val_loss: 0.4645\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5001 - val_loss: 0.4643\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4991 - val_loss: 0.4641\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.4638\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4971 - val_loss: 0.4636\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4962 - val_loss: 0.4634\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.4632\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4942 - val_loss: 0.4629\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4933 - val_loss: 0.4627\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4923 - val_loss: 0.4625\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4914 - val_loss: 0.4623\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4904 - val_loss: 0.4621\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4895 - val_loss: 0.4619\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4886 - val_loss: 0.4617\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4876 - val_loss: 0.4616\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4867 - val_loss: 0.4614\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4858 - val_loss: 0.4613\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4849 - val_loss: 0.4611\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4841 - val_loss: 0.4610\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4608\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4823 - val_loss: 0.4607\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4815 - val_loss: 0.4605\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 111.6892159594304, my average MASE = 112347014.53903662\n",
      "Cluster 4, 111.6892159594304\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=7, 7, 884, (12, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0672 - val_loss: 0.0440\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0611 - val_loss: 0.0410\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0576 - val_loss: 0.0390\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0552 - val_loss: 0.0374\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0533 - val_loss: 0.0361\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0517 - val_loss: 0.0350\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0504 - val_loss: 0.0340\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0493 - val_loss: 0.0332\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0484 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0476 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0469 - val_loss: 0.0313\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0462 - val_loss: 0.0308\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0457 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0447 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0442 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0435 - val_loss: 0.0287\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0285\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0283\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0281\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0280\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0278\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0277\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0275\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0274\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0273\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0411 - val_loss: 0.0271\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0270\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0408 - val_loss: 0.0269\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0268\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0267\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0405 - val_loss: 0.0266\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0403 - val_loss: 0.0265\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0401 - val_loss: 0.0264\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0263\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0399 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1103404601.9868512, my average MASE = 55700347192.937294\n",
      "Cluster 1, 1103404601.9868512\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5205 - val_loss: 0.4218\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5186 - val_loss: 0.4208\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5167 - val_loss: 0.4198\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5148 - val_loss: 0.4189\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5129 - val_loss: 0.4179\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5111 - val_loss: 0.4170\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5093 - val_loss: 0.4161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5074 - val_loss: 0.4152\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5057 - val_loss: 0.4143\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5039 - val_loss: 0.4134\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5022 - val_loss: 0.4125\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5004 - val_loss: 0.4117\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4987 - val_loss: 0.4108\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4971 - val_loss: 0.4100\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4954 - val_loss: 0.4092\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4938 - val_loss: 0.4083\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4922 - val_loss: 0.4075\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4906 - val_loss: 0.4067\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4890 - val_loss: 0.4060\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4875 - val_loss: 0.4052\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4860 - val_loss: 0.4044\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4845 - val_loss: 0.4036\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4830 - val_loss: 0.4028\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4815 - val_loss: 0.4021\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4800 - val_loss: 0.4013\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4771 - val_loss: 0.3999\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4757 - val_loss: 0.3992\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4743 - val_loss: 0.3985\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4730 - val_loss: 0.3978\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4716 - val_loss: 0.3971\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4703 - val_loss: 0.3964\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4689 - val_loss: 0.3958\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.3951\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.3945\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4650 - val_loss: 0.3939\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4637 - val_loss: 0.3932\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4625 - val_loss: 0.3926\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4612 - val_loss: 0.3920\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4600 - val_loss: 0.3913\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3560489905.356454, my average MASE = 9030960108.787361\n",
      "Cluster 2, 3560489905.356454\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3774 - val_loss: 0.3465\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3767 - val_loss: 0.3460\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3759 - val_loss: 0.3456\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3752 - val_loss: 0.3452\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3744 - val_loss: 0.3448\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3737 - val_loss: 0.3444\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 0.3440\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3723 - val_loss: 0.3436\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3716 - val_loss: 0.3432\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3710 - val_loss: 0.3429\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3703 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3696 - val_loss: 0.3421\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.3418\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3683 - val_loss: 0.3415\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3411\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3671 - val_loss: 0.3408\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3665 - val_loss: 0.3405\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3659 - val_loss: 0.3401\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3653 - val_loss: 0.3398\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3647 - val_loss: 0.3395\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3641 - val_loss: 0.3392\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3635 - val_loss: 0.3389\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3630 - val_loss: 0.3386\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.3383\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.3380\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3613 - val_loss: 0.3377\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3608 - val_loss: 0.3374\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3602 - val_loss: 0.3371\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3597 - val_loss: 0.3368\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3592 - val_loss: 0.3365\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3362\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3581 - val_loss: 0.3359\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3576 - val_loss: 0.3356\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3571 - val_loss: 0.3353\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3566 - val_loss: 0.3350\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3561 - val_loss: 0.3347\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3556 - val_loss: 0.3344\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3551 - val_loss: 0.3342\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3546 - val_loss: 0.3339\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3541 - val_loss: 0.3336\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 332.8608286989534, my average MASE = 85442913.95523748\n",
      "Cluster 3, 332.8608286989534\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7187 - val_loss: 0.5712\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7172 - val_loss: 0.5706\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7158 - val_loss: 0.5700\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7145 - val_loss: 0.5694\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7132 - val_loss: 0.5688\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7119 - val_loss: 0.5682\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7107 - val_loss: 0.5677\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7095 - val_loss: 0.5671\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7083 - val_loss: 0.5666\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7071 - val_loss: 0.5660\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7060 - val_loss: 0.5655\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7049 - val_loss: 0.5650\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7038 - val_loss: 0.5646\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7028 - val_loss: 0.5641\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7018 - val_loss: 0.5636\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7008 - val_loss: 0.5631\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6999 - val_loss: 0.5627\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6989 - val_loss: 0.5622\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6980 - val_loss: 0.5618\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6971 - val_loss: 0.5613\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5609\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6953 - val_loss: 0.5604\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6944 - val_loss: 0.5600\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6935 - val_loss: 0.5596\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6927 - val_loss: 0.5592\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6918 - val_loss: 0.5587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6910 - val_loss: 0.5583\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6902 - val_loss: 0.5579\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6894 - val_loss: 0.5576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6886 - val_loss: 0.5572\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6878 - val_loss: 0.5568\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5564\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6862 - val_loss: 0.5560\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6854 - val_loss: 0.5557\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6846 - val_loss: 0.5553\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6839 - val_loss: 0.5549\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6831 - val_loss: 0.5546\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6824 - val_loss: 0.5542\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6816 - val_loss: 0.5538\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6809 - val_loss: 0.5535\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.45484282658396, my average MASE = 350849744.5231373\n",
      "Cluster 4, 139.45484282658396\n",
      "Before prediction: train_X.shape=(133, 10, 67), train_y.shape=(133, 67), test_X.shape=(44, 10, 67), test_y.shape=(44, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4266 - val_loss: 0.6651\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4259 - val_loss: 0.6645\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4253 - val_loss: 0.6639\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4247 - val_loss: 0.6633\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4242 - val_loss: 0.6628\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4236 - val_loss: 0.6623\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4231 - val_loss: 0.6618\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4226 - val_loss: 0.6613\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4221 - val_loss: 0.6608\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4216 - val_loss: 0.6603\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4211 - val_loss: 0.6599\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4206 - val_loss: 0.6594\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4201 - val_loss: 0.6590\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4197 - val_loss: 0.6585\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4192 - val_loss: 0.6581\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4188 - val_loss: 0.6576\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4184 - val_loss: 0.6572\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4180 - val_loss: 0.6568\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4175 - val_loss: 0.6564\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4171 - val_loss: 0.6559\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4167 - val_loss: 0.6554\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4163 - val_loss: 0.6550\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4159 - val_loss: 0.6545\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4155 - val_loss: 0.6541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4151 - val_loss: 0.6537\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4147 - val_loss: 0.6533\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4143 - val_loss: 0.6529\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4139 - val_loss: 0.6525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4135 - val_loss: 0.6521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4131 - val_loss: 0.6518\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4128 - val_loss: 0.6514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4124 - val_loss: 0.6511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4120 - val_loss: 0.6507\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4117 - val_loss: 0.6504\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4114 - val_loss: 0.6501\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4110 - val_loss: 0.6498\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4107 - val_loss: 0.6494\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4103 - val_loss: 0.6491\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4100 - val_loss: 0.6487\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4096 - val_loss: 0.6484\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(44, 67), test_y.shape=(44, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 116.65244791791511, my average MASE = 142786035.78420427\n",
      "Cluster 5, 116.65244791791511\n",
      "Before prediction: train_X.shape=(78, 10, 67), train_y.shape=(78, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4078 - val_loss: 0.4868\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4070 - val_loss: 0.4862\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4062 - val_loss: 0.4856\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4055 - val_loss: 0.4850\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4048 - val_loss: 0.4845\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4041 - val_loss: 0.4839\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.4833\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4828\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4021 - val_loss: 0.4823\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4015 - val_loss: 0.4818\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4008 - val_loss: 0.4813\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4002 - val_loss: 0.4808\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3997 - val_loss: 0.4803\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3991 - val_loss: 0.4798\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3985 - val_loss: 0.4794\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3980 - val_loss: 0.4789\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3974 - val_loss: 0.4785\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3969 - val_loss: 0.4780\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3964 - val_loss: 0.4776\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4772\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3954 - val_loss: 0.4768\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3949 - val_loss: 0.4764\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3944 - val_loss: 0.4760\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.4757\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3934 - val_loss: 0.4753\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3930 - val_loss: 0.4750\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3925 - val_loss: 0.4747\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3921 - val_loss: 0.4743\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3916 - val_loss: 0.4740\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3912 - val_loss: 0.4737\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3907 - val_loss: 0.4733\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3903 - val_loss: 0.4730\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.4727\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3895 - val_loss: 0.4724\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3890 - val_loss: 0.4721\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3886 - val_loss: 0.4718\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4715\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3878 - val_loss: 0.4712\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.4709\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3870 - val_loss: 0.4706\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 221.65144919995234, my average MASE = 102271349.10812314\n",
      "Cluster 6, 221.65144919995234\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=9, 9, 14, (3245, 67)\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1141 - val_loss: 0.1031\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1086 - val_loss: 0.1010\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1042 - val_loss: 0.0995\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1005 - val_loss: 0.0982\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0973 - val_loss: 0.0973\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0945 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0920 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0897 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0877 - val_loss: 0.0950\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0858 - val_loss: 0.0947\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0841 - val_loss: 0.0943\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0826 - val_loss: 0.0941\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0812 - val_loss: 0.0938\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0798 - val_loss: 0.0935\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0786 - val_loss: 0.0933\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0930\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0765 - val_loss: 0.0928\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0755 - val_loss: 0.0926\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0746 - val_loss: 0.0925\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0737 - val_loss: 0.0923\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0729 - val_loss: 0.0921\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0722 - val_loss: 0.0920\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0715 - val_loss: 0.0919\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0708 - val_loss: 0.0917\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0916\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0915\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0691 - val_loss: 0.0914\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0686 - val_loss: 0.0913\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0681 - val_loss: 0.0912\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0676 - val_loss: 0.0911\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0910\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0668 - val_loss: 0.0910\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0664 - val_loss: 0.0909\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0660 - val_loss: 0.0909\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0656 - val_loss: 0.0908\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0653 - val_loss: 0.0908\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0650 - val_loss: 0.0907\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0647 - val_loss: 0.0907\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0644 - val_loss: 0.0907\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0906\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1289233887.8234715, my average MASE = 15636865244.557127\n",
      "Cluster 0, 1289233887.8234715\n",
      "Before prediction: train_X.shape=(29, 10, 67), train_y.shape=(29, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4693 - val_loss: 0.6570\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4687 - val_loss: 0.6567\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4680 - val_loss: 0.6563\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4674 - val_loss: 0.6560\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4668 - val_loss: 0.6557\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4662 - val_loss: 0.6554\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4656 - val_loss: 0.6551\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4650 - val_loss: 0.6548\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4644 - val_loss: 0.6545\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4638 - val_loss: 0.6542\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4633 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4627 - val_loss: 0.6536\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4621 - val_loss: 0.6533\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.6530\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4610 - val_loss: 0.6527\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4605 - val_loss: 0.6524\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4599 - val_loss: 0.6521\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4594 - val_loss: 0.6519\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4588 - val_loss: 0.6516\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4583 - val_loss: 0.6513\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4578 - val_loss: 0.6510\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4573 - val_loss: 0.6508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4568 - val_loss: 0.6505\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4563 - val_loss: 0.6502\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4558 - val_loss: 0.6499\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4553 - val_loss: 0.6496\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4548 - val_loss: 0.6493\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4543 - val_loss: 0.6491\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4538 - val_loss: 0.6488\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4533 - val_loss: 0.6485\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4528 - val_loss: 0.6483\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4524 - val_loss: 0.6480\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4519 - val_loss: 0.6478\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4514 - val_loss: 0.6475\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4510 - val_loss: 0.6473\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4505 - val_loss: 0.6470\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4500 - val_loss: 0.6468\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4496 - val_loss: 0.6465\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4492 - val_loss: 0.6463\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.6460\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 10049120.449906044, my average MASE = 246733533.9412494\n",
      "Cluster 1, 10049120.449906044\n",
      "Before prediction: train_X.shape=(1564, 10, 67), train_y.shape=(1564, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2359 - val_loss: 0.2748\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2264 - val_loss: 0.2656\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2192 - val_loss: 0.2584\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2135 - val_loss: 0.2523\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2087 - val_loss: 0.2471\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2045 - val_loss: 0.2424\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2007 - val_loss: 0.2382\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1973 - val_loss: 0.2342\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1941 - val_loss: 0.2307\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1912 - val_loss: 0.2273\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1884 - val_loss: 0.2242\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1858 - val_loss: 0.2214\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1833 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1810 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1789 - val_loss: 0.2140\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1769 - val_loss: 0.2119\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1750 - val_loss: 0.2100\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1733 - val_loss: 0.2082\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1717 - val_loss: 0.2066\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1702 - val_loss: 0.2051\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1689 - val_loss: 0.2038\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1677 - val_loss: 0.2024\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2012\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2001\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1645 - val_loss: 0.1989\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1979\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1627 - val_loss: 0.1969\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1619 - val_loss: 0.1959\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1611 - val_loss: 0.1950\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1603 - val_loss: 0.1941\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1596 - val_loss: 0.1933\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1589 - val_loss: 0.1925\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1582 - val_loss: 0.1917\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1576 - val_loss: 0.1910\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1570 - val_loss: 0.1903\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1564 - val_loss: 0.1895\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1558 - val_loss: 0.1889\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1553 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1548 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1543 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 187.65491616156584, my average MASE = 1727876346.7517292\n",
      "Cluster 2, 187.65491616156584\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5179 - val_loss: 0.4772\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5158 - val_loss: 0.4757\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4743\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5118 - val_loss: 0.4729\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5098 - val_loss: 0.4715\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5079 - val_loss: 0.4701\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5059 - val_loss: 0.4687\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5040 - val_loss: 0.4673\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4660\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5002 - val_loss: 0.4646\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4984 - val_loss: 0.4633\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4966 - val_loss: 0.4620\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4948 - val_loss: 0.4607\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4931 - val_loss: 0.4594\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4913 - val_loss: 0.4581\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4896 - val_loss: 0.4568\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4879 - val_loss: 0.4555\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4862 - val_loss: 0.4543\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4845 - val_loss: 0.4531\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4828 - val_loss: 0.4518\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4812 - val_loss: 0.4506\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4795 - val_loss: 0.4495\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4779 - val_loss: 0.4483\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4763 - val_loss: 0.4471\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4747 - val_loss: 0.4460\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4731 - val_loss: 0.4449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4716 - val_loss: 0.4438\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4700 - val_loss: 0.4427\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4685 - val_loss: 0.4416\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4670 - val_loss: 0.4405\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4655 - val_loss: 0.4395\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4640 - val_loss: 0.4385\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4626 - val_loss: 0.4374\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4611 - val_loss: 0.4364\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4597 - val_loss: 0.4354\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4582 - val_loss: 0.4344\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4568 - val_loss: 0.4334\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4555 - val_loss: 0.4324\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4541 - val_loss: 0.4314\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4527 - val_loss: 0.4304\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3258333520.23763, my average MASE = 7487984704.271554\n",
      "Cluster 3, 3258333520.23763\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3367 - val_loss: 0.3564\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3362 - val_loss: 0.3564\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3356 - val_loss: 0.3564\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3351 - val_loss: 0.3563\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3346 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3340 - val_loss: 0.3563\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3335 - val_loss: 0.3563\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3330 - val_loss: 0.3562\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3325 - val_loss: 0.3562\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3319 - val_loss: 0.3562\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3314 - val_loss: 0.3561\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3309 - val_loss: 0.3561\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3304 - val_loss: 0.3561\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3560\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3294 - val_loss: 0.3560\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3289 - val_loss: 0.3560\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.3559\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3280 - val_loss: 0.3559\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3275 - val_loss: 0.3559\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3270 - val_loss: 0.3559\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3266 - val_loss: 0.3558\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3261 - val_loss: 0.3558\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3256 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3252 - val_loss: 0.3558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3248 - val_loss: 0.3558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3243 - val_loss: 0.3557\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3239 - val_loss: 0.3557\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.3557\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3230 - val_loss: 0.3557\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3226 - val_loss: 0.3557\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3222 - val_loss: 0.3556\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3218 - val_loss: 0.3556\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3214 - val_loss: 0.3556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3556\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3205 - val_loss: 0.3556\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3201 - val_loss: 0.3556\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.3556\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3193 - val_loss: 0.3555\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3189 - val_loss: 0.3555\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3185 - val_loss: 0.3555\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 544.8910068645505, my average MASE = 25915172.7591836\n",
      "Cluster 4, 544.8910068645505\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5189 - val_loss: 0.8510\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5183 - val_loss: 0.8507\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5176 - val_loss: 0.8503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5170 - val_loss: 0.8500\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5163 - val_loss: 0.8496\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5157 - val_loss: 0.8493\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5151 - val_loss: 0.8490\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5145 - val_loss: 0.8487\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5138 - val_loss: 0.8484\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5132 - val_loss: 0.8481\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5126 - val_loss: 0.8478\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5120 - val_loss: 0.8476\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5114 - val_loss: 0.8473\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5108 - val_loss: 0.8471\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5102 - val_loss: 0.8468\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5096 - val_loss: 0.8466\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5090 - val_loss: 0.8463\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5084 - val_loss: 0.8461\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5078 - val_loss: 0.8458\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5072 - val_loss: 0.8456\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.8454\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5060 - val_loss: 0.8451\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5055 - val_loss: 0.8449\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5049 - val_loss: 0.8447\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5043 - val_loss: 0.8445\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5038 - val_loss: 0.8443\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5032 - val_loss: 0.8441\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5027 - val_loss: 0.8439\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5021 - val_loss: 0.8437\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5016 - val_loss: 0.8435\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5010 - val_loss: 0.8433\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5005 - val_loss: 0.8431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4999 - val_loss: 0.8429\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4994 - val_loss: 0.8428\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4989 - val_loss: 0.8426\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4983 - val_loss: 0.8424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4978 - val_loss: 0.8422\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4973 - val_loss: 0.8420\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4967 - val_loss: 0.8419\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4962 - val_loss: 0.8417\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1963484.3822421303, my average MASE = 64800710.430740915\n",
      "Cluster 5, 1963484.3822421303\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8495 - val_loss: 4.3516\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8473 - val_loss: 4.3510\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8451 - val_loss: 4.3503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8429 - val_loss: 4.3497\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8408 - val_loss: 4.3491\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8386 - val_loss: 4.3485\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8365 - val_loss: 4.3479\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8344 - val_loss: 4.3473\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8323 - val_loss: 4.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8301 - val_loss: 4.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8280 - val_loss: 4.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8259 - val_loss: 4.3451\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8238 - val_loss: 4.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8217 - val_loss: 4.3440\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8197 - val_loss: 4.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8176 - val_loss: 4.3428\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8156 - val_loss: 4.3423\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8136 - val_loss: 4.3417\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8117 - val_loss: 4.3412\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8098 - val_loss: 4.3407\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 4.3403\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8061 - val_loss: 4.3399\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8042 - val_loss: 4.3395\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8023 - val_loss: 4.3390\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8004 - val_loss: 4.3386\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7986 - val_loss: 4.3382\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7967 - val_loss: 4.3378\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7949 - val_loss: 4.3374\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7930 - val_loss: 4.3370\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7912 - val_loss: 4.3365\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7893 - val_loss: 4.3361\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7874 - val_loss: 4.3357\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7856 - val_loss: 4.3353\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7839 - val_loss: 4.3349\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7822 - val_loss: 4.3345\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7805 - val_loss: 4.3341\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7787 - val_loss: 4.3338\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7771 - val_loss: 4.3334\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7754 - val_loss: 4.3330\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7738 - val_loss: 4.3327\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4.116072897890656, my average MASE = 12.21206426084865\n",
      "Cluster 6, 4.116072897890656\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3660 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3652 - val_loss: 0.3455\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3645 - val_loss: 0.3451\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3638 - val_loss: 0.3448\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3632 - val_loss: 0.3445\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3625 - val_loss: 0.3441\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3619 - val_loss: 0.3438\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3435\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3606 - val_loss: 0.3431\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3599 - val_loss: 0.3428\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3593 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3422\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3581 - val_loss: 0.3419\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3576 - val_loss: 0.3416\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3570 - val_loss: 0.3413\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3564 - val_loss: 0.3410\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3558 - val_loss: 0.3407\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3553 - val_loss: 0.3404\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3547 - val_loss: 0.3401\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3542 - val_loss: 0.3398\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3536 - val_loss: 0.3395\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3531 - val_loss: 0.3393\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3526 - val_loss: 0.3390\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3521 - val_loss: 0.3387\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3516 - val_loss: 0.3384\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3511 - val_loss: 0.3382\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3506 - val_loss: 0.3379\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3501 - val_loss: 0.3376\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3496 - val_loss: 0.3373\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3491 - val_loss: 0.3371\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3487 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3482 - val_loss: 0.3366\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3477 - val_loss: 0.3363\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3473 - val_loss: 0.3360\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3464 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3459 - val_loss: 0.3353\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3455 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3451 - val_loss: 0.3348\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3446 - val_loss: 0.3345\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 266.09609302896547, my average MASE = 71685898.00003502\n",
      "Cluster 8, 266.09609302896547\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=11, 11, 663, (11, 67)\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3610 - val_loss: 0.4969\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3601 - val_loss: 0.4969\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3592 - val_loss: 0.4970\n",
      "Epoch 3: early stopping\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.35712691602972574, my average MASE = 0.5241910168311086\n",
      "Cluster 0, 0.35712691602972574\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2752 - val_loss: 0.2714\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2747 - val_loss: 0.2712\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2742 - val_loss: 0.2710\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2737 - val_loss: 0.2707\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2733 - val_loss: 0.2705\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2728 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2723 - val_loss: 0.2701\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2718 - val_loss: 0.2699\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2714 - val_loss: 0.2697\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2709 - val_loss: 0.2695\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2704 - val_loss: 0.2693\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2700 - val_loss: 0.2691\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2695 - val_loss: 0.2690\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2691 - val_loss: 0.2688\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2687 - val_loss: 0.2686\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2682 - val_loss: 0.2684\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2678 - val_loss: 0.2682\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2673 - val_loss: 0.2680\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2669 - val_loss: 0.2678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2665 - val_loss: 0.2676\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2661 - val_loss: 0.2674\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.2672\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2653 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2649 - val_loss: 0.2669\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2645 - val_loss: 0.2667\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2641 - val_loss: 0.2665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2637 - val_loss: 0.2663\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2633 - val_loss: 0.2662\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2629 - val_loss: 0.2660\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2625 - val_loss: 0.2658\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2621 - val_loss: 0.2656\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2618 - val_loss: 0.2655\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2614 - val_loss: 0.2653\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2610 - val_loss: 0.2652\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2606 - val_loss: 0.2650\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2602 - val_loss: 0.2649\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2599 - val_loss: 0.2647\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2595 - val_loss: 0.2646\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2591 - val_loss: 0.2644\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2588 - val_loss: 0.2643\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 114.92828938190037, my average MASE = 64775351.69732988\n",
      "Cluster 1, 114.92828938190037\n",
      "Before prediction: train_X.shape=(21, 10, 67), train_y.shape=(21, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6587 - val_loss: 0.2666\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6569 - val_loss: 0.2655\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6551 - val_loss: 0.2645\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6533 - val_loss: 0.2635\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6515 - val_loss: 0.2624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6497 - val_loss: 0.2614\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6480 - val_loss: 0.2604\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6463 - val_loss: 0.2594\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6446 - val_loss: 0.2584\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6429 - val_loss: 0.2574\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6412 - val_loss: 0.2565\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6395 - val_loss: 0.2555\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6379 - val_loss: 0.2546\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6363 - val_loss: 0.2538\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6346 - val_loss: 0.2529\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6331 - val_loss: 0.2520\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6315 - val_loss: 0.2512\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6300 - val_loss: 0.2504\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6285 - val_loss: 0.2496\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6270 - val_loss: 0.2488\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6255 - val_loss: 0.2480\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6240 - val_loss: 0.2473\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6225 - val_loss: 0.2466\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6211 - val_loss: 0.2458\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6197 - val_loss: 0.2451\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6182 - val_loss: 0.2444\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6168 - val_loss: 0.2437\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6155 - val_loss: 0.2430\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6141 - val_loss: 0.2423\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6127 - val_loss: 0.2416\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6114 - val_loss: 0.2410\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6101 - val_loss: 0.2403\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6088 - val_loss: 0.2397\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6075 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6063 - val_loss: 0.2384\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6050 - val_loss: 0.2378\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6038 - val_loss: 0.2372\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6026 - val_loss: 0.2365\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6014 - val_loss: 0.2359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6002 - val_loss: 0.2353\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 26456338.054780327, my average MASE = 1170397376.6808207\n",
      "Cluster 2, 26456338.054780327\n",
      "Before prediction: train_X.shape=(62, 10, 67), train_y.shape=(62, 67), test_X.shape=(21, 10, 67), test_y.shape=(21, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3828 - val_loss: 0.5067\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3824 - val_loss: 0.5064\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3820 - val_loss: 0.5062\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3816 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3812 - val_loss: 0.5056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3808 - val_loss: 0.5053\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3804 - val_loss: 0.5051\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3801 - val_loss: 0.5048\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3797 - val_loss: 0.5045\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3793 - val_loss: 0.5043\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3790 - val_loss: 0.5040\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3786 - val_loss: 0.5038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3783 - val_loss: 0.5035\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3779 - val_loss: 0.5032\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3776 - val_loss: 0.5030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3772 - val_loss: 0.5027\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3769 - val_loss: 0.5025\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3765 - val_loss: 0.5022\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3762 - val_loss: 0.5020\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3758 - val_loss: 0.5017\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3755 - val_loss: 0.5015\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3752 - val_loss: 0.5012\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3748 - val_loss: 0.5010\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3745 - val_loss: 0.5008\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3742 - val_loss: 0.5005\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3738 - val_loss: 0.5003\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3735 - val_loss: 0.5000\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3732 - val_loss: 0.4998\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3729 - val_loss: 0.4995\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3726 - val_loss: 0.4993\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3722 - val_loss: 0.4991\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3719 - val_loss: 0.4988\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3716 - val_loss: 0.4986\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3713 - val_loss: 0.4984\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3710 - val_loss: 0.4982\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3707 - val_loss: 0.4979\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3704 - val_loss: 0.4977\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3701 - val_loss: 0.4975\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3698 - val_loss: 0.4973\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3695 - val_loss: 0.4971\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(21, 67), test_y.shape=(21, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 88.873907317969, my average MASE = 105114880.66517946\n",
      "Cluster 3, 88.873907317969\n",
      "Before prediction: train_X.shape=(58, 10, 67), train_y.shape=(58, 67), test_X.shape=(19, 10, 67), test_y.shape=(19, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6113 - val_loss: 0.3397\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6107 - val_loss: 0.3395\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6100 - val_loss: 0.3394\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6094 - val_loss: 0.3393\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6087 - val_loss: 0.3392\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6081 - val_loss: 0.3391\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6075 - val_loss: 0.3390\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6069 - val_loss: 0.3389\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6062 - val_loss: 0.3388\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6056 - val_loss: 0.3387\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6050 - val_loss: 0.3386\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6044 - val_loss: 0.3385\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6038 - val_loss: 0.3384\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6032 - val_loss: 0.3383\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6026 - val_loss: 0.3382\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6020 - val_loss: 0.3381\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6014 - val_loss: 0.3380\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6009 - val_loss: 0.3379\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6003 - val_loss: 0.3378\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5997 - val_loss: 0.3377\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5992 - val_loss: 0.3376\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5986 - val_loss: 0.3375\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5981 - val_loss: 0.3374\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5976 - val_loss: 0.3373\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5970 - val_loss: 0.3372\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5965 - val_loss: 0.3372\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5960 - val_loss: 0.3371\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5955 - val_loss: 0.3370\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5949 - val_loss: 0.3369\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5944 - val_loss: 0.3369\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5939 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5934 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5929 - val_loss: 0.3366\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5924 - val_loss: 0.3366\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5919 - val_loss: 0.3365\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5915 - val_loss: 0.3364\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5910 - val_loss: 0.3364\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5905 - val_loss: 0.3363\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5900 - val_loss: 0.3362\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5895 - val_loss: 0.3362\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(19, 67), test_y.shape=(19, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2288977.9462372796, my average MASE = 275894539.3328722\n",
      "Cluster 4, 2288977.9462372796\n",
      "Before prediction: train_X.shape=(22, 10, 67), train_y.shape=(22, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6507 - val_loss: 0.5866\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6499 - val_loss: 0.5864\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6491 - val_loss: 0.5862\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6483 - val_loss: 0.5861\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6475 - val_loss: 0.5859\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6467 - val_loss: 0.5857\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6459 - val_loss: 0.5855\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6451 - val_loss: 0.5854\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6443 - val_loss: 0.5852\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6435 - val_loss: 0.5851\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6427 - val_loss: 0.5849\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6420 - val_loss: 0.5848\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6412 - val_loss: 0.5846\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6405 - val_loss: 0.5844\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6397 - val_loss: 0.5843\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6389 - val_loss: 0.5841\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6382 - val_loss: 0.5840\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6374 - val_loss: 0.5838\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6367 - val_loss: 0.5837\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6359 - val_loss: 0.5836\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6352 - val_loss: 0.5834\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6345 - val_loss: 0.5833\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6337 - val_loss: 0.5832\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6330 - val_loss: 0.5830\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6323 - val_loss: 0.5829\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6316 - val_loss: 0.5827\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6309 - val_loss: 0.5826\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6302 - val_loss: 0.5825\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 0.5824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6288 - val_loss: 0.5822\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6281 - val_loss: 0.5821\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6275 - val_loss: 0.5820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6268 - val_loss: 0.5819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6261 - val_loss: 0.5818\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6254 - val_loss: 0.5816\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6248 - val_loss: 0.5815\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6241 - val_loss: 0.5814\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6235 - val_loss: 0.5813\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6228 - val_loss: 0.5811\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6222 - val_loss: 0.5810\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 56.939779008571485, my average MASE = 37107546.21609385\n",
      "Cluster 5, 56.939779008571485\n",
      "Before prediction: train_X.shape=(4681, 10, 67), train_y.shape=(4681, 67), test_X.shape=(1560, 10, 67), test_y.shape=(1560, 67)\n",
      "Epoch 1/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0785 - val_loss: 0.0245\n",
      "Epoch 2/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0726 - val_loss: 0.0222\n",
      "Epoch 3/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0688 - val_loss: 0.0210\n",
      "Epoch 4/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0661 - val_loss: 0.0201\n",
      "Epoch 5/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0638 - val_loss: 0.0195\n",
      "Epoch 6/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0620 - val_loss: 0.0189\n",
      "Epoch 7/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0604 - val_loss: 0.0185\n",
      "Epoch 8/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0590 - val_loss: 0.0182\n",
      "Epoch 9/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0579 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0569 - val_loss: 0.0176\n",
      "Epoch 11/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0560 - val_loss: 0.0174\n",
      "Epoch 12/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0552 - val_loss: 0.0172\n",
      "Epoch 13/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0545 - val_loss: 0.0171\n",
      "Epoch 14/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0539 - val_loss: 0.0169\n",
      "Epoch 15/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0533 - val_loss: 0.0168\n",
      "Epoch 16/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0528 - val_loss: 0.0167\n",
      "Epoch 17/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0524 - val_loss: 0.0166\n",
      "Epoch 18/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0519 - val_loss: 0.0165\n",
      "Epoch 19/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0516 - val_loss: 0.0165\n",
      "Epoch 20/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0512 - val_loss: 0.0164\n",
      "Epoch 21/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0509 - val_loss: 0.0163\n",
      "Epoch 22/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0505 - val_loss: 0.0163\n",
      "Epoch 23/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0502 - val_loss: 0.0162\n",
      "Epoch 24/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0500 - val_loss: 0.0162\n",
      "Epoch 25/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0497 - val_loss: 0.0161\n",
      "Epoch 26/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0495 - val_loss: 0.0161\n",
      "Epoch 27/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0492 - val_loss: 0.0161\n",
      "Epoch 28/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0490 - val_loss: 0.0160\n",
      "Epoch 29/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0488 - val_loss: 0.0160\n",
      "Epoch 30/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0486 - val_loss: 0.0159\n",
      "Epoch 31/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0485 - val_loss: 0.0159\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0483 - val_loss: 0.0158\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0481 - val_loss: 0.0158\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0480 - val_loss: 0.0158\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0479 - val_loss: 0.0157\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0477 - val_loss: 0.0157\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0476 - val_loss: 0.0157\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0475 - val_loss: 0.0156\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0474 - val_loss: 0.0156\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0473 - val_loss: 0.0156\n",
      "49/49 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1560, 67), test_y.shape=(1560, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 149408746.52177918, my average MASE = 566572768.961764\n",
      "Cluster 6, 149408746.52177918\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5377 - val_loss: 0.4682\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5358 - val_loss: 0.4667\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5339 - val_loss: 0.4653\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5320 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5302 - val_loss: 0.4624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5283 - val_loss: 0.4609\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5265 - val_loss: 0.4595\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5247 - val_loss: 0.4581\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5229 - val_loss: 0.4567\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5211 - val_loss: 0.4554\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5194 - val_loss: 0.4540\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5177 - val_loss: 0.4527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5160 - val_loss: 0.4514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5143 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5126 - val_loss: 0.4488\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5110 - val_loss: 0.4475\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5093 - val_loss: 0.4462\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5077 - val_loss: 0.4450\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5062 - val_loss: 0.4438\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5046 - val_loss: 0.4425\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5030 - val_loss: 0.4413\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5015 - val_loss: 0.4401\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5000 - val_loss: 0.4390\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4985 - val_loss: 0.4378\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4970 - val_loss: 0.4367\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4955 - val_loss: 0.4355\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4940 - val_loss: 0.4344\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4925 - val_loss: 0.4334\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4911 - val_loss: 0.4323\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4897 - val_loss: 0.4312\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4882 - val_loss: 0.4302\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4868 - val_loss: 0.4292\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4854 - val_loss: 0.4281\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4840 - val_loss: 0.4271\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4826 - val_loss: 0.4261\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4813 - val_loss: 0.4251\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4242\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4232\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4772 - val_loss: 0.4223\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4759 - val_loss: 0.4214\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3453236106.5511885, my average MASE = 6985920382.132476\n",
      "Cluster 7, 3453236106.5511885\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3084 - val_loss: 0.3104\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3075 - val_loss: 0.3100\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3066 - val_loss: 0.3095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3058 - val_loss: 0.3091\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3050 - val_loss: 0.3086\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3042 - val_loss: 0.3082\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3034 - val_loss: 0.3077\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3026 - val_loss: 0.3073\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3018 - val_loss: 0.3068\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3010 - val_loss: 0.3064\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3002 - val_loss: 0.3059\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2995 - val_loss: 0.3055\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2987 - val_loss: 0.3051\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2980 - val_loss: 0.3047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2973 - val_loss: 0.3043\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2965 - val_loss: 0.3039\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2958 - val_loss: 0.3035\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2951 - val_loss: 0.3031\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2944 - val_loss: 0.3027\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2937 - val_loss: 0.3024\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2930 - val_loss: 0.3020\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2924 - val_loss: 0.3017\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2917 - val_loss: 0.3014\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2911 - val_loss: 0.3011\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2904 - val_loss: 0.3008\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2898 - val_loss: 0.3006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2891 - val_loss: 0.3003\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2885 - val_loss: 0.3001\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2878 - val_loss: 0.2998\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2872 - val_loss: 0.2996\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2866 - val_loss: 0.2994\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2859 - val_loss: 0.2992\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2853 - val_loss: 0.2990\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2846 - val_loss: 0.2988\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2840 - val_loss: 0.2985\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2834 - val_loss: 0.2983\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2827 - val_loss: 0.2981\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2822 - val_loss: 0.2979\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2816 - val_loss: 0.2977\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2810 - val_loss: 0.2975\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2112740905793214, my average MASE = 0.3813496945040607\n",
      "Cluster 8, 0.2112740905793214\n",
      "Before prediction: train_X.shape=(33, 10, 67), train_y.shape=(33, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5052 - val_loss: 0.6961\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5045 - val_loss: 0.6956\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5038 - val_loss: 0.6950\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5030 - val_loss: 0.6945\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5023 - val_loss: 0.6939\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5016 - val_loss: 0.6934\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5009 - val_loss: 0.6928\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5002 - val_loss: 0.6923\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4995 - val_loss: 0.6918\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4988 - val_loss: 0.6913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.6908\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4975 - val_loss: 0.6903\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4968 - val_loss: 0.6898\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4961 - val_loss: 0.6893\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4955 - val_loss: 0.6888\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4948 - val_loss: 0.6883\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4942 - val_loss: 0.6879\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4935 - val_loss: 0.6874\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4929 - val_loss: 0.6869\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4923 - val_loss: 0.6865\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.6860\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4910 - val_loss: 0.6855\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4904 - val_loss: 0.6851\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4898 - val_loss: 0.6846\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4892 - val_loss: 0.6842\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4886 - val_loss: 0.6837\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4880 - val_loss: 0.6833\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4874 - val_loss: 0.6829\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4868 - val_loss: 0.6824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4863 - val_loss: 0.6820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4857 - val_loss: 0.6816\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4851 - val_loss: 0.6811\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4845 - val_loss: 0.6807\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4840 - val_loss: 0.6803\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4834 - val_loss: 0.6799\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4828 - val_loss: 0.6794\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6790\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4817 - val_loss: 0.6786\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4811 - val_loss: 0.6782\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4806 - val_loss: 0.6778\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 74.79960857799604, my average MASE = 23518054.91533832\n",
      "Cluster 9, 74.79960857799604\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3521 - val_loss: 0.2993\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3508 - val_loss: 0.2987\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3496 - val_loss: 0.2982\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3483 - val_loss: 0.2976\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3470 - val_loss: 0.2971\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3458 - val_loss: 0.2966\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3446 - val_loss: 0.2961\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3435 - val_loss: 0.2957\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3423 - val_loss: 0.2954\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3412 - val_loss: 0.2950\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3400 - val_loss: 0.2946\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3389 - val_loss: 0.2943\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3378 - val_loss: 0.2939\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3368 - val_loss: 0.2935\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3357 - val_loss: 0.2932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3347 - val_loss: 0.2928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3337 - val_loss: 0.2925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3326 - val_loss: 0.2921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3317 - val_loss: 0.2918\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3307 - val_loss: 0.2915\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3298 - val_loss: 0.2912\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3289 - val_loss: 0.2910\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3279 - val_loss: 0.2908\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.2905\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3261 - val_loss: 0.2903\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3252 - val_loss: 0.2901\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3244 - val_loss: 0.2899\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.2897\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3227 - val_loss: 0.2895\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3219 - val_loss: 0.2894\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3211 - val_loss: 0.2892\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3203 - val_loss: 0.2891\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3195 - val_loss: 0.2890\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3187 - val_loss: 0.2889\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3179 - val_loss: 0.2888\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3171 - val_loss: 0.2887\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3163 - val_loss: 0.2886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3155 - val_loss: 0.2886\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.2885\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3139 - val_loss: 0.2885\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.1864435054204945, my average MASE = 0.27675363785512175\n",
      "Cluster 10, 0.1864435054204945\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=2, 2, 18, (30612, 67)\n",
      "Before prediction: train_X.shape=(18361, 10, 67), train_y.shape=(18361, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.3015 - val_loss: 0.3194\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2836 - val_loss: 0.3051\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2695 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2585 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2510 - val_loss: 0.2789\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2456 - val_loss: 0.2737\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2410 - val_loss: 0.2693\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2369 - val_loss: 0.2653\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2332 - val_loss: 0.2616\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2298 - val_loss: 0.2584\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2267 - val_loss: 0.2555\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2238 - val_loss: 0.2531\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2212 - val_loss: 0.2509\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2190 - val_loss: 0.2490\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2172 - val_loss: 0.2474\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2156 - val_loss: 0.2461\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2143 - val_loss: 0.2448\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2120 - val_loss: 0.2428\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2110 - val_loss: 0.2420\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2101 - val_loss: 0.2412\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2092 - val_loss: 0.2404\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2084 - val_loss: 0.2395\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2077 - val_loss: 0.2390\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2070 - val_loss: 0.2383\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2064 - val_loss: 0.2377\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2058 - val_loss: 0.2371\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2052 - val_loss: 0.2365\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2047 - val_loss: 0.2361\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2041 - val_loss: 0.2356\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2352\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2032 - val_loss: 0.2348\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2020 - val_loss: 0.2336\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2016 - val_loss: 0.2332\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2013 - val_loss: 0.2329\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2009 - val_loss: 0.2327\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2006 - val_loss: 0.2324\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2321\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2046.5122369835897, my average MASE = 2805.5341357338157\n",
      "Cluster 0, 2046.5122369835897\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5756 - val_loss: 1.2952\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5738 - val_loss: 1.2950\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5721 - val_loss: 1.2949\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5703 - val_loss: 1.2948\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5686 - val_loss: 1.2947\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5670 - val_loss: 1.2946\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5653 - val_loss: 1.2945\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5637 - val_loss: 1.2944\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5621 - val_loss: 1.2943\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5605 - val_loss: 1.2941\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5589 - val_loss: 1.2940\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5573 - val_loss: 1.2939\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5558 - val_loss: 1.2937\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5542 - val_loss: 1.2936\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5527 - val_loss: 1.2934\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5512 - val_loss: 1.2932\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5497 - val_loss: 1.2930\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 1.2929\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5468 - val_loss: 1.2927\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 1.2925\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5440 - val_loss: 1.2924\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5426 - val_loss: 1.2922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5413 - val_loss: 1.2921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5400 - val_loss: 1.2920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5386 - val_loss: 1.2919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5374 - val_loss: 1.2918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 1.2918\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5349 - val_loss: 1.2917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5337 - val_loss: 1.2916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5325 - val_loss: 1.2915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5314 - val_loss: 1.2914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5302 - val_loss: 1.2912\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5290 - val_loss: 1.2911\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5279 - val_loss: 1.2909\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5268 - val_loss: 1.2907\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5256 - val_loss: 1.2905\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5246 - val_loss: 1.2903\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5235 - val_loss: 1.2902\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5224 - val_loss: 1.2901\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5213 - val_loss: 1.2900\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 950350834.5172157, my average MASE = 2745439088.6097794\n",
      "Cluster 1, 950350834.5172157\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=5, 5, 599, (8, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3119 - val_loss: 0.2829\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3116 - val_loss: 0.2829\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3112 - val_loss: 0.2828\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3109 - val_loss: 0.2828\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3106 - val_loss: 0.2828\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3102 - val_loss: 0.2827\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3099 - val_loss: 0.2827\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3096 - val_loss: 0.2827\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3092 - val_loss: 0.2827\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3089 - val_loss: 0.2826\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3086 - val_loss: 0.2826\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3083 - val_loss: 0.2826\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3080 - val_loss: 0.2826\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3077 - val_loss: 0.2825\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3074 - val_loss: 0.2825\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3070 - val_loss: 0.2825\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3067 - val_loss: 0.2825\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3064 - val_loss: 0.2824\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3061 - val_loss: 0.2824\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3058 - val_loss: 0.2824\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3055 - val_loss: 0.2823\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3052 - val_loss: 0.2823\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3049 - val_loss: 0.2823\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3047 - val_loss: 0.2822\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3044 - val_loss: 0.2822\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3041 - val_loss: 0.2822\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3038 - val_loss: 0.2821\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3035 - val_loss: 0.2821\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3032 - val_loss: 0.2821\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3029 - val_loss: 0.2820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3027 - val_loss: 0.2820\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3024 - val_loss: 0.2820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3021 - val_loss: 0.2819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.2819\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3016 - val_loss: 0.2818\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3013 - val_loss: 0.2818\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3010 - val_loss: 0.2818\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3008 - val_loss: 0.2817\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3005 - val_loss: 0.2817\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3002 - val_loss: 0.2816\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 104.97029321074898, my average MASE = 15924142.879668588\n",
      "Cluster 0, 104.97029321074898\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5420 - val_loss: 0.4071\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5399 - val_loss: 0.4062\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5378 - val_loss: 0.4054\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5357 - val_loss: 0.4045\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5337 - val_loss: 0.4037\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5316 - val_loss: 0.4029\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5296 - val_loss: 0.4021\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5276 - val_loss: 0.4013\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5257 - val_loss: 0.4005\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5237 - val_loss: 0.3998\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5218 - val_loss: 0.3990\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5199 - val_loss: 0.3983\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5179 - val_loss: 0.3975\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5161 - val_loss: 0.3968\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5142 - val_loss: 0.3961\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5124 - val_loss: 0.3954\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5106 - val_loss: 0.3947\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5088 - val_loss: 0.3940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5070 - val_loss: 0.3933\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5052 - val_loss: 0.3926\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5035 - val_loss: 0.3919\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5018 - val_loss: 0.3913\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5001 - val_loss: 0.3906\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4985 - val_loss: 0.3899\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4968 - val_loss: 0.3892\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.3886\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4936 - val_loss: 0.3879\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4920 - val_loss: 0.3873\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4905 - val_loss: 0.3866\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4889 - val_loss: 0.3860\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4874 - val_loss: 0.3853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4858 - val_loss: 0.3847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4843 - val_loss: 0.3840\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4828 - val_loss: 0.3834\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4813 - val_loss: 0.3828\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4798 - val_loss: 0.3821\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4783 - val_loss: 0.3815\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4769 - val_loss: 0.3809\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4754 - val_loss: 0.3803\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4740 - val_loss: 0.3797\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3145368812.0062547, my average MASE = 5974295545.526059\n",
      "Cluster 1, 3145368812.0062547\n",
      "Before prediction: train_X.shape=(2220, 10, 67), train_y.shape=(2220, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.5043 - val_loss: 0.3721\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4967 - val_loss: 0.3684\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4907 - val_loss: 0.3653\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4855 - val_loss: 0.3625\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4810 - val_loss: 0.3601\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4769 - val_loss: 0.3579\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4731 - val_loss: 0.3558\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4695 - val_loss: 0.3540\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4661 - val_loss: 0.3522\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4629 - val_loss: 0.3506\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4598 - val_loss: 0.3490\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4568 - val_loss: 0.3476\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4539 - val_loss: 0.3462\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4510 - val_loss: 0.3448\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4483 - val_loss: 0.3435\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4455 - val_loss: 0.3422\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4429 - val_loss: 0.3410\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4402 - val_loss: 0.3398\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4376 - val_loss: 0.3386\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4351 - val_loss: 0.3375\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4326 - val_loss: 0.3363\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4302 - val_loss: 0.3352\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4278 - val_loss: 0.3342\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4255 - val_loss: 0.3331\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4232 - val_loss: 0.3321\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4211 - val_loss: 0.3311\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4189 - val_loss: 0.3302\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4169 - val_loss: 0.3292\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4149 - val_loss: 0.3284\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4129 - val_loss: 0.3276\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4111 - val_loss: 0.3268\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4093 - val_loss: 0.3260\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4076 - val_loss: 0.3253\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4060 - val_loss: 0.3246\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4044 - val_loss: 0.3240\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4029 - val_loss: 0.3234\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4014 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4000 - val_loss: 0.3222\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3986 - val_loss: 0.3217\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3972 - val_loss: 0.3211\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 487.922050733615, my average MASE = 1880.6635092100216\n",
      "Cluster 2, 487.922050733615\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1089 - val_loss: 0.0991\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1039 - val_loss: 0.0970\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0998 - val_loss: 0.0956\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0965 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0938\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0911 - val_loss: 0.0932\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0889 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0869 - val_loss: 0.0924\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0852 - val_loss: 0.0922\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0836 - val_loss: 0.0920\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0821 - val_loss: 0.0918\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0808 - val_loss: 0.0917\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0795 - val_loss: 0.0915\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0783 - val_loss: 0.0913\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0773 - val_loss: 0.0912\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0763 - val_loss: 0.0910\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0908\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0744 - val_loss: 0.0907\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0736 - val_loss: 0.0905\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0903\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0901\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0900\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0708 - val_loss: 0.0899\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0897\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0696 - val_loss: 0.0896\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0690 - val_loss: 0.0895\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0894\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0680 - val_loss: 0.0893\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0675 - val_loss: 0.0892\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0892\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0666 - val_loss: 0.0891\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0661 - val_loss: 0.0890\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0658 - val_loss: 0.0890\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0654 - val_loss: 0.0889\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0650 - val_loss: 0.0889\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0647 - val_loss: 0.0888\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0644 - val_loss: 0.0888\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0888\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0887\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0636 - val_loss: 0.0887\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1152398695.5185678, my average MASE = 7118534712.468365\n",
      "Cluster 3, 1152398695.5185678\n",
      "Before prediction: train_X.shape=(156, 10, 67), train_y.shape=(156, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5146 - val_loss: 0.4378\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5133 - val_loss: 0.4370\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5122 - val_loss: 0.4361\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5111 - val_loss: 0.4352\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5100 - val_loss: 0.4344\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5089 - val_loss: 0.4335\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5078 - val_loss: 0.4327\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5068 - val_loss: 0.4319\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5057 - val_loss: 0.4311\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4303\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5037 - val_loss: 0.4296\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5028 - val_loss: 0.4288\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5018 - val_loss: 0.4281\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5008 - val_loss: 0.4273\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4999 - val_loss: 0.4266\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4990 - val_loss: 0.4259\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4981 - val_loss: 0.4252\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4972 - val_loss: 0.4245\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4963 - val_loss: 0.4238\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4954 - val_loss: 0.4232\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4945 - val_loss: 0.4225\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4937 - val_loss: 0.4219\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4929 - val_loss: 0.4213\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4920 - val_loss: 0.4207\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4912 - val_loss: 0.4201\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4905 - val_loss: 0.4195\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4897 - val_loss: 0.4189\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4889 - val_loss: 0.4183\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4881 - val_loss: 0.4177\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4874 - val_loss: 0.4172\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4867 - val_loss: 0.4166\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4859 - val_loss: 0.4161\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4852 - val_loss: 0.4155\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4845 - val_loss: 0.4150\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4838 - val_loss: 0.4145\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4831 - val_loss: 0.4139\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4824 - val_loss: 0.4134\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4817 - val_loss: 0.4129\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4811 - val_loss: 0.4124\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4804 - val_loss: 0.4119\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 117.29272898284657, my average MASE = 138077149.3198319\n",
      "Cluster 4, 117.29272898284657\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=7, 7, 49, (317, 67)\n",
      "Before prediction: train_X.shape=(184, 10, 67), train_y.shape=(184, 67), test_X.shape=(61, 10, 67), test_y.shape=(61, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6997 - val_loss: 0.6374\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6982 - val_loss: 0.6363\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6968 - val_loss: 0.6352\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6954 - val_loss: 0.6341\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.6331\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6927 - val_loss: 0.6320\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.6310\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6901 - val_loss: 0.6300\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6889 - val_loss: 0.6290\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6876 - val_loss: 0.6281\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6864 - val_loss: 0.6272\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6852 - val_loss: 0.6262\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6840 - val_loss: 0.6253\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6829 - val_loss: 0.6244\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6818 - val_loss: 0.6235\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6807 - val_loss: 0.6227\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6796 - val_loss: 0.6218\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6785 - val_loss: 0.6210\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6774 - val_loss: 0.6202\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6763 - val_loss: 0.6194\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.6186\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6743 - val_loss: 0.6178\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6733 - val_loss: 0.6171\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6723 - val_loss: 0.6163\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6713 - val_loss: 0.6156\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6704 - val_loss: 0.6149\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6694 - val_loss: 0.6142\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6685 - val_loss: 0.6135\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6676 - val_loss: 0.6127\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6666 - val_loss: 0.6121\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6658 - val_loss: 0.6114\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6649 - val_loss: 0.6107\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6640 - val_loss: 0.6100\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6631 - val_loss: 0.6093\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6622 - val_loss: 0.6086\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6614 - val_loss: 0.6079\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6605 - val_loss: 0.6073\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6597 - val_loss: 0.6066\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6588 - val_loss: 0.6060\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6580 - val_loss: 0.6053\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(61, 67), test_y.shape=(61, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 140.79883300988942, my average MASE = 132025753.41047312\n",
      "Cluster 0, 140.79883300988942\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5180 - val_loss: 0.4305\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5161 - val_loss: 0.4294\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5142 - val_loss: 0.4283\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5123 - val_loss: 0.4272\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5104 - val_loss: 0.4261\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5085 - val_loss: 0.4251\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5067 - val_loss: 0.4241\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5049 - val_loss: 0.4230\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.4221\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5013 - val_loss: 0.4211\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4996 - val_loss: 0.4202\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4978 - val_loss: 0.4193\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4961 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4944 - val_loss: 0.4175\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4927 - val_loss: 0.4166\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4911 - val_loss: 0.4158\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4895 - val_loss: 0.4149\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4879 - val_loss: 0.4141\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4863 - val_loss: 0.4133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4847 - val_loss: 0.4126\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4118\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4816 - val_loss: 0.4110\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4801 - val_loss: 0.4103\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4787 - val_loss: 0.4095\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4772 - val_loss: 0.4088\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4758 - val_loss: 0.4080\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4743 - val_loss: 0.4073\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4729 - val_loss: 0.4066\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4715 - val_loss: 0.4058\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4701 - val_loss: 0.4051\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4687 - val_loss: 0.4044\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4673 - val_loss: 0.4038\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4660 - val_loss: 0.4031\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4646 - val_loss: 0.4024\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4633 - val_loss: 0.4017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4620 - val_loss: 0.4010\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4607 - val_loss: 0.4004\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4594 - val_loss: 0.3997\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4582 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4569 - val_loss: 0.3985\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3225148693.3924103, my average MASE = 6345532768.562708\n",
      "Cluster 1, 3225148693.3924103\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1129 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1075 - val_loss: 0.0981\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1032 - val_loss: 0.0968\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0996 - val_loss: 0.0960\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0965 - val_loss: 0.0953\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0938 - val_loss: 0.0949\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0913 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0892 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0872 - val_loss: 0.0938\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0854 - val_loss: 0.0935\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0838 - val_loss: 0.0933\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0823 - val_loss: 0.0931\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0809 - val_loss: 0.0928\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0796 - val_loss: 0.0926\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0784 - val_loss: 0.0924\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0773 - val_loss: 0.0921\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0762 - val_loss: 0.0919\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0752 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0743 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0734 - val_loss: 0.0913\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0726 - val_loss: 0.0912\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0719 - val_loss: 0.0910\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0907\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0699 - val_loss: 0.0906\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0693 - val_loss: 0.0904\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0687 - val_loss: 0.0903\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0682 - val_loss: 0.0903\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0677 - val_loss: 0.0902\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0901\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0668 - val_loss: 0.0901\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0663 - val_loss: 0.0900\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0899\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0655 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0898\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0648 - val_loss: 0.0897\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0645 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0636 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1209643109.1461504, my average MASE = 20216236756.2103\n",
      "Cluster 2, 1209643109.1461504\n",
      "Before prediction: train_X.shape=(47, 10, 67), train_y.shape=(47, 67), test_X.shape=(16, 10, 67), test_y.shape=(16, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4112 - val_loss: 0.3544\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.3542\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4104 - val_loss: 0.3540\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4100 - val_loss: 0.3538\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4095 - val_loss: 0.3536\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4091 - val_loss: 0.3534\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4087 - val_loss: 0.3533\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4083 - val_loss: 0.3531\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4079 - val_loss: 0.3529\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4075 - val_loss: 0.3527\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4071 - val_loss: 0.3525\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4067 - val_loss: 0.3524\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4063 - val_loss: 0.3522\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4059 - val_loss: 0.3520\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4055 - val_loss: 0.3519\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4051 - val_loss: 0.3517\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4047 - val_loss: 0.3515\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4043 - val_loss: 0.3514\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4039 - val_loss: 0.3512\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3511\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4032 - val_loss: 0.3509\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4028 - val_loss: 0.3508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4024 - val_loss: 0.3506\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4020 - val_loss: 0.3505\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4017 - val_loss: 0.3503\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4009 - val_loss: 0.3501\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4006 - val_loss: 0.3499\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4002 - val_loss: 0.3498\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3999 - val_loss: 0.3497\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.3495\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3992 - val_loss: 0.3494\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.3493\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3985 - val_loss: 0.3492\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3982 - val_loss: 0.3491\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3978 - val_loss: 0.3489\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3975 - val_loss: 0.3488\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3972 - val_loss: 0.3487\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3968 - val_loss: 0.3486\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3965 - val_loss: 0.3485\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(16, 67), test_y.shape=(16, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 66.79284837728264, my average MASE = 54990938.33317367\n",
      "Cluster 3, 66.79284837728264\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5009 - val_loss: 0.4222\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4998 - val_loss: 0.4214\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4988 - val_loss: 0.4207\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4978 - val_loss: 0.4200\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4968 - val_loss: 0.4193\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4958 - val_loss: 0.4186\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4949 - val_loss: 0.4179\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4939 - val_loss: 0.4172\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4930 - val_loss: 0.4165\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4921 - val_loss: 0.4159\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4912 - val_loss: 0.4153\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4903 - val_loss: 0.4146\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4894 - val_loss: 0.4140\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4886 - val_loss: 0.4134\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4877 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4869 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4861 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4853 - val_loss: 0.4111\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4845 - val_loss: 0.4105\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4837 - val_loss: 0.4100\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4829 - val_loss: 0.4094\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4822 - val_loss: 0.4089\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4814 - val_loss: 0.4084\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4807 - val_loss: 0.4078\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4799 - val_loss: 0.4073\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4792 - val_loss: 0.4068\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4785 - val_loss: 0.4063\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4777 - val_loss: 0.4058\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4770 - val_loss: 0.4052\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4763 - val_loss: 0.4047\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4756 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4749 - val_loss: 0.4037\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4742 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4735 - val_loss: 0.4027\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4728 - val_loss: 0.4023\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4721 - val_loss: 0.4018\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4715 - val_loss: 0.4013\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4708 - val_loss: 0.4008\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4701 - val_loss: 0.4003\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4695 - val_loss: 0.3999\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.45341483860946, my average MASE = 95916870.45268953\n",
      "Cluster 4, 127.45341483860946\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2476 - val_loss: 0.2883\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2353 - val_loss: 0.2762\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2258 - val_loss: 0.2666\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2185 - val_loss: 0.2589\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2127 - val_loss: 0.2526\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2078 - val_loss: 0.2473\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2036 - val_loss: 0.2426\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1999 - val_loss: 0.2383\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1966 - val_loss: 0.2346\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1935 - val_loss: 0.2311\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1907 - val_loss: 0.2280\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1881 - val_loss: 0.2251\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1857 - val_loss: 0.2225\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1834 - val_loss: 0.2200\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1813 - val_loss: 0.2178\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1794 - val_loss: 0.2157\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1777 - val_loss: 0.2137\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1760 - val_loss: 0.2120\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1746 - val_loss: 0.2103\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1732 - val_loss: 0.2087\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1719 - val_loss: 0.2072\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1707 - val_loss: 0.2058\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1695 - val_loss: 0.2045\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2032\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1674 - val_loss: 0.2020\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1664 - val_loss: 0.2009\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1655 - val_loss: 0.1998\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1646 - val_loss: 0.1988\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1638 - val_loss: 0.1978\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1630 - val_loss: 0.1968\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1622 - val_loss: 0.1960\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1614 - val_loss: 0.1951\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1607 - val_loss: 0.1943\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1600 - val_loss: 0.1935\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1594 - val_loss: 0.1927\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1587 - val_loss: 0.1920\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1913\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1575 - val_loss: 0.1906\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1570 - val_loss: 0.1899\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1893\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 224.71735313764052, my average MASE = 374017026.3746446\n",
      "Cluster 5, 224.71735313764052\n",
      "Before prediction: train_X.shape=(51, 10, 67), train_y.shape=(51, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4065 - val_loss: 0.3790\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4060 - val_loss: 0.3788\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4055 - val_loss: 0.3787\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4049 - val_loss: 0.3786\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4044 - val_loss: 0.3784\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4038 - val_loss: 0.3783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4033 - val_loss: 0.3782\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4028 - val_loss: 0.3780\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4023 - val_loss: 0.3779\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4018 - val_loss: 0.3778\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4013 - val_loss: 0.3776\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3775\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4003 - val_loss: 0.3774\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3773\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3993 - val_loss: 0.3771\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3988 - val_loss: 0.3770\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3984 - val_loss: 0.3769\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3768\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3975 - val_loss: 0.3767\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3970 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3966 - val_loss: 0.3764\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3763\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3762\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3953 - val_loss: 0.3761\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3949 - val_loss: 0.3760\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3945 - val_loss: 0.3759\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3941 - val_loss: 0.3757\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3937 - val_loss: 0.3756\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3933 - val_loss: 0.3755\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3929 - val_loss: 0.3754\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3925 - val_loss: 0.3753\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3921 - val_loss: 0.3752\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3917 - val_loss: 0.3751\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3913 - val_loss: 0.3750\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3749\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3905 - val_loss: 0.3748\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3902 - val_loss: 0.3747\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3898 - val_loss: 0.3745\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3894 - val_loss: 0.3744\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3891 - val_loss: 0.3743\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 82.26261385879712, my average MASE = 20260153.97451399\n",
      "Cluster 6, 82.26261385879712\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=9, 9, 48, (301, 67)\n",
      "Before prediction: train_X.shape=(174, 10, 67), train_y.shape=(174, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7089 - val_loss: 0.5627\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7074 - val_loss: 0.5619\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7059 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7045 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7031 - val_loss: 0.5598\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7017 - val_loss: 0.5591\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7004 - val_loss: 0.5585\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6991 - val_loss: 0.5578\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6979 - val_loss: 0.5572\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6966 - val_loss: 0.5566\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6954 - val_loss: 0.5559\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.5553\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6930 - val_loss: 0.5548\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6918 - val_loss: 0.5542\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6907 - val_loss: 0.5536\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6895 - val_loss: 0.5531\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6884 - val_loss: 0.5525\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6873 - val_loss: 0.5520\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6863 - val_loss: 0.5515\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6852 - val_loss: 0.5509\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6842 - val_loss: 0.5504\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6831 - val_loss: 0.5499\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6821 - val_loss: 0.5494\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6811 - val_loss: 0.5489\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6801 - val_loss: 0.5484\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6792 - val_loss: 0.5479\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6782 - val_loss: 0.5475\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6772 - val_loss: 0.5470\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.5465\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.5461\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6744 - val_loss: 0.5456\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6735 - val_loss: 0.5452\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6726 - val_loss: 0.5447\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5443\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6707 - val_loss: 0.5439\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6698 - val_loss: 0.5434\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6689 - val_loss: 0.5430\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6680 - val_loss: 0.5426\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6671 - val_loss: 0.5422\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6663 - val_loss: 0.5417\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 144.45290178213432, my average MASE = 192607450.5447097\n",
      "Cluster 0, 144.45290178213432\n",
      "Before prediction: train_X.shape=(86, 10, 67), train_y.shape=(86, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3954 - val_loss: 0.4825\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3947 - val_loss: 0.4820\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3940 - val_loss: 0.4815\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3933 - val_loss: 0.4810\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3927 - val_loss: 0.4806\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3921 - val_loss: 0.4801\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4797\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3909 - val_loss: 0.4793\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3903 - val_loss: 0.4789\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3898 - val_loss: 0.4785\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3892 - val_loss: 0.4781\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3887 - val_loss: 0.4777\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4774\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3877 - val_loss: 0.4770\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3872 - val_loss: 0.4767\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4763\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3862 - val_loss: 0.4760\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.4757\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3853 - val_loss: 0.4753\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3848 - val_loss: 0.4750\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3844 - val_loss: 0.4747\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3840 - val_loss: 0.4744\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3835 - val_loss: 0.4741\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3831 - val_loss: 0.4738\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3827 - val_loss: 0.4735\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3822 - val_loss: 0.4732\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3818 - val_loss: 0.4729\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3814 - val_loss: 0.4726\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3810 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3806 - val_loss: 0.4720\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3802 - val_loss: 0.4717\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3798 - val_loss: 0.4714\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.4711\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3790 - val_loss: 0.4708\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3786 - val_loss: 0.4705\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3783 - val_loss: 0.4703\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3779 - val_loss: 0.4700\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3775 - val_loss: 0.4697\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3771 - val_loss: 0.4695\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3768 - val_loss: 0.4692\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 261.83661307224526, my average MASE = 165152999.01271424\n",
      "Cluster 1, 261.83661307224526\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3860 - val_loss: 0.4764\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3839 - val_loss: 0.4752\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3818 - val_loss: 0.4741\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3798 - val_loss: 0.4730\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3778 - val_loss: 0.4719\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3758 - val_loss: 0.4709\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3738 - val_loss: 0.4699\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3718 - val_loss: 0.4689\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3699 - val_loss: 0.4680\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3680 - val_loss: 0.4670\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4660\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3643 - val_loss: 0.4650\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.4640\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3606 - val_loss: 0.4630\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3588 - val_loss: 0.4620\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3570 - val_loss: 0.4610\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3553 - val_loss: 0.4599\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3535 - val_loss: 0.4588\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3518 - val_loss: 0.4578\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3501 - val_loss: 0.4567\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3484 - val_loss: 0.4557\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.4547\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3452 - val_loss: 0.4537\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3437 - val_loss: 0.4528\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3422 - val_loss: 0.4521\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3407 - val_loss: 0.4513\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.4506\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3378 - val_loss: 0.4498\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3363 - val_loss: 0.4493\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3349 - val_loss: 0.4487\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3336 - val_loss: 0.4481\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3323 - val_loss: 0.4475\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3311 - val_loss: 0.4470\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3299 - val_loss: 0.4464\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3287 - val_loss: 0.4459\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3276 - val_loss: 0.4453\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3264 - val_loss: 0.4447\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3253 - val_loss: 0.4441\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3241 - val_loss: 0.4436\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3231 - val_loss: 0.4430\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.29600762869721386, my average MASE = 0.4272698543687938\n",
      "Cluster 2, 0.29600762869721386\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4866 - val_loss: 0.4310\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4848 - val_loss: 0.4300\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4830 - val_loss: 0.4290\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4812 - val_loss: 0.4280\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.4271\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4777 - val_loss: 0.4261\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4760 - val_loss: 0.4252\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4744 - val_loss: 0.4243\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4727 - val_loss: 0.4235\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4711 - val_loss: 0.4226\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4695 - val_loss: 0.4217\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4679 - val_loss: 0.4209\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4663 - val_loss: 0.4200\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4648 - val_loss: 0.4192\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4633 - val_loss: 0.4184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4618 - val_loss: 0.4175\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4603 - val_loss: 0.4167\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4589 - val_loss: 0.4159\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4574 - val_loss: 0.4150\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4560 - val_loss: 0.4142\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4546 - val_loss: 0.4134\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4532 - val_loss: 0.4126\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4518 - val_loss: 0.4118\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4504 - val_loss: 0.4109\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4491 - val_loss: 0.4101\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4477 - val_loss: 0.4093\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4464 - val_loss: 0.4085\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4451 - val_loss: 0.4077\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4438 - val_loss: 0.4069\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4425 - val_loss: 0.4061\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4412 - val_loss: 0.4053\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4399 - val_loss: 0.4045\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4387 - val_loss: 0.4037\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4029\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4362 - val_loss: 0.4021\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4350 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4337 - val_loss: 0.4006\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4325 - val_loss: 0.3998\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4313 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4301 - val_loss: 0.3983\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3346396028.9972167, my average MASE = 7814754000.575592\n",
      "Cluster 3, 3346396028.9972167\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3142 - val_loss: 0.7771\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3138 - val_loss: 0.7770\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3135 - val_loss: 0.7769\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3131 - val_loss: 0.7768\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3127 - val_loss: 0.7767\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3123 - val_loss: 0.7765\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3119 - val_loss: 0.7764\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3116 - val_loss: 0.7763\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3112 - val_loss: 0.7762\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3108 - val_loss: 0.7761\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3105 - val_loss: 0.7759\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3101 - val_loss: 0.7758\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3097 - val_loss: 0.7757\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3094 - val_loss: 0.7756\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3090 - val_loss: 0.7755\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3087 - val_loss: 0.7754\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3083 - val_loss: 0.7753\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3080 - val_loss: 0.7752\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3076 - val_loss: 0.7751\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3073 - val_loss: 0.7749\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3069 - val_loss: 0.7748\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3066 - val_loss: 0.7747\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3063 - val_loss: 0.7746\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3059 - val_loss: 0.7746\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3056 - val_loss: 0.7745\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3053 - val_loss: 0.7744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3049 - val_loss: 0.7743\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3046 - val_loss: 0.7742\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3043 - val_loss: 0.7741\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3040 - val_loss: 0.7740\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3037 - val_loss: 0.7739\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3033 - val_loss: 0.7739\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3030 - val_loss: 0.7738\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3027 - val_loss: 0.7737\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3024 - val_loss: 0.7736\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3021 - val_loss: 0.7735\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.7734\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3015 - val_loss: 0.7733\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3012 - val_loss: 0.7732\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3009 - val_loss: 0.7731\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 93.69104182165661, my average MASE = 20945629.206220664\n",
      "Cluster 4, 93.69104182165661\n",
      "Before prediction: train_X.shape=(89, 10, 67), train_y.shape=(89, 67), test_X.shape=(30, 10, 67), test_y.shape=(30, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3424 - val_loss: 0.3360\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3416 - val_loss: 0.3355\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3408 - val_loss: 0.3350\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3400 - val_loss: 0.3346\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.3341\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3386 - val_loss: 0.3337\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3379 - val_loss: 0.3333\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3372 - val_loss: 0.3329\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3365 - val_loss: 0.3324\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3358 - val_loss: 0.3320\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3351 - val_loss: 0.3316\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3344 - val_loss: 0.3312\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3338 - val_loss: 0.3309\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3331 - val_loss: 0.3305\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3325 - val_loss: 0.3301\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3319 - val_loss: 0.3297\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3312 - val_loss: 0.3293\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3306 - val_loss: 0.3290\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3300 - val_loss: 0.3286\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3294 - val_loss: 0.3282\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3288 - val_loss: 0.3279\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3282 - val_loss: 0.3275\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3276 - val_loss: 0.3272\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3271 - val_loss: 0.3268\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3265 - val_loss: 0.3265\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3260 - val_loss: 0.3262\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3254 - val_loss: 0.3258\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3249 - val_loss: 0.3255\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3244 - val_loss: 0.3252\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.3249\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3234 - val_loss: 0.3246\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3228 - val_loss: 0.3243\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3223 - val_loss: 0.3240\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3237\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3214 - val_loss: 0.3234\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3231\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3204 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3199 - val_loss: 0.3225\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3195 - val_loss: 0.3222\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3190 - val_loss: 0.3219\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(30, 67), test_y.shape=(30, 67)\n",
      "average MASE = 188.45046029060867, my average MASE = 121680879.21353056\n",
      "Cluster 5, 188.45046029060867\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1120 - val_loss: 0.1007\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0987\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1025 - val_loss: 0.0974\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0990 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0960 - val_loss: 0.0954\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0933 - val_loss: 0.0947\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0942\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0888 - val_loss: 0.0938\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0868 - val_loss: 0.0934\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0931\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0834 - val_loss: 0.0928\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0819 - val_loss: 0.0926\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0806 - val_loss: 0.0923\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0793 - val_loss: 0.0921\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0781 - val_loss: 0.0919\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0770 - val_loss: 0.0917\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0759 - val_loss: 0.0916\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0749 - val_loss: 0.0914\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0740 - val_loss: 0.0912\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0732 - val_loss: 0.0911\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0724 - val_loss: 0.0910\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0716 - val_loss: 0.0909\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0709 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0908\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0695 - val_loss: 0.0907\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0689 - val_loss: 0.0906\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0683 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0678 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0673 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0660 - val_loss: 0.0902\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0901\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0900\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0645 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0637 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0634 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1073797047.1669116, my average MASE = 13075073766.705614\n",
      "Cluster 6, 1073797047.1669116\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2348 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2252 - val_loss: 0.2653\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2178 - val_loss: 0.2575\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2120 - val_loss: 0.2511\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2071 - val_loss: 0.2457\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2029 - val_loss: 0.2409\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1991 - val_loss: 0.2366\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1956 - val_loss: 0.2328\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1924 - val_loss: 0.2293\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1895 - val_loss: 0.2261\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1868 - val_loss: 0.2231\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2203\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1820 - val_loss: 0.2178\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1799 - val_loss: 0.2155\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1762 - val_loss: 0.2114\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1745 - val_loss: 0.2096\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1730 - val_loss: 0.2079\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1715 - val_loss: 0.2063\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1702 - val_loss: 0.2048\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1689 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1678 - val_loss: 0.2020\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1666 - val_loss: 0.2007\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1656 - val_loss: 0.1995\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1646 - val_loss: 0.1984\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1636 - val_loss: 0.1973\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1627 - val_loss: 0.1962\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1619 - val_loss: 0.1952\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1610 - val_loss: 0.1943\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1934\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1595 - val_loss: 0.1925\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1588 - val_loss: 0.1917\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1909\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1574 - val_loss: 0.1901\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1568 - val_loss: 0.1894\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1886\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1556 - val_loss: 0.1880\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1550 - val_loss: 0.1873\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1867\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1539 - val_loss: 0.1860\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 180.26488918007823, my average MASE = 179278352.44392422\n",
      "Cluster 7, 180.26488918007823\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=11, 11, 904, (6, 67)\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3401 - val_loss: 0.3875\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3395 - val_loss: 0.3872\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3390 - val_loss: 0.3870\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3385 - val_loss: 0.3868\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3380 - val_loss: 0.3866\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3375 - val_loss: 0.3863\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3370 - val_loss: 0.3861\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3366 - val_loss: 0.3859\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3361 - val_loss: 0.3856\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3357 - val_loss: 0.3854\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3352 - val_loss: 0.3852\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3348 - val_loss: 0.3850\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3343 - val_loss: 0.3848\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3339 - val_loss: 0.3846\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3335 - val_loss: 0.3844\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3331 - val_loss: 0.3842\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3327 - val_loss: 0.3840\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3323 - val_loss: 0.3837\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3318 - val_loss: 0.3835\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3314 - val_loss: 0.3833\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.3831\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3307 - val_loss: 0.3829\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3303 - val_loss: 0.3827\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3825\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3295 - val_loss: 0.3823\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3292 - val_loss: 0.3821\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3288 - val_loss: 0.3820\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3284 - val_loss: 0.3818\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3281 - val_loss: 0.3816\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.3814\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3274 - val_loss: 0.3812\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.3810\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3267 - val_loss: 0.3808\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3263 - val_loss: 0.3806\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3260 - val_loss: 0.3805\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3257 - val_loss: 0.3803\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3254 - val_loss: 0.3801\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3250 - val_loss: 0.3799\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3247 - val_loss: 0.3798\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.3796\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 122.2598699731945, my average MASE = 164200403.28208458\n",
      "Cluster 0, 122.2598699731945\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5011 - val_loss: 0.7038\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5005 - val_loss: 0.7036\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4998 - val_loss: 0.7034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4991 - val_loss: 0.7032\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4984 - val_loss: 0.7030\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4978 - val_loss: 0.7028\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4971 - val_loss: 0.7026\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4964 - val_loss: 0.7024\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4958 - val_loss: 0.7022\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4951 - val_loss: 0.7020\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4945 - val_loss: 0.7017\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4938 - val_loss: 0.7015\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4932 - val_loss: 0.7014\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4926 - val_loss: 0.7012\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4919 - val_loss: 0.7010\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4913 - val_loss: 0.7008\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4907 - val_loss: 0.7006\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4901 - val_loss: 0.7004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4894 - val_loss: 0.7002\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4888 - val_loss: 0.7000\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4882 - val_loss: 0.6998\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4877 - val_loss: 0.6997\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4871 - val_loss: 0.6995\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4865 - val_loss: 0.6993\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4859 - val_loss: 0.6991\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4853 - val_loss: 0.6989\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4847 - val_loss: 0.6988\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4842 - val_loss: 0.6986\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4836 - val_loss: 0.6984\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4831 - val_loss: 0.6983\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4825 - val_loss: 0.6981\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4820 - val_loss: 0.6979\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4815 - val_loss: 0.6978\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4809 - val_loss: 0.6976\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4804 - val_loss: 0.6974\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4799 - val_loss: 0.6973\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4794 - val_loss: 0.6971\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4789 - val_loss: 0.6970\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4783 - val_loss: 0.6968\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4778 - val_loss: 0.6966\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2966824.6919978233, my average MASE = 79205816.45072892\n",
      "Cluster 1, 2966824.6919978233\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1998 - val_loss: 0.3035\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1993 - val_loss: 0.3034\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1988 - val_loss: 0.3034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1982 - val_loss: 0.3033\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1977 - val_loss: 0.3033\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1972 - val_loss: 0.3032\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1967 - val_loss: 0.3032\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1962 - val_loss: 0.3032\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1957 - val_loss: 0.3031\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1952 - val_loss: 0.3031\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1947 - val_loss: 0.3031\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1942 - val_loss: 0.3031\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1938 - val_loss: 0.3030\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1933 - val_loss: 0.3030\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1928 - val_loss: 0.3030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1924 - val_loss: 0.3030\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1919 - val_loss: 0.3030\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1915 - val_loss: 0.3030\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1911 - val_loss: 0.3030\n",
      "Epoch 19: early stopping\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 130.97936905502368, my average MASE = 132554988.34305501\n",
      "Cluster 2, 130.97936905502368\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4496 - val_loss: 0.4061\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4490 - val_loss: 0.4060\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4484 - val_loss: 0.4058\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4478 - val_loss: 0.4057\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4472 - val_loss: 0.4056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4466 - val_loss: 0.4055\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4461 - val_loss: 0.4054\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4455 - val_loss: 0.4053\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4450 - val_loss: 0.4052\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4444 - val_loss: 0.4051\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4439 - val_loss: 0.4050\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4433 - val_loss: 0.4049\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4428 - val_loss: 0.4048\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4423 - val_loss: 0.4047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4417 - val_loss: 0.4046\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4412 - val_loss: 0.4045\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4407 - val_loss: 0.4044\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4402 - val_loss: 0.4043\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4397 - val_loss: 0.4042\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4041\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4387 - val_loss: 0.4040\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4382 - val_loss: 0.4039\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4377 - val_loss: 0.4038\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4372 - val_loss: 0.4037\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4367 - val_loss: 0.4036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4362 - val_loss: 0.4035\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4357 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4352 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4032\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4343 - val_loss: 0.4031\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4338 - val_loss: 0.4030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4333 - val_loss: 0.4029\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4329 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4028\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4027\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4315 - val_loss: 0.4026\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4311 - val_loss: 0.4025\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4306 - val_loss: 0.4024\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4302 - val_loss: 0.4023\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4297 - val_loss: 0.4022\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1437.7621485075726, my average MASE = 33408169.939470924\n",
      "Cluster 3, 1437.7621485075726\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3791 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3768 - val_loss: 0.4780\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3745 - val_loss: 0.4765\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4750\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3700 - val_loss: 0.4735\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3678 - val_loss: 0.4721\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3657 - val_loss: 0.4707\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3636 - val_loss: 0.4693\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3616 - val_loss: 0.4679\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3595 - val_loss: 0.4665\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3576 - val_loss: 0.4652\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3556 - val_loss: 0.4639\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3537 - val_loss: 0.4626\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.4614\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3500 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3482 - val_loss: 0.4590\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3464 - val_loss: 0.4578\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3447 - val_loss: 0.4567\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3430 - val_loss: 0.4556\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3414 - val_loss: 0.4545\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3398 - val_loss: 0.4534\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3382 - val_loss: 0.4524\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3366 - val_loss: 0.4513\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3351 - val_loss: 0.4504\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3335 - val_loss: 0.4494\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3320 - val_loss: 0.4484\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3305 - val_loss: 0.4475\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3291 - val_loss: 0.4466\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3277 - val_loss: 0.4457\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3263 - val_loss: 0.4448\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3249 - val_loss: 0.4439\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3236 - val_loss: 0.4431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3222 - val_loss: 0.4422\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3209 - val_loss: 0.4413\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.4404\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3184 - val_loss: 0.4395\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3171 - val_loss: 0.4386\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3159 - val_loss: 0.4378\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.4369\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3135 - val_loss: 0.4360\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1399316882.5162897, my average MASE = 3857319737.5045514\n",
      "Cluster 4, 1399316882.5162897\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2312 - val_loss: 0.2708\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2231 - val_loss: 0.2627\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2165 - val_loss: 0.2559\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2110 - val_loss: 0.2500\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2061 - val_loss: 0.2449\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2018 - val_loss: 0.2403\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1979 - val_loss: 0.2361\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1944 - val_loss: 0.2322\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1912 - val_loss: 0.2287\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1882 - val_loss: 0.2255\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1854 - val_loss: 0.2224\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1829 - val_loss: 0.2197\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1806 - val_loss: 0.2172\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1785 - val_loss: 0.2150\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1767 - val_loss: 0.2129\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1750 - val_loss: 0.2110\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1734 - val_loss: 0.2093\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1720 - val_loss: 0.2077\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1707 - val_loss: 0.2061\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1695 - val_loss: 0.2047\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1683 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1672 - val_loss: 0.2021\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1661 - val_loss: 0.2009\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1651 - val_loss: 0.1997\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1641 - val_loss: 0.1986\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1632 - val_loss: 0.1975\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1623 - val_loss: 0.1965\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1615 - val_loss: 0.1955\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1599 - val_loss: 0.1937\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1577 - val_loss: 0.1912\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1570 - val_loss: 0.1904\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1897\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1558 - val_loss: 0.1890\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1552 - val_loss: 0.1883\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1547 - val_loss: 0.1877\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1542 - val_loss: 0.1871\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1537 - val_loss: 0.1864\n",
      "17/17 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n",
      "average MASE = 146.93947390831542, my average MASE = 534465305.08164215\n",
      "Cluster 5, 146.93947390831542\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3864 - val_loss: 0.3280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.3279\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3849 - val_loss: 0.3278\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3842 - val_loss: 0.3277\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3834 - val_loss: 0.3276\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3827 - val_loss: 0.3275\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3820 - val_loss: 0.3274\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3813 - val_loss: 0.3274\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.3273\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3799 - val_loss: 0.3272\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.3272\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3785 - val_loss: 0.3271\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3778 - val_loss: 0.3270\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3772 - val_loss: 0.3270\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3765 - val_loss: 0.3269\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.3269\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3753 - val_loss: 0.3268\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3746 - val_loss: 0.3268\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3740 - val_loss: 0.3267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3734 - val_loss: 0.3266\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3728 - val_loss: 0.3266\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3722 - val_loss: 0.3265\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3717 - val_loss: 0.3265\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3711 - val_loss: 0.3264\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3705 - val_loss: 0.3264\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3699 - val_loss: 0.3263\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3694 - val_loss: 0.3263\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3688 - val_loss: 0.3262\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3682 - val_loss: 0.3262\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3262\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3671 - val_loss: 0.3261\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3666 - val_loss: 0.3261\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3660 - val_loss: 0.3260\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3655 - val_loss: 0.3260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3649 - val_loss: 0.3260\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3643 - val_loss: 0.3259\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3632 - val_loss: 0.3259\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3259\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3621 - val_loss: 0.3259\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 304.5484747914777, my average MASE = 15252291.46578898\n",
      "Cluster 6, 304.5484747914777\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8703 - val_loss: 8.9197\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8672 - val_loss: 8.9197\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8642 - val_loss: 8.9196\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8613 - val_loss: 8.9196\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8586 - val_loss: 8.9196\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8558 - val_loss: 8.9195\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8532 - val_loss: 8.9194\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8506 - val_loss: 8.9194\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8480 - val_loss: 8.9193\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8455 - val_loss: 8.9192\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8431 - val_loss: 8.9192\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8407 - val_loss: 8.9191\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8383 - val_loss: 8.9190\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8360 - val_loss: 8.9189\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8337 - val_loss: 8.9188\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8315 - val_loss: 8.9187\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8293 - val_loss: 8.9187\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8271 - val_loss: 8.9186\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8250 - val_loss: 8.9185\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 8.9184\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8209 - val_loss: 8.9184\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 8.9183\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8170 - val_loss: 8.9182\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8150 - val_loss: 8.9181\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8131 - val_loss: 8.9180\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8113 - val_loss: 8.9179\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8095 - val_loss: 8.9179\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 8.9178\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8062 - val_loss: 8.9177\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8046 - val_loss: 8.9176\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8031 - val_loss: 8.9175\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8016 - val_loss: 8.9175\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8000 - val_loss: 8.9174\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7985 - val_loss: 8.9173\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7970 - val_loss: 8.9172\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7955 - val_loss: 8.9171\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7941 - val_loss: 8.9171\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7927 - val_loss: 8.9170\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7913 - val_loss: 8.9170\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7899 - val_loss: 8.9170\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 192382848.4747458, my average MASE = 882590618.8453726\n",
      "Cluster 7, 192382848.4747458\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1119 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0986\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1024 - val_loss: 0.0973\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0988 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0957 - val_loss: 0.0956\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0930 - val_loss: 0.0950\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0905 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0883 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0863 - val_loss: 0.0937\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0933\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0828 - val_loss: 0.0930\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0813 - val_loss: 0.0928\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0799 - val_loss: 0.0925\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0787 - val_loss: 0.0924\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0775 - val_loss: 0.0922\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0764 - val_loss: 0.0920\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0754 - val_loss: 0.0918\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0744 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0735 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0727 - val_loss: 0.0914\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0719 - val_loss: 0.0913\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0711 - val_loss: 0.0912\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0705 - val_loss: 0.0910\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0909\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0692 - val_loss: 0.0908\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0687 - val_loss: 0.0907\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0677 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0660 - val_loss: 0.0901\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0900\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0653 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0646 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0898\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0897\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0896\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0635 - val_loss: 0.0896\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1222984943.0994627, my average MASE = 34180380931.05725\n",
      "Cluster 8, 1222984943.0994627\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3097 - val_loss: 0.3956\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3089 - val_loss: 0.3954\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3081 - val_loss: 0.3952\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3074 - val_loss: 0.3950\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3066 - val_loss: 0.3948\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3059 - val_loss: 0.3945\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3051 - val_loss: 0.3943\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3044 - val_loss: 0.3941\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3037 - val_loss: 0.3939\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3030 - val_loss: 0.3937\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.3935\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3017 - val_loss: 0.3934\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3010 - val_loss: 0.3933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3003 - val_loss: 0.3931\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2997 - val_loss: 0.3930\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2990 - val_loss: 0.3929\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2984 - val_loss: 0.3927\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2977 - val_loss: 0.3926\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2971 - val_loss: 0.3925\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2965 - val_loss: 0.3924\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2959 - val_loss: 0.3923\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2953 - val_loss: 0.3922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2947 - val_loss: 0.3921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2941 - val_loss: 0.3920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2935 - val_loss: 0.3919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2930 - val_loss: 0.3918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2924 - val_loss: 0.3917\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.3917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2913 - val_loss: 0.3916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2907 - val_loss: 0.3915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2902 - val_loss: 0.3914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2896 - val_loss: 0.3914\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2891 - val_loss: 0.3913\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2885 - val_loss: 0.3912\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2880 - val_loss: 0.3911\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2875 - val_loss: 0.3910\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2870 - val_loss: 0.3909\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2865 - val_loss: 0.3908\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2859 - val_loss: 0.3907\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2854 - val_loss: 0.3907\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 561.7864488366092, my average MASE = 24722978.57949824\n",
      "Cluster 10, 561.7864488366092\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=2, 2, 13, (10045, 67)\n",
      "Before prediction: train_X.shape=(6020, 10, 67), train_y.shape=(6020, 67), test_X.shape=(2007, 10, 67), test_y.shape=(2007, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0647 - val_loss: 0.0484\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0596 - val_loss: 0.0453\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0565 - val_loss: 0.0429\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0542 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0523 - val_loss: 0.0394\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0508 - val_loss: 0.0381\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0495 - val_loss: 0.0370\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0484 - val_loss: 0.0360\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0475 - val_loss: 0.0351\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0467 - val_loss: 0.0344\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0461 - val_loss: 0.0338\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0454 - val_loss: 0.0333\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0328\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0444 - val_loss: 0.0323\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0440 - val_loss: 0.0320\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0435 - val_loss: 0.0316\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0313\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0428 - val_loss: 0.0311\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0308\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0306\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0304\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0415 - val_loss: 0.0303\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0412 - val_loss: 0.0301\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0410 - val_loss: 0.0300\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0298\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0297\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0296\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0294\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0293\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0292\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0397 - val_loss: 0.0291\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0396 - val_loss: 0.0291\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0395 - val_loss: 0.0290\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0394 - val_loss: 0.0289\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0393 - val_loss: 0.0289\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0288\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0287\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0390 - val_loss: 0.0287\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0389 - val_loss: 0.0286\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0388 - val_loss: 0.0286\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2007, 67), test_y.shape=(2007, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 124611449.52884135, my average MASE = 52097635280.213745\n",
      "Cluster 0, 124611449.52884135\n",
      "Before prediction: train_X.shape=(18364, 10, 67), train_y.shape=(18364, 67), test_X.shape=(6121, 10, 67), test_y.shape=(6121, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3019 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2812 - val_loss: 0.3011\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2652 - val_loss: 0.2888\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2545 - val_loss: 0.2808\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2479 - val_loss: 0.2750\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2428 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2385 - val_loss: 0.2663\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2348 - val_loss: 0.2629\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2315 - val_loss: 0.2599\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2283 - val_loss: 0.2570\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2254 - val_loss: 0.2544\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2226 - val_loss: 0.2520\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2201 - val_loss: 0.2499\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2179 - val_loss: 0.2480\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2161 - val_loss: 0.2464\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2145 - val_loss: 0.2449\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2436\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2118 - val_loss: 0.2425\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2107 - val_loss: 0.2414\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2096 - val_loss: 0.2403\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2087 - val_loss: 0.2395\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2387\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2070 - val_loss: 0.2379\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2063 - val_loss: 0.2371\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2056 - val_loss: 0.2364\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2049 - val_loss: 0.2358\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2352\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2038 - val_loss: 0.2346\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2032 - val_loss: 0.2342\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2027 - val_loss: 0.2337\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2023 - val_loss: 0.2332\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2018 - val_loss: 0.2329\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2014 - val_loss: 0.2325\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2321\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2006 - val_loss: 0.2318\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2314\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1999 - val_loss: 0.2311\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1996 - val_loss: 0.2308\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.1993 - val_loss: 0.2305\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1990 - val_loss: 0.2302\n",
      "192/192 [==============================] - 2s 11ms/step\n",
      "predicted_original.shape=(6121, 67), test_y.shape=(6121, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1515.0877642124253, my average MASE = 2752.3099444505265\n",
      "Cluster 1, 1515.0877642124253\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=5, 5, 12, (3253, 67)\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1101 - val_loss: 0.0983\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1050 - val_loss: 0.0966\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1009 - val_loss: 0.0954\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0975 - val_loss: 0.0944\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0945 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0919 - val_loss: 0.0931\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0895 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0923\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0855 - val_loss: 0.0921\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0838 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0915\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0807 - val_loss: 0.0912\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0794 - val_loss: 0.0910\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0782 - val_loss: 0.0908\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0771 - val_loss: 0.0906\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0760 - val_loss: 0.0904\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0750 - val_loss: 0.0902\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0741 - val_loss: 0.0901\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0733 - val_loss: 0.0899\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0725 - val_loss: 0.0898\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0717 - val_loss: 0.0897\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0710 - val_loss: 0.0895\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0704 - val_loss: 0.0895\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0894\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0691 - val_loss: 0.0893\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0686 - val_loss: 0.0892\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0681 - val_loss: 0.0892\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0891\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0671 - val_loss: 0.0891\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0890\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0662 - val_loss: 0.0889\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0658 - val_loss: 0.0889\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0888\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0651 - val_loss: 0.0887\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0647 - val_loss: 0.0887\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0644 - val_loss: 0.0886\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0641 - val_loss: 0.0885\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0638 - val_loss: 0.0885\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0636 - val_loss: 0.0884\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0633 - val_loss: 0.0883\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n",
      "average MASE = 1286975259.8033035, my average MASE = 26869301348.284866\n",
      "Cluster 0, 1286975259.8033035\n",
      "Before prediction: train_X.shape=(2221, 10, 67), train_y.shape=(2221, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5056 - val_loss: 0.3755\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4985 - val_loss: 0.3720\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4926 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4874 - val_loss: 0.3660\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4828 - val_loss: 0.3635\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4785 - val_loss: 0.3611\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4745 - val_loss: 0.3590\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4707 - val_loss: 0.3570\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4671 - val_loss: 0.3552\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4637 - val_loss: 0.3535\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4604 - val_loss: 0.3519\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4572 - val_loss: 0.3504\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4542 - val_loss: 0.3489\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4512 - val_loss: 0.3475\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4483 - val_loss: 0.3462\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4455 - val_loss: 0.3449\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4428 - val_loss: 0.3436\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4401 - val_loss: 0.3424\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4375 - val_loss: 0.3412\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4350 - val_loss: 0.3401\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4325 - val_loss: 0.3390\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4301 - val_loss: 0.3380\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4278 - val_loss: 0.3370\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4255 - val_loss: 0.3360\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4233 - val_loss: 0.3350\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4211 - val_loss: 0.3341\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4190 - val_loss: 0.3332\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4170 - val_loss: 0.3324\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4150 - val_loss: 0.3315\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4131 - val_loss: 0.3307\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4113 - val_loss: 0.3299\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4095 - val_loss: 0.3292\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4078 - val_loss: 0.3285\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4061 - val_loss: 0.3278\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4045 - val_loss: 0.3271\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4030 - val_loss: 0.3265\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4014 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3999 - val_loss: 0.3253\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3985 - val_loss: 0.3247\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3971 - val_loss: 0.3242\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 455.57479189703486, my average MASE = 880.739926655778\n",
      "Cluster 1, 455.57479189703486\n",
      "Before prediction: train_X.shape=(41, 10, 67), train_y.shape=(41, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4961 - val_loss: 0.6170\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4945 - val_loss: 0.6160\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4928 - val_loss: 0.6151\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4912 - val_loss: 0.6141\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4896 - val_loss: 0.6132\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4880 - val_loss: 0.6123\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4864 - val_loss: 0.6114\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4849 - val_loss: 0.6105\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4834 - val_loss: 0.6096\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4818 - val_loss: 0.6088\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4803 - val_loss: 0.6080\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4788 - val_loss: 0.6071\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4774 - val_loss: 0.6063\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4759 - val_loss: 0.6055\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4745 - val_loss: 0.6047\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4731 - val_loss: 0.6040\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4717 - val_loss: 0.6033\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4703 - val_loss: 0.6025\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4689 - val_loss: 0.6018\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4676 - val_loss: 0.6012\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4663 - val_loss: 0.6005\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4649 - val_loss: 0.5998\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4636 - val_loss: 0.5992\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4624 - val_loss: 0.5985\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4611 - val_loss: 0.5979\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4598 - val_loss: 0.5973\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4586 - val_loss: 0.5967\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4574 - val_loss: 0.5961\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4561 - val_loss: 0.5955\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4549 - val_loss: 0.5950\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4537 - val_loss: 0.5944\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4525 - val_loss: 0.5939\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4513 - val_loss: 0.5933\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4501 - val_loss: 0.5928\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4489 - val_loss: 0.5922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4478 - val_loss: 0.5917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4466 - val_loss: 0.5912\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4455 - val_loss: 0.5907\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4443 - val_loss: 0.5902\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4432 - val_loss: 0.5897\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3633974576.8812943, my average MASE = 9316750037.661146\n",
      "Cluster 2, 3633974576.8812943\n",
      "Before prediction: train_X.shape=(158, 10, 67), train_y.shape=(158, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5152 - val_loss: 0.4273\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5139 - val_loss: 0.4265\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5128 - val_loss: 0.4257\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5117 - val_loss: 0.4249\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5105 - val_loss: 0.4241\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5095 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5084 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5074 - val_loss: 0.4219\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5064 - val_loss: 0.4212\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5054 - val_loss: 0.4204\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5044 - val_loss: 0.4197\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5034 - val_loss: 0.4191\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5025 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5015 - val_loss: 0.4178\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5006 - val_loss: 0.4171\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4997 - val_loss: 0.4165\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4988 - val_loss: 0.4159\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4979 - val_loss: 0.4153\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4970 - val_loss: 0.4147\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4961 - val_loss: 0.4141\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4953 - val_loss: 0.4135\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4944 - val_loss: 0.4129\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4936 - val_loss: 0.4123\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4928 - val_loss: 0.4118\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4920 - val_loss: 0.4112\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4912 - val_loss: 0.4107\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4904 - val_loss: 0.4101\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4096\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4889 - val_loss: 0.4091\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4882 - val_loss: 0.4086\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4874 - val_loss: 0.4080\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4867 - val_loss: 0.4075\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4860 - val_loss: 0.4070\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4852 - val_loss: 0.4065\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4845 - val_loss: 0.4060\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4838 - val_loss: 0.4055\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4831 - val_loss: 0.4050\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4045\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4818 - val_loss: 0.4040\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4811 - val_loss: 0.4036\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 113.07393682707622, my average MASE = 188079219.47717956\n",
      "Cluster 3, 113.07393682707622\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7117 - val_loss: 0.7129\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7087 - val_loss: 0.7117\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7057 - val_loss: 0.7104\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7028 - val_loss: 0.7094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7000 - val_loss: 0.7084\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6972 - val_loss: 0.7075\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6945 - val_loss: 0.7066\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6918 - val_loss: 0.7056\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6891 - val_loss: 0.7047\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6865 - val_loss: 0.7037\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6838 - val_loss: 0.7028\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6811 - val_loss: 0.7018\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6785 - val_loss: 0.7009\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6758 - val_loss: 0.6999\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6732 - val_loss: 0.6990\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6706 - val_loss: 0.6981\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6680 - val_loss: 0.6971\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6654 - val_loss: 0.6961\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6628 - val_loss: 0.6951\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6604 - val_loss: 0.6942\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6580 - val_loss: 0.6934\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6556 - val_loss: 0.6926\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6534 - val_loss: 0.6918\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6512 - val_loss: 0.6910\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6491 - val_loss: 0.6902\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6470 - val_loss: 0.6894\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6449 - val_loss: 0.6886\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6429 - val_loss: 0.6877\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6409 - val_loss: 0.6869\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6389 - val_loss: 0.6861\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6369 - val_loss: 0.6853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6350 - val_loss: 0.6847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6332 - val_loss: 0.6841\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6314 - val_loss: 0.6836\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6297 - val_loss: 0.6831\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6280 - val_loss: 0.6827\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6263 - val_loss: 0.6825\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6246 - val_loss: 0.6824\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6229 - val_loss: 0.6823\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6212 - val_loss: 0.6822\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2798887382418345, my average MASE = 0.5334982550486497\n",
      "Cluster 4, 0.2798887382418345\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=7, 7, 431, (13, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(180, 10, 67), train_y.shape=(180, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6852 - val_loss: 0.5575\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6838 - val_loss: 0.5569\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6824 - val_loss: 0.5563\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6811 - val_loss: 0.5557\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6799 - val_loss: 0.5551\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6786 - val_loss: 0.5545\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6774 - val_loss: 0.5540\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6762 - val_loss: 0.5534\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6750 - val_loss: 0.5528\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6739 - val_loss: 0.5523\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6727 - val_loss: 0.5518\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5512\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6705 - val_loss: 0.5507\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6694 - val_loss: 0.5501\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6684 - val_loss: 0.5496\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6673 - val_loss: 0.5491\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6663 - val_loss: 0.5486\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6653 - val_loss: 0.5481\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6643 - val_loss: 0.5475\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6632 - val_loss: 0.5470\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6623 - val_loss: 0.5465\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6613 - val_loss: 0.5461\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6603 - val_loss: 0.5456\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6594 - val_loss: 0.5451\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6584 - val_loss: 0.5446\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6575 - val_loss: 0.5441\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6566 - val_loss: 0.5437\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6557 - val_loss: 0.5432\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6548 - val_loss: 0.5427\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6539 - val_loss: 0.5423\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6531 - val_loss: 0.5418\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6522 - val_loss: 0.5414\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6513 - val_loss: 0.5409\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6505 - val_loss: 0.5405\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6497 - val_loss: 0.5400\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6489 - val_loss: 0.5396\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6480 - val_loss: 0.5392\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6472 - val_loss: 0.5387\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6464 - val_loss: 0.5383\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6456 - val_loss: 0.5379\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 161.0036674860674, my average MASE = 412096886.9283237\n",
      "Cluster 1, 161.0036674860674\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6031 - val_loss: 0.4390\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6002 - val_loss: 0.4369\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5975 - val_loss: 0.4349\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5947 - val_loss: 0.4328\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5919 - val_loss: 0.4307\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5892 - val_loss: 0.4287\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5864 - val_loss: 0.4267\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5838 - val_loss: 0.4248\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5812 - val_loss: 0.4230\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5786 - val_loss: 0.4213\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5761 - val_loss: 0.4196\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5736 - val_loss: 0.4180\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5712 - val_loss: 0.4164\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5687 - val_loss: 0.4148\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5663 - val_loss: 0.4132\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5638 - val_loss: 0.4116\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5614 - val_loss: 0.4101\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5590 - val_loss: 0.4085\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5566 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5542 - val_loss: 0.4054\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5518 - val_loss: 0.4039\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5494 - val_loss: 0.4024\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5471 - val_loss: 0.4008\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5448 - val_loss: 0.3992\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5424 - val_loss: 0.3977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5401 - val_loss: 0.3961\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5378 - val_loss: 0.3945\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5355 - val_loss: 0.3930\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5333 - val_loss: 0.3914\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5310 - val_loss: 0.3898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5288 - val_loss: 0.3883\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5266 - val_loss: 0.3868\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5243 - val_loss: 0.3855\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5221 - val_loss: 0.3842\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5199 - val_loss: 0.3830\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5176 - val_loss: 0.3817\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5154 - val_loss: 0.3804\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5133 - val_loss: 0.3792\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5111 - val_loss: 0.3780\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5089 - val_loss: 0.3770\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.22679251401977166, my average MASE = 0.3179573135228401\n",
      "Cluster 2, 0.22679251401977166\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4783 - val_loss: 0.4457\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4766 - val_loss: 0.4444\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4750 - val_loss: 0.4432\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4734 - val_loss: 0.4420\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4719 - val_loss: 0.4408\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4703 - val_loss: 0.4397\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4687 - val_loss: 0.4385\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4672 - val_loss: 0.4374\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4657 - val_loss: 0.4362\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4642 - val_loss: 0.4351\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4627 - val_loss: 0.4340\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4613 - val_loss: 0.4329\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4598 - val_loss: 0.4318\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4584 - val_loss: 0.4307\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4296\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4555 - val_loss: 0.4286\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4541 - val_loss: 0.4275\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4527 - val_loss: 0.4265\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4513 - val_loss: 0.4255\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4499 - val_loss: 0.4245\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4486 - val_loss: 0.4235\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4472 - val_loss: 0.4225\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4459 - val_loss: 0.4215\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4445 - val_loss: 0.4205\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4432 - val_loss: 0.4195\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4186\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4406 - val_loss: 0.4176\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4167\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4380 - val_loss: 0.4158\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4368 - val_loss: 0.4149\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4355 - val_loss: 0.4139\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4343 - val_loss: 0.4130\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4330 - val_loss: 0.4121\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4318 - val_loss: 0.4112\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4306 - val_loss: 0.4103\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4294 - val_loss: 0.4094\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4282 - val_loss: 0.4085\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4270 - val_loss: 0.4077\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4258 - val_loss: 0.4068\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4246 - val_loss: 0.4059\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3532936323.38913, my average MASE = 7800622104.848636\n",
      "Cluster 3, 3532936323.38913\n",
      "Before prediction: train_X.shape=(152, 10, 67), train_y.shape=(152, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3354 - val_loss: 0.2774\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3344 - val_loss: 0.2769\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3336 - val_loss: 0.2763\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3328 - val_loss: 0.2758\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3320 - val_loss: 0.2753\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3312 - val_loss: 0.2747\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3304 - val_loss: 0.2742\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3297 - val_loss: 0.2737\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3290 - val_loss: 0.2733\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3282 - val_loss: 0.2728\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3275 - val_loss: 0.2723\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3268 - val_loss: 0.2718\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3262 - val_loss: 0.2714\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3255 - val_loss: 0.2709\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3248 - val_loss: 0.2705\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3242 - val_loss: 0.2700\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3235 - val_loss: 0.2696\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3229 - val_loss: 0.2692\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3223 - val_loss: 0.2687\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3217 - val_loss: 0.2683\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3210 - val_loss: 0.2678\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3204 - val_loss: 0.2674\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3198 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3192 - val_loss: 0.2666\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3187 - val_loss: 0.2662\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3181 - val_loss: 0.2658\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3175 - val_loss: 0.2654\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3170 - val_loss: 0.2650\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3164 - val_loss: 0.2647\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3158 - val_loss: 0.2643\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3153 - val_loss: 0.2639\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3148 - val_loss: 0.2635\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3142 - val_loss: 0.2632\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3137 - val_loss: 0.2628\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3132 - val_loss: 0.2624\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3127 - val_loss: 0.2621\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3122 - val_loss: 0.2617\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3117 - val_loss: 0.2614\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3112 - val_loss: 0.2610\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3107 - val_loss: 0.2607\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 185.09520141259705, my average MASE = 132066880.5161765\n",
      "Cluster 4, 185.09520141259705\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0679 - val_loss: 0.0461\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0619 - val_loss: 0.0426\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0586 - val_loss: 0.0401\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0561 - val_loss: 0.0381\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0542 - val_loss: 0.0366\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0527 - val_loss: 0.0352\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0514 - val_loss: 0.0341\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0503 - val_loss: 0.0333\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0312\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0473 - val_loss: 0.0307\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0468 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0463 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0459 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0455 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0452 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0448 - val_loss: 0.0288\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0286\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0443 - val_loss: 0.0284\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0283\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0281\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0436 - val_loss: 0.0279\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0434 - val_loss: 0.0278\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0277\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0276\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0274\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0273\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0426 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0425 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0423 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0422 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0421 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0420 - val_loss: 0.0269\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0419 - val_loss: 0.0268\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0267\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 1042799882.6542007, my average MASE = 20591462481.802387\n",
      "Cluster 5, 1042799882.6542007\n",
      "Before prediction: train_X.shape=(82, 10, 67), train_y.shape=(82, 67), test_X.shape=(27, 10, 67), test_y.shape=(27, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3924 - val_loss: 0.4859\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3915 - val_loss: 0.4852\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3907 - val_loss: 0.4846\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3899 - val_loss: 0.4840\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3891 - val_loss: 0.4835\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3883 - val_loss: 0.4829\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3876 - val_loss: 0.4824\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3868 - val_loss: 0.4818\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3861 - val_loss: 0.4813\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 0.4808\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3847 - val_loss: 0.4802\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3841 - val_loss: 0.4797\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3834 - val_loss: 0.4792\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3828 - val_loss: 0.4787\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3821 - val_loss: 0.4783\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3815 - val_loss: 0.4778\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3809 - val_loss: 0.4773\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3804 - val_loss: 0.4769\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3798 - val_loss: 0.4764\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.4760\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3787 - val_loss: 0.4755\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3781 - val_loss: 0.4751\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4747\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3771 - val_loss: 0.4743\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3766 - val_loss: 0.4738\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3761 - val_loss: 0.4734\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3756 - val_loss: 0.4731\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3751 - val_loss: 0.4727\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3746 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3741 - val_loss: 0.4719\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3737 - val_loss: 0.4715\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3732 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3728 - val_loss: 0.4707\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3723 - val_loss: 0.4703\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3719 - val_loss: 0.4699\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3715 - val_loss: 0.4696\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3710 - val_loss: 0.4692\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3706 - val_loss: 0.4688\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3702 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3698 - val_loss: 0.4681\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(27, 67), test_y.shape=(27, 67)\n",
      "average MASE = 307.7375965485456, my average MASE = 158440912.42565766\n",
      "Cluster 6, 307.7375965485456\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=9, 9, 32, (76, 67)\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4763 - val_loss: 0.4497\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4746 - val_loss: 0.4487\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4729 - val_loss: 0.4477\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4713 - val_loss: 0.4467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4696 - val_loss: 0.4458\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4680 - val_loss: 0.4448\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.4439\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4647 - val_loss: 0.4429\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4631 - val_loss: 0.4420\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.4410\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4600 - val_loss: 0.4401\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4585 - val_loss: 0.4392\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4554 - val_loss: 0.4373\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4539 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4524 - val_loss: 0.4355\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4510 - val_loss: 0.4345\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4495 - val_loss: 0.4336\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4481 - val_loss: 0.4327\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.4319\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4453 - val_loss: 0.4310\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4439 - val_loss: 0.4301\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4425 - val_loss: 0.4293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4412 - val_loss: 0.4284\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4398 - val_loss: 0.4276\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4385 - val_loss: 0.4267\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4371 - val_loss: 0.4259\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4358 - val_loss: 0.4251\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.4243\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4332 - val_loss: 0.4234\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4226\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4307 - val_loss: 0.4218\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4294 - val_loss: 0.4210\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4282 - val_loss: 0.4202\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4270 - val_loss: 0.4195\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4258 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4246 - val_loss: 0.4179\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4234 - val_loss: 0.4172\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4222 - val_loss: 0.4164\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4211 - val_loss: 0.4157\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3502979890.5184355, my average MASE = 5633924620.870799\n",
      "Cluster 0, 3502979890.5184355\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1163 - val_loss: 0.0998\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1111 - val_loss: 0.0974\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1069 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1034 - val_loss: 0.0946\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1003 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0952 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0929 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0909 - val_loss: 0.0914\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0891 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0907\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0859 - val_loss: 0.0904\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0902\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0831 - val_loss: 0.0900\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0808 - val_loss: 0.0896\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0797 - val_loss: 0.0894\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0787 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0778 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0769 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0761 - val_loss: 0.0890\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0889\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0745 - val_loss: 0.0888\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0738 - val_loss: 0.0887\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0731 - val_loss: 0.0886\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0725 - val_loss: 0.0886\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0885\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0713 - val_loss: 0.0885\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0707 - val_loss: 0.0884\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0702 - val_loss: 0.0884\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0697 - val_loss: 0.0883\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0692 - val_loss: 0.0883\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0882\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0683 - val_loss: 0.0882\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0881\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0881\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0880\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0880\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0665 - val_loss: 0.0879\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0662 - val_loss: 0.0879\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1199834821.8603294, my average MASE = 15362171394.25593\n",
      "Cluster 1, 1199834821.8603294\n",
      "Before prediction: train_X.shape=(1567, 10, 67), train_y.shape=(1567, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2378 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2280 - val_loss: 0.2658\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2204 - val_loss: 0.2582\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2142 - val_loss: 0.2520\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2091 - val_loss: 0.2467\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2046 - val_loss: 0.2420\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2006 - val_loss: 0.2378\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1971 - val_loss: 0.2340\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1938 - val_loss: 0.2304\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1908 - val_loss: 0.2272\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1880 - val_loss: 0.2241\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1853 - val_loss: 0.2213\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1829 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1806 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1784 - val_loss: 0.2141\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1765 - val_loss: 0.2121\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1747 - val_loss: 0.2103\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1730 - val_loss: 0.2086\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1715 - val_loss: 0.2071\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1702 - val_loss: 0.2056\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1689 - val_loss: 0.2042\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1677 - val_loss: 0.2029\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2016\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2005\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1645 - val_loss: 0.1993\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1983\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1626 - val_loss: 0.1973\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1618 - val_loss: 0.1962\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1610 - val_loss: 0.1953\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1944\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1594 - val_loss: 0.1935\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1587 - val_loss: 0.1927\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1580 - val_loss: 0.1919\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1573 - val_loss: 0.1911\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1567 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1555 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1550 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1539 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 164.5516081334958, my average MASE = 793528060.8539205\n",
      "Cluster 2, 164.5516081334958\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3929 - val_loss: 0.4650\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 0.4646\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3912 - val_loss: 0.4642\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3904 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3896 - val_loss: 0.4635\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3889 - val_loss: 0.4631\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3881 - val_loss: 0.4627\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3874 - val_loss: 0.4624\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4621\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.4617\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3854 - val_loss: 0.4614\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3847 - val_loss: 0.4611\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3841 - val_loss: 0.4608\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3835 - val_loss: 0.4605\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3829 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3823 - val_loss: 0.4600\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3817 - val_loss: 0.4597\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3812 - val_loss: 0.4594\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.4591\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3800 - val_loss: 0.4588\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3795 - val_loss: 0.4585\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3790 - val_loss: 0.4583\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3785 - val_loss: 0.4580\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.4578\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3775 - val_loss: 0.4575\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3770 - val_loss: 0.4572\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3765 - val_loss: 0.4570\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3761 - val_loss: 0.4567\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3756 - val_loss: 0.4565\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3752 - val_loss: 0.4563\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3747 - val_loss: 0.4560\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3738 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3734 - val_loss: 0.4553\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3730 - val_loss: 0.4551\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3725 - val_loss: 0.4549\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3721 - val_loss: 0.4547\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3717 - val_loss: 0.4545\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3713 - val_loss: 0.4542\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3709 - val_loss: 0.4540\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 177.05816941536048, my average MASE = 104373067.45181417\n",
      "Cluster 3, 177.05816941536048\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4712 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4689 - val_loss: 0.3159\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.3148\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4644 - val_loss: 0.3137\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4621 - val_loss: 0.3125\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4598 - val_loss: 0.3114\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4576 - val_loss: 0.3103\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4553 - val_loss: 0.3092\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4531 - val_loss: 0.3081\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4509 - val_loss: 0.3071\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.3062\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4465 - val_loss: 0.3053\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4444 - val_loss: 0.3044\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4422 - val_loss: 0.3036\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4401 - val_loss: 0.3028\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4379 - val_loss: 0.3020\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4358 - val_loss: 0.3012\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.3004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4317 - val_loss: 0.2996\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4297 - val_loss: 0.2988\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4278 - val_loss: 0.2979\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4259 - val_loss: 0.2970\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4240 - val_loss: 0.2961\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4222 - val_loss: 0.2952\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4204 - val_loss: 0.2943\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4186 - val_loss: 0.2934\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4168 - val_loss: 0.2924\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4151 - val_loss: 0.2915\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4134 - val_loss: 0.2906\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4118 - val_loss: 0.2898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4102 - val_loss: 0.2890\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4086 - val_loss: 0.2883\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4070 - val_loss: 0.2876\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.2869\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4039 - val_loss: 0.2863\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4009 - val_loss: 0.2850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.2845\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3980 - val_loss: 0.2840\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3966 - val_loss: 0.2835\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 254.89087963107983, my average MASE = 19795911.088192035\n",
      "Cluster 5, 254.89087963107983\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(176, 10, 67), train_y.shape=(176, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7010 - val_loss: 0.5674\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6997 - val_loss: 0.5667\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6984 - val_loss: 0.5660\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6972 - val_loss: 0.5654\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6960 - val_loss: 0.5647\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6948 - val_loss: 0.5641\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6937 - val_loss: 0.5635\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6925 - val_loss: 0.5629\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.5623\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6903 - val_loss: 0.5617\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6893 - val_loss: 0.5611\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6882 - val_loss: 0.5605\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6871 - val_loss: 0.5599\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6861 - val_loss: 0.5594\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6851 - val_loss: 0.5588\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6841 - val_loss: 0.5583\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6831 - val_loss: 0.5577\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6821 - val_loss: 0.5572\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6811 - val_loss: 0.5567\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6802 - val_loss: 0.5562\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6792 - val_loss: 0.5556\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6783 - val_loss: 0.5551\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6774 - val_loss: 0.5546\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6765 - val_loss: 0.5541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6756 - val_loss: 0.5536\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6747 - val_loss: 0.5531\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6738 - val_loss: 0.5526\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6729 - val_loss: 0.5521\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6720 - val_loss: 0.5516\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6712 - val_loss: 0.5512\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6703 - val_loss: 0.5507\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6695 - val_loss: 0.5502\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6686 - val_loss: 0.5497\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6678 - val_loss: 0.5493\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6670 - val_loss: 0.5488\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6661 - val_loss: 0.5483\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6653 - val_loss: 0.5479\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.5474\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6637 - val_loss: 0.5469\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6629 - val_loss: 0.5464\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 154.34881195949765, my average MASE = 318959730.30915844\n",
      "Cluster 7, 154.34881195949765\n",
      "Before prediction: train_X.shape=(150, 10, 67), train_y.shape=(150, 67), test_X.shape=(50, 10, 67), test_y.shape=(50, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3127 - val_loss: 0.2620\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3118 - val_loss: 0.2614\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3110 - val_loss: 0.2608\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3103 - val_loss: 0.2603\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3096 - val_loss: 0.2597\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3088 - val_loss: 0.2592\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3081 - val_loss: 0.2587\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3074 - val_loss: 0.2582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3067 - val_loss: 0.2577\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3060 - val_loss: 0.2572\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3054 - val_loss: 0.2567\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3047 - val_loss: 0.2563\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3041 - val_loss: 0.2558\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3035 - val_loss: 0.2554\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3029 - val_loss: 0.2549\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3023 - val_loss: 0.2545\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3017 - val_loss: 0.2541\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3011 - val_loss: 0.2537\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3005 - val_loss: 0.2533\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3000 - val_loss: 0.2529\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2994 - val_loss: 0.2525\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2988 - val_loss: 0.2521\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2983 - val_loss: 0.2517\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2978 - val_loss: 0.2513\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2973 - val_loss: 0.2509\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2967 - val_loss: 0.2505\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2962 - val_loss: 0.2502\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2957 - val_loss: 0.2498\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2952 - val_loss: 0.2494\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2948 - val_loss: 0.2491\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2943 - val_loss: 0.2487\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2938 - val_loss: 0.2484\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2933 - val_loss: 0.2480\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2929 - val_loss: 0.2477\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2924 - val_loss: 0.2473\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2920 - val_loss: 0.2470\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2915 - val_loss: 0.2467\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2911 - val_loss: 0.2463\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2907 - val_loss: 0.2460\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2902 - val_loss: 0.2457\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(50, 67), test_y.shape=(50, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 222.6692241509544, my average MASE = 77008768.33506098\n",
      "Cluster 8, 222.6692241509544\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=11, 11, 435, (11, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4436 - val_loss: 0.3307\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4426 - val_loss: 0.3306\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4417 - val_loss: 0.3306\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4408 - val_loss: 0.3305\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4398 - val_loss: 0.3305\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4389 - val_loss: 0.3304\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4380 - val_loss: 0.3303\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4371 - val_loss: 0.3303\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4362 - val_loss: 0.3302\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4354 - val_loss: 0.3301\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.3301\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4337 - val_loss: 0.3300\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4329 - val_loss: 0.3299\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4320 - val_loss: 0.3299\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4312 - val_loss: 0.3298\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4304 - val_loss: 0.3298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4296 - val_loss: 0.3297\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4288 - val_loss: 0.3296\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4280 - val_loss: 0.3295\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4273 - val_loss: 0.3295\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4265 - val_loss: 0.3294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4258 - val_loss: 0.3293\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4250 - val_loss: 0.3293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4243 - val_loss: 0.3292\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4235 - val_loss: 0.3291\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4228 - val_loss: 0.3291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4221 - val_loss: 0.3290\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4213 - val_loss: 0.3290\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.3289\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4199 - val_loss: 0.3288\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4191 - val_loss: 0.3288\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4184 - val_loss: 0.3287\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4177 - val_loss: 0.3287\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4170 - val_loss: 0.3286\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4163 - val_loss: 0.3286\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 0.3285\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4149 - val_loss: 0.3285\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4143 - val_loss: 0.3285\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4136 - val_loss: 0.3284\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4129 - val_loss: 0.3284\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 623.4242587364998, my average MASE = 13116998.58946489\n",
      "Cluster 0, 623.4242587364998\n",
      "Before prediction: train_X.shape=(18, 10, 67), train_y.shape=(18, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4512 - val_loss: 0.5917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4491 - val_loss: 0.5900\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4470 - val_loss: 0.5884\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4449 - val_loss: 0.5867\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4429 - val_loss: 0.5851\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4408 - val_loss: 0.5835\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.5818\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4369 - val_loss: 0.5802\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4349 - val_loss: 0.5786\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4330 - val_loss: 0.5770\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4311 - val_loss: 0.5755\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4293 - val_loss: 0.5739\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4275 - val_loss: 0.5724\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4257 - val_loss: 0.5709\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4239 - val_loss: 0.5694\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4222 - val_loss: 0.5680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4205 - val_loss: 0.5666\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4188 - val_loss: 0.5652\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4171 - val_loss: 0.5638\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4155 - val_loss: 0.5625\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4139 - val_loss: 0.5611\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4123 - val_loss: 0.5598\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4107 - val_loss: 0.5584\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4092 - val_loss: 0.5571\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4077 - val_loss: 0.5558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4062 - val_loss: 0.5545\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4047 - val_loss: 0.5532\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4032 - val_loss: 0.5519\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4017 - val_loss: 0.5506\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4003 - val_loss: 0.5494\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.5482\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5470\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3960 - val_loss: 0.5458\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.5446\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3933 - val_loss: 0.5435\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3920 - val_loss: 0.5424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3906 - val_loss: 0.5414\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3893 - val_loss: 0.5403\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3881 - val_loss: 0.5393\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3868 - val_loss: 0.5382\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1669347283.8471758, my average MASE = 4344504132.76493\n",
      "Cluster 1, 1669347283.8471758\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0678 - val_loss: 0.0460\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0618 - val_loss: 0.0427\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0585 - val_loss: 0.0404\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0561 - val_loss: 0.0385\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0542 - val_loss: 0.0369\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0527 - val_loss: 0.0355\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0514 - val_loss: 0.0344\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0503 - val_loss: 0.0335\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0327\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0321\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0315\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0473 - val_loss: 0.0310\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0468 - val_loss: 0.0306\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0463 - val_loss: 0.0302\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0458 - val_loss: 0.0299\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0454 - val_loss: 0.0296\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0293\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0447 - val_loss: 0.0291\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0444 - val_loss: 0.0289\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0442 - val_loss: 0.0287\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0439 - val_loss: 0.0285\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0283\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0434 - val_loss: 0.0281\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0430 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0427 - val_loss: 0.0276\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0423 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0419 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0266\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0415 - val_loss: 0.0265\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0264\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0263\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 811440996.3412759, my average MASE = 40052487777.48425\n",
      "Cluster 2, 811440996.3412759\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1986 - val_loss: 0.8095\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1967 - val_loss: 0.8095\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1948 - val_loss: 0.8095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1930 - val_loss: 0.8094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1912 - val_loss: 0.8094\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1894 - val_loss: 0.8094\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1876 - val_loss: 0.8094\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1858 - val_loss: 0.8094\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1840 - val_loss: 0.8094\n",
      "Epoch 9: early stopping\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 72.88641883174732, my average MASE = 50002377.286928184\n",
      "Cluster 3, 72.88641883174732\n",
      "Before prediction: train_X.shape=(87, 10, 67), train_y.shape=(87, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5691 - val_loss: 0.5072\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5682 - val_loss: 0.5068\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5674 - val_loss: 0.5063\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5666 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5659 - val_loss: 0.5055\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5651 - val_loss: 0.5051\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5643 - val_loss: 0.5047\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5636 - val_loss: 0.5042\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5628 - val_loss: 0.5038\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5621 - val_loss: 0.5034\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5614 - val_loss: 0.5030\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5606 - val_loss: 0.5026\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5600 - val_loss: 0.5022\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5592 - val_loss: 0.5018\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5586 - val_loss: 0.5014\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5579 - val_loss: 0.5011\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5572 - val_loss: 0.5007\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5565 - val_loss: 0.5003\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5558 - val_loss: 0.4999\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5552 - val_loss: 0.4996\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5545 - val_loss: 0.4993\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5539 - val_loss: 0.4989\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5532 - val_loss: 0.4986\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5526 - val_loss: 0.4983\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5520 - val_loss: 0.4979\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5513 - val_loss: 0.4976\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5507 - val_loss: 0.4973\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5501 - val_loss: 0.4970\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5495 - val_loss: 0.4967\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5489 - val_loss: 0.4964\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5483 - val_loss: 0.4961\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5477 - val_loss: 0.4958\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5471 - val_loss: 0.4956\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5465 - val_loss: 0.4953\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5459 - val_loss: 0.4950\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5453 - val_loss: 0.4947\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5447 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5442 - val_loss: 0.4942\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.4939\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5430 - val_loss: 0.4936\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 98.29689269118158, my average MASE = 78492579.83265808\n",
      "Cluster 4, 98.29689269118158\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4003 - val_loss: 0.3997\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3997 - val_loss: 0.3991\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3991 - val_loss: 0.3986\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3985 - val_loss: 0.3981\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3976\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3973 - val_loss: 0.3971\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3968 - val_loss: 0.3967\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3962\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3957 - val_loss: 0.3958\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3953\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3946 - val_loss: 0.3949\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3940 - val_loss: 0.3945\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3935 - val_loss: 0.3941\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3930 - val_loss: 0.3937\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3924 - val_loss: 0.3932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3919 - val_loss: 0.3928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3914 - val_loss: 0.3925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3904 - val_loss: 0.3917\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3899 - val_loss: 0.3913\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3894 - val_loss: 0.3909\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3889 - val_loss: 0.3906\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3884 - val_loss: 0.3902\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3879 - val_loss: 0.3898\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3870 - val_loss: 0.3891\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3865 - val_loss: 0.3887\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.3883\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3856 - val_loss: 0.3880\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3851 - val_loss: 0.3876\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3847 - val_loss: 0.3872\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3842 - val_loss: 0.3869\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3838 - val_loss: 0.3865\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3833 - val_loss: 0.3861\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3829 - val_loss: 0.3857\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3824 - val_loss: 0.3853\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 0.3850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3815 - val_loss: 0.3846\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3811 - val_loss: 0.3842\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3807 - val_loss: 0.3838\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 517837.8778283109, my average MASE = 16943290.739345513\n",
      "Cluster 6, 517837.8778283109\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2151 - val_loss: 0.4042\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2146 - val_loss: 0.4041\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2142 - val_loss: 0.4041\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2137 - val_loss: 0.4040\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2133 - val_loss: 0.4040\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2128 - val_loss: 0.4040\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2124 - val_loss: 0.4039\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2119 - val_loss: 0.4039\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2115 - val_loss: 0.4038\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2111 - val_loss: 0.4038\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2107 - val_loss: 0.4038\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2103 - val_loss: 0.4038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2099 - val_loss: 0.4037\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2096 - val_loss: 0.4037\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2092 - val_loss: 0.4037\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2088 - val_loss: 0.4036\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2084 - val_loss: 0.4036\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2081 - val_loss: 0.4036\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2077 - val_loss: 0.4035\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2074 - val_loss: 0.4035\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2070 - val_loss: 0.4035\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2067 - val_loss: 0.4035\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2063 - val_loss: 0.4035\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2060 - val_loss: 0.4034\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2057 - val_loss: 0.4034\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2054 - val_loss: 0.4034\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2050 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2047 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2044 - val_loss: 0.4033\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2041 - val_loss: 0.4033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2038 - val_loss: 0.4032\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2035 - val_loss: 0.4032\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2032 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2029 - val_loss: 0.4031\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2026 - val_loss: 0.4031\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2023 - val_loss: 0.4031\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2020 - val_loss: 0.4030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2017 - val_loss: 0.4030\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2014 - val_loss: 0.4029\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2011 - val_loss: 0.4029\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 181.01448499364625, my average MASE = 73613295.18701741\n",
      "Cluster 7, 181.01448499364625\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2941 - val_loss: 0.3652\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2932 - val_loss: 0.3650\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2923 - val_loss: 0.3648\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2914 - val_loss: 0.3646\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2905 - val_loss: 0.3644\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2897 - val_loss: 0.3641\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2888 - val_loss: 0.3639\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2880 - val_loss: 0.3638\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2872 - val_loss: 0.3636\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2864 - val_loss: 0.3634\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2856 - val_loss: 0.3632\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2848 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2840 - val_loss: 0.3629\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2832 - val_loss: 0.3628\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2824 - val_loss: 0.3626\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2817 - val_loss: 0.3625\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2809 - val_loss: 0.3624\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2802 - val_loss: 0.3622\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2794 - val_loss: 0.3621\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2787 - val_loss: 0.3620\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2780 - val_loss: 0.3619\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2772 - val_loss: 0.3618\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2765 - val_loss: 0.3617\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2758 - val_loss: 0.3616\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2751 - val_loss: 0.3615\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2744 - val_loss: 0.3615\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2738 - val_loss: 0.3614\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2731 - val_loss: 0.3613\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2725 - val_loss: 0.3613\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2718 - val_loss: 0.3612\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2712 - val_loss: 0.3612\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2705 - val_loss: 0.3611\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2699 - val_loss: 0.3611\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2693 - val_loss: 0.3610\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2687 - val_loss: 0.3610\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2681 - val_loss: 0.3610\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2675 - val_loss: 0.3609\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2669 - val_loss: 0.3609\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2663 - val_loss: 0.3608\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.3608\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 679.6913673037432, my average MASE = 68962615.13093176\n",
      "Cluster 9, 679.6913673037432\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=2, 2, 11, (10056, 67)\n",
      "Before prediction: train_X.shape=(6027, 10, 67), train_y.shape=(6027, 67), test_X.shape=(2009, 10, 67), test_y.shape=(2009, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0641 - val_loss: 0.0494\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0590 - val_loss: 0.0459\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0558 - val_loss: 0.0432\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0535 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0516 - val_loss: 0.0393\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0501 - val_loss: 0.0378\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0489 - val_loss: 0.0366\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0478 - val_loss: 0.0357\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0470 - val_loss: 0.0348\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0462 - val_loss: 0.0341\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0455 - val_loss: 0.0335\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0330\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0443 - val_loss: 0.0325\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0321\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0317\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0314\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0311\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0423 - val_loss: 0.0308\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0419 - val_loss: 0.0305\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0303\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0414 - val_loss: 0.0300\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0298\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0296\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0406 - val_loss: 0.0294\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0404 - val_loss: 0.0293\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0403 - val_loss: 0.0291\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0401 - val_loss: 0.0290\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0399 - val_loss: 0.0289\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0397 - val_loss: 0.0287\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0396 - val_loss: 0.0286\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0394 - val_loss: 0.0286\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0393 - val_loss: 0.0285\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0392 - val_loss: 0.0284\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0391 - val_loss: 0.0283\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0389 - val_loss: 0.0282\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0388 - val_loss: 0.0282\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0387 - val_loss: 0.0281\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0386 - val_loss: 0.0281\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0385 - val_loss: 0.0280\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0384 - val_loss: 0.0280\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2009, 67), test_y.shape=(2009, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 137177179.8661396, my average MASE = 15662264218.215044\n",
      "Cluster 0, 137177179.8661396\n",
      "Before prediction: train_X.shape=(18366, 10, 67), train_y.shape=(18366, 67), test_X.shape=(6122, 10, 67), test_y.shape=(6122, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3004 - val_loss: 0.3159\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2809 - val_loss: 0.3004\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2655 - val_loss: 0.2878\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2540 - val_loss: 0.2790\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2465 - val_loss: 0.2727\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2409 - val_loss: 0.2676\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2364 - val_loss: 0.2633\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2324 - val_loss: 0.2598\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2290 - val_loss: 0.2567\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2259 - val_loss: 0.2539\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2230 - val_loss: 0.2514\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2204 - val_loss: 0.2493\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2181 - val_loss: 0.2474\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2161 - val_loss: 0.2457\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2144 - val_loss: 0.2442\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2129 - val_loss: 0.2429\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2115 - val_loss: 0.2418\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2103 - val_loss: 0.2406\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2092 - val_loss: 0.2396\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2083 - val_loss: 0.2386\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2073 - val_loss: 0.2378\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2065 - val_loss: 0.2370\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2057 - val_loss: 0.2363\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2050 - val_loss: 0.2356\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2350\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2344\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2031 - val_loss: 0.2338\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2025 - val_loss: 0.2333\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2020 - val_loss: 0.2328\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2015 - val_loss: 0.2324\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2319\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2006 - val_loss: 0.2314\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2002 - val_loss: 0.2311\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1998 - val_loss: 0.2307\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.1994 - val_loss: 0.2304\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1991 - val_loss: 0.2301\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.1987 - val_loss: 0.2298\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1984 - val_loss: 0.2294\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1981 - val_loss: 0.2291\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1978 - val_loss: 0.2290\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6122, 67), test_y.shape=(6122, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1800.7465590842255, my average MASE = 3633.615501921918\n",
      "Cluster 1, 1800.7465590842255\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=5, 5, 58, (3715, 67)\n",
      "Before prediction: train_X.shape=(2222, 10, 67), train_y.shape=(2222, 67), test_X.shape=(741, 10, 67), test_y.shape=(741, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5001 - val_loss: 0.3691\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4918 - val_loss: 0.3651\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4851 - val_loss: 0.3618\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4795 - val_loss: 0.3589\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4744 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4699 - val_loss: 0.3539\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4657 - val_loss: 0.3517\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4618 - val_loss: 0.3497\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4582 - val_loss: 0.3478\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4548 - val_loss: 0.3460\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4516 - val_loss: 0.3443\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4485 - val_loss: 0.3427\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4455 - val_loss: 0.3412\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4426 - val_loss: 0.3398\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4398 - val_loss: 0.3384\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4370 - val_loss: 0.3370\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4342 - val_loss: 0.3357\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4315 - val_loss: 0.3345\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4289 - val_loss: 0.3332\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4263 - val_loss: 0.3321\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4237 - val_loss: 0.3309\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4213 - val_loss: 0.3298\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4189 - val_loss: 0.3287\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4166 - val_loss: 0.3277\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4143 - val_loss: 0.3266\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4120 - val_loss: 0.3256\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4099 - val_loss: 0.3247\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4079 - val_loss: 0.3238\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4059 - val_loss: 0.3230\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4040 - val_loss: 0.3222\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4022 - val_loss: 0.3214\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4005 - val_loss: 0.3206\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3988 - val_loss: 0.3199\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3972 - val_loss: 0.3193\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3956 - val_loss: 0.3186\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3941 - val_loss: 0.3180\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3927 - val_loss: 0.3175\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3912 - val_loss: 0.3169\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3899 - val_loss: 0.3163\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3885 - val_loss: 0.3158\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(741, 67), test_y.shape=(741, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 461.9721639366225, my average MASE = 1222.9207656733142\n",
      "Cluster 0, 461.9721639366225\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1169 - val_loss: 0.0965\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1118 - val_loss: 0.0947\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1077 - val_loss: 0.0935\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1043 - val_loss: 0.0926\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1013 - val_loss: 0.0919\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0987 - val_loss: 0.0913\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0964 - val_loss: 0.0909\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0942 - val_loss: 0.0906\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0923 - val_loss: 0.0904\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0901\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0890 - val_loss: 0.0899\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0875 - val_loss: 0.0897\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0861 - val_loss: 0.0895\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0849 - val_loss: 0.0894\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0837 - val_loss: 0.0892\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0826 - val_loss: 0.0891\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0816 - val_loss: 0.0889\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0807 - val_loss: 0.0888\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0798 - val_loss: 0.0886\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0790 - val_loss: 0.0885\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0782 - val_loss: 0.0884\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0883\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0881\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0761 - val_loss: 0.0880\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0755 - val_loss: 0.0879\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0749 - val_loss: 0.0878\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0743 - val_loss: 0.0877\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0738 - val_loss: 0.0876\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0732 - val_loss: 0.0875\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0727 - val_loss: 0.0875\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0722 - val_loss: 0.0874\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0718 - val_loss: 0.0874\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0713 - val_loss: 0.0874\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0873\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0705 - val_loss: 0.0873\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0873\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0872\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0695 - val_loss: 0.0872\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0689 - val_loss: 0.0871\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 979857680.8759673, my average MASE = 20246393999.460716\n",
      "Cluster 1, 979857680.8759673\n",
      "Before prediction: train_X.shape=(160, 10, 67), train_y.shape=(160, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5150 - val_loss: 0.4228\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5137 - val_loss: 0.4220\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5125 - val_loss: 0.4212\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5113 - val_loss: 0.4205\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5101 - val_loss: 0.4197\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5090 - val_loss: 0.4189\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5079 - val_loss: 0.4182\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5068 - val_loss: 0.4175\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5058 - val_loss: 0.4168\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4161\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5037 - val_loss: 0.4154\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5026 - val_loss: 0.4148\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5016 - val_loss: 0.4141\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5006 - val_loss: 0.4135\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4997 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4987 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4977 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4968 - val_loss: 0.4110\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4958 - val_loss: 0.4104\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4949 - val_loss: 0.4098\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4940 - val_loss: 0.4092\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4931 - val_loss: 0.4086\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4923 - val_loss: 0.4081\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4914 - val_loss: 0.4075\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4905 - val_loss: 0.4069\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4064\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4888 - val_loss: 0.4059\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4880 - val_loss: 0.4053\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4871 - val_loss: 0.4048\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4863 - val_loss: 0.4043\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4855 - val_loss: 0.4038\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4847 - val_loss: 0.4033\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4840 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4832 - val_loss: 0.4023\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4018\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4817 - val_loss: 0.4013\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4809 - val_loss: 0.4008\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4802 - val_loss: 0.4003\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4795 - val_loss: 0.3998\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4787 - val_loss: 0.3994\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.13783551729924, my average MASE = 51951538.633395046\n",
      "Cluster 2, 127.13783551729924\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8383 - val_loss: 0.5938\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8360 - val_loss: 0.5928\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8338 - val_loss: 0.5919\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8316 - val_loss: 0.5910\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8294 - val_loss: 0.5901\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8272 - val_loss: 0.5891\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8251 - val_loss: 0.5882\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 0.5873\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8208 - val_loss: 0.5864\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8187 - val_loss: 0.5855\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8167 - val_loss: 0.5847\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8146 - val_loss: 0.5838\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8126 - val_loss: 0.5830\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8107 - val_loss: 0.5821\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8087 - val_loss: 0.5812\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8068 - val_loss: 0.5803\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8048 - val_loss: 0.5794\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8029 - val_loss: 0.5786\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8009 - val_loss: 0.5777\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7989 - val_loss: 0.5768\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7970 - val_loss: 0.5760\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7951 - val_loss: 0.5751\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7932 - val_loss: 0.5743\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7913 - val_loss: 0.5735\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7894 - val_loss: 0.5727\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7875 - val_loss: 0.5720\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7857 - val_loss: 0.5712\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7839 - val_loss: 0.5704\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7820 - val_loss: 0.5697\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7802 - val_loss: 0.5690\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7784 - val_loss: 0.5682\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7767 - val_loss: 0.5675\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7749 - val_loss: 0.5668\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7732 - val_loss: 0.5661\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7715 - val_loss: 0.5655\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7698 - val_loss: 0.5648\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7681 - val_loss: 0.5641\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7664 - val_loss: 0.5635\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7647 - val_loss: 0.5629\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7630 - val_loss: 0.5623\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1378.9503839591846, my average MASE = 44152799.2879618\n",
      "Cluster 3, 1378.9503839591846\n",
      "Before prediction: train_X.shape=(44, 10, 67), train_y.shape=(44, 67), test_X.shape=(15, 10, 67), test_y.shape=(15, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5170 - val_loss: 0.7315\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5154 - val_loss: 0.7308\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.7300\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5122 - val_loss: 0.7293\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5107 - val_loss: 0.7285\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5092 - val_loss: 0.7278\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5077 - val_loss: 0.7271\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5062 - val_loss: 0.7264\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5047 - val_loss: 0.7257\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5033 - val_loss: 0.7250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5018 - val_loss: 0.7243\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.7236\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4990 - val_loss: 0.7229\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4977 - val_loss: 0.7222\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4963 - val_loss: 0.7215\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4949 - val_loss: 0.7209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4936 - val_loss: 0.7202\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4923 - val_loss: 0.7196\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4910 - val_loss: 0.7189\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4897 - val_loss: 0.7183\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4884 - val_loss: 0.7177\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.7170\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4859 - val_loss: 0.7164\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4847 - val_loss: 0.7158\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4835 - val_loss: 0.7152\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4823 - val_loss: 0.7146\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4811 - val_loss: 0.7140\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4799 - val_loss: 0.7135\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4788 - val_loss: 0.7129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4776 - val_loss: 0.7123\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4765 - val_loss: 0.7118\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4753 - val_loss: 0.7113\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4742 - val_loss: 0.7107\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4731 - val_loss: 0.7102\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4720 - val_loss: 0.7097\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4709 - val_loss: 0.7092\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4698 - val_loss: 0.7087\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4687 - val_loss: 0.7082\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.7077\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.7073\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(15, 67), test_y.shape=(15, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2846600473.0797715, my average MASE = 8256296780.299102\n",
      "Cluster 4, 2846600473.0797715\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=7, 7, 176, (267, 67)\n",
      "Before prediction: train_X.shape=(154, 10, 67), train_y.shape=(154, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3225 - val_loss: 0.2694\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3217 - val_loss: 0.2689\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3209 - val_loss: 0.2684\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3201 - val_loss: 0.2679\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3194 - val_loss: 0.2674\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3187 - val_loss: 0.2669\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3179 - val_loss: 0.2664\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3172 - val_loss: 0.2659\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3165 - val_loss: 0.2655\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3159 - val_loss: 0.2650\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3152 - val_loss: 0.2646\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3145 - val_loss: 0.2641\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3139 - val_loss: 0.2637\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3133 - val_loss: 0.2633\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3127 - val_loss: 0.2629\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3121 - val_loss: 0.2624\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3115 - val_loss: 0.2620\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3109 - val_loss: 0.2616\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3103 - val_loss: 0.2612\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3098 - val_loss: 0.2609\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3092 - val_loss: 0.2605\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3087 - val_loss: 0.2601\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3081 - val_loss: 0.2598\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3076 - val_loss: 0.2594\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3071 - val_loss: 0.2590\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3066 - val_loss: 0.2587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3061 - val_loss: 0.2584\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3056 - val_loss: 0.2580\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3051 - val_loss: 0.2576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3046 - val_loss: 0.2573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3041 - val_loss: 0.2569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3037 - val_loss: 0.2566\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3032 - val_loss: 0.2563\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3027 - val_loss: 0.2559\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3023 - val_loss: 0.2556\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3018 - val_loss: 0.2553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3013 - val_loss: 0.2550\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3009 - val_loss: 0.2546\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3005 - val_loss: 0.2543\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3000 - val_loss: 0.2540\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 173.3029589389659, my average MASE = 89033224.06135572\n",
      "Cluster 0, 173.3029589389659\n",
      "Before prediction: train_X.shape=(5960, 10, 67), train_y.shape=(5960, 67), test_X.shape=(1987, 10, 67), test_y.shape=(1987, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0675 - val_loss: 0.0464\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0617 - val_loss: 0.0432\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0584 - val_loss: 0.0410\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0560 - val_loss: 0.0393\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0541 - val_loss: 0.0377\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0525 - val_loss: 0.0364\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0512 - val_loss: 0.0353\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0501 - val_loss: 0.0343\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0492 - val_loss: 0.0335\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0484 - val_loss: 0.0327\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0477 - val_loss: 0.0321\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0471 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0466 - val_loss: 0.0310\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0461 - val_loss: 0.0306\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0457 - val_loss: 0.0302\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0453 - val_loss: 0.0299\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0449 - val_loss: 0.0296\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0445 - val_loss: 0.0293\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0442 - val_loss: 0.0291\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0288\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0286\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0284\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0432 - val_loss: 0.0282\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0424 - val_loss: 0.0275\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0421 - val_loss: 0.0272\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0420 - val_loss: 0.0271\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0419 - val_loss: 0.0270\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0417 - val_loss: 0.0269\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0268\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0413 - val_loss: 0.0265\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0412 - val_loss: 0.0264\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0409 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1987, 67), test_y.shape=(1987, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 783030752.0753396, my average MASE = 36192993113.38622\n",
      "Cluster 1, 783030752.0753396\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5458 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.3449\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.3440\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5391 - val_loss: 0.3431\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5369 - val_loss: 0.3422\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5348 - val_loss: 0.3413\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.3405\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5304 - val_loss: 0.3396\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5283 - val_loss: 0.3387\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5261 - val_loss: 0.3379\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5240 - val_loss: 0.3371\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5219 - val_loss: 0.3362\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5198 - val_loss: 0.3354\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5177 - val_loss: 0.3346\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5157 - val_loss: 0.3338\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5137 - val_loss: 0.3330\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5117 - val_loss: 0.3322\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5097 - val_loss: 0.3314\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5078 - val_loss: 0.3308\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5059 - val_loss: 0.3301\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5041 - val_loss: 0.3295\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5022 - val_loss: 0.3290\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.3284\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4986 - val_loss: 0.3279\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4968 - val_loss: 0.3274\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4951 - val_loss: 0.3269\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4933 - val_loss: 0.3264\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.3260\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4900 - val_loss: 0.3257\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4884 - val_loss: 0.3254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4868 - val_loss: 0.3251\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4852 - val_loss: 0.3249\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4836 - val_loss: 0.3247\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4821 - val_loss: 0.3245\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4805 - val_loss: 0.3244\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4790 - val_loss: 0.3242\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4775 - val_loss: 0.3241\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4760 - val_loss: 0.3240\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4745 - val_loss: 0.3239\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4730 - val_loss: 0.3238\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 300.2247881778862, my average MASE = 45822553.10580316\n",
      "Cluster 2, 300.2247881778862\n",
      "Before prediction: train_X.shape=(85, 10, 67), train_y.shape=(85, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3796 - val_loss: 0.4594\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3789 - val_loss: 0.4589\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3782 - val_loss: 0.4585\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4581\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3770 - val_loss: 0.4577\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3764 - val_loss: 0.4573\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.4569\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3753 - val_loss: 0.4565\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3748 - val_loss: 0.4561\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3737 - val_loss: 0.4554\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3732 - val_loss: 0.4550\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3727 - val_loss: 0.4547\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4543\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3717 - val_loss: 0.4540\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3713 - val_loss: 0.4537\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3708 - val_loss: 0.4533\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3703 - val_loss: 0.4530\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3699 - val_loss: 0.4527\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3694 - val_loss: 0.4524\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.4521\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3685 - val_loss: 0.4517\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3681 - val_loss: 0.4514\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3677 - val_loss: 0.4512\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3673 - val_loss: 0.4509\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3669 - val_loss: 0.4506\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3664 - val_loss: 0.4503\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4501\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3657 - val_loss: 0.4498\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3653 - val_loss: 0.4495\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3649 - val_loss: 0.4493\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3645 - val_loss: 0.4490\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3641 - val_loss: 0.4487\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.4485\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3634 - val_loss: 0.4482\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3630 - val_loss: 0.4480\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.4478\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3623 - val_loss: 0.4475\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.4473\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3616 - val_loss: 0.4470\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n",
      "average MASE = 329.8443195642471, my average MASE = 91063731.05477783\n",
      "Cluster 3, 329.8443195642471\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6262 - val_loss: 0.5214\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6239 - val_loss: 0.5202\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6216 - val_loss: 0.5190\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6193 - val_loss: 0.5179\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6170 - val_loss: 0.5167\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6148 - val_loss: 0.5156\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6125 - val_loss: 0.5145\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6102 - val_loss: 0.5134\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6080 - val_loss: 0.5123\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6058 - val_loss: 0.5112\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6036 - val_loss: 0.5101\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6015 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5994 - val_loss: 0.5080\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5973 - val_loss: 0.5070\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5953 - val_loss: 0.5060\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5932 - val_loss: 0.5051\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5912 - val_loss: 0.5041\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5892 - val_loss: 0.5032\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5872 - val_loss: 0.5023\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5853 - val_loss: 0.5015\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5834 - val_loss: 0.5006\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5816 - val_loss: 0.4999\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5799 - val_loss: 0.4991\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5782 - val_loss: 0.4984\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5765 - val_loss: 0.4977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5749 - val_loss: 0.4970\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5732 - val_loss: 0.4963\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5716 - val_loss: 0.4957\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5699 - val_loss: 0.4951\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5683 - val_loss: 0.4946\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5667 - val_loss: 0.4941\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5651 - val_loss: 0.4936\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5635 - val_loss: 0.4931\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5619 - val_loss: 0.4927\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5604 - val_loss: 0.4922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5588 - val_loss: 0.4917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5573 - val_loss: 0.4913\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5557 - val_loss: 0.4909\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5542 - val_loss: 0.4906\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5526 - val_loss: 0.4902\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32309710873507563, my average MASE = 0.5656513264705396\n",
      "Cluster 4, 0.32309710873507563\n",
      "Before prediction: train_X.shape=(43, 10, 67), train_y.shape=(43, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5119 - val_loss: 0.6850\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5101 - val_loss: 0.6839\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5083 - val_loss: 0.6829\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5066 - val_loss: 0.6819\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5048 - val_loss: 0.6808\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.6798\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5014 - val_loss: 0.6788\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.6778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4980 - val_loss: 0.6769\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4964 - val_loss: 0.6759\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4948 - val_loss: 0.6749\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4931 - val_loss: 0.6740\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4915 - val_loss: 0.6730\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4900 - val_loss: 0.6721\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4884 - val_loss: 0.6711\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4869 - val_loss: 0.6702\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4853 - val_loss: 0.6693\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4838 - val_loss: 0.6683\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6674\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4808 - val_loss: 0.6665\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.6656\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4779 - val_loss: 0.6647\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4765 - val_loss: 0.6639\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4751 - val_loss: 0.6630\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4737 - val_loss: 0.6622\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4723 - val_loss: 0.6613\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4710 - val_loss: 0.6605\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4697 - val_loss: 0.6596\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4683 - val_loss: 0.6588\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4670 - val_loss: 0.6580\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4657 - val_loss: 0.6572\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4644 - val_loss: 0.6564\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4631 - val_loss: 0.6556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4619 - val_loss: 0.6548\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4606 - val_loss: 0.6540\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4594 - val_loss: 0.6532\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4581 - val_loss: 0.6525\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4569 - val_loss: 0.6517\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4557 - val_loss: 0.6510\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4545 - val_loss: 0.6502\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2340337256.388025, my average MASE = 7806499481.251814\n",
      "Cluster 5, 2340337256.388025\n",
      "Before prediction: train_X.shape=(181, 10, 67), train_y.shape=(181, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6846 - val_loss: 0.5744\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6833 - val_loss: 0.5737\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6820 - val_loss: 0.5730\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6807 - val_loss: 0.5723\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6795 - val_loss: 0.5716\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6783 - val_loss: 0.5709\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6771 - val_loss: 0.5703\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6760 - val_loss: 0.5696\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6749 - val_loss: 0.5690\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6737 - val_loss: 0.5683\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6727 - val_loss: 0.5677\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6716 - val_loss: 0.5671\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6705 - val_loss: 0.5666\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6695 - val_loss: 0.5660\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6685 - val_loss: 0.5654\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6675 - val_loss: 0.5648\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6664 - val_loss: 0.5643\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6654 - val_loss: 0.5637\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6645 - val_loss: 0.5632\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6635 - val_loss: 0.5626\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6626 - val_loss: 0.5621\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.6616 - val_loss: 0.5615\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6607 - val_loss: 0.5610\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6597 - val_loss: 0.5605\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6588 - val_loss: 0.5600\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6579 - val_loss: 0.5594\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6570 - val_loss: 0.5589\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6561 - val_loss: 0.5584\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6553 - val_loss: 0.5579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6544 - val_loss: 0.5574\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6536 - val_loss: 0.5569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6527 - val_loss: 0.5563\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6519 - val_loss: 0.5558\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6510 - val_loss: 0.5553\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6502 - val_loss: 0.5548\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6493 - val_loss: 0.5543\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6485 - val_loss: 0.5538\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6477 - val_loss: 0.5533\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6468 - val_loss: 0.5528\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6460 - val_loss: 0.5523\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 153.88341287865387, my average MASE = 335532064.75560737\n",
      "Cluster 6, 153.88341287865387\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=9, 9, 3, (61, 67)\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5800 - val_loss: 0.4525\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5784 - val_loss: 0.4515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5768 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5753 - val_loss: 0.4496\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5738 - val_loss: 0.4487\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5722 - val_loss: 0.4477\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5707 - val_loss: 0.4468\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5692 - val_loss: 0.4459\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5678 - val_loss: 0.4450\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5663 - val_loss: 0.4441\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5648 - val_loss: 0.4433\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5634 - val_loss: 0.4424\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5619 - val_loss: 0.4415\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5605 - val_loss: 0.4407\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5590 - val_loss: 0.4398\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5576 - val_loss: 0.4390\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5562 - val_loss: 0.4382\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5548 - val_loss: 0.4374\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5534 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5520 - val_loss: 0.4359\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5507 - val_loss: 0.4352\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5493 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5480 - val_loss: 0.4337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5467 - val_loss: 0.4329\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 0.4322\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5441 - val_loss: 0.4315\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5428 - val_loss: 0.4308\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5415 - val_loss: 0.4301\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5403 - val_loss: 0.4294\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5390 - val_loss: 0.4287\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5378 - val_loss: 0.4280\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5366 - val_loss: 0.4273\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5354 - val_loss: 0.4266\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5342 - val_loss: 0.4260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5330 - val_loss: 0.4253\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5318 - val_loss: 0.4246\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5307 - val_loss: 0.4240\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5295 - val_loss: 0.4234\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5284 - val_loss: 0.4227\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5273 - val_loss: 0.4221\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 35650627.66244785, my average MASE = 4899168813.139491\n",
      "Cluster 0, 35650627.66244785\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7142 - val_loss: 0.5624\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7129 - val_loss: 0.5618\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7116 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7104 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7092 - val_loss: 0.5599\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7080 - val_loss: 0.5593\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7069 - val_loss: 0.5588\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7057 - val_loss: 0.5582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7046 - val_loss: 0.5576\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7035 - val_loss: 0.5571\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5565\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7013 - val_loss: 0.5560\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7002 - val_loss: 0.5555\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6993 - val_loss: 0.5550\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6982 - val_loss: 0.5545\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6972 - val_loss: 0.5540\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5535\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6952 - val_loss: 0.5530\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6942 - val_loss: 0.5525\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6932 - val_loss: 0.5520\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5516\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6913 - val_loss: 0.5511\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6903 - val_loss: 0.5506\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6894 - val_loss: 0.5502\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6885 - val_loss: 0.5498\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6875 - val_loss: 0.5493\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6866 - val_loss: 0.5489\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6857 - val_loss: 0.5485\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6848 - val_loss: 0.5481\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6839 - val_loss: 0.5477\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6830 - val_loss: 0.5472\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6821 - val_loss: 0.5468\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6812 - val_loss: 0.5464\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6803 - val_loss: 0.5460\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6794 - val_loss: 0.5456\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.5452\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6777 - val_loss: 0.5449\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6768 - val_loss: 0.5445\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6759 - val_loss: 0.5441\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6751 - val_loss: 0.5437\n",
      "2/2 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n",
      "average MASE = 167.81473432422789, my average MASE = 220460085.3598021\n",
      "Cluster 1, 167.81473432422789\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4267 - val_loss: 0.6677\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4246 - val_loss: 0.6662\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4226 - val_loss: 0.6647\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4205 - val_loss: 0.6632\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.6618\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4166 - val_loss: 0.6605\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4146 - val_loss: 0.6592\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4127 - val_loss: 0.6578\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4107 - val_loss: 0.6565\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4088 - val_loss: 0.6552\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4070 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4051 - val_loss: 0.6527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4033 - val_loss: 0.6514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4014 - val_loss: 0.6502\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3997 - val_loss: 0.6490\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3979 - val_loss: 0.6478\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3961 - val_loss: 0.6466\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3944 - val_loss: 0.6455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3927 - val_loss: 0.6444\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3910 - val_loss: 0.6433\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3893 - val_loss: 0.6423\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3877 - val_loss: 0.6412\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3861 - val_loss: 0.6402\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3845 - val_loss: 0.6392\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3829 - val_loss: 0.6383\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3814 - val_loss: 0.6374\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3799 - val_loss: 0.6364\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3784 - val_loss: 0.6356\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3769 - val_loss: 0.6347\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3754 - val_loss: 0.6338\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3740 - val_loss: 0.6330\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3725 - val_loss: 0.6322\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3711 - val_loss: 0.6314\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3697 - val_loss: 0.6305\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3683 - val_loss: 0.6297\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3669 - val_loss: 0.6289\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.6281\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3642 - val_loss: 0.6273\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3629 - val_loss: 0.6264\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3616 - val_loss: 0.6256\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1967377505.4498963, my average MASE = 5262000054.755049\n",
      "Cluster 2, 1967377505.4498963\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6328 - val_loss: 0.7373\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6300 - val_loss: 0.7359\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6272 - val_loss: 0.7344\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6245 - val_loss: 0.7330\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6218 - val_loss: 0.7316\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6191 - val_loss: 0.7301\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6164 - val_loss: 0.7287\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6137 - val_loss: 0.7273\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6111 - val_loss: 0.7259\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6085 - val_loss: 0.7245\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6058 - val_loss: 0.7230\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6033 - val_loss: 0.7216\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6009 - val_loss: 0.7202\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5985 - val_loss: 0.7188\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5961 - val_loss: 0.7174\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5938 - val_loss: 0.7159\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5915 - val_loss: 0.7146\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5892 - val_loss: 0.7133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5869 - val_loss: 0.7119\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5847 - val_loss: 0.7106\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5825 - val_loss: 0.7092\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5803 - val_loss: 0.7078\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5781 - val_loss: 0.7064\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5759 - val_loss: 0.7050\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5738 - val_loss: 0.7036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5716 - val_loss: 0.7022\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5695 - val_loss: 0.7009\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5674 - val_loss: 0.6996\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5653 - val_loss: 0.6983\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5632 - val_loss: 0.6971\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5611 - val_loss: 0.6959\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5590 - val_loss: 0.6946\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5569 - val_loss: 0.6934\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5549 - val_loss: 0.6922\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5528 - val_loss: 0.6910\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5509 - val_loss: 0.6898\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5490 - val_loss: 0.6886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5472 - val_loss: 0.6874\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5454 - val_loss: 0.6862\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.6850\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.27232041656941225, my average MASE = 0.501167640234202\n",
      "Cluster 3, 0.27232041656941225\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4602 - val_loss: 0.3734\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4580 - val_loss: 0.3723\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4558 - val_loss: 0.3714\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4536 - val_loss: 0.3704\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4515 - val_loss: 0.3694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4494 - val_loss: 0.3685\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4474 - val_loss: 0.3675\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4454 - val_loss: 0.3666\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4435 - val_loss: 0.3657\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4416 - val_loss: 0.3648\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4397 - val_loss: 0.3640\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4379 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4361 - val_loss: 0.3623\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4344 - val_loss: 0.3616\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4328 - val_loss: 0.3608\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4312 - val_loss: 0.3601\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4296 - val_loss: 0.3594\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4279 - val_loss: 0.3587\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4263 - val_loss: 0.3581\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4247 - val_loss: 0.3575\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4231 - val_loss: 0.3569\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.3564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4200 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4184 - val_loss: 0.3553\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4169 - val_loss: 0.3547\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4154 - val_loss: 0.3542\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4138 - val_loss: 0.3537\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4123 - val_loss: 0.3533\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4109 - val_loss: 0.3528\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4094 - val_loss: 0.3524\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4080 - val_loss: 0.3520\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4066 - val_loss: 0.3516\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4053 - val_loss: 0.3512\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4039 - val_loss: 0.3508\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4026 - val_loss: 0.3505\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4000 - val_loss: 0.3498\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3987 - val_loss: 0.3495\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3974 - val_loss: 0.3492\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3490\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 363.8540679781247, my average MASE = 17706113.36217601\n",
      "Cluster 4, 363.8540679781247\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4172 - val_loss: 0.5128\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4165 - val_loss: 0.5124\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4158 - val_loss: 0.5121\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4151 - val_loss: 0.5117\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.5113\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4139 - val_loss: 0.5110\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4132 - val_loss: 0.5107\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4126 - val_loss: 0.5103\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4120 - val_loss: 0.5100\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4114 - val_loss: 0.5096\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4108 - val_loss: 0.5093\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4102 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4097 - val_loss: 0.5086\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4091 - val_loss: 0.5083\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4085 - val_loss: 0.5080\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4080 - val_loss: 0.5077\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.5074\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4069 - val_loss: 0.5071\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4064 - val_loss: 0.5068\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4059 - val_loss: 0.5065\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.5062\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4048 - val_loss: 0.5059\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4043 - val_loss: 0.5056\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4038 - val_loss: 0.5053\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.5051\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4029 - val_loss: 0.5048\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4019 - val_loss: 0.5042\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4014 - val_loss: 0.5039\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4010 - val_loss: 0.5036\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4005 - val_loss: 0.5033\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4000 - val_loss: 0.5030\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3996 - val_loss: 0.5028\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3991 - val_loss: 0.5025\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3987 - val_loss: 0.5022\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3983 - val_loss: 0.5019\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3978 - val_loss: 0.5016\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5013\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3969 - val_loss: 0.5011\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3965 - val_loss: 0.5008\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 210.04101539413423, my average MASE = 60624707.44207928\n",
      "Cluster 5, 210.04101539413423\n",
      "Before prediction: train_X.shape=(104, 10, 67), train_y.shape=(104, 67), test_X.shape=(35, 10, 67), test_y.shape=(35, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3090 - val_loss: 0.2755\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3084 - val_loss: 0.2752\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3078 - val_loss: 0.2749\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3072 - val_loss: 0.2745\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3066 - val_loss: 0.2742\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3061 - val_loss: 0.2739\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3055 - val_loss: 0.2736\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3049 - val_loss: 0.2733\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3044 - val_loss: 0.2730\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3039 - val_loss: 0.2727\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.2724\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3028 - val_loss: 0.2722\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.2719\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3018 - val_loss: 0.2716\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3013 - val_loss: 0.2713\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3008 - val_loss: 0.2711\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3003 - val_loss: 0.2708\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2998 - val_loss: 0.2705\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2994 - val_loss: 0.2703\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2989 - val_loss: 0.2700\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2984 - val_loss: 0.2698\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2980 - val_loss: 0.2695\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2975 - val_loss: 0.2693\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2971 - val_loss: 0.2690\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2966 - val_loss: 0.2688\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2962 - val_loss: 0.2686\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2958 - val_loss: 0.2683\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2953 - val_loss: 0.2681\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2949 - val_loss: 0.2678\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2945 - val_loss: 0.2676\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2941 - val_loss: 0.2674\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2937 - val_loss: 0.2671\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2933 - val_loss: 0.2669\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2929 - val_loss: 0.2667\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2925 - val_loss: 0.2664\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2921 - val_loss: 0.2662\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2917 - val_loss: 0.2660\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2913 - val_loss: 0.2658\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2909 - val_loss: 0.2656\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2906 - val_loss: 0.2654\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(35, 67), test_y.shape=(35, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 554.2347835476104, my average MASE = 43885073.200175166\n",
      "Cluster 6, 554.2347835476104\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6507 - val_loss: 0.5207\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6481 - val_loss: 0.5200\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6456 - val_loss: 0.5192\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6431 - val_loss: 0.5184\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6407 - val_loss: 0.5176\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6383 - val_loss: 0.5169\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6360 - val_loss: 0.5161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6338 - val_loss: 0.5154\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6316 - val_loss: 0.5147\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6293 - val_loss: 0.5140\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6271 - val_loss: 0.5133\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6249 - val_loss: 0.5126\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6227 - val_loss: 0.5119\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6206 - val_loss: 0.5112\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6185 - val_loss: 0.5105\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6164 - val_loss: 0.5099\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6145 - val_loss: 0.5093\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6125 - val_loss: 0.5087\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6107 - val_loss: 0.5082\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6088 - val_loss: 0.5076\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6069 - val_loss: 0.5071\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6051 - val_loss: 0.5067\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6032 - val_loss: 0.5062\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6014 - val_loss: 0.5058\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5996 - val_loss: 0.5053\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5978 - val_loss: 0.5049\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5959 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5941 - val_loss: 0.5040\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5923 - val_loss: 0.5036\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5905 - val_loss: 0.5033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5888 - val_loss: 0.5030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5871 - val_loss: 0.5027\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5853 - val_loss: 0.5024\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5837 - val_loss: 0.5021\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5822 - val_loss: 0.5017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5806 - val_loss: 0.5014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5791 - val_loss: 0.5011\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5775 - val_loss: 0.5009\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5760 - val_loss: 0.5006\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5745 - val_loss: 0.5004\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2390672605525707, my average MASE = 0.4689912396588464\n",
      "Cluster 7, 0.2390672605525707\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1191 - val_loss: 0.0992\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1138 - val_loss: 0.0972\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1096 - val_loss: 0.0959\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1060 - val_loss: 0.0949\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1029 - val_loss: 0.0942\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1002 - val_loss: 0.0935\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0977 - val_loss: 0.0930\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0955 - val_loss: 0.0925\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0916 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0899 - val_loss: 0.0913\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0884 - val_loss: 0.0909\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0870 - val_loss: 0.0906\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0856 - val_loss: 0.0903\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0844 - val_loss: 0.0900\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0833 - val_loss: 0.0898\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0896\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0812 - val_loss: 0.0894\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0803 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0778 - val_loss: 0.0887\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0771 - val_loss: 0.0886\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0764 - val_loss: 0.0885\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0757 - val_loss: 0.0884\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0751 - val_loss: 0.0883\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0745 - val_loss: 0.0882\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0739 - val_loss: 0.0881\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0880\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0879\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0723 - val_loss: 0.0879\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0878\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0877\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0711 - val_loss: 0.0876\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0707 - val_loss: 0.0876\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0703 - val_loss: 0.0875\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0700 - val_loss: 0.0874\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0873\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0694 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 1385618831.00148, my average MASE = 22365614226.60064\n",
      "Cluster 8, 1385618831.00148\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=11, 11, 68, (49, 67)\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5560 - val_loss: 0.4967\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5553 - val_loss: 0.4965\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5546 - val_loss: 0.4963\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5538 - val_loss: 0.4961\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5531 - val_loss: 0.4960\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5524 - val_loss: 0.4958\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5517 - val_loss: 0.4956\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5510 - val_loss: 0.4955\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5503 - val_loss: 0.4953\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5496 - val_loss: 0.4952\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5489 - val_loss: 0.4950\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 0.4949\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5476 - val_loss: 0.4947\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5469 - val_loss: 0.4946\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5463 - val_loss: 0.4945\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5456 - val_loss: 0.4943\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5450 - val_loss: 0.4942\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5443 - val_loss: 0.4940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5437 - val_loss: 0.4939\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5431 - val_loss: 0.4938\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5425 - val_loss: 0.4936\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5419 - val_loss: 0.4935\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.4934\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5407 - val_loss: 0.4933\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5401 - val_loss: 0.4932\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5395 - val_loss: 0.4930\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5389 - val_loss: 0.4929\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5384 - val_loss: 0.4928\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5378 - val_loss: 0.4927\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5372 - val_loss: 0.4926\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5367 - val_loss: 0.4925\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 0.4923\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5356 - val_loss: 0.4922\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5351 - val_loss: 0.4921\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5345 - val_loss: 0.4920\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5340 - val_loss: 0.4919\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5335 - val_loss: 0.4918\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5329 - val_loss: 0.4917\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5324 - val_loss: 0.4915\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5319 - val_loss: 0.4914\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 62.874751666083846, my average MASE = 63681940.89448814\n",
      "Cluster 0, 62.874751666083846\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3794 - val_loss: 0.4534\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3770 - val_loss: 0.4520\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3747 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3724 - val_loss: 0.4494\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3701 - val_loss: 0.4481\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3678 - val_loss: 0.4468\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.4455\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3634 - val_loss: 0.4443\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3612 - val_loss: 0.4430\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3591 - val_loss: 0.4418\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3571 - val_loss: 0.4406\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3551 - val_loss: 0.4394\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3531 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3511 - val_loss: 0.4371\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3492 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3473 - val_loss: 0.4348\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3454 - val_loss: 0.4337\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3436 - val_loss: 0.4326\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3418 - val_loss: 0.4315\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3400 - val_loss: 0.4305\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3382 - val_loss: 0.4294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3365 - val_loss: 0.4284\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3349 - val_loss: 0.4273\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3332 - val_loss: 0.4263\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3316 - val_loss: 0.4253\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3300 - val_loss: 0.4243\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.4233\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3269 - val_loss: 0.4224\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3254 - val_loss: 0.4214\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.4205\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3224 - val_loss: 0.4196\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.4186\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3195 - val_loss: 0.4177\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3181 - val_loss: 0.4168\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3166 - val_loss: 0.4159\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3153 - val_loss: 0.4151\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3139 - val_loss: 0.4142\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3125 - val_loss: 0.4134\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3112 - val_loss: 0.4125\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3098 - val_loss: 0.4117\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1188796320.3185039, my average MASE = 2779981174.701244\n",
      "Cluster 1, 1188796320.3185039\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6283 - val_loss: 0.6105\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6261 - val_loss: 0.6091\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6239 - val_loss: 0.6076\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6218 - val_loss: 0.6062\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6196 - val_loss: 0.6047\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6175 - val_loss: 0.6033\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6153 - val_loss: 0.6018\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6132 - val_loss: 0.6004\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6110 - val_loss: 0.5990\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6089 - val_loss: 0.5976\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6067 - val_loss: 0.5961\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6046 - val_loss: 0.5947\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6026 - val_loss: 0.5933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6005 - val_loss: 0.5919\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5985 - val_loss: 0.5905\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5964 - val_loss: 0.5891\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5944 - val_loss: 0.5877\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5923 - val_loss: 0.5866\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5903 - val_loss: 0.5854\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5882 - val_loss: 0.5842\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5861 - val_loss: 0.5831\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5841 - val_loss: 0.5819\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5820 - val_loss: 0.5808\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5799 - val_loss: 0.5796\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5778 - val_loss: 0.5784\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5758 - val_loss: 0.5773\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5737 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5717 - val_loss: 0.5751\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5697 - val_loss: 0.5740\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5676 - val_loss: 0.5731\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5656 - val_loss: 0.5721\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5636 - val_loss: 0.5712\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5616 - val_loss: 0.5703\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5597 - val_loss: 0.5694\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5577 - val_loss: 0.5686\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5558 - val_loss: 0.5678\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5538 - val_loss: 0.5670\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5519 - val_loss: 0.5663\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5499 - val_loss: 0.5655\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5480 - val_loss: 0.5647\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32481366416229096, my average MASE = 0.6312112420260654\n",
      "Cluster 2, 0.32481366416229096\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4564 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4555 - val_loss: 0.4793\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4547 - val_loss: 0.4791\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4538 - val_loss: 0.4788\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4529 - val_loss: 0.4786\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4521 - val_loss: 0.4783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4512 - val_loss: 0.4781\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4504 - val_loss: 0.4778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4496 - val_loss: 0.4776\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4487 - val_loss: 0.4773\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4479 - val_loss: 0.4771\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4471 - val_loss: 0.4768\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4463 - val_loss: 0.4766\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4455 - val_loss: 0.4763\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4447 - val_loss: 0.4760\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4439 - val_loss: 0.4758\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4431 - val_loss: 0.4755\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4423 - val_loss: 0.4753\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4415 - val_loss: 0.4750\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4407 - val_loss: 0.4747\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4400 - val_loss: 0.4745\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4742\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4385 - val_loss: 0.4739\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4377 - val_loss: 0.4736\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4370 - val_loss: 0.4733\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4362 - val_loss: 0.4730\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4355 - val_loss: 0.4727\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4724\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4341 - val_loss: 0.4721\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4334 - val_loss: 0.4717\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4327 - val_loss: 0.4714\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4320 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4313 - val_loss: 0.4708\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4307 - val_loss: 0.4705\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4300 - val_loss: 0.4701\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4293 - val_loss: 0.4698\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4286 - val_loss: 0.4694\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4280 - val_loss: 0.4691\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4273 - val_loss: 0.4688\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4266 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1418783.6078857174, my average MASE = 35875462.94910899\n",
      "Cluster 3, 1418783.6078857174\n",
      "Before prediction: train_X.shape=(27, 10, 67), train_y.shape=(27, 67), test_X.shape=(9, 10, 67), test_y.shape=(9, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3810 - val_loss: 0.3926\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3805 - val_loss: 0.3924\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3799 - val_loss: 0.3923\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3794 - val_loss: 0.3921\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3789 - val_loss: 0.3920\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3784 - val_loss: 0.3918\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3779 - val_loss: 0.3917\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3774 - val_loss: 0.3916\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3769 - val_loss: 0.3914\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3764 - val_loss: 0.3913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3759 - val_loss: 0.3911\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3754 - val_loss: 0.3910\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3749 - val_loss: 0.3909\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3744 - val_loss: 0.3907\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3739 - val_loss: 0.3906\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3734 - val_loss: 0.3905\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3729 - val_loss: 0.3903\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3725 - val_loss: 0.3902\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3720 - val_loss: 0.3901\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3715 - val_loss: 0.3900\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3711 - val_loss: 0.3899\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3706 - val_loss: 0.3898\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3701 - val_loss: 0.3896\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3697 - val_loss: 0.3895\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3692 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3688 - val_loss: 0.3893\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3683 - val_loss: 0.3892\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3679 - val_loss: 0.3891\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3674 - val_loss: 0.3890\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3670 - val_loss: 0.3889\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3666 - val_loss: 0.3888\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3661 - val_loss: 0.3887\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3657 - val_loss: 0.3886\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3653 - val_loss: 0.3885\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3648 - val_loss: 0.3884\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3644 - val_loss: 0.3883\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3640 - val_loss: 0.3882\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3636 - val_loss: 0.3881\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3632 - val_loss: 0.3880\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3627 - val_loss: 0.3879\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(9, 67), test_y.shape=(9, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 73.99923698083529, my average MASE = 28273926.299095076\n",
      "Cluster 4, 73.99923698083529\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1188 - val_loss: 0.0994\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1133 - val_loss: 0.0973\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1090 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1053 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1021 - val_loss: 0.0936\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0993 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0969 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0946 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0893 - val_loss: 0.0908\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0878 - val_loss: 0.0906\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0864 - val_loss: 0.0903\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0852 - val_loss: 0.0901\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0841 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0830 - val_loss: 0.0897\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0820 - val_loss: 0.0895\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0811 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0802 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0888\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0772 - val_loss: 0.0887\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0886\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0759 - val_loss: 0.0885\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0753 - val_loss: 0.0884\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0747 - val_loss: 0.0884\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0742 - val_loss: 0.0883\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0737 - val_loss: 0.0882\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0881\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0881\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0724 - val_loss: 0.0880\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0720 - val_loss: 0.0880\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0716 - val_loss: 0.0879\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0879\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0879\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0878\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0877\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0699 - val_loss: 0.0877\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0877\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 772933595.2163092, my average MASE = 33112652144.926693\n",
      "Cluster 5, 772933595.2163092\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6742 - val_loss: 0.5426\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6711 - val_loss: 0.5410\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6680 - val_loss: 0.5395\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6649 - val_loss: 0.5381\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6619 - val_loss: 0.5366\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6589 - val_loss: 0.5352\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6560 - val_loss: 0.5338\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6532 - val_loss: 0.5324\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6503 - val_loss: 0.5310\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6475 - val_loss: 0.5296\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6447 - val_loss: 0.5282\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6420 - val_loss: 0.5269\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6393 - val_loss: 0.5255\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6367 - val_loss: 0.5242\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6340 - val_loss: 0.5229\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6314 - val_loss: 0.5216\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6289 - val_loss: 0.5203\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6264 - val_loss: 0.5190\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6240 - val_loss: 0.5178\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6215 - val_loss: 0.5165\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6191 - val_loss: 0.5153\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6168 - val_loss: 0.5141\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6145 - val_loss: 0.5128\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6122 - val_loss: 0.5115\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6098 - val_loss: 0.5102\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6076 - val_loss: 0.5089\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6054 - val_loss: 0.5076\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6033 - val_loss: 0.5062\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6011 - val_loss: 0.5049\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5989 - val_loss: 0.5035\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5968 - val_loss: 0.5022\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5947 - val_loss: 0.5009\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5928 - val_loss: 0.4996\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5908 - val_loss: 0.4982\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5889 - val_loss: 0.4969\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5869 - val_loss: 0.4956\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5850 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5831 - val_loss: 0.4932\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5812 - val_loss: 0.4921\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5794 - val_loss: 0.4911\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.24234404135098125, my average MASE = 0.42071116848846357\n",
      "Cluster 6, 0.24234404135098125\n",
      "Before prediction: train_X.shape=(50, 10, 67), train_y.shape=(50, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4441 - val_loss: 0.4379\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4435 - val_loss: 0.4378\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4430 - val_loss: 0.4376\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4425 - val_loss: 0.4374\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4372\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4414 - val_loss: 0.4371\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4409 - val_loss: 0.4369\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4404 - val_loss: 0.4367\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4398 - val_loss: 0.4366\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4364\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.4362\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4383 - val_loss: 0.4361\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4378 - val_loss: 0.4359\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4373 - val_loss: 0.4357\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4368 - val_loss: 0.4356\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4363 - val_loss: 0.4354\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4358 - val_loss: 0.4352\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4353 - val_loss: 0.4351\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4348 - val_loss: 0.4349\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4343 - val_loss: 0.4348\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4339 - val_loss: 0.4346\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4334 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4329 - val_loss: 0.4343\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4341\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4320 - val_loss: 0.4340\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4315 - val_loss: 0.4338\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4310 - val_loss: 0.4337\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4306 - val_loss: 0.4335\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4301 - val_loss: 0.4334\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4296 - val_loss: 0.4332\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4292 - val_loss: 0.4331\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4287 - val_loss: 0.4329\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4283 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4278 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4274 - val_loss: 0.4325\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4269 - val_loss: 0.4323\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4265 - val_loss: 0.4322\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4261 - val_loss: 0.4320\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4256 - val_loss: 0.4319\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4252 - val_loss: 0.4317\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 191.2474349797922, my average MASE = 74799483.45709221\n",
      "Cluster 7, 191.2474349797922\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2212 - val_loss: 0.1239\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2202 - val_loss: 0.1236\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2192 - val_loss: 0.1233\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2183 - val_loss: 0.1230\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2174 - val_loss: 0.1228\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2165 - val_loss: 0.1225\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2156 - val_loss: 0.1223\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2147 - val_loss: 0.1221\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2138 - val_loss: 0.1219\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2129 - val_loss: 0.1217\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2120 - val_loss: 0.1215\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2111 - val_loss: 0.1213\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2102 - val_loss: 0.1212\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2093 - val_loss: 0.1211\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2085 - val_loss: 0.1210\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2076 - val_loss: 0.1209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2068 - val_loss: 0.1208\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2059 - val_loss: 0.1207\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2051 - val_loss: 0.1207\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2042 - val_loss: 0.1206\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2034 - val_loss: 0.1206\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2026 - val_loss: 0.1205\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2018 - val_loss: 0.1204\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2010 - val_loss: 0.1204\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2002 - val_loss: 0.1203\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1995 - val_loss: 0.1203\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1987 - val_loss: 0.1203\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1980 - val_loss: 0.1203\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1973 - val_loss: 0.1203\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1965 - val_loss: 0.1203\n",
      "Epoch 30: early stopping\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.15391611936993946, my average MASE = 0.29566028544300293\n",
      "Cluster 8, 0.15391611936993946\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5076 - val_loss: 0.4286\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5055 - val_loss: 0.4276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5036 - val_loss: 0.4266\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5017 - val_loss: 0.4256\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4998 - val_loss: 0.4246\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4980 - val_loss: 0.4236\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4962 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4944 - val_loss: 0.4217\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4926 - val_loss: 0.4208\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4908 - val_loss: 0.4199\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4890 - val_loss: 0.4191\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4871 - val_loss: 0.4182\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4853 - val_loss: 0.4173\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4835 - val_loss: 0.4164\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4817 - val_loss: 0.4156\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4148\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4782 - val_loss: 0.4140\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4765 - val_loss: 0.4133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4749 - val_loss: 0.4126\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4732 - val_loss: 0.4118\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4717 - val_loss: 0.4111\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4701 - val_loss: 0.4104\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4686 - val_loss: 0.4097\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4671 - val_loss: 0.4089\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4656 - val_loss: 0.4082\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4641 - val_loss: 0.4075\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4627 - val_loss: 0.4068\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4613 - val_loss: 0.4061\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4600 - val_loss: 0.4054\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4587 - val_loss: 0.4048\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4573 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4560 - val_loss: 0.4036\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4546 - val_loss: 0.4030\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4533 - val_loss: 0.4025\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4520 - val_loss: 0.4019\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4506 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4493 - val_loss: 0.4009\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4480 - val_loss: 0.4004\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.3999\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4454 - val_loss: 0.3994\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2425229695624874, my average MASE = 0.5232189989788755\n",
      "Cluster 9, 0.2425229695624874\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4116 - val_loss: 0.3522\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4095 - val_loss: 0.3515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.3508\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4055 - val_loss: 0.3501\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3494\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4016 - val_loss: 0.3488\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3996 - val_loss: 0.3481\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3977 - val_loss: 0.3475\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3920 - val_loss: 0.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3902 - val_loss: 0.3450\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3884 - val_loss: 0.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3865 - val_loss: 0.3439\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3847 - val_loss: 0.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3829 - val_loss: 0.3430\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3811 - val_loss: 0.3425\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3793 - val_loss: 0.3420\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3776 - val_loss: 0.3416\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3759 - val_loss: 0.3411\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3742 - val_loss: 0.3407\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3725 - val_loss: 0.3402\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3708 - val_loss: 0.3398\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3692 - val_loss: 0.3394\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3675 - val_loss: 0.3390\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3659 - val_loss: 0.3386\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3644 - val_loss: 0.3382\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3628 - val_loss: 0.3379\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3376\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3597 - val_loss: 0.3373\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3583 - val_loss: 0.3370\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3568 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3554 - val_loss: 0.3364\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3540 - val_loss: 0.3361\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3526 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3512 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3498 - val_loss: 0.3352\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3484 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3471 - val_loss: 0.3347\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3457 - val_loss: 0.3344\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 624.4867423423187, my average MASE = 18127046.32229549\n",
      "Cluster 10, 624.4867423423187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maes = defaultdict(lambda: [])\n",
    "mases = defaultdict(lambda: [])\n",
    "mapes = defaultdict(lambda: [])\n",
    "answers = {}\n",
    "bad_values = np.zeros(dataset.shape[1])\n",
    "\n",
    "dif=True\n",
    "\n",
    "for window_size in window_sizes_for_clustering:\n",
    "    for N_clusters in Ns_clusters:\n",
    "        dataset_windows, dataset_y = Forecasting.create_windows(dataset, window_size=window_size)\n",
    "        clusters_labels = Clustering.KMeans_for_windows(dataset_windows, W=window_size, N_clusters=N_clusters, max_iter=50)\n",
    "        print(f\"{clusters_labels.shape=}\")\n",
    "        datasets_clusters = Clustering.flatten_from_interceting_windows(dataset_windows, clusters_labels, W=window_size, \\\n",
    "                N_clusters=N_clusters)\n",
    "        # list of list of ndarrays [N_i, Q], dataset_clusters[cluster_num][i] - i-th part of dataset for cluster_num\n",
    "\n",
    "        print(f\"{N_clusters=}, {len(datasets_clusters)}, {len(datasets_clusters[0])}, {datasets_clusters[0][0].shape}\")\n",
    "        ###window_size for model\n",
    "        errors = [1] * N_clusters\n",
    "        for cluster_num in range(N_clusters):\n",
    "            sc = Forecasting.MyStandardScaler(dif=dif)\n",
    "            #datasets_clusters[cluster_num] - list of [N_i, Q] ndarrays\n",
    "            sc.fit(datasets_clusters[cluster_num])\n",
    "            prepared_data = sc.transform(datasets_clusters[cluster_num])\n",
    "            data_X, data_y = Forecasting.create_windows(prepared_data, window_size=10)\n",
    "            #data_X - list of [N_i-W, W, Q] ndarrays\n",
    "            train_X, train_y, valid_X, valid_y, test_X, test_y, ind = Forecasting.split_to_train_test(data_X, data_y, part_of_test=0.2, part_of_valid=0.2)\n",
    "            #ndarrays [N_i, W, Q] or [N_i, Q]\n",
    "            ind = np.array(ind) + window_size\n",
    "            print(f\"Before prediction: {train_X.shape=}, {train_y.shape=}, {test_X.shape=}, {test_y.shape=}\")\n",
    "            try:\n",
    "                assert(len(test_X.shape) == 3 and test_X.shape[0] > 0)\n",
    "                assert(len(valid_X.shape) == 3 and valid_X.shape[0] > 0)\n",
    "                assert(len(train_X.shape) == 3 and train_X.shape[0] > 0)\n",
    "            except AssertionError:\n",
    "                print(f\"FAIL - {test_X.shape=}, {valid_X.shape=}, {train_X.shape=}\")\n",
    "                errors[cluster_num] = np.Inf\n",
    "                continue\n",
    "            model, history = Forecasting.learn(train_X, train_y, valid_X=valid_X, valid_y=valid_y)\n",
    "            predicted = model.predict(test_X)\n",
    "            predicted_original = sc.inverse_transform(predicted)[0]\n",
    "            #inverse_trasform returns list of ndarrays \n",
    "            # if dif:\n",
    "                #константа при дифференцировании\n",
    "                # predicted_original = sc.add_first_element(predicted_original, ind)[0]\n",
    "            print(f\"{predicted_original.shape=}, {test_y.shape=}\")\n",
    "\n",
    "            #calc all metrics\n",
    "            cur_mae = mae(test_y, predicted_original, multioutput='raw_values')\n",
    "#             error_out = mase(test_y, predicted_original, y_train=test_y)\n",
    "#             error_in = mase(test_y, predicted_original, y_train=train_y)\n",
    "            # cur_mase = mase(test_y, predicted_original, y_train=test_y)\n",
    "            cur_mape = mape(test_y, predicted_original)\n",
    "            cur_mase = Forecasting.my_mase(test_y, predicted_original, multioutput='raw_values')\n",
    "            maes[(window_size, N_clusters)].append(cur_mae)\n",
    "#             mases[(window_size, N_clusters)].append((error_in, error_out))\n",
    "            mapes[(window_size, N_clusters)].append(cur_mape)\n",
    "#             errors[cluster_num] = mase_uni(test_y, predicted_original, y_train=test_y)\n",
    "            tmp_bad = cur_mase > np.percentile(cur_mase, 90)\n",
    "            bad_values += tmp_bad\n",
    "            cur_mase[tmp_bad] = -1\n",
    "#             errors[cluster_num] = Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')\n",
    "            errors[cluster_num] = np.mean(cur_mase[~tmp_bad])\n",
    "            \n",
    "            #show all metrics\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.suptitle(f\"K={N_clusters}, W={window_size}, C={cluster_num}\")\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(cur_mae, color=\"green\", label=\"library\")\n",
    "            plt.plot(Forecasting.my_mae(test_y, predicted_original, multioutput='raw_values'), color=\"red\", label=\"custom\")\n",
    "            plt.title(\"MAE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "#             plt.plot(error_in, label=\"library, in\")\n",
    "#             plt.plot(error_out, label=\"library, out\")\n",
    "            plt.plot(cur_mase, label=\"custom, out\")\n",
    "            plt.title(\"MASE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(cur_mape)\n",
    "            plt.title(\"MAPE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f\"plots/Dataset2/K={N_clusters}  W={window_size} C={cluster_num}.png\")\n",
    "#             plt.show()    \n",
    "            plt.clf()\n",
    "            # print(f\"{cur_mae=}, {cur_mase=}, {cur_mape=}\")\n",
    "            # my_mase = mase()\n",
    "            # print(f\"MASE in_sample = {error_in}, MASE out_sample = {error_out}\")\n",
    "            print(f\"average MASE = {errors[cluster_num]}, my average MASE = {Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')}\")\n",
    "            print(f\"Cluster {cluster_num}, {errors[cluster_num]}\")\n",
    "        answers[(window_size, N_clusters)] = errors\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.suptitle(f\"K={N_clusters}, W={window_size}\")\n",
    "        plt.subplot(2, 2, 1)\n",
    "\n",
    "        plt.bar(np.arange(N_clusters), [np.sum(clusters_labels == i) for i in range(N_clusters)], color='blue')\n",
    "        plt.title(\"Размеры кластеров\")\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.bar(np.arange(N_clusters), [len(datasets_clusters[i]) for i in range(N_clusters)], color=\"green\")\n",
    "        plt.title(\"Количество непрерывных отрезков\")\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.bar(np.arange(N_clusters), errors, color=\"red\")\n",
    "        plt.title(\"MASE на тесте каждого из кластеров\")\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        plt.table(cellText= [[f\"{x:.2f}\"] for x in errors],\n",
    "                      rowLabels=list(range(N_clusters)),\n",
    "                      loc='center')\n",
    "#         plt.show()\n",
    "        plt.savefig(f\"plots/Dataset2/method1: {N_clusters=}  W={window_size}.png\")\n",
    "        #         plt.show()\n",
    "        plt.clf()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.bar(np.arange(bad_values.shape[0]), bad_values)\n",
    "plt.title(\"Количество раз, когда переменная имела максимум MASE\")\n",
    "plt.savefig(f\"plots/Dataset2/bad_values.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([ 2,  4,  7,  8, 11, 14, 18, 21, 23, 25, 28, 30, 33, 37, 39, 43, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 5)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33,\n",
      "       39, 48, 50, 53, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 28, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 33, 37, 39,\n",
      "       41, 43, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 9)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 30, 31, 33, 35, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 12, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 23, 25, 26, 28, 30, 39, 41, 42, 48,\n",
      "       51, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(3, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 13, 14, 15, 18, 21, 23, 25, 26, 28, 30, 33,\n",
      "       37, 39, 41, 42, 44, 48, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 5)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 26, 28, 30, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 7)\n",
      "     (array([ 2, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 35, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 9)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 23, 25, 28, 30, 31, 33, 35, 39,\n",
      "       41, 43, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(3, 11)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 37, 39, 44, 48,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 2)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 12, 14, 18, 21, 23, 25, 30, 31, 33, 37, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 5)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 31, 39, 60, 61,\n",
      "       62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(5, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 16, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 23, 25, 28, 30, 33, 35, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "(5, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 14, 15, 16, 18, 19, 21, 23, 25, 27, 28, 30,\n",
      "       39, 42, 44, 47, 48, 52, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 15, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35,\n",
      "       37, 39, 60, 61, 62, 63, 65]),)\n",
      "(5, 11)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 28, 30, 31, 33, 39,\n",
      "       41, 42, 49, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(10, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 11, 13, 14, 18, 21, 23, 25, 28, 30, 31, 33,\n",
      "       35, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 5)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 22, 23, 25, 28, 30, 31, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 7)\n",
      "     (array([ 2,  4,  8,  9, 14, 16, 18, 19, 30, 58, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "(10, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 23, 24, 25, 26, 28, 30, 31,\n",
      "       33, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(10, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 12, 14, 18, 21, 22, 23, 25, 28, 30, 39, 56, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in maes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in mases.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c[0] < 1)}, {np.where(val_c[1] < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([14, 18, 25, 30, 31, 33, 35, 37, 43]),)\n",
      "     (array([14, 30]),)\n",
      "(1, 5)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(1, 7)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 11, 14]),)\n",
      "     (array([14]),)\n",
      "(1, 9)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 4,  8, 14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14, 60, 61]),)\n",
      "(1, 11)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(3, 2)\n",
      "     (array([ 4, 14, 18, 30, 31, 33, 35, 37, 42, 62]),)\n",
      "     (array([14, 30]),)\n",
      "(3, 5)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(3, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61]),)\n",
      "(3, 9)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 28, 39, 62]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 19, 30]),)\n",
      "(3, 11)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 23, 28, 39, 62, 65]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "(5, 2)\n",
      "     (array([12, 14, 18, 30, 31, 33, 35, 37, 60, 62, 65]),)\n",
      "     (array([14, 30]),)\n",
      "(5, 5)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "(5, 7)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 9, 11, 14, 18, 19, 21, 23, 25, 30, 39, 42, 44, 47, 52, 60, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 11)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 21, 23, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "(10, 2)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "(10, 5)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 14]),)\n",
      "(10, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 11)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in mapes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
