{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSet2.csv\", sep=\";\")#, parse_dates=['Timestamp']) #, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "df = data.groupby(data.index // K).mean() #усреднение\n",
    "df_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError, MeanAbsolutePercentageError\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mase = MeanAbsoluteScaledError(multioutput='raw_values')\n",
    "mase_uni = MeanAbsoluteScaledError(multioutput='uniform_average')\n",
    "mape = MeanAbsolutePercentageError(multioutput='raw_values')\n",
    "# mae = MeanAbsoluteError()\n",
    "\n",
    "\n",
    "#if ‘raw_values’, returns a full set of errors in case of multioutput input. If ‘uniform_average’, errors of all outputs are averaged with uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 67)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_np[:, :]\n",
    "# dataset = np.concatenate((dataset[:, :8], dataset[:, 9:]), axis=1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**__Отбор признаков на минималках__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удаление константных\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(0.001)\n",
    "dataset1 = selector.fit_transform(dataset) \n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 14}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(range(67)) - set(selector.get_feature_names_out(input_features=np.arange(dataset.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset[:, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(dataset[:, 8], color=\"green\")\n",
    "plt.plot(np.concatenate((dataset[:32714, 8], dataset[32717:, 8])))\n",
    "plt.title(\"consumption_09\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00292  0.00733  0.754974 1.658794 1.956544]\n",
      "[32714, 375379, 1, 1, 1]\n",
      "Изменение только в [[32713]\n",
      " [32714]\n",
      " [32715]\n",
      " [32716]]\n"
     ]
    }
   ],
   "source": [
    "values = np.unique(dataset[:, 8])\n",
    "print(values)\n",
    "print([len(np.argwhere(dataset[:, 8] == val)) for val in values])\n",
    "print(f\"Изменение только в {np.argwhere(dataset[1:, 8] - dataset[:-1, 8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Эти датчики пока выкинем из-за константности: ** \n",
    "\n",
    "8: consumption_09\n",
    "\n",
    "14 : consumption_07 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('consumption_07', 'consumption_09')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[15], columns[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9a2240ef20>]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset[7])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import correlate\n",
    "# a = np.array([np.sin(x + 1) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 2) for x in range(10)])\n",
    "# c = correlate(a, b, mode=\"full\") #mode='same'\n",
    "# plt.plot(a, label=\"a\")\n",
    "# plt.plot(b, label=\"b\")\n",
    "# plt.plot(c, label=\"correlation\")\n",
    "# plt.legend()\n",
    "# c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "#еще не поняла до конца\n",
    "from sklearn.feature_selection import f_regression\n",
    "for i in range(1):\n",
    "    X = np.concatenate((dataset[:, :i], dataset[:, i + 1:]), axis=1)\n",
    "    y = dataset[:, i]\n",
    "    res = f_regression(X, y)\n",
    "    print(res[0].shape)\n",
    "    # plt.plot(res[0], label=\"f_statistics\")\n",
    "    # # plt.plot(res[1], label=\"p_values\")\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([2.30337015]), array([0.16757113])),\n",
       " (array([645.88225824]), array([6.15681791e-09])))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.array([np.sin(x) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 1) + 1 for x in range(10)])\n",
    "# c = np.array([np.sin(x + 0.1) for x in range(10)])\n",
    "\n",
    "# f_regression(a[:, None], b), f_regression(a[:, None], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прогнозирование**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "window_sizes_for_clustering = 10\n",
    "# X, y = dataset[:-window_sizes_for_clustering, ...], dataset[window_sizes_for_clustering:, ...]\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "n_split = round(0.2 * dataset.shape[0])\n",
    "dataset_train, dataset_test = dataset[:-n_split, ...], dataset[-n_split:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((326477, 65), (81619, 65))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_sizes_for_clustering = [1, 3, 5, 10, 15]\n",
    "# Ns_clusters = [2, 5, 7, 9, 11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns_clusters = [7]\n",
    "window_sizes_for_clustering = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_windows.shape=(326472, 5, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "Before prediction: train_X.shape=(151, 10, 65), train_y.shape=(151, 65), test_X.shape=(50, 10, 65), test_y.shape=(50, 65)\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.4524 - val_loss: 0.3706\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Before prediction: train_X.shape=(28, 10, 65), train_y.shape=(28, 65), test_X.shape=(9, 10, 65), test_y.shape=(9, 65)\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3234 - val_loss: 0.3414\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Before prediction: train_X.shape=(3, 10, 65), train_y.shape=(3, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.6555 - val_loss: 1.0745\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Before prediction: train_X.shape=(22, 10, 65), train_y.shape=(22, 65), test_X.shape=(7, 10, 65), test_y.shape=(7, 65)\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4284 - val_loss: 0.3991\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Before prediction: train_X.shape=(2220, 10, 65), train_y.shape=(2220, 65), test_X.shape=(740, 10, 65), test_y.shape=(740, 65)\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5111 - val_loss: 0.3773\n",
      "24/24 [==============================] - 0s 8ms/step\n",
      "Before prediction: train_X.shape=(5957, 10, 65), train_y.shape=(5957, 65), test_X.shape=(1986, 10, 65), test_y.shape=(1986, 65)\n",
      "94/94 [==============================] - 2s 25ms/step - loss: 0.0686 - val_loss: 0.0469\n",
      "63/63 [==============================] - 0s 7ms/step\n",
      "Before prediction: train_X.shape=(38, 10, 65), train_y.shape=(38, 65), test_X.shape=(13, 10, 65), test_y.shape=(13, 65)\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5772 - val_loss: 0.5744\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"N_clusters\":Ns_clusters, \"window_size_for_clustering\":window_sizes_for_clustering, \"dif\":True}\n",
    "models, model_mase = Forecasting.try_parameters(parameters, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [<keras.engine.sequential.Sequential at 0x7f9a0b4b9480>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f99e2ecf7f0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f99e2edf940>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f99e1055cc0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f99e2e43f70>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f99e14a7b20>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f99e1176b00>],\n",
       " 'scalers': [<Forecasting.MyStandardScaler at 0x7f9a225eadd0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f9a225eb0a0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f9a0b4b9240>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f99e2f26b90>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f99e0fcc670>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f99e2f26140>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f99e11774c0>],\n",
       " 'clusters_model': KMeans(init='random', max_iter=1, n_clusters=7)}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22420062349.355923"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_model = models[\"clusters_model\"]\n",
    "forecasting_models = models['models']\n",
    "scalers = models['scalers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.shape=(81619, 65), dataset_windows.shape=(81614, 325), cluster_nums=array([2, 2, 2, ..., 2, 2, 2], dtype=int32)\n",
      "dataset.shape=(81619, 65)\n",
      "dataset_windows.shape=(81609, 1, 11, 65)\n"
     ]
    }
   ],
   "source": [
    "window_sizes_for_clustering = clusters_model.cluster_centers_.shape[-1] // dataset_test.shape[-1]\n",
    "y_pred = Forecasting.predict_through_clusters(dataset_test, clusters_model, forecasting_models, scalers, window_size_clustering=window_sizes_for_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81609, 65)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape=(81609, 65), dataset_test.shape=(81619, 65)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{y_pred.shape=}, {dataset_test.shape=}\")\n",
    "y_true = dataset_test[-y_pred.shape[0]:]\n",
    "cur_mase = Forecasting.my_mase(y_true, y_pred, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAACb70lEQVR4nO2deZgcZbX/v9V79+yTSSb7SlZCQgghBIwB2QWMyKbAJcJVAQMoilz1XgTvRQMqKkoEQS942YL4E5F9D2ELJoFAIEBC9j2ZZPal1/r90f2+VV1d1fVWb1XdfT7Pw6OZqep6p7u66tQ53/M9kizLMgiCIAiCICoQl90LIAiCIAiCKBYU6BAEQRAEUbFQoEMQBEEQRMVCgQ5BEARBEBULBToEQRAEQVQsFOgQBEEQBFGxUKBDEARBEETFQoEOQRAEQRAVCwU6BEEQBEFULBToEAThCL7+9a+jtrbW7mUQBFFhUKBDEBXO8uXLIUmS7n8rV67M2P6tt97C5z73OYRCIQwdOhTXXnstenp60rbZtWsXzjzzTNTX12PatGl48sknM17n73//O4YMGYLOzs6i/W350tfXh5tvvhnLly8X2l79Xj744IO62xx//PGQJAnTp0/X/X08Hsfw4cMhSRKeffZZw2O98cYbOOOMMzBixAgEAgGMHj0aZ599Nh5++OG07Yw+W0mScOWVVwr9XQRRyXjsXgBBEKXh2muvxZw5c9J+dthhh6X9e+3atTjppJMwdepU/PrXv8bOnTvxq1/9Chs3bky7KS9atAi7du3CbbfdhjfffBPnn38+PvnkE4wdOxYAMDAwgOuvvx633HILGhoaiv635UpfXx9++tOfAgBOOOEE4f0CgQAefvhhXHLJJWk/37p1K9566y0EAgHDfV955RXs2bMHY8eOxUMPPYQzzjgjY5vHHnsMF154IY488kh85zvfQVNTE7Zs2YIVK1bg3nvvxUUXXZS2/SmnnIJLL70043UmTZok/DcRRKVCgQ5BVAnz58/Heeedl3WbH//4x2hqasLy5ctRX18PABg7diy++c1v4oUXXsCpp56K/v5+vPLKK1i+fDk+//nP48orr8Rbb72F559/HldccQUA4Fe/+hUaGhrwjW98o+h/lx188YtfxD//+U+0tbWhpaWF//zhhx9Ga2srJk6ciPb2dt19H3zwQRx11FFYtGgRfvzjH6O3txc1NTVp29x8882YNm0aVq5cCZ/Pl/a7/fv3Z7zmpEmTMoIugiCSUOmKIKqI7u5uxGIx3d91dXXhxRdfxCWXXMKDHAC49NJLUVtbi7/+9a8AktkaWZbR1NQEIFk6aWxsRF9fH4BkWevWW2/FHXfcAZfL+iVm8+bNOO2001BTU4Phw4fjv//7vyHLcto2iUQCv/3tb3H44YcjEAigtbUVV1xxRUZwsXr1apx22mloaWlBMBjEuHHjcPnllwNIZl8GDx4MAPjpT3/Kyz0333yz6RoXLlwIv9+Pxx57LO3nDz/8MC644AK43W7d/fr7+/H444/jq1/9Ki644AL09/fjiSeeyNhu06ZNmDNnTkaQAwBDhgwxXR9BEAoU6BBElXDZZZehvr4egUAAJ554IlavXp32+3Xr1iEWi+Hoo49O+7nP58ORRx6J9957DwDQ1NSECRMm4Oc//zm2bNmChx56CGvXrsUxxxwDALjhhhtwxhln4POf/7zlNcbjcZx++ulobW3FL37xC8yePRs33XQTbrrpprTtrrjiCvzgBz/A8ccfjzvuuAOXXXYZHnroIZx22mmIRqMAkpmPU089FVu3bsUPf/hD/P73v8fFF1/MdUmDBw/GXXfdBQA455xz8MADD+CBBx7AV77yFdN1hkIhLFy4EI888gj/2fvvv4+PPvooo6yk5p///Cd6enrw1a9+FUOHDsUJJ5yAhx56KGO7MWPG4OWXX8bOnTvN3zQkg8+2traM/yKRiND+BFHRyARBVDRvvvmmfO6558p//vOf5SeeeEJesmSJPGjQIDkQCMjvvvsu3+6xxx6TAcgrVqzIeI3zzz9fHjp0KP/3yy+/LDc1NckAZADyd7/7XX6sYDAob9261fI6Fy1aJAOQr7nmGv6zRCIhn3nmmbLP55MPHDggy7Isv/766zIA+aGHHkrb/7nnnkv7+eOPPy4DkFetWmV4zAMHDsgA5Jtuukloja+++qoMQH7sscfkp556SpYkSd6+fbssy7L8gx/8QB4/frwsy7K8YMEC+fDDD8/Y/6yzzpKPP/54/u977rlH9ng88v79+9O2+/Of/ywDkH0+n3ziiSfKN954o/z666/L8Xg84zXZZ6D33yOPPCL0dxFEJUMZHYKocI477jj87W9/w+WXX44vfelL+OEPf4iVK1dCkiT86Ec/4tv19/cDAPx+f8ZrBAIB/nsA+MIXvoDt27dj5cqV2L59O37zm98gkUjg2muvxfe//32MGTMGd911F6ZMmYLJkyfj7rvvFl7v1Vdfzf+/JEm4+uqrEYlE8NJLLwFICnUbGhpwyimnpGUvZs+ejdraWrz66qsAgMbGRgDAU089xbM8heTUU09Fc3Mzli1bBlmWsWzZMnzta18z3P7gwYN4/vnn07Y599xzIUkSLwsyLr/8cjz33HM44YQT8MYbb+B//ud/MH/+fEycOBFvvfVWxmsvXLgQL774YsZ/J554YuH+YIIoU0iMTBBVyGGHHYaFCxfi73//O+LxONxuN4LBIAAgHA5nbD8wMMB/z6itrcXcuXP5v++77z7s3bsXP/zhD/HSSy/hBz/4AR588EFIkoSLLroIkydPNr3xulwujB8/Pu1nrHNo69atAICNGzeis7PTUKvCxLoLFizAueeei5/+9Kf4zW9+gxNOOAFf/vKXcdFFF+kGc1bxer04//zz8fDDD+OYY47Bjh07spatHn30UUSjUcyaNQufffYZ//ncuXPx0EMPYfHixWnbn3baaTjttNPQ19eHNWvW4NFHH8Xdd9+Ns846C5988kna3z9y5EicfPLJef9NBFGJUKBDEFXKqFGjEIlE0Nvbi/r6egwbNgwAsGfPnoxt9+zZg+HDhxu+VldXF/7zP/8Tv/rVr1BTU4NHHnkE5513Hr785S8DAM477zw89NBDBckwJBIJDBkyRFfbAoALjCVJwt/+9jesXLkSTz75JJ5//nlcfvnluP3227Fy5cqCmBNedNFFuPvuu3HzzTdj5syZmDZtmuG2bL3HH3+87u83b96cEeQBST3Q/PnzMX/+fLS0tOCnP/0pnn32WSxatCjv9RNENUCBDkFUKZs3b0YgEOA3/OnTp8Pj8WD16tW44IIL+HaRSARr165N+5mW//7v/8a4ceNw8cUXAwB2796NWbNm8d8PHz4ca9euNV1TIpHA5s2b0/xfNmzYAADco2fChAl46aWXcPzxx2dkmfQ49thjceyxx+JnP/sZHn74YVx88cVYtmwZvvGNb0CSJNP9s/G5z30Oo0ePxvLly3HbbbcZbrdlyxa89dZbuPrqq7FgwYK03yUSCfzbv/0bHn74YfzXf/1X1uMxobheMEoQhD6k0SGICufAgQMZP3v//ffxz3/+E6eeeipvAW9oaMDJJ5+MBx98EN3d3XzbBx54AD09PTj//PN1X3/Dhg248847cccdd/DAobW1FZ988gnf5uOPP8bQoUOF1nvnnXfy/y/LMu688054vV6cdNJJAIALLrgA8Xgc//M//5OxbywWQ0dHBwCgvb09oy39yCOPBKCU50KhEADwfawiSRJ+97vf4aabbsK//du/GW7Hsjk33HADzjvvvLT/LrjgAixYsCAtQ/Xyyy/rvs4zzzwDAJg8eXJO6yWIaoQyOgRR4Vx44YUIBoM47rjjMGTIEKxfvx733HMPQqEQbr311rRtf/azn+G4447DggUL8K1vfQs7d+7E7bffjlNPPRWnn3667utfd911uPDCC3l7OZAsVS1cuBA//vGPAQBPPvkknnrqKdO1BgIBPPfcc1i0aBHmzp2LZ599Fk8//TR+/OMf85LUggULcMUVV2DJkiVYu3YtTj31VHi9XmzcuBGPPfYY7rjjDpx33nn4y1/+gj/84Q8455xzMGHCBHR3d+Pee+9FfX09vvjFLwIAgsEgpk2bhkcffRSTJk1Cc3Mzpk+fbji+QY+FCxdi4cKFWbd56KGHcOSRR2LUqFG6v//Sl76Ea665Bu+++y6OOuooLFy4EOPGjcPZZ5+NCRMmoLe3Fy+99BKefPJJzJkzB2effXba/hs2bNAdSdHa2opTTjlF+G8hiIrE5q4vgiCKzB133CEfc8wxcnNzs+zxeORhw4bJl1xyibxx40bd7V9//XX5uOOOkwOBgDx48GB58eLFcldXl+62Tz/9tFxbWyvv3r0743dLliyRhw8fLg8bNky+7bbbTNe5aNEiuaamRt60aZN86qmnyqFQSG5tbZVvuukm3bbqe+65R549e7YcDAbluro6+YgjjpBvuOEGvpZ3331X/trXviaPHj1a9vv98pAhQ+SzzjpLXr16ddrrvPXWW/Ls2bNln89n2mqubi/Phrq9fM2aNTIA+cYbbzTcfuvWrTIA+brrrpNlWZYfeeQR+atf/ao8YcIEORgMyoFAQJ42bZr8n//5nxmfBbK0ly9YsCDrOgmiGpBkWZPbJQiCIAiCqBBIo0MQBEEQRMVCgQ5BEARBEBULBToEQRAEQVQsFOgQBEEQBFGxUKBDEARBEETFQoEOQRAEQRAVS1UbBiYSCezevRt1dXV5W8ETBEEQBFEaZFlGd3c3hg8fzt3djajqQGf37t2GTqUEQRAEQTibHTt2YOTIkVm3qepAp66uDkDyjaqvr7d5NQRBEARBiNDV1YVRo0bx+3g2qjrQYeWq+vp6CnQIgiAIoswQkZ2QGJkgCIIgiIqFAh2CIAiCICoWCnQIgiAIgqhYKNAhCIIgCKJioUCHIAiCIIiKhQIdgiAIgiAqFgp0CIIgCIKoWCjQIQiCIAiiYqFAhyAIgiCIioUCHYIgCIIgKhYKdAiCIAiCqFjKPtDp6OjA0UcfjSOPPBLTp0/Hvffea/eSCIIgCIJwCGU/1LOurg4rVqxAKBRCb28vpk+fjq985SsYNGiQrevqDcew6UAPZoxstHUdBEEQBFHNlH1Gx+12IxQKAQDC4TBkWYYsy7auadOBHsz86Qu46N53EIsnbF0LQRAEQVQztgc6K1aswNlnn43hw4dDkiT84x//yNhm6dKlGDt2LAKBAObOnYt//etfab/v6OjAzJkzMXLkSPzgBz9AS0tLiVavz7hBNagNeNATjuH9nZ22roUgCIIgqhnbA53e3l7MnDkTS5cu1f39o48+iu9973u46aab8O6772LmzJk47bTTsH//fr5NY2Mj3n//fWzZsgUPP/ww9u3bV6rl6+JySZg3Plk6e+uzNlvXQhAEQRDVjO2BzhlnnIFbbrkF55xzju7vf/3rX+Ob3/wmLrvsMkybNg133303QqEQ/vd//zdj29bWVsycOROvv/667muFw2F0dXWl/VcsjjssmVV6cxMFOgRBEARhF7YHOtmIRCJYs2YNTj75ZP4zl8uFk08+GW+//TYAYN++feju7gYAdHZ2YsWKFZg8ebLu6y1ZsgQNDQ38v1GjRhVt7cdPSGZ03t3Wgf5IvGjHIQiCIAjCGEcHOm1tbYjH42htbU37eWtrK/bu3QsA2LZtG+bPn4+ZM2di/vz5uOaaa3DEEUfovt6PfvQjdHZ28v927NhRtLWPa6nBsIYAIvEEVm87VLTjEARBEARhTNm3lx9zzDFYu3at0LZ+vx9+v7+4C0ohSRKOm9CC//fuTrz52UHMnzi4JMclCIIgCELB0RmdlpYWuN3uDHHxvn37MHToUJtWJc7xh6UEyaTTIQiCIAhbcHSg4/P5MHv2bLz88sv8Z4lEAi+//DLmzZtn48rEOD4lSF63qxOdfVGbV0MQBEEQ1Yftpauenh589tln/N9btmzB2rVr0dzcjNGjR+N73/seFi1ahKOPPhrHHHMMfvvb36K3txeXXXaZjasWo7U+gAmDa7DpQC/e3nwQp093fhaKIAiCICoJ2wOd1atX48QTT+T//t73vgcAWLRoEe6//35ceOGFOHDgAH7yk59g7969OPLII/Hcc89lCJSdyvGHtWDTgV68+VkbBToEQRAEUWIk2e55CTbS1dWFhoYGdHZ2or6+vijHeO7DvbjywTUYP7gGr3z/hKIcgyAIgiCqCSv3b0drdCqBeeMHwSUBmw/0Ym/ngN3LIQiCIIiqggKdItMQ8mL6iAYAwJs0DoIgCIIgSgoFOiXguAk0DoIgCIIg7IACnRLA/XQ+O4gqlkQRBEEQRMmhQKcEzBnbDJ/Hhb1dA9jc1mv3cgiCIAiiaqBApwQEvG7MHt0EAHiLdDoEQRAEUTIo0CkRrHz15mcHbV4JQRAEQVQPFOiUiONS4yDe3nwQ8QTpdAiCIAiiFFRloLN06VJMmzYNc+bMKdkxZ4xoQJ3fg87+KNbv7irZcQmCIAiimqnKQGfx4sVYv349Vq1aVbJjetwuzB3fDIDazAmCIAiiVFRloGMX3E+HBMkEQRAEURIo0Ckhx6d0Oqu2HkI4Frd5NQRBEARR+VCgU0ImtdaipdaPgWgC723vsHs5BEEQBFHxUKBTQiRJwnETWJs5la8IgiAIothQoFNiFD8dCnQIgiAIothQoFNimCB57Y4OPLByG82+IgiCIIgiQoFOiRnVHMKXjxyOhAzc+I8PceWDa9DRF7F7WQRBEARRkVCgYwO/ufBI/NeZU+F1S3j+o3344h2vY9XWQ3YviyAIgiAqDgp0bECSJHxj/nj8/arjMXZQCLs7B3DhH9/G717eSOMhCIIgCKKAUKBjI0eMbMBT187HV2aNQEIGfv3iBlz8p5XY2zlg99IIgiAIoiKgQMdmav0e/PrCI/HrC2Yi5HNj5eZDOOv3r2NXR7/dSyMIgiCIsocCHYfwlaNG4ulr52NSay3aeiK45uF3EY0n7F4WQRAEQZQ1FOg4iHEtNfjTpXNQF/Dg3e0d+NXzn9q9JIIgCIIoayjQcRijB4Xwy/NmAAD+uGIzXvlkn80rIgiCIIjyhQIdB3L69GH4+nFjAQDf++v72E16HYIgCILICQp0HMqPvjgFR4xoQEdfFNc88h7pdQiCIAgiByjQcSh+jxtLLzoKdX4P1mxrx+0vbLB7SQRBEARRdlRloLN06VJMmzYNc+bMsXspWRk9KIRfpPQ6d7+2Ca9+st/mFREEQRBEeSHJVTxVsqurCw0NDejs7ER9fb3dyzHkpic+xF/e3oamkBfPfGc+hjUE7V4SQRAEQdiGlft3VWZ0yo0fnzkV00fUo70vimsefg8JGhNBEARBEEJQoFMGML2Oz+PC6m3t2HSgx+4lEQRBEERZQIFOmTBmUA2G1PkBAF0DMZtXQxAEQRDlAQU6ZUTI5wYADETjNq+EIAiCIMoDCnTKiKDPAwDoi1CgQxAEQRAiUKBTRoS8yYxOX4RKVwRBEAQhAgU6ZUQwVbrqp4wOQRAEQQhBgU4ZwQMd0ugQBEEQhBAU6JQRSumKAh2CIAiCEIECnTIiRKUrgiAIgrAEBTplRMBHGR2CIAiCsAIFOmVEyJtsLyeNDkEQBEGIQYFOGaGUrqi9nCAIgiBEoECnjAhS6YogCIIgLEGBThkR9FJ7OUEQBEFYgQKdMoK6rgiCIAjCGhTolBFUuiIIgiAIa1CgU0aEfNR1RRAEQRBWoECnjAjSUE+CIAiCsERVBjpLly7FtGnTMGfOHLuXYgka6kkQBEEQ1qjKQGfx4sVYv349Vq1aZfdSLBGioZ4EQRAEYYmqDHTKFRboROMyovGEzashCIIgCOdDgU4ZEUhpdADqvCIIgiAIESjQKSP8HhdcUvL/D1D5iiAIgiBMoUCnjJAkibeYU0aHIAiCIMyhQKfMUEwDqcWcIAiCIMygQKfM4POuKKNDEARBEKZQoFNmUIs5QRAEQYhDgU6ZQfOuCIIgCEIcCnTKDJpgThAEQRDiUKBTZijzrijQIQiCIAgzKNApM4I0wZwgCIIghKFAp8wI8a4rai8nCIIgCDMo0CkzSIxMEARBEOJQoFNmUKBDEARBEOJQoFNmsNIVzboiCIIgCHMo0CkzKKNDEARBEOJQoFNm0FBPgiAIghCHAp0yI+hLfmT9Ueq6sotYPIFfPv8J3vqsze6lEARBECZQoFNmBL0pHx3K6NjG25sPYumrm3Dbc5/YvRSCIAjCBAp0yowQaXRs50B3GADQNUBZNYIgCKdDgU6ZQdPL7aejLwqAsmoEQRDlAAU6ZUaAZl3ZTkdfBAAFmwRBEOVAVQY6S5cuxbRp0zBnzhy7l2IZltEZoEDHNjr6UxkdCnQIgiAcT1UGOosXL8b69euxatUqu5diGd5eHo1DlmWbV1OdtKdKV5FYAvEEfQYEQRBOpioDnXKGGQbGEzIi8YTNq6lOWOkKIIdqgiAIp0OBTpkRTGl0ABLD2gUTIwOklSIIgnA6FOiUGT6PCx6XBIA0InbR0U8ZHYIgiHKBAp0yhOZd2UtHr5LRoWCTIAjC2VCgU4ZwLx0KdEpONJ5Ad1gxCqTPgCAIwtlQoFOGBMlLxzY6+6Np/6aMDkEQhLOhQKcMCaZazOkmW3rUQmSAPgOCIAinQ4FOGaKUrmjWUqlRt5YDZNxIEAThdCjQKUNosKd9UEaHIAiivKBApwyheVf20a7J6FCgQxAE4Wwo0ClD+LwrusmWnAwxMgWbRIpP9nbh+FtfwWOrd9i9FIIgVFCgU4ZQ6co+tBkdCjYJxtubDmJXRz+e/2if3UshCEIFBTplSNCbGuxJgU7JaSeNDmEAOxfCMTonCMJJUKBThgR9yY+Nuq5KT2cq0FE632iwKpFkIJpI/S8FOgThJCjQKUNC5KNjG6x0NawhAIA+A0KBBTgs4CEIwhlQoFOGkDOyfbD28mENQQD09E4osHOBgl+CcBYU6JQhNOvKPjo0GZ0+Kh9WHPu7B/DL5z/BjkN9lvZj30cKfgnCWVCgU4bQ9HL76OhnGR1WuqIyRaXx2OqdWPrqJtz/1lZL+w3EmEaHzgmCcBIU6JQhrHRFKfIkH+/pwhl3vI6X1he3rTcci/PgclhjqnRFwWbFwbyStJ5JZlBGhyCcCQU6ZQgXI9NNFgDwyif78fGeLjy9bk9Rj8M6rlwSMLjWD4CCTSfTG47hlU/2WW73VkTF1vZjx6FAhyCcBQU6ZQgvXUVJHwIoAV+x/UuYh05jyIeQn7JqTueu5Ztw+f2r8dfVOy3tl2ugw87DWEJGNE7lK4JwChTolCG8dEUZHQCKVilcZG0EEyI3Br30GZQBuzv7AQB7U/8rCtPYWA1iB1SBNmV1CMI5UKBThlDXVTqKI21xAx0lo+PlWTW6oTmXcDQ3cTBvE7f4/VJvT4JkgnAOFOiUIXzWVTQOWZZtXo39DJTIer+zP5XRCflIEF4G5Oprw7qnrHbUqYMbCoAJImnVcP7db+Hy+1fZug6PrUcncoJlE2Q5mcUIpG661Qp7ko6UMqOjCnRkWYYkSUU9NmGdgRzFwblqdNTbU6BDEED3QAyrtrajLmBvqEEZnTIkqApsyEsnmdkCil+6Yq7IjUFfRrBJOA+WYbGq3SpMoEPnBEGw74TdD+MU6JQhHrcLPnfyo3OiM29bTxj/b83Okj3VDkRKFegkS1dNIW/aF5ee3p1Jrr42uZS8ZFlO236AJpgTBA/4gxTolJ6lS5di2rRpmDNnjt1LyRkni2HveGkjvv/Y+3hi7a6SHI+LkYv8XnSoSldetwtet5R2fMJZ8NKVZR+dlEbHQrY0GpeRUMnlqFGAIJRrcsBrb6hRlYHO4sWLsX79eqxaZa9AKh9CDh4DsadzAABwoDtckuOxrFbxu64UMTKgpGPppuZMwjkELIBa3J5AIiEm9tcGu058ACGIUtNPpSsiH5w8wbw3nAw8SqVT4FqMIgc6bCRAY8gLgEZxOB1Fa5ObRgcQzwZps4kDpNsiCP7dC3go0CFyIOhgL53eCAt0SrM2xUen2M7ITKOTzOg4uXxIqAIdq6UrVZAi+v3KyOg48HtJEKWGi5F9FOgQOcBNAx14k+1hGZ0SCTJZ6SoalxEXLDXkAtPoNATTMzpOzKoRSsBipesqkZDTbApEMzParJHVc393Rz+NjSBspWsgilueWo/XNhwo2Guy70HAQxodIgeCqcGeTrzJ9gyUrnSVSMhpxymWl05/JM5LY001pNFxOtF4gge9VjJu2vJnzhkdC8f8cFcnjrv1FfzH//tAeB+CKCS94Rguu28V/vTGFvzkiQ8L9rrs+0MaHSIngikVe78D28sVjU7xAwDtjalY5auOlCuyxyWhJpVNI42Oc1Gfe1Y+H+05K3oOa7frj4gH3JsO9AAAPtnTLbwPQRSK/kgc//6XVVizrR0AsO1gH9p6CtNIwq7P1HVF5ETIoRmdREJGL/cvKX5GR+sjVCxBcnuvMrmcuSCTRqc07Onsx19X77AUxGrHMYiOStGWnESDpIyMjoW1su9w10BUeB+CKAQD0Ti+9cBqrNx8CLV+D4bU+QEA76aCnkK8PkAZHSJHgg7V6PSp1lNscTCQ+fcXa4I5y+g0pTquAJoiXyp++dynuOFvH+D5j/YJ76MOPhNyUr8ltl9upauMrisL30t2jK5+CnSI0hGJJXD1w+/i9Y1tCHrduO+yOfjClCEAgHe3dxTkGOx7QIaBRE6EHHqTZWUroDSZDu0xila66ktvLQdUGh2y+y8q+1N+TG0WfJm054FohiWjBJVrRsdKoJPatjscE/btIYh8iMUT+O6j7+Glj/fD73Hhz4uOxpyxzThqdBMA4N3thcroJK+Nfgp0iFwIOtQwsEcV6JRiBpRWC1GsYyqBjo//LOhL6aQcllWrNJhdgZX3WXte5Kq1Ed9Pezzx85CVX2UZ6HGg5o6oLOIJGT/42wd4Zt1e+Nwu/PHfZuO4w1oAAEeNSQY6H+zsKEgXoGIYSBodIgccG+gMlDajk6nRKc4xuStyMLN0RRqd4tIXtj6zSpvBGRAUB2cGLIIZnUg+pSvlmFS+IopJIiHjPx9fh8ff2wWPS8KdF83CCZOH8N+Pb6lBQ9CLgWgCH+/pyvt4XKNDhoFELoQcepNNL12VIKNTKo0OMwusUWV0HFo+rDR4RsfC+5yRmREtXWnFyILHZPu5pNR+lkpXynemq58yOkTxWPrqZ1i2agdcEvDbrx6JUw8fmvZ7l0vCrNGNAAojSOZDPckwkMgFpevKWRfGHts1OsUtXTWoMzqpz4BKV8WFZS2ttYnnlpnRiopF9VfMCZmVNnMRIwPUeUUUj1c/3Y9fv7QBAPCzc47AWTOG626n6HQ68j4my7BT6YrIiYBDS1e9kVKXrkojRm5PBTpNao2OlzQ6pSCX2WmZWhuxfbWfpehnyxyUmVjdmkZHFehQ6YooAlvbevGdR96DLAMXzx2Nrx0z2nDbQgqSuWEgla6IXAg51KyuJ6weiGhD6apIx+zsZ5PL1RmdVPnQYcFmJRGLJ/hnakmjk2vAkqdGh2m4cum6AoCuAWdlaInypy8Sw5UPrkHXQAxHjW7ETWcfnnX7maMaIEnAzvZ+7O8ayOvYfAQEdV0RuRBy6FBPtRg5EksUvV1W+/cXzTAwa3u5sz6DSkLty2SpdBUrdddVcrumfEtXlNEhCogsy7jhbx/gk73daKn1465LZsNnMneqLuDF5NY6APlndZT2cipdETng1K4rtRgZKH6LeakCHd5eHtQRI1OgUzT6VBlCK0F9rgZ+uRoGsnOAaXSsiZGVbTsp0CEKyJ9e34KnPtgDj0vCXZcchdb6gNB+rM08X50OGQYSeeFUZ+QeTaBTbJ1OZtdV4Y8ny7Kq6yqzdOW0rFolodZ85TOzSrQbL9+SV1MOGh0SIxPF4K3P2rDk2Y8BADeeNQ1zxjYL78t1Onl2XrHvAZWuiJwIeZ3ZdaXN6FiZ+ZMLpdDo9EbiiKVKcJTRKS3qjI41jY6mdGWxvbwu4LF0TF66qsmhdKXW6FB7OVEAdnX04+pH3kNCBr5y1AhcOm+Mpf2PSrWYf7CrE5E8rqk064rIC2WgZPF1MFbojWgzOsUtXZWivby9N5nN8XtcaX4QAfLRKTq5ZnQyuqeEZ1axzIy1EtQAL10lMzphC/q0PsroEAVkIBrHVQ+uwaHeCKaPqMfPzzmCDyIWZVxLDZpCXkRiCazPwzhQCXRIo0PkQEh1wy121sQK3QOlLV2xmwQzaitGeznTTaiFyIBzy4eVRF+OdgW5tpdrAxbLGh1Vxk806E7P6FCgQ+ROIiHj+399Hx/s7ERTyIu7L5mdUzZFkiTMSpWv1uRYvorFEzwTThodIifUJ6+TBMkZpatia3RSfzsz8iuGMzIb/6D20AFoBEQp6M1RjJxz6UojKrYaIKmn24ucF/GEnFYaoPZyIh9ue+4TPL1uD7xuCX+4eDZGNoVyfi1Wvsq180rd+UilKyIn3C4J/lSboJNKJ+obE1D80pW226UYpSs9V2RACXSicbkgA/CITNIzOhYMA1OBTchnLRjNFBVb26/G74HXnUwvimT6tNtQRofIlQdWbsMfV2wGAPzivBmYN2FQXq/HOq/eyzGjo74v+U1a2osNBTplTMiBpZOMrqtii5Ej6aWGYpSuOowyOuryoYM+g0pCHThH4gnEBAPKMM+wWMzMxNL3s6rRCXjd3AVW5JzQNhOQRofIhZc/3oebnvgQAPD9UybhnFkj837NmSMb4ZKA3Z0D2Ntp3TiQnf9+j8uyRqjQUKBTxijzrpxzk2XiUR54lKi9nDnSFjOjo9XoqJ9SnBRsVhLaQEDUbZsFNo2WMzMajY6oM7LKLySgahQwPZ5mqnpPOOao5gLC+XywswNXP5zssLrw6FG4+guHFeR1a/weTBlaDyC38lXYIa7IAAU6ZY1iGuiMur4sy1yjM6jG2pN0rmSUroqi0WGBTnpGR5IkRacTodJVMejVBPHC08Q1AYv10pVP+HiyLKd1lwQszEDrS00ur/N7Uq8FdIed8X0mnM+OQ324/P7V6I/GMX9iC245Z3pBsydHjWkEkJufDp9cToEOkQ9Bh7U3h2MJROPJp9FBtX4ApRMjF7V0pTPniuHE8mEl0ZejuJ2VoFgXVK4ZHZE28Ug8AbZJwKeUrkSymVxMH/LyDCHpdAgROvuiuOz+VWjrCWPK0Dr84eKj4HUX9pbOjAPX5JDRcUprOUCBTlnjtPZmdcdVS61147Rc0Lb1FrN01aQT6NC8q+KizehYzcw0WHQqDvMp5OJt4urXDnjciseVQNDNAp2Qz83F7qTTIcyIxBK44sHV+Gx/D4bWB3DfZXNQF8i8PuULC3Q+2tVl+SGyP0qlK6IAhBw274oJR4NeN4Ip5+ZiTzDPzOgUI9BJZnQagr6M39EYiOKiLctaFQfz7inBi7R2CrnIMdmx3C4JXrfEMzr9AuVMtbanPnVMmndFmPHMuj1YufkQav0e3HfZHAxrCBblOGMGhTCoxodIPIEPd1kzDlQGelKgQ+SB0yaYs46rGr+HpyuLmdGJJ2TVE3jxxM/ZMjrkpVNctHYFljU6QXGtDZDels7tGwQDnUCqu8Rv4dxnDylBnxv1qbETNAaCMGPbwT4AwFkzhmHqsPqiHUdtHPiexfKVMtDT/jDD/hUQOcNSgo7J6KSevmv9br62YoqR1TcSVmrIZy6LER2pJ2w2x0gNzbsqLrlndNJLV6KZPnWbuGi2jmdlUtvz4NdC6Uqd0aHSFWHGwd4wAKAlpYUsJlyQnGOg44TSlcfuBRC54zQhbE/K1bU2UJqMjvrvZk/DhS5dJRLK5PLGoI5Gx2FZtUoj04DSakZHvOsq2T3F0u2uVAkqarov3ydVsrIyA42dwyGfB+7UHBMSIxNmHOxJXpMG1WY+fBWao1SjIGRZFu7qUjKd9gc6lNEpY5iPTr9D2st56crnUTpPimgYyG4kAa8ybLPQgU53OMY7ahp0S1fJr1CfQ4LNSoNldJTA2fzzVc/YUUY5mH8+YY1lvajYvz+SntFhaxU5F/siylNvfTBVuqIxEIQJbT3JjM6gEmR0ZoxsgNslYV9XGLstGAey7yp1XRF5EXRa6SrMSlcelU6heKUr9dOwv0iBFcvmJDUbmU8mio+OMz6DSoN1XQ2qSV7QRbKXagF8k4Wuq7CmeyogqL8aiCkBN2BNt6Wcw27Up7pmKKNDmHGwN3ldatEppxeakM+DqcPqAFjz03FS6aoqA52lS5di2rRpmDNnjt1LyQundfyki5GLL9JV6xuYcLTQGR1FiKx/QXFai3+lwXx0mF2ByLmuPudYy3Z/NA5Zzu6HwwIWlwR43RLP1pkdc0B1HgIWS1epjFXQRxodQpyDJczoAEr5yopOZ4Ccke1l8eLFWL9+PVatWmX3UvLCaRodpqeo8XsszfvJFcWnwcUDnUgsYXpDs0I7by3X96ggH53ikUjIvCTILuhCGR3VjJ2Aah6ZuR+OErBIkiQcxGov6H4rYmR1eznP6FDpijAmFk9wt/ZSaHQAYDYb8Lm9Q3gfpXRFgQ6RB44rXam6rkpSuuJma540r4ZCZnU6eceVfqDjNHfqSmIgFgeLWZtrxLU26gus2n7ebDyI9sIsGqwzvxy2X9BCx2GfyjBQ0ehQRocw5lDq4UuSjDPNhWbMoBoAwIHusPA+6gdRu7F/BUTOKGJkZ9xku1nXld+rlK6KKUaOZpaugMIGOu29rOPKoHRFPjpFg2UIkxf0VAnKQukq4HXB63bxbiazc1GrKRDtqMvYz8KsK55FIo0OIQjruGoO+fi5XWxqUt+FXguNL6TRIQpC0Mc6fpyR6u7lGp3S+OjwriufGx6XBNb1WEhBcrvB5HIGaXSKB+u4CnndPKgXCZy1U5MDHkGtDSt5aUTF/SbnsBJwu9KOK2Je2afS97DyaDd1XRFZKGVrOSOUGjprpXoQrtShnrIsY//+/YV8SSILbMyCUzI66q4rdnMphlMxg+k3QilNBRckFzC4YqUro0DHivCUsAbL6IT8HpXw3vyz5SUoja+NaUYnlr6faLZO++RqpXSlbk3nYmTK6BBZYGaBrBOxFIRS53QklkAsbtV80/58iqUVhEIhHDhwgP/7zDPPxJ49e/i/9+/fj2HDhhVudURWnD0CovglnQGNf4nSYl7A0lWqHm7YdUVi5KLBMjo1Pre1lu1I+gVWNLuovTDz4ZyCgU4wh9JVent58sGlOxxD3GRiOlG9tNmS0VGyMqKeYWU71HNgYCCto2XFihXo7+9P26aQHS9EdvhQT4fcZBUxsirQKeJQT+0XSWkxL9z7wdrLjbquQoI3Q8I6vSqxuZWAkmVu/JrAw2pmRrSjrj+afjx/TkGZO236dDcJkgkDWGt5KcY/MHwqrVtfWOxap3Q/llmgI4KoPTSRP06bdVXqERB9Gv8SvwVHWlE6TDI6AdLoFI0+tebLQvYyo3tKMPAIZ+wnqu1J1yJYyT71qYI5n8fF96UWc8IIrtEpgVkgQ5Ik5cFaUJBMzshEQWAnXiSWcESqu4f56PjSS1fFyvINqNL+gKp0VUCNToeJRofay4uHOqMTEJwkDqRPEwfEAx0jh2PRjI7VUpl6TexY1GJOmME1OiXM6ACqCoLgtY59n8pOjCxJUlrGRvtvorSwThTAGRmFdDFy8uROyEA0XpxARztjqBilK95ebqLRKWZ3WbXCNTp+t7BeRr2NdvaU2WfEy0gWxchhA42OtYxOKtChFnPCBDs0OkDyARZQrvNmaDOkdmJperksy5g0aRIPbnp6ejBr1iy4XC7+e6J0qFOCfZEYav32DaOPJ2QebNWoDAOBZGTv8xQ+eWis0SlM0BFPyHzAIrWXlx7edaXS6FgZzsm7rgSN/5TJ5alAxycWxGrPQ9G1yrKcsS+NgSDMYBmdlhIHOkyQXI5iZEt3xvvuu69Y6yByQJIkBL1u9EfjtpdO1EZSNX4P/B4XJAmQ5eQFvz6gHyjkg/ZpuNBdV52qp+pGAzGy4k5NmopCo+66sjJqQ9s9FRDtnorpl6BMR0AYaILYfC2jrLc6gFIyOqnSFWl0CAMUjU6JS1cpOxOrYmQnaHQsBTqLFi0q1jqIHAn5UoGOzRkFJkT2uKRUkJP834FooqCaGTVafQMXIxfovWBC5Dq/Bx63/pdVrcdIJGS4SuRUWg3o++hYCXQ0GR3BWVfazIzZMTPa2TVlW59H/5xQf2cpo0OI0BeJ8Qe8UpeueEZH4KFOluWM67Od5F3rGBgYwKOPPore3l6ccsopmDhxYiHWRQgS9LmBXvs7r7g+J+DhT7ABrxsD0UTROq+KXbrirsgGc64ApbzBjqv+N5Ef/VE9Hx1xw0Bte7lo91SG0aBgJohrdHxiZVt2w/B7lNbdBjINJLLAsjk+j6vkUgUrYuRoXAbrj/GXW6Dzve99D9FoFL///e8BAJFIBPPmzcNHH32EUCiEG264AS+++CLmzZtXlMUSmTjFNJCbBaoE0skbRrRoQl2j0lWkYKWr7HOuAKWzB0gGXhToFA61RocFHZF40pnVKMMG6JSuBJ2Rw5r9RLuuBiLpAbfPrSrbRozLtloxPaASI9MYCEKHg6nmiJYaX8kbgVjzi0igk56ttL90ZWkFL7zwAk455RT+74ceegjbtm3Dxo0b0d7ejvPPPx+33HJLwRdJGOOUCebspqR+yuDdJ0Ua7Kntril4Rqc3e2s5AHjcLvjc4q3PhDhpXVeqp0KzEhTP9Gm6p0ynl2tmZLFZcqaBTmo97DyUJEklgDY+JndFVv1tvL2cMjqEDswssNSt5QAs+eiwhwZJAr8+2omlFWzfvh3Tpk3j/37hhRdw3nnnYcyYMZAkCd/5znfw3nvvFXyRhDFO6frpUZm7MYo9BqLf0DCwQBod7qGTvRYuWhohrKHO6Kin04t2T2mN/0T3C3qtla60bemAqmMry7nIHk4COhmdTgp0CB3sGOjJCPH2cgumnR63IyxoLAU6LpcrrYV85cqVOPbYY/m/Gxsb0d7eXrjVEaawk6/f5q6fXtWcK4bfgq4iF9iTRbFmXSmuyNk7xqx4vBDiqDM6LpckHFCGDbqnREdAaKeXM6G5HrIsK5kglTZHZGK6es4Vg8TIRDbabBjoyajhD9Xm9xquW3NIKd9SoDN16lQ8+eSTAICPPvoI27dvx4knnsh/v23bNrS2thZ2hURWghYEYsWEZXTqAmqNTnHHQGifwAs9vZzNuTLL6NBgz+KgdkYGcp8m7hfV2mi7rjRCcz3CsQTYs5/aL0QkuGJBEGvbBdSGgaTRITJhGZ1Se+gAyvdBJKOjZDntL1sBFsXIN9xwA7761a/i6aefxkcffYQvfvGLGDduHP/9M888g2OOOabgiySMcYpGR1eMXMTSVSyeQCSuDXRYRqcwx2OTy408dBjcN4VKVwWlT3NOBb1utCNqwdeGtXuLOSNnlLxUpSgjobk6qA7qBTpZsov9eqUrGgFBZEHR6JQ+0GHZepF7jfahwW4shVvnnHMOnnnmGcyYMQPXXXcdHn300bTfh0IhfPvb3y7oAonsOGV6tl7pShEjF750pb7Z8dJVgYd6Mp1EU5b2cvXxKaNTWHhGx8/atsUCSqPMjLBhYCowcrkk3hpu9Nmyn7tdErwq0aVIma1PT4xMIyCILLCuKztKV1bEyOya74TWciAHH52TTjoJJ510ku7vbrrpJnz44Yd5L4oQxymlK/WcK0aAd7sUfm39KlU/K1kxdX/hfHTM28sB5wSblYbijJw8p1iGxbwLKjfDQL3ZPEGvG5FYwjBgMTJF4+d+luzigF57eSp72BuJm7bRE9WHXXOuAGvt5cr3whnnb0FW0d3djXvuuQdz587FzJkzC/GShCDcltv20hWbc6X10SlOADAQUcpWTNVfeGdk8/ZytgaASleFJBJL8GGwLKMjOnvK0PjPYiYIMNcFaSeXi+4HKN9ZdaCj1rh1k5cOoYGVrloc3l5e1qUrLStWrMCiRYswbNgw/OpXv8KJJ56IlStXFmpthADc68PmrquecDIoqA3olK6K0HXVr/MkXfiuK9H2cipdFRr1xZSVdqyLkV1p/2vm56Q3m8es7GV0QRfRbemdw163i99QSKdDqEkkZBzqtTOjI149cFqgY7l0tXfvXtx///3485//jK6uLlxwwQUIh8P4xz/+keaxQ5SGIGsvt12jwwwDS+Ojo20tB9SGgfkfLxpPcIG1aXs5BToFh+lz/B4XL9+IBpTaEpTIeag3SVzkmEYTmv0C+jT2cBLSiJwbgl70ReLUeUWk0TUQRSxlc2BLe7klMXJ6Q4DdWFrF2WefjcmTJ+ODDz7Ab3/7W+zevZuPgyDsgT3t2l+6yuy64j46RXBG1s/oFE6jw7I5kgTUmUxe50/9VLoqGH064naRwZ7xhMy78TIDHePzQj2bR91tZSYqDmssDvhaRdrLDYIkZQwEZXQIBabPqQ94DOenFRN2TjM9ZjZ4RsdThhmdZ599Ftdeey2uuuoqGt7pEJwy60pfjFy80pV2/AOgBFaF8NFhc64agl4+cNEIp7T4VxKKh45aL2M+kkEdWGSUrrLtpwrG/erSlWBGx0iMnG2t2lltDBoDQehhpz4HUB46wrEE4gk563WRZ3TK0TDwjTfeQHd3N2bPno25c+fizjvvRFtbW7HWRggQcFjXVanEyFzIqZvRyf94fHK5iYcOQBqdYqD10AHESlBpgY5GjByOGTscs/3UXXyAeWZG66as3S9b0G3UsUUZHUKPgzbqc4D0gNxMkKydN2c3lgKdY489Fvfeey/27NmDK664AsuWLcPw4cORSCTw4osvoru7u1jrJAwIFVEHY4UeXR+d4o2A0Jv8XMjSVXvqotJgIkRWr4ECney8v6MDd76yEdG4+eej9dABxLrbmCbG53bBlXriVJeGDB2OU+eo3+NKm80TMOn0Ms7oCPjo6JzDgNJiTvOuCDXcLNAGfQ6Q/G6wJI64l1UZanQYNTU1uPzyy/HGG29g3bp1+P73v49bb70VQ4YMwZe+9KVCr5HIghVvg2Ihy7L+CIgCD9lUo/c0XMiuK1YPHyzw9CTaDVTt3PL0evzqhQ14Y6N5FljroQOo3YbNMzrqDEtAYCCoUZeIWelK66ZsZa1GQVJ9gJWuSIxMKNjpoQMAkiQpgz2F582VYUZHj8mTJ+MXv/gFdu7ciWXLljliUmk1EbTgbVAsBqIJLuTUz+gUsXSVptEpnI/O/u4BAMDguoDptuSjI8aezuR7uq9rwHRb1sWn/nwVMbK1cpDH7YLXnbwuGQUeWu8dfkyTz9bMMFBo1pUvXSpJgz0JPQ6ygZ42aXQAcS8d7RxCu7EkRr788stNtxk0aFDOiyGs44SySU840/MEsMNHp3Clq/3dyYvKkDrzi0rAAZ9BOcAGEjL9UzaUjI64eV/ydwYZFo8b0XjM8FwciOmn2s2EzEYpekW3laW9nAvq0/elMRCEHnYO9GTU+D1Ad9i0guC00pWlQOf+++/HmDFjMGvWLMiyvqiPMjqlhQUW0biMaDyRNm+nVHAhss/NdRFAccXI2QwDI/EEZFnO61zc35UMdAYLBDpBgZtatdMfifPPrCM1WiMbLKMTUreXC4i+wwYXWL/Xje5wzDQzY7V0pTeYU318IWdkrzajwwZ7UumKUGCBjl0aHUC8xbyfl5DLMKNz1VVX4ZFHHsGWLVtw2WWX4ZJLLkFzc3Ox1kYIoE7t90fjtgQ6ekJkoMg+Ojqtuax0JcvJwM/nyT3QOdAjntHhmQYqXRnC0u6AMkMsG3oZHb+AwFc754ph5o5smAkysW9QBoHqB0jZyqh6s64AyugQ+rT12je5nFHjFyvTO80Z2dJdcenSpdizZw9uuOEGPPnkkxg1ahQuuOACPP/884YZHqK4WFHCFwsW6KjHPwBFLl3pPEmr24LzFUAfSOlIhtQLaHTYGA4qXRnCnkYB4FCv+Q28l7sGW8vomGltrJag+H4G5VCmF9IGK2aWA7IsK9PLDbquSKNDqHFC6SooKEZWvofOKF1ZXoXf78fXvvY1vPjii1i/fj0OP/xwfPvb38bYsWPR09NTjDUSWZAkyXbDOj2zQKC4YmS90pXPrQ50cg+uZFm2mNFxxhgOJ8Nm9ABipas+PiQ2U4ws4qOj9bXhXjpGGh2z0pVpRsdI26N/vEg8abqmd8wGFuhQ1xWRIhJLcLsBO0tXNTzDaSZG1s9W2kVe4ZbLlfSckGUZ8Thd5O0iyFvM7bkw6o1/AMxvLvmg1+0iSVJBBMntfVE+OVvEhZRGQJhzUBXoiJSusmV0chmrYCoqjhlkgsyGehqUn8yC/AFV51hGRocMAwkN7Dvjdkk8ELYDdp6bZ3TKuHQFAOFwGI888ghOOeUUTJo0CevWrcOdd96J7du3o7a2thhrJEwICTzpFpNe/vStCXRSQYf66bVQGJmt8UAnj/fiQKrjqinkFZopQ0M9zWFmZ4AyRywb7POt0RkSK1S6sjiSwVDE7DHx0THUBGXfry+aDOS8bilDV8fEyH2RuJC5IlH5tKW+P801vrSGj1JTI+jbZlRCtgtLYuRvf/vbWLZsGUaNGoXLL78cjzzyCFpaWoq1NkIQxdvA7tKV/sUeSGpmtH4h+WBktubzuAHE8sroMA+dIQIeOuo1xBL2db45nUOajE4iIWe9YLNzKi2jIzDXTRkmqB+wGLaXG5WuTI7JtWIGgY5RNtNoPyC9BNw9EENzjX2aDMIZKB1X9p4LzKm8z6TrysiuwS4s3XnuvvtujB49GuPHj8drr72G1157TXe7v//97wVZHCFGwGaNTrdB15X6Ij4QTcBsmkI0nsC6XZ04YkSDabCgNwICKIyXDmstH1IvVgsPqHxQ7Op8czrq0lVCTt7AG0LGKXie0dEtXRl/tmGTgMVYjKyfCTIXMWffj2UztQMQjQZ6AkmDw1q/Bz3hGLr6oxToELxr0a6BnoyQV1SM7KzSlaVA59JLLyWfHAdi9wTzXoOuK7dLgtctIRqXhbqg7n9zK372zMe48axp+PfPjcu6bb9Bx0oh3JGZWeBgwYuKz53sfEvISc0G01gQCurSFZDM6mQLdLhGR6d0ZRQ8ACqtjVaM7MneXt5vIGIW7dYymnXFttE+BBjtx6gPJAMdmndFAKqMjo0dV4C6vdw4oyPLsuEDgF1YNgwknEfIZmdeHujolKbMHGnVbG7rBQB8tt+8e88o9V+IeVdMozNYMKPDOt96I3Hbp8g7FXXpCgAO9UUwFjWG2/OuK52MDqAfPLCfa7cFVOJgM8PADDFydusAQ2dkT/a1Khoz/UtwfdCL3Z0DJEguAm991oan1+3Bf545taDl9GLS5gCzQEBMjKy+9jqldOWMVRB5EbR5sKeRYSCgMg0UCMLY67T3mnflGGl0ClK6sqjRAZwxisPJsAs1S8KYtZgrXVf6PklmgYfWkVUxDDTS6Og/gZqJkY3OQ5dL4kJ2vWMq++lfghXTQGoxLyRb23rxzf9bjYfe2Y4X1++zeznC8Mnldmd0UvcaEZ0c4JyMDgU6FUCQO8bac1E08tEBxKzwGd2pp1eR9mOjgYhKoJN/6UrEQ4ch0hFUzbCMzqjmEACgPYtpYDyhpL7VwbPLJfHzyXiUg8k0cdPuKU3pimt7EkjodA5mS9GzcpneWo3OX4YyBoIyOoUiGk/gO4+u5dmIcioLMo2bnWaBgDqjY3yvYd+JpHTBGSGGM1ZRYpYuXYpp06Zhzpw5di+lIIRszugYtZcD6huMeYalJzXbxyzQicYTiKVuOhkZnQJ49xzIIdChMRDG9EViPACcMDhpQZHtM1b7QWk1WLk6HJsFOoYi5rTOwfRzSpZlQ98es2Nm2w+gMRDF4I6XNuL9HR38391lNEuMZ3RsLl1Zyeg4ZXI5UKWBzuLFi7F+/XqsWrXK7qUUBLvLJt0GYmTAfMZQ2uukLjxmIwLUf2fAp20jzr90xTU6VgIdKl0ZwoSUPo8LI5uCAMwCneR76HZJaeUqwNyzyMj4zyzgVjIz+gGS3jHNtAjsnNDLLmbrugJoDESheWfzQSxd/hkAYPzgpDasx6RF2km0OUSMzJoDsmV0+g0eNuzEOSshcoZNMLe968qvl75nGRYLGp2+SNbZaQOqG6HPbRTo5PZe9EVifB0ic64YVLoyhpWtBtX40JTyGGjPYhqoeOi4M7o8AybnulFbKy95mWWCNAGSW6210exrpkVgr9UfyQyuTLuuaAwEgOT7tLdzIK/X6OyL4rpH10KWgfNnj8RZM4YDUDLITkeWZee0l1vwsvI7xCwQoECnIgg6xDAw39IVe3qNJ2R0ZbkI8Y4Vb+aNMN+uK+ahE/K5dTVHRpjNRKpmeKBT60NTqqU8mxhZz0OHwc8nQ1Fx9i4oc41O5sXZKIvEzmmPgRYhmz6NleeMZgHVB0ijAwD//pdV+Nxtr2BPZ39O+8uyjB//Yx12dw5g7KAQbv7S4ahLfa/LJaPTF4nzc83ujA77TjK5gh5G2VE7cc5KiJyxO9AxmnUFiIuRZVlOu/Bk67zKpm9QfHRyDHRy0OcAYnOYqhXFvt6PppT5XTYxMs/o6GQIzZyKzRyOjYd6Jn+u9dFJvpa+qNio40rZjwVlemJk/annDCWjU92Bzqd7uxFLyNi0vzen/f+2Ziee/mAPPC4Jd3x1Fmr8Hl5iLxeNDiv9Br1u29vh1SV6PXE+oJzvThnoCVCgUxHYOesqGk/w7IleBkS0vbw3Eoe6WnUoyxM/v8H4Mk9fP5+vldt7kYs+J7kWKl0ZoV+6yi2jI+5UbDBN3KCkma2UZHRMo1Z25ZjGQVl/atZVyEyMXCY342IgyzIv3XX0m3diatna1oub/vkRAOC6UyZh5qhGAMp1qidcHkFkW68zWsuB9O+k6dw4Kl0RhSTotW96ea8qC6NbuvJkLzUwtPXyrBkdJuT06gRWnuxP7mbk4qEDqDMNNIRRi9VAR89Dh2GmhTLSB5iWrrK1iRscM1vAndwvi4+OwQgTBm8vr+KMTjiWQCQ11NRqK3g0nsB3lr2Hvkgcc8c148oFE/jvWEanXEpXiiuyvfocIHlOM7WAkSDZrKPQDijQqQDsLF2xi4XP49Kd9C1auurWaBG0TrpquCuyzk0i366r/blmdEiMbAjrGGmu9aExpdFp74saCs77stgViJauMmagCU8vFy+XGQmY+X7c6sC468pYo0NdV+q/XWTivZo/vLoJ7+/sREPQi99ceGTauBCu0XFAtmzNtnZ87rZX8MonxuaFrLW8xQEzzyRJMm1+IY0OURTsHAHBRGlGwl1RMXK35ukq2xN/NldZrtHJsevK6kBPBml0jDnEUu81Pj6gMhJLGJ6v2TI6QbPuqZh+ZkYJuA00OlmmLQcNBNBGQZVyzGylq+z6noaURqecTO0KjbrjzOr78OLHewEAPzpjCoY3BtN+56SMzgsf7cXO9n7cvXyz4TYHe53RWs4I+bMLks1KunZAgU4FYGfHjzL+wehiL5rRSb/oZPPSyeYqm3fXVap0JTrQk2GWaahm+IW6xo+Qz80tAYyydkJdVzrnUyIhI8J9dMSHc8YTMqJxObVfFo1ORkZH37MnY626YmQTH51URmcgmsjL5bucUWd0Oi1mdJjYffLQuozfsYcyJ+if2APd6m2HDDsR2/j4B/tLV4D6wVr//WPfCzIMJAqKndPLe7N0XAEqHx2Ti7UljU6Wp2FeuspRo8NdkS146ADko5ONg6rSlSRJvHxlVI7I2nWVJWBJN/DTNwzUOy9M/XCMNDpZSqjq/fSySIq+R/97ozbfLJfuoEKj/rutipFZBqgxlJkFqfMnz79IzP4gkvlJJWRg+acHdLfhGh0HlK4A5QHTKKNDhoFEUeAanWg8q9FeMcg25wqwULrSanQESle67eV5GgbmMv4BUG7ANL08E5a5aUnZ15sJkkUyOnoBZbaAhf07Ek8grmmLVb+W1ok52zF5uUtnn+R+xmW2/ohxsA4kjQqZlqRaBcnqv9tK6SoSS/BMc2OqBKhGnX3O5gdTCtSZqpc/2a+7jVPMAhkhrgnVD8Cp64ooCqz7KJ6QeZdCqcg2/gEQL12xCxO70WTL6GSzz/flIUaOxhO8zGI50PGJDy+tJtRzrppTGoOmGkWQrIeYj45OZiYVeHjdUpr4FEh/ujRqE/d5XHBp9kse08BHx0RQnK3MZjYCAlCPgajOjE6uYmQWFEmS8h6q8bhdPMC0W5CsDvaXf7ofUZ3r90GHjH9ghEyaX4y8rOyEAp0KQH2hHShxe3M2V2RA3EeHXczZdOtsGZ1sItB8NDqsFu5xSTzrIAp1XemjnnNVk/q8eEYnB41OttIVLyXpPEmqf5YZ6OjresyOGTaYq6XdT69cJtKCW0mmgQd7wthxqM/SPurSlZWMDtO61Ae8GQEvg5sG2uyl06H6u7oHYli9tT1jGz7nyuaBngwW6PSadF2RYSBRUHweFzypL3SfgUCsWPDSlZFGR7B0xZ6sxqQCHREfnazOyDmUrljZqqXWr/tknw2zGUzVilK28vFxHY2mpatsXVfZSlfM3ThzP5d6ZpVB95RR0GEU6JhndMxLV1kzOhU0BuL8u9/GKb95zVLAkmvpigUPbNyIHnUB+1vMZVnmQdlxEwYBAF7+OL3NPJGQeddii0MyOsoEcwMxcox5WTknvHDOSoi8sEsj0pPF8wRQnpLNppczjQ7L6HT0RzO0FAx249C7SeQjRs61tRyg9nIjmL6gWXWRbjITI0eMzym/wTgGIHuLOKA6FzMyM9kDnYCBfYPSRmuk0dE/J2JxxQgvW2dKpQz2HIjGsbmtFwPRBHZ3iM+sUgd4fZE476gzgz0kNWTJyjph3lVfJM67/c49aiSATJ1OR38U7DLY5BAxMgvsDcXIWR5E7YICnQrBrvbmbJPLAQsZnXB66UqWjZ/isgk58yld5TrnCqAREEbwjitV2p156eST0dELnM0yM0aBh5nBGZ9CrjmHhWddGTgqA9nT+5ViGnhQlZ21kpnRdpuJ7ssyOnpCZIYTvHTY+e9zu3Dq4a3wuiVsaevF5gM9fBtmFtgY8uoOjrUD9gBi1cvKTpzxzhF5wxT5ezoHSnrcHlMxsrE7rN7rNIW8PGVv5LMi1F6eQ+mKe+jkEuiQRkcXdemKwUpXhj46OTojh80CFpOZVYalK0Nn5OwXdKVbSz9AkqTs6f1ijYHoi8Tw1Xvexo8fX1fQ1zWiLfUAAVgLdLR/d6dgiznrZMpWumJdona27rOMZmPIi7qAF8eOZ+UrJavT5rDWckCl0TEIEpXvk3PCC+eshMiLKSljrI/3dJX0uD0mYmTRrismRq4LeE2f+LP5lwS8uXddKQM9rXnoJI9LGh092NN8c42V0pVARidLe7lRhiVokF00M/4zG+ppmNHhZVR9bU/I6+a6JT2KldH5+7u7sHLzITzyr+2GN6tCwkT+gDXjP20QItp5xa4beh46jNqUl46dGZ0OHpAl1/mFKUMAAC+rxkEc7HWWWSBg7tsWNvle2AEFOhXC1GH1AIBP9hYu0LnjpY048r9fwCZVKlWLmY+OX3ioZ5S/DqtFGz7xR5UbhdHxctLoFKB0FY4lkDDQFlUjarNAhqkYmWV0rPromGltDIJuUa2NkUbH6MmVnRNGpSuzrpRiaHRkWcb/vb019f+BT/d1F+y1jUgLdKxkdAa0GR2LpSuHi5HZ+d+QWudJU1oBAKu2tvOAkH1/nCJEBlSGgTTUkyg1U4YlMzqf7CnMhSsci+NPb2xGR18Uz3+013A7U2dkiyMg6gIeNJu0Hw9k6XZRl66smifmFeiovtRmwutqgneM6Gh09J7QZVlWMjpZfXSydF0ZZGb8RhkdkwDJLGAxL12l72c20JPBSriFnHf1zpZD2LBPeXAp1PUiG6z8AlgtXSnlbEA8o8M6mbJqdBwgRtZ2h40eFMLEIbWIJ2S8tjHpksw0Ok5pLQdEfHRoqCdRJKYMTWZ0thzsNXSstMKbn7Xx4GP9buMskXnpSrlJZAs82OvUBZSMjpGhXHZn5OTPEjIQs5hZOdCVv0YHoPKVmmylq55wLKOTJhxL8C6T7LOujEc5mGl0MjMz2bU2RvorU/GzxyCwMnFFZiiGgYULdFg2h9lRFDIDbIQ6o2NllAPrxBydalAQzuhw7UuW0pUDWvc7ellApqzzpKnJrA5rM29z2EBPQMnomBkGGj1w2AEFOhXC4Do/Wmr9kGWkPbHlylMf7OH/f30W3U+P2QgIVeDBWim1xOIJ/qUR0ehkc5VVlx+s6HRkWcaBntzmXAFJnxaWTSJBsoKeq2t9wAtmU6QdZKjWjOgFAuxneqMcTMXBBu3litYm+ygH7VDPfpPhhQHmlq3JLioZHf3vDINrdAqU0dnbOYDnP0reQP99/jgApdH0pWd0xB7CYvEEtxkYqbKcEEEt8jWCZ3TsFCOzEluNss6TpiZ1Oss/PYBYPKFkdByo0TETI5NhIFEUpg4rjCA5HIvjxfWKIG5Lm3GWiHkpGHVdqQMPo5KO2o+h1u/h4jwjjU42EahP1YIp6rsBJC+OLBCzOrmcYVTiqGa4mFKVene5JDQE9cdAqINY3XEM6hJhgTQzYZPMjFFGx2w/9nNZTg+6+00CKwbvuirQzfjhd7YhnpBxzLhmnDNrBIBk6arY8/EO5qDRUQuRRzYFk/tmcUtX0yEgRq5zUHu5OqNz1OgmNIa86OyPYs22dkWj46CuKzYrzLC93OSBww4o0KkguCA5z0DnjY3JstWQOj8G1yWzRB/r1PLVeooaAx8dv8cF1lhiFACw9LHf44LP40Izm4WkE+jIspxVzOlySTzYsdJizvQ5TSEvd9C1Cr8hlngMh1Ppi8T4Ra9Zk3o3EpwrHVdG4nblszEsJRmkzAMGHktmvh+G08tNu66Un6vF8YorcvaMTkMBR0BEYgk8/K8dAIBL543B+JZaeN0SusMx7LJg4pcLuYiRWaAT8rn5g4dVMbJIe7mdgY5eG7zbJeHEyaz7aj8v/Toro2M8vVw9b9FopIodOGclRN7wFvO9+QkMn06Vrb54xDAcPjwZPOmVr/oicbCHQaPSlSRJpm7Fan0OoLRb6s27UpcsjFKjubgj5+OhwyAvnXTY06hfNeeKwT7jzNIV89DR/2xdLkkZrZDha5Nf15XhrCueCUqkZT/MMkjq4aLqbKZZgMRgGp1wLJF3lvDZD/egrSeMIXV+nHb4UPg8LkwYXAug+ILktNKVYFaGPfzUBTz8fRApXYVjcZ4VVGdKtDihdGXUBs/KVy9/vI8Hic7S6LAHusz3Tv1wSRkdoigwQfLHe7pyTkery1ZnzhiGaakskZ4gmdVoXVL2i3a2Kc6AuuMqeUHjGh2djI56aKnRMf05eOkc4B1X1vU5DPZ3FkIMXgnwp1HVnCsGe4rNLF1lz+gA2XxtxAwDjQIkvRlZ6uMB+iUoowu6JEk8eFIfU7Trqtbn4dnQfI3t/u/tbQCAi+aO5g67LANcTJ1OLJ5I09qJZmVYFqs+4OXdUyJdVyxL4pKUByc92LWm2wE+Olot0ecnDYbHJWHTgV7+ubc4qusqJUaOxjOsNNTCewp0iKJw2JBaeFwSugdi2J2jQ/LrG9rQHY6htd6P2aObMC1LRqdH1VqezfjMqPtEeR3FQwcwLmsAys3F45IMLdGVMRDWS1e5tJYzSKOTziGdOVcMIy8dntHJEgQYdkGZtInz9vKYtgQlVroClIBFlmUhLUJA55iiGR2XS+IzmfLpDvpwVyfWbGuHxyXhomNG858zTd8neWaAs3GoLwL1M1fXQEzoIaxLZTdhpYTHsj4NQW/WwbxO8NFRSmzp34/6gBfHjGvm//a4JK7XcgIsoyPLmd8ldu3zuV2Gk+PtgAKdCsLnceGwIcl09MdZWsKz8cy6ZNnqjOnD4HJJOHx4A4Ck7icWTw9UzMY/MHjJwCDwUHvoAOA+Ol0DMUQ1xxQxW1O8dCyUrlIDPQfnMNCTQaWrdHjHlc7TqFHWjmd0DEqhgHGLufgUcqP99C+HbpXui3226nMr27mol0Xqz+L8rKW+ADqdB1LZnDOOGJbWUcgzwEVsMW/rTn6+7CEmnpCFdDEssKsPenlQLFK6YudTNiGyej390XjGda0UJBKySjSdqSViLslAsmyV7UGy1KgDdG2LeT/PjjortHDWaoi8YTqdXPwx1GWrs2YMAwCMaQ4h5HMjHEtgS1tv2vZmHjoM0dIVu/jUB9Xtx/qljWxPw758NDp5iP6UmxqJkYH00pWWRoPSFZ9cLhI8WPTDMdfoZDtmeqCjfo1sokvlmDpdVyKBDh8DkVvmoaMvgife3wUgKUJWw0xGt7b1Fs37iWlMRjYF+fdSpATFrgn1AS8/Vzr7o6bZIBFXZCD9mmU0hbuYdIdj3C+qQcfY8OSUnw7gLLNAIJlpZNffvrDBd8lBZSuAAp2Kg9fdc0hHs7LV0PoAjhrdBCB5UrPX1JaverMMX1Rj5EjL0Gp03Gntx+lP/CIeDbkM9uQanRw8dBg0wTydQ1nMzozEyH1hAY2O4ZBNMcNA7XkYFihBaY/JPmOvW4Iny1RpvdJVn6BhIJD/YM/HVu/EQDSBqcPqcfSYprTfDa71Y1CNDwkZ2FCkURDMXqCl1s+/0yI6Hfb3qktXItkgEVdkIPkwxK4T3eHSmwaydQa9bt3zbmxLDcYPrgHgLCEygzUL9EXTPw8nuiIDFOhUHFPyEBg+zcpWRwxNq28bCZKVOVfZL9hGRm0MptFRiweNdDosW5LtJuE3aCPOxoFCaHQEx11UC3zOlc4TaZORRodldLKcU4ZiZNYmbtRebpTRiWUPkPSOaTYINGO/tNKVseGlFpbRyWUMRCIh44GVybLVonljMsofkiQVZUaeGla6aqn1WdLaqEtXAa+bByVm2SARV2SGnV46HQIT1llWZ2geD1/FwqjF3IkDPQEKdCqOqTmmoweicbzEuq2OGJb2OyNBco/JnCuGeNeV8jpG86546SpbRsdrPaNTEDEyTTBPQzEL1MvoGHRdhc0/X6PSlamBn8cgQBJIt2uzQewzDpgEK9nEyCLp/XzGQLy24QC2H+pDfcCDhUeO0N2GW1IUqcW8TeXs22ihTVxdugKQVr7KhmjpCrC3xVxkwvriEw/Dtz4/HleeMKFUyxLGaIK5Ewd6AhToVBy5pqNf35hZtmIwL52Pdqe3rZuNf2AoYmSDrquBzNfhGR3NE79Ix4pVH52+SIz/Lfn46ASodJVG1tKVwZgPRaNThNKVLzPoSO5nnm7XliVFskDq36vLZX2ChoGAegyE9ZvxX1JzrS44epRh4DilyBkdNlYln9IVAOF9O3Tcho1gTRT5tu7nQqdAQNYQ9OLHX5zK/Y6cBB8DETEoXTlozhVAgU7FIUmSMsncwsXrGYOyFQBMaq2D2yXhUG8E+7oUl9Ne4a6rVCnJ0Bk5XaMDGGd0so1/YFgtXbGOq6DXbRq0ZYO6rtJRSlfGYuTO/mjazKo+gY6kgMFMMdNp4kZDNgWGELJ9eaAjqLPR67pSdGbml9+GHDM6uzv68dqG5ATsS44dY7idMjamOKMg+AgDVelKKNBRla4AJXAxD3RSJaEa8YyOHV467LqmbS0vF5TBntpAh7quiBIxlRsHimV0BqKZ3VZqAl43JqSEcev3dPKfC3ddGZQMlNdJ+ejoanT0ZyEVUoysDPP059XGyW7O2uGP1YrenCsGu8DLcrpmQ0Tgzj57beBsbhho0nUlIEZmn62ZZ49yzGxiZIGMTo5i5A92dkCWgekj6jG2pcZwu8OG1MLtktDZH8Xerty8t7LRpsro1FsIdJTSldKJCZhrdFiGUK+TSUutP7mNPaWrlN+PQInNibBrnba9XPR7UWoo0KlArAqSX9/Yhp5U2WrWqCbdbfQEyb1WS1emXVcqjU6NfteVUOnKa610xTI6+ehz1GuijE76nCu90pXX7eJmeOrypEhGx9Aw0CQzY6QVU2ZdmYuR2TGZKN480NFpLxd0RgZyby9nJoDMK8cIv0d5iCnGKAh1oMOyeCLt5coIiHSNTkd/9hESuYmRS9911Skwj8vJ8EAno73cvFnEDijQqUDUjqci6einP9gNIDnbyshNVE+QLOJiC5iLkfmsK7VGx2CC+YBQRsdi6aoAc64AY5FsNaKec2UUtDTWsBuf8hmLaHT03mdZlvnnbcUwMJGQ+ZR7ETGy1kfHLNDR6xBjr2HFMFB0RhSDBS1MbJyNYhkHJhKyUrqqs9h1ldIkNaQyWo2C2SArAYSd7sh6k8vLCWbomZHRMdHJ2YWzVkMUBCvp6IFoHC99vB8AcOaMoYbbMYfkj1QZHdHSlZH1PkProwOonHO1PitFKF3tL8CcK/WaqOsq+5wrBm8xV5UnuY9OtvZy/j4rAYs6qDX30VE+nzSH46ylq/Syl5JZNBMj6wQ6Fnx0hjcmz8ktbb2WNDSf7hPL6ADqmVeFzeh0DUQRS+mvmmvENTqyLKObaXRS1wS+r2DpSkiMbKNGx2jOVblQw0tX+hodKl0RRUedjjYrX63YcAA94RiGNRiXrQDlYrjtYB+/CGmnjhthVrriXVciPjpWuq4EMzrMQyffjI6Rv0s1wuZcDcriNK3npdMn0nWl8z6nORWbOCPHEjIfLSKyn/qYVjM62kAnkZAtOSNPHFIHn9uFroEYdrb3m24PJG8+Ww8mXcwni2R0WAa4wMM9WdmqPuCB3+MWbhHvjcS5a7C2dJVt34FonF9jGkXEyDZmdDoE2sudTNBnltGhQIcoAaJPaU99kD7byojmGh+GNSSfLln9v7cAYuSBaByR1E1HxEdHTKPDxKqipavCanS0X/5qpC1LxxVD8dJRl67YOWVNo8NucNmGvaovvtz4L6Y4HGcbQsgDlkh6oCPcdZVan2gGieHzuDBpaLK9+MNdnSZbJ9m4rweynOx0EgneWfPC5rbeggbpB5hZYGoNDUExnQ0rbXndEg9OG7iTtnGgw37nVg1DzQbbxhbDwDLX6NSYtZdToEOUAl53z/KUtrujn7eVLzxyuOlragXJ1mddZQYe6ouM+imeZXR6I/G0EtSAgL6BZXQigsP69qfKe/mMfwDIR0dNNg8dhjLBXF26MveY8et0T4k8SfpVM6nYuSjq+5Gp0bEqRk7up071iwo2Dx+WWTbOBrOVEMnmAEBrfVIoHE/I+Gx/j9A+IqjHPwDi5Se1WSArezYImA2yAKoh6BXqnqy10RlZdPioUzE3DHRWaOGs1RAFY4pKkGzEva9vRiwh49jxzZg5qtH0NbkgOXXBtdp1paeZUQ/0VD9R1weUf6uf4li2ROSGJtxezkpXeQz0BKh0peZQloGeDO28q0gswYNTkdJVWkZHwMBPkqSMwINdqP0mQUdQk5kRdYDVZjP5dGePK2sGVc3hI5hhp1hGR7TjiiFJksqSonDlq7ZuFugkP2cmrO4Ox9K8k7QoHVfKOdAoIGS2qnth7eWlNgyMxRO8i65cNTp8BIRR6YoMA4lSwLIvmw/06N54D/VGsOxfOwAA3z7hMKHX5A7JKS8d0aGe2bqu9FyRgeTFV6/zSqQ1l3ddCZSuovEEb28eUl+g9nIqXXF9ht6cKwa3EEiJkdXvW7bPV0/0zTIs2Uz/AJV5Zcyaw7H2mKLdJdx/RxNYiXRcMfQaAbLxaSrQEc3oAGIPRlZp42aB6RkdWQbX+enRrTELVO+rHQKrRnSgJ6PWptKV2ipAdK1OQ2kvp9IVYSND6vxoCnmRkJM1ey33v7kF/dE4po+ox/yJLUKvOS2VQt+wtwe94Rh/+q41nXVlLEZmFzU9d2XlRqhc3IRKV15xMfLBnghkOantaM4zjaweE1AMl9lywkrpigWarN7vc7vg8xhfmnRbtiNigYfWHTnXNnERrZh6PQOaTJAVn5Gpw+ogSUktGbNCMEKWZR6sTBXM6Ki3LeQoCLWHDpAMQtnfnU1UzFrL0zI6qcxHbyTOheRalEGZYt/jOj4CorQ+OkyTVuf3ZJ1872SM2svDgg8OpcZZqyEKhnoysdYfoyccw/1vbQWQzOaIugGPbAqizu9BJJ7A+zs7+M+zCUeB7GLk7iydW02aGyFQ+NIVu3G01PqFSwlGsDUlZHF9UKXC/FOslK64WaDZ+ZS1dCUWeLB9wwJzrtS/H8jYz9q5L2KPoCXk82B8yt3YLKtzoCeMQ70RuCRgYqv4jKQpRRgFwTI66mBXpMW8S9NaDiS7r9hlymhfq27Ddg315CU2gc4wp2LWXk6GgUTJMBIkP/zONnQNxDC+pQanHW7snaPF5VKCp1Vb2gEkbwBmTyXZfHS6DUpXgMpLR126KvCsK+aKnG9ruXZNA5HqDnRYRidb11WjZoK5YkCZPUOoV7oym1zO0JZRRTUF2uBKOKPj099PZKCnGla+Wm8S6DCjwLGDaiyVDya11sElJT83plnLF21GBxALdLSTy4H0TiqjzismRhY14WNZ5N5IPKtmqNBYGTzqVIIGIyBoejlRchR/DKXuHo7F8afXtwAArlwwIWtLrR5MkLxq6yEA5kJkIHvpqkfn6Y2hN+9KGYgokNER0OjwOVcFCHTULcrV3Hkly3JGx40eLAjq6ItAlmVeujLTryjzo5TPV2QCedq+rHQlmAky8tExG16oLZVZMQtUM11QkMz0Oey7L0rA68a4VNbo4wLpdHQDHYExENrJ5QxW6jQKkjr7rLVsq69d2jbpYlLuZoGA8jCS6aOT0spR6YooFUyQ/MneLp6O/n9rdmF/dxjDGgL48qwR1l8zFeis2ZbM6JgJkQETMXKWzq3mLIZyoSwDEX1WSlddykDPfJEkieZdIfkZsQtedh+d5O+icRk94ZjSWm5yTrH3OBJL8Cdx8cxMeglKNEDSDvW0qtFhGScrc67UsIzOh7uyZ3RYmXpyq7g+h8Fm5BXKOJCVLwdbzOhoJ5dn7qsvSOauyIIBhN/jgtedfDApZfmKrbNcJ5cD6qGesbRSJxkGEiXnsCG1cEnJ0sC+rjBi8QT+uGITAOAb88dnFXwawYIndqE3KzMAqk4XXTGysUaHXbBYGUSWFVfZgM947ZZKV3zOVX4eOgxe4qjiziv2eQW8xnOugOTNnmXfOvqiilmgSRCQViLUlqAszl1TMjNWMzpiGp2gpnTVl6OGgXU8bj/UxwMBPXLN6ADKd7sQLea94Rj/m61rdNInlzPMhoJaGegJJB9MmPNyKTuv2N9ezhkd9jCSkNOvszTUkyg5Aa8b4wcnBYkf7+3CMx/uxbaDfWgKefG1Y0bl9JoTW2vhUZW79LqlMtahMvDT1sKZGFm/6yo9oxOOJcAeHoSmlwsFOoXT6AAqI60qzugoc678pkJ39RgInq0zCZ7Vxn888GCDOc0yOh5toJOrYaBYZoa9biwhIxZP8IyQlfZyIHnzHtEYBGCs04nFE9iYMvwTGeaphe1TiBZzVrYKet1pWV+R4ZxK6cooo2MW6IgHEHzelQ0ZnXI1CwTSr7+9qiCRMjqELUxVuRnftTyZzfn6ceMsiyEZfo8bhw1RujnENDrKSa8tJ+kN9GRo512l+ayIdF0JBBsHCjT+QbuuajYNPMg9dMwv5OrPWBkpkv0i6XIpxn+5+9po28vFtT2yLFsWMQPJYIx3DVoMdAClbGzUebX1YC8isQRCPjdGNYUsvz4rXX22v4dPdM8Vrs+pSz8HRNyReUbHoHRVKDEyYI+XDhPfl6uHDpAUh7PvTF+anxW1lxM2wJ7SHlq5DR/v6UKNz41Fx43J6zXZBRewptEBMgXJTIysN5tGO++KPU373Nk7vayUrgod6AQMrNGriYMCHjqMJlU5QjSjA2QGlLmOZBAWI/vUwXpCNZjTpONQnX2KxNEXTQmuc3jinc6NA/UFySwTM6m1LierhOENAdQHPIglZGw6kN8oCN5arjGMbBAYzqlMLtcvXRU0o2PDYE8umi7j9nIgU5Aciyf4tHpyRiZKCqu77+5MalEumjs675QpE0YCQK3J0zeQjP6Z6E+b6cim0WEZAeajIzpHhd1cWLnACFmWlUAnzzlXjKDGp6UaEWktZ6hLV6IaHcC4lGR+bqRbHQj76GgCFq7tMbmgu1wSPx8HonFeurIqRgZUzuQGgmTWXZlL2QpIalamFEino9dxBQhqdPr1s7wsU6O3b38kzh9srAQ6ymDP0pkGtldAezmgbjFPfl7qLkgqXRElRS1K9Lld+Mb88Xm/JgueADExMmBsGtiTRaPDyhoD0QT6I3GVfb6JhkN108pm3NfRF+W/bxHIPohAXVdK6SqbWSCDPdW290WFu64AdUaHTQW3VkrKKF2Z7Odxu+BLZRH7okpXmUjAwrYJx+I5GQYy2MyrzwzGuigzrnILdABgaoF0Om2pyeWDDUpX2YZzKl1X6edBtjEQrGzlcUlC5XRGbaD0Gp1KaC8HMjM66nPSn0OjSzFx1mqIgjO0PsAvEOfOHoHWAmQu0gIdwYuKX3ODYWTT6NT43PzmcqgvoioXZL9J+FRlrWxeOsxDpzHkNX0yF0XPzK7aUEpX5uXAJlV5Mp+MTr+AY3by9+kZN1FRsXpf9Y1W5MmVBVH9kUROIyAYQ+sDaK7xIZ6QeXeVGmVqufXWckahMjpGPkoNJsM5B6Jxrg/K0OhkKV2xeWmNIbHJ5Qw7NDodFdBeDmSaBvIBuRYG1pYKCnQqHEmScOGcURjdHBIe3mlGQ8jLO0D0Sk56cG1Ehhg5NetKJ2CSJEl54u+NCN/MPG4X7wzLptPhHjoF0ueo11bdGR3x0lWjuuvKSkYnY8imoB+OgbbHrL1cfUy1GDYg8OSqPvdzGerJkCRJKV9pBMk94Rh2tvcDyC+jw/b9eE+eGR2DrJ5Z6Yo9+EhS5gy9bNkgltFpsCjwLXVGJxJL8InfZZ/R8aeXrsKCejc7oECnCvjxF6dixQ0nYlSz9U4MI2aPaQIADG0QyxDpmQbKssyfpLTCQ4Z6grlin2/+RRKZd6V46BQu0KEJ5qqBnkIaHUWMbCWjkxGwxMT8cLSeTlyMLBSwJPdlGguvWxIayqg+9/O1yOfGgRpBMsvwtNb7eck3F8a3JDsq23rCeXUOstJVi+a7xQLbnnBMdzin+sFHmxVggYFeNqjT4kBPRl2J512xgEyS9N3gy4lgyrSVjW4RfdiwA+etiCgLbjxrGv5w8VHCs7IUh1jl4tYXiYPZ6hj58ai9dKzY57MbXrY2WT3n1nyh9nL15HKB0pXO5yvSdWUsRrbWdSWaJQSUz7adGyKKBStqE0krnWV6GGV0WNlqSh5lKyCpi2HZ0EO9mVoYUYzEyOoHGr2ApUtnzhWDiXc7+qIZg0fbc9S9FKp09cy6PZjzs5ewcvPBrNuxbGBD0Ou48o5VtBkdpw70BCjQIXJkcJ0fXzxiGLwCT7SAvhiZpYvdLsnwy6H2WbHyNKxkdIwDnbaUjkDkhiyK1gm32pBl2bBsoUe6Riflti3QyWdYujLJzGQESMxoUERrwzM6UeF9ktux0lUi75sBC3Q+2dOV1lH4aQGEyAArF6f7V+WCEuiknwMet4sHF3rlK6M5V4BSloolZH6uMJTSlbWMTm0qoOrOM9B5/qO9ONAdxnMf7s26XUeOmScnEtKIkZ060BOgQIcoEcogRuUCxVo6a/0eQwGh2kvHypwgkdIVy+iI+L2IUu0jIPpUbb5WfHTa+6L8yVAoo+NJ13yJior9moBbmXpufilkwQkLAESDFXWWL5+uKyA5lbzG50Y4lsDmtl7+c95ansPoBy2D8gx0wrE4z8zoDXXNptPpNjALBJKfERtbo923w+JATwbP6GQZqyECC+zM/IdY2dOqlsiJhDRiZCt6t1JDgQ5REvQmmHdl8dBhNKm8dLhGRyijk67F0IO1QbfUFEGjU6UZnfQ5V+YBC9Ns9EfjfF8rGR3mSxMWzMwYOyNbESMrf6MIehqdXDM6LpfEDTs/3JXU6ciyrHRc5TDMU0tznoEOe4DwuiXdG3o2UXGXgVkgkMw2GbWYd1gc6Mlgx8m3dMX8uDYf6M26ndUJ606mRuujw60anBdWOG9FREXi19GuMAFgNt+LZvbE3xu1ltERmHdlxcFXFOVGWp2BjlK2Egse6wMeuFNaBfY0L+LNlDlkU9BHJyMTJDbrSn1MVroSDVbSAp08uq4Yh3OH5GRws6dzAF0DMbhdEiYMqcn5dRns4eJgnoGO0ayzbC3m7GdGQl2jWVlWB3oyCuWMzAKd3Z39Wb/7lTC5nBE08NGh0pVDWLp0KaZNm4Y5c+bYvZSqIaAzlqE7i/CQkb9GR6R0RRmdQnHIYvAoSVLG061IEJCrM7Jh15VAdsav8dERTdEr5cyEsBdUNpSZV8mMDtPnTBhcUxA/KFa6as8x0OHBrsE5kGvpClCNgegzCnRyK13lo9GJxhM8+JVlYEubcVaHZbEaKiGjoxUjx5w5uRyo0kBn8eLFWL9+PVatWmX3UqoGbbcLoNLoZCldpXVdWWovzwys1FgVzYpS7YaBBy2Mf2Bon8JFTCiV95mVoERnXeXWrQWoNDp91jQ67NzvHoginmozzCfQYTOv1u/uSpWtkoFOPkaBaprzzOgcMOi4YhgFK4BSujIqZxuVvXIZ6AmoMjrhWEYnlyjsgYmRrXxVKWaBgHL+84xORPyhodQ4b0VERaK13geyz7liqGchWWkv9/EJ5vqBTk84Zkk0K4qS0clv+nO5YsUskKHO6LgkMft4tcBXlmUeuPhNMzpKwJ2cQs4ElOLH7OhlXVfWNDqHVLqSfJ56J7bWwud2oWsgaRKotJbnL0QG1GLkcE77G7WWM7JqdExKVw0G865ybS+v8ye3l+X0KdxWYH8vY3MWQbLawbncYQ8kfWEqXREEAP2MTreIRoen0ZWunEABuq7YDTnkc+fsaaIHC9p2HOrjYudq4pCB9X821E+3NT7jDjw16vMpbGGYoDpAsrIfoGRhWJnDatcVKwV53ZKwLYMeXrcLk4Ymjf0+3NVZsNZyRr7t5ey7ZTQ/rl6odKX/nWxUGUwyZFnm2SGrAUTA6+IasVwFyUyfw9ictXTFRNPln9FhmfVeXrqiQIeochSNTmagozfnisFugpF4QglOCuCjc7A3u44gV44Y0YCpw+rRE47h1mc/KehrlwO5ZXSUbUMCHVdAeglKnbUzExUzXU1CTr+xiYiRtRdwqz46hyyKmLNx+LBk+Wrtzg58tj+ZQZgyrLClq1wDHdGMjq6PDi9dGWV0Mvfti8T5cF6rJSFJUoaA5joGggU6LGDKltHhWqKKaC9Pvm+ZY1go0CGqFL3SFdPoZCtdBX1ufqPY1dHPf2aGmUanjT91Fk6IDCQN0W758nQAwGNrdmLV1kMFfX2nc9DC+AdGY41y0RfpuALSRd/sSdIlJbMl2VCXm5heQmQ/9TGV17IWlLHj5aPPYUxPTTJ/6v09iCVk1AU8GC44jsUM1jGXd6BTp38ONGYZzmnWoKDsq6yNlcC8bimnbjYl0MnNS4dpkqanROKbD/Qa6n0qyzAwPaPTL9gQYAfOWxFRkWQrXZkNBmWmgfu6krOpxEZAMI1O9tKVaBu0FWaPacJX54wCAPzX4x/qzvSpVHLJlOWS0VGLvtXaALOyl8/tAtukQ+VwLFYuyy/QYYFDIUql01KCZBb8TxlaZ2lqdzZYRqejXxFPW8Hsu8WzMnpiZKbRMShdKT46yr4d3ITPl9N7UJenlw7L6Bw9thkuKVna1JazGO05+v04kUzDQCpdEVWOro9O2FyjAyiaAXbNteaMbFC6MrCoLxT/cfoUNIW8+HRfN/7y1taiHMNpyLKMLamOk1FN4gNkm9WBjsWMzkA0billLknKuJEOi6Mcgr70y6VVHx0W2BfiRjB1WB3U9/TJBdLnAIo4XJaVG7MV8itdZS9n6+2bqysyozbPwZ4sozO8McgHJ2/S6bxS68IqIdDhYuRIUtgfFhzDYgfOWxFRkeiVrswuagyt3kMoo2NSuiqGWaCaphoffnjGFADAb17cgD2d/UU5jpPY1dGP3kgcXreEsS3ixnXqi77I5HIgXaNjdX4ULyWlbpaiF+bM0pXonLf07fIxC1Rew4Pxqve4UK3lQLL8ygIKq1468YTMM1eGpSuDzql4QuYPP3rOyIAi4k3P6OTXycRazHP10mlLZW8G1/n5Z7K5LVOnw4JGj0syfbgrB9gDZzwhIxJPUEaHILSOtIAyX8Y0o6OpZxdi1pVVB99cOH/2KBw1uhG9kThueerjoh3HKSjGdbWWuoqaatSlK8GMjmqUw4BgazmDnYt8lIPF4Eq7BtG18n8X6EYwfUQD//9TC5jRARSNlVUvnUO9ESRkQJLSM3VqWBDVH42nfT/VGRUrGR2lHJTbQws7Vr4ZncG1fowfnOyG0/PSUQdkhSoz2om6KaQvHC+IGWaxoECHKAm5+ugAOWZ0uEbHqHRV3IwOkJxLdMuXj4BLAp5etwevbThQtGM5gU/3MeM6azfdpnwzOmzOlaArcEBbuhLcLyOjY/F4/HUKdCNgk8wBYFKBA51cO6+YRqsp5IPHINitC3h42U0dsLCOK/XwTi2sW6knHOPaN/YauXYy8dJVnhqdwXU+jB+cyujodF7lG5A5DY9b+Zx6IzHlgaMA7tyFhgIdoiQo1vuZGh2zQCe3jI5Z6cq630suTBtej68fNw4AcNMTH1b0DKwNqYzOpFargU7uGp1ILIF+5q8kmNFherF2i8M5teedcCbIU5yMzsyRjQCAMYNCWceo5EKu7sht3dk9dIDkA0BdKrjo0gl0sv0t6tEQbN9cB3oy8hEjD0Tj/IFtcG0A41tSGR0dL51Kai1n1KQ1BTCtnPPCCuetiKhItF1XsXiCq/XNNTrpvxfT6IgZBhYzo8O47pSJGFLnx9aDfbhnxeaiH88uPt2XfIqdbDHQUU+4FplcDqSfA+1WRcVsZlW/tf0yuq5EtT2+wmt0AOCYcc342TnT8esLjizI66lpznHelZkQmcGyGmkZnX7zBx+3S+K/Z/u25zjQk5GPjw77e31uF+qDHkxIZXR2HOrLuPbkOnjUybAHk95InAwDCYKXrlIZlt6wchEQ7brSvlY2sk0vj8UT3I6/mBodRl3AixvPmgYAuPPVz7DtoLFzarkSiyewKWVcZ7V05XG7uPhUNKOjHhPByitWA5ZOywFSbiUobSq/UDcCSZJw8dwxmD2mqSCvpybX0pUy0DP790qvTZxndEwyHtwdmWd08hQj51G6alO5QEuShMF1ftT6PUjIwPaDfWnbKpPLKyejo7SYx7hMgIZ6ElULS9+zjA67qPk9xvV4hlrU6Pcolu3ZyFa6au+LQk4JJkt10TlrxjB87rAWRGIJXHTvO/ivf6zDE2t3cR+UcmfrwT5E4gmEfG6MaAxa3p8Fs6IaHZdL4lnCDoslKKXrKrf9jP4tul+hMjrFJOfSlcn4B4aeqNjMLDBj37700lWuJnx8sGcOhoEHVB1XQDL4ZDodbYs51xJVUqCjmnfV7+Cuq/LvcSPKAu0wRVF9DpCe0RF/ijbO6DB9TnMWwWShkSQJ/73wcHzlrrewq6MfD67cjgdXbgcADG8IYPbYZswZ24TTpw/FkLrCONyWkg0pIfLE1jq4BAJRLU0hH7Yd7LNkphf0ujEQTVgWFbNzkQ1YFBYj59g9Vayuq2LCSrpWB3uKlq4adNyRmebG7JqgbU/vyFOMXJdHRocFOuq/d3xLDT7Y2ZnRYs7KgBVVumITzKNq407n5U+ctyKiIlHPGIrG1YGO+cVJ3XUlepPgGR0d8W8p9Tlqxg+uxfLrT8Ddl8zGNz43DjNHNcLjkrC7cwBPvr8bP3niI5z5uzdytt63k0/YYEmL+hzGUaOb4HZJmDZc3A8mwEXFqeygaIYldW6wG6X4fumXy1x9dJzYfquFZUcO9VrLcrSpWq2zoZfRES1dNfDBnpHU/0bTfm4V7qOTh0aHZXQAGLaYd1RgRodp6nrDMUf76FBGhygJ6pvCQCzO58qIGGepLwzCGZ3U8SI6GZ1SeOgY0Rjy4fTpQ3H69KEAkrXttTs6sHprOx5bswM7DvXjJ098iDsvOqrka8sH3nGVY5vzjWdNxXdOmmjpZqU4HFssQaXOIRZsi+7ncbvgc7v4AEnRC7rH7YLHJSGWsvYuh0BHmXdlLaMj+hChp9GxXLrqj0GW5fxLV3mIkbWlKwCGLeb5rtOJBH2KMJw514tmSEsJZXSIkqCeMaRuyRQpXfk9bn4xEs/oZCld2ZTR0SPk8+C4CS249qSJ+MNFs+F2SXjqgz14dt0eu5dmCVa6stpxxZAkyfITuZLRSQ3LtJjR0b6OCGpTQiv7qddWFhqdWkWMbDSgUg/h0lUqWOnKqXTFxMgR9EbiPIC0o71cv3Sl32LeXsHt5eosdMDnvLDCeSsiKhJJkvgNJhxN8EBH1Aq9KdVibrl0pdNeXioPHascMbIBVy2YAAD4r398yOdxFYv/fWML/vvJ9YjlOXR0IBrH1lQn2aShtYVYmhAsM2J1ZpU2g2PlCVR9/lnR2vjT9nN+Ip01AETjsvBoBFmW+UNES51Je3k2MbJZ6UolRma6F5/HlbP2qdavmBBaCeoA/dLVuNQYiI6+aFoAUMnt5ezvlKTkQ63TcN6KiIpFLUjmAz0FMjqAcuEVTfuzTi49Z2RlurLzLjjXnHQYJrfW4WBvBD/550dFO05POIZbnl6P/31zC/7+7q68Xuuz/T1IyMkONjNtRiHhpSvuh5Nr95T4ZVB9/lnJ6KiPUQ6lq6DPzd9fUS+droEYL+uZfbd46UrXMNAko6MSMqtdkXMdq8CuQfGEnObcLsIBnQxWUNV5uClVvkorsdVUTkYnpMnoBDxuR463oECHKBnqMRDdAi6oaljnVSFKV228dOWsjA6QzET96vyZcLskPP3BHjxTpBLW+zs6eE39Ny9tyMuxmZWtJrXWlfQix86neOoPydUPJ5cSlM8tZnOgd8xyKF0B1lvMWXajzu8xfU+zipFNNTqpwZ790bw9dIBk+YWdtt1hi+JrHY0OkKnTSSuxBZ33gJUrIb8m0HFgxxVAgQ5RQvyqwZ49FktXVjM67FiReAKJRHo6mpWunKDR0eOIkQ349gnJEtaNRSphrdnWzv//ns4B/N/bW3N+LTbM06pRYL7kWoLK2M/CxZndwEUHiGr3A8qjvRxQtZj3CAY6TK9iUrYClPKUfukq+zVBHSQVYn6UJCnTxK0M9uwNx9CbcnfXBjoTNJ1XLCvm97jKIqMnCmsvZ4GOU89tCnSIkqFkdKyJkQHlQiac0VFtF9FoUA4KmprZyTVfmIgpQ1MlrCcKX8J6d3sy0DlyVCMAYOmrm9JuOlbIdZhnvmjPBdHgQ9tOnksJyuoFvdxKV4B1d2RRs0AgvfzEdDFMjGyW0eHOyH3RvD10GLl46bAMVsDryjC61JoGVqJZIKAYBlp1Jy81FOgQJcOvLl1Z1OjMGt0IADh8RIPYsVTeJVqdjp3t5aL4PC6lhLVuD57+oHAlrERCxrupjM7NXzocE4fUorM/intWbMrp9Vhrea4dV7mSMWQzR6diK9OWWYBj9YJejhkdHuj0iQU6PFMq8L1iWZlILIGBaAKyLKNrQMxbS8noRNDRW5iWbcUd2XqgM7jOn1GyVTqvkqWr9gpsLQeUMiwLEEU9qUoNBTpEyWDGacmMDmslFXvCOXvmcKz9ySn4t2PHCG3vcUlgEgp151VfJMaHiTq1dMWYPqIBi1kJ64kP+YU1XzYd6EHXQAxBrxuHD6/H9adNBgD87xtbsb9rwNJrdQ1Esbszuc/EUgc6uY5kyMPAj21rPaNThhqdkMWMDi9dmX+vav0ernHq7I+iPxrnWiuz0hXLikTjMj/38s2UcC8dCxkd7qGjo/VjGZ3tB/sQjSvu3Q0V1FoOADUaJ3PS6BBVj7p0xZ2RBTU6gLU6vCRJuvOuWNnK73EJ64Ps5OpUCetQbwTXPPwePtzVmfdrsrLVjJEN8LpdOHVaK2aNbkR/NI7fvbLR0mttTJWthjUESn4Rz32aeG77qY9p9YKuXqtT0/tamJfOQUGNzgFeujLP6EiSlKa1YZPLPS7JNIgMet28hZkNyM3VFZlRm3rgspLR0fPQYQytDyDodSOWkLHjUF9FmgUCmUG7E80CAQp0iBLC28tjCcsanVxQJpgrGR3WQdJSm5ludiI+jwu3XzATXreEtzcfxFm/fwNfXvom/rZmZ86dUkyIzKZeS5KE/zh9CgBg2b92YKvG6Cwbn+5NpuYnlTibAxSudJVL15XVYCWYOhddUnpZ1ckM4hodsUziQcHJ5Yy0QGdAMQs0+15KksTFzNtSE8LzDSBy0eiwwE4rRAaSQ2eZn87mA73cLLCSWssBZMymc6r+rDy+cURFwG4O4aiq66qYgQ4vlakzOs7uuNLj8OEN+PtVx+NLM4fD65awdkcHrn/sfRy75GX87On1lgITAHh3eweA5HwpxrHjB+GEyYMRS8i4/cUNwq+1wSYhMpBP6ar0gQ7bPuh1ps+IHs1sDESfmEhdmXMl9t2q52MgIordhGBWkJWqdnf2J/+dZzaxNpdAx6C1nMFbzNt6VKWr8rnuiMDayxlUuiKqHnaDSe+6Kt4TTrbSlRPNArNxxMgG/O5rs/DWD0/CD06bjBGNQXT0RXHv61twwq+W40d//0DI1bWjL4LP9iezMEeNaUr73Q2nJbM6T76/W7hE9sneLgD2ZHS0F1XhERAFaC/PVaMTtDCd3W6aU9kH0YxOm4XSFQDd0pVwF2ZqX3bK5+s2zB64WGZJhGylKyB9uKdSuqq0jA6VrggiDXZDUTuoFlMno5gGKiWetl5r6XWnMbjOj8UnHoYVN5yIPy86GidOHgxJAh751w58tLvLdP/3dnQASNrUN2uCvWnD67HwyOEAgF88/6npa8myrHjo2BLo5PY0mVfpypefRifowDlARvCMjqiPjsXSVaNO6UrUQFSrByuUGDnXris9JgxWSleVOLkcyCxdUdcVUfWwiz3rzgCKHOjoTDB30kDPfHC7JJw0tRX3XXYMTp3WCgB49kPzFnTWVq4uW6n5/imT4XVLWLHhAN7a1Jb1tdp6Imjvi0KSgImtpZtxxcj00clRo2PhKfQLU4ZgytA6nDVjuPA+yWMmz8VQGcy5YrBAuDcSN9WDdfZHeTdja30uGh2xyeV831BhA51cBnuaZnRULeaFMDZ0ItqMjlOtEyjQIUoGuxGx+TA1PrclG33Lx9MtXaUuTg720LHKF48YBgB4Zt1e0/IV67iaPUY/0Bk9KISLjhkNALjtuU+zvh7T54wdVGNLJ1GmGFk0o5O+nRWX46nD6vHcdz+Pk1PBpSgsmAo4VKypR33AA0/q+9lu4qXDdGJD6vwZT/lGpJeuxCaXa/dl5O2jYzGjI8syz+gMMcjojEtldNp6IthxKCmarqTJ5QDgdbvShniSRoeoetiXgD0JFVOfA+jPu2JdV+We0VHzhSlD4PO4sKWtF5+kSkl6xOIJrGVC5DGNhttd/YWJCPnceH9HB17+eL/hdqxsNcmGbA6Q/vRoZWpyQLNfKbqgWFAWcugTrx6SJPEZc2Yt5mx6/dhBNcKvr3ZHFp1czvdViXr9HlfegTa7Fon66HSHY/y6YpTRqfV7eHaL6ZeaykwbKIJakOxU6wQKdIiSwZ5q2ZNQMTuuAFWgo0q7O3mgZ67UBbz4/MTBAIBnswwB/XRfN3ojcdT5PZg4xFhTM7jOj0vnjQUA3PHyRsOsDu+4skGfA2i8aSxMTfaqBnL6Pa6SdEFNHloHSQKmDLPnvcqVQYJjIFib95hBIeHXrs9Do6MuVRXCm8aqMzJ7WKv1e7K2VLPyFaPSNDpAevBOGR2i6mE3JnbRLKaHDqBfulLGP1TWk9WZM4YCAJ75cK/hNqyt/MjRjaYlw2/OH4eg1411uzrx6qf6WR2WPZpkQ2s5oDXhsygOTgXBpXoCPWp0E/7145Nx45nTSnK8QiE674pndFrEMzoNvL08v9JVIYIHq+3lRlPLtbAWc0YlTS5nhFQ6S8roEFUPuxmxYeLFdiZWDAOTgU4iIfMLtmgLbLlw0tRWeN0SPtvfw92KtZgJkdUMqvXj0nnJcRt3vJSZ1UkkZH4cuzI66idpywZ+rHuqhO2wg+v8cBVRk1YMhAOdNuulKxasdOVQulKLkQvhyG1VjHygx3j8gxo2xRxIahJ9ZWIWaYVQHt/DUlF57zrhWLRfAtE0da5o28s7+6N8no62tbrcqQ94MT9VvnraoHzFhMha/xwjvvn58Qh63Xh/ZyeWbziQ9rtdHf3ojcThdUuWnuILSdCb+wWWZfucmmp3CsUsXak1OkrpynpGpyClK4ti5AOCc73UGZ1K67hiUKBDECq0N5ViZ3R8XKOTzOiw6coNQW9FPlmx7qtn12WWr9p6wth2sA+SBBw5qlHo9Vpq/bjk2GQHljarw/Q5EwbXwisoAi406kDHqqCYnYtOvTA7BS5GzhLodA1E+e+tBDq8dJXWdSUqRi5w6SoVYEXiiTTfLSPacsjoVKI+B0j30rEyN66UOHNVREWiLROUWqPTViEeOkacMrUVHpeET/d1c/djBitbTRpSZynV/83Pj4ff48LaHR14faPiq/OpjaMfGOrgxuqMHRbgONXgzCmIzLvansrmtNT6LHVSsvMwnpCxNzWF3GxyOUOdHSlEpkQ9hVskq2PmocMY3hjkD1WVG+hQRocgONqbSsm6rlJPaKxFtpI8dNQ0hLw4/rAWAJndV2t42arR0msOqQvg4rkprY6qA2sDby23L9BxuSQlM2NRa8NnVjn0CdQpMHfk9l7j0QhbctDnAOlTyHtTZoOi5Wx1iasQAYTbJaEmdcMW0em0ZRnoqX3dcan3pVJLV+ogkYZ6ElWPtnRVfB+d9IzOwd7yG+hplTOZeaCm++q9bR0AxITIWq5ckMzqrNnWjjc/OwgA+HRfMmNklxCZoQzZzG0kg1OfQJ1CMy9dGWd0tqU6rsZYDHTUU8gZooGOx+3iE8cLZcLHHry6LWR0zAIdQNHpVJpZICOtKYBmXRHVjvamUleqrqtodZSuAOCUaa1wuyR8vKeLP2lHYgm8v7MDgLgQWc2Q+gC+lnJLvuPlDYjGE9iUKo3ZWboCcg9YWGDkVMt6pyDSdbU1Vboaa0Gfw2jQlKqsZHlZ51WhMiVMM2gl0BHp3jx6bDMA+78rxaImzTDQmSGFM1dFVCQZgU7JS1fMQ6cyS1dAUjx63IRBAJTZVx/v6UI4lkBjyIvxOXZIXXXCBPg8Lqza2o5l/9qOSDyBkM+NEY3Bgq09F4I5Bjr+HDNB1QYLdDpUHYtaeEYnh3NLrRer83ssjYSZ3Jo0YSyUM3dtKptkVrpKJGSe4RLJ6Hz9uLF48brP45JUCbjSSBMjO/TBgb7lRMnQ6iGKr9HRlK6YRqeCMzqAevZVMtBZkxIizx7dlLMLcGt9AF+dMwoAsOTZTwAAE1vrbPeFCeRauvJQ6UqEplTWRJaBDoN5V1vakhmdcRZLV0B6Nsbqg8/Si4/Cih+ciPGDCxPo1HHTQGM9EpBsh4/Gk0GfSHbY7ZIc8V0pFmoxspW5caXEmasiKpLMjE5pZ10pGp3KzegAwKnTWuGSgA93dWH7wT6VENl62UrNVSdMgM/t4lOqJ9s040oN0wf4rYqRfdReLoLH7eJiX73yVU84xlutR+dUulKuAaJmgYyA141RzdaPaUSd4BgIZhbYEPRaPu8qEXWg49RSMAU6RMnQ3lRK5oycmnXFNToVZhaoZVCtH8eOV8pX71lwRM7GsIYgLpgzkv978tD6vF6vEORaumLdRIUwm6t0mkPGXjqsbNVc48vJoTitdFXkDK8ZXKNjUroSHf9QLVDpiiBUuF0SvG4lfSvqgpormT46zM208i9QrHz1wMpt2N05ALdLwsxRDXm/7lUnHMY/Q7s7roDcS1eL5o3BT86ahn+bV5m6iUKSTZCciyOymrSMTpEzvGaIDvZkGZ1KL4GLwsTIyeu7M0MKZ66KqFjU7Yel8tGJxJJup6ybolJ9dNScdvhQSBKws70fADB1WF3ak1eujGgM4tavzMDXjxuLeSnRs53wmVUWnyQH1fpx+efGVdwokGKQLdBhnX256HOA/EpXhaZOcLCn0loeKPqayoGgN/m+OdmTyrkrIyoS1u3idklFr+equ67YRdrjkoTdV8uZwXV+HJNqawXyL1upOXf2SNz8pcMtdcgUiy/NHI7pI+px0pQhdi+lYmGCW/2MTm4eOgxHla4sZnTMxj9UCyyj41SzQACo/Cs+4ShYiaHW78m5A0gUFlSFYwnecTWo1lf04zqFLx4xDO9sOQQAmJ2nENmpnDKtFadMa7V7GRVNtowO99BpqYDSlT95fDONjuhAz2phytB6zJ/Y4uhrDGV0iJLCSgyleHpTd121VYGHjpYzpifLV0BhMzpEddEkIEa2Ov6BoR7fYHemVTSjw8c/UEYHQHJ48gP/PhffPXmS3UsxhDI6RElRZ3SKDQ90ovG0jE61MKQ+gDu+OgsDkXhB23CJ6oJ9Z9o1gU5fJIZ9XckHiFwDnfTSVblpdCjQKRco0CFKChMjlyJNnVa66hW3bK8kvjRzuN1LIMoc1oqvzeiwjqvGkJePY7CKo0pXfNZVdsNAK+MfCGdApSuipLDSVbE7rgBt6ao6PHQIotAM4hqd9MGe+QqRgfROK9tLVwIZnXhC5u/DEMrolA0U6BAlhZWuSqHR8anaHfd0DgCofFdkgig0TSoxsiwr866YEHlcjh46QPLBR7km2C1GNh/qeag3goQMSBLImqCMoECHKCmsnFRKjQ4A7O5I+slUk0aHIAoBy+hE43JaR9LWtvwzOgAwY0QjanzunL14CgUrnYVjCURSJqNaWNmqOeSDx6HmeEQmpNEhSgrT6JTi6c2nuhDtShnnkZspQVgj4HUj5HOjLxJHe2+EBwRbWcdVjq3ljAe/MRf9kXjOOp9CwfxgAKA3HIPPk3mtYN2bJEQuLygkJUrK2FSae/zg4j+9SZLEszr7upOlKxIQEoR1WJlGLUhWxj/k9132eVy2BzlAcoApMzE10umQELk8oYwOUVKuOmECTpwyBNOGlWYgpN/jQjiWAJMWkEaHIKzTXOPDzvZ+HEqJ+geica57s7vkVEhqAx70R+OGOh3K6JQnlNEhSorH7cL0EQ1wlWh8gF8zZoK6rgjCOlp3ZJbNqQ940kz/yh0zLx3y0ClPKNAhKhq1ILnW77E8/JEgCFWg05cMdBR9Tk1FjVTh7shhfS8dmlxenlCgQ1Q06kCHOq4IIjcGZWR0CtNx5TTMWsypdFWeUKBDVDR+j5LBobIVQeQGd0fuYRmd/D10nEhrfQAA8PA72xGLZ7aYkxi5PKFAh6ho/F51RocuTgSRC801SR0OcwUulIeO01h84mGo9XvwzpZDuO25TzJ+Txqd8oQCHaKiUZeuqK5OELnBMjqH+pLaFSZGztdDx2kcNqQWvzp/BgDg3te34KkPdvPfReMJtKf+fppcXl5QoENUNOmlK7o4EUQuNKvmXQ1E49jdmTTgrLSMDgCcPn0YrlwwAQBww98+wIZ93QCUsp3bJaEpRA9N5QQFOkRFQ2JkgsgfLkbuiWBnex9kOdmKXam6t+tPnYTjJgxCXySOKx9Yg66BKBciD6rxlcwegygMFOgQFY3aR4c0OgSRG2ywZ28kjk/2JjMcY1pCFdVarsbjduH3X5uF4Q0BbG7rxfV/fR/7upIGiaTPKT8o0CEqGtLoEET+1Ac88LqTQc172zsAVGbZSs2gWj/uumQ2fG4XXli/D79+cQMA6rgqRyjQISqa9ECHLlAEkQuSpOhS3t3eDkCZW1fJzBzViJ8uPBwA8NHuLgCU0SlHKNAhKhry0SGIwsAEyR/tSt7wx1Z4RofxtWNG48KjR/F/U6BTflCgQ1Q0zEfHJQGN1ClBEDnDAp1IykhvbEt1BDoA8NOFh2PGyAYAwPgq+rsrBZpeTlQ0Pncy0Gmu8cFNnRIEkTPNmozomCooXTECXjce+sZcvL3pIE6cMsTu5RAWoUCHqGhYRoc8dAgiP9Sl3xqfu+pM8+oCXpx6+FC7l0HkAJWuiIqGaXTIQ4cg8qNZ9bAwZlBlTS0nKhsKdIiKhnWGTB5aZ/NKCKK8YfOugMob/UBUNlS6IiqaL0wZgue+Ox/jSEBIEHmhzegQRLlAgQ5R0UiShClD6+1eBkGUPWoxcjV46BCVA5WuCIIgCFPUOrdq8dAhKgMKdAiCIAhT0jI6VAomyggqXREEQRCmDKrx4cTJg+F2SRhC7sBEGUGBDkEQBGGKJEm477Jj7F4GQViGSlcEQRAEQVQsFOgQBEEQBFGxUKBDEARBEETFQoEOQRAEQRAVCwU6BEEQBEFULBToEARBEARRsVCgQxAEQRBExUKBDkEQBEEQFQsFOgRBEARBVCwU6BAEQRAEUbFQoEMQBEEQRMVCgQ5BEARBEBULBToEQRAEQVQsFOgQBEEQBFGxeOxegJ3IsgwA6OrqsnklBEEQBEGIwu7b7D6ejaoOdLq7uwEAo0aNsnklBEEQBEFYpbu7Gw0NDVm3kWSRcKhCSSQS2L17N+rq6iBJUkFfu6urC6NGjcKOHTtQX19f0NcuZ+h9MYbeG33ofTGG3ht96H0xplLeG1mW0d3djeHDh8Plyq7CqeqMjsvlwsiRI4t6jPr6+rI+mYoFvS/G0HujD70vxtB7ow+9L8ZUwntjlslhkBiZIAiCIIiKhQIdgiAIgiAqFgp0ioTf78dNN90Ev99v91IcBb0vxtB7ow+9L8bQe6MPvS/GVON7U9ViZIIgCIIgKhvK6BAEQRAEUbFQoEMQBEEQRMVCgQ5BEARBEBULBToEQRAEQVQsFOgUgaVLl2Ls2LEIBAKYO3cu/vWvf9m9pJKzYsUKnH322Rg+fDgkScI//vGPtN/Lsoyf/OQnGDZsGILBIE4++WRs3LjRnsWWkCVLlmDOnDmoq6vDkCFD8OUvfxmffvpp2jYDAwNYvHgxBg0ahNraWpx77rnYt2+fTSsuHXfddRdmzJjBjczmzZuHZ599lv++Wt8XLbfeeiskScJ3v/td/rNqfW9uvvlmSJKU9t+UKVP476v1fQGAXbt24ZJLLsGgQYMQDAZxxBFHYPXq1fz31XQNpkCnwDz66KP43ve+h5tuugnvvvsuZs6cidNOOw379++3e2klpbe3FzNnzsTSpUt1f/+LX/wCv/vd73D33XfjnXfeQU1NDU477TQMDAyUeKWl5bXXXsPixYuxcuVKvPjii4hGozj11FPR29vLt7nuuuvw5JNP4rHHHsNrr72G3bt34ytf+YqNqy4NI0eOxK233oo1a9Zg9erV+MIXvoCFCxfio48+AlC974uaVatW4Y9//CNmzJiR9vNqfm8OP/xw7Nmzh//3xhtv8N9V6/vS3t6O448/Hl6vF88++yzWr1+P22+/HU1NTXybqroGy0RBOeaYY+TFixfzf8fjcXn48OHykiVLbFyVvQCQH3/8cf7vRCIhDx06VP7lL3/Jf9bR0SH7/X75kUcesWGF9rF//34ZgPzaa6/Jspx8H7xer/zYY4/xbT7++GMZgPz222/btUzbaGpqkv/0pz/R+yLLcnd3tzxx4kT5xRdflBcsWCB/5zvfkWW5us+Zm266SZ45c6bu76r5ffmP//gP+XOf+5zh76vtGkwZnQISiUSwZs0anHzyyfxnLpcLJ598Mt5++20bV+YstmzZgr1796a9Tw0NDZg7d27VvU+dnZ0AgObmZgDAmjVrEI1G096bKVOmYPTo0VX13sTjcSxbtgy9vb2YN28evS8AFi9ejDPPPDPtPQDonNm4cSOGDx+O8ePH4+KLL8b27dsBVPf78s9//hNHH300zj//fAwZMgSzZs3Cvffey39fbddgCnQKSFtbG+LxOFpbW9N+3trair1799q0KufB3otqf58SiQS++93v4vjjj8f06dMBJN8bn8+HxsbGtG2r5b1Zt24damtr4ff7ceWVV+Lxxx/HtGnTqv59WbZsGd59910sWbIk43fV/N7MnTsX999/P5577jncdddd2LJlC+bPn4/u7u6qfl82b96Mu+66CxMnTsTzzz+Pq666Ctdeey3+8pe/AKi+a3BVTy8nCDtZvHgxPvzwwzRNQbUzefJkrF27Fp2dnfjb3/6GRYsW4bXXXrN7WbayY8cOfOc738GLL76IQCBg93IcxRlnnMH//4wZMzB37lyMGTMGf/3rXxEMBm1cmb0kEgkcffTR+PnPfw4AmDVrFj788EPcfffdWLRokc2rKz2U0SkgLS0tcLvdGar+ffv2YejQoTatynmw96Ka36err74aTz31FF599VWMHDmS/3zo0KGIRCLo6OhI275a3hufz4fDDjsMs2fPxpIlSzBz5kzccccdVf2+rFmzBvv378dRRx0Fj8cDj8eD1157Db/73e/g8XjQ2tpate+NlsbGRkyaNAmfffZZVZ8zw4YNw7Rp09J+NnXqVF7Wq7ZrMAU6BcTn82H27Nl4+eWX+c8SiQRefvllzJs3z8aVOYtx48Zh6NChae9TV1cX3nnnnYp/n2RZxtVXX43HH38cr7zyCsaNG5f2+9mzZ8Pr9aa9N59++im2b99e8e+NHolEAuFwuKrfl5NOOgnr1q3D2rVr+X9HH300Lr74Yv7/q/W90dLT04NNmzZh2LBhVX3OHH/88Rm2FRs2bMCYMWMAVOE12G41dKWxbNky2e/3y/fff7+8fv16+Vvf+pbc2Ngo79271+6llZTu7m75vffek9977z0ZgPzrX/9afu+99+Rt27bJsizLt956q9zY2Cg/8cQT8gcffCAvXLhQHjdunNzf32/zyovLVVddJTc0NMjLly+X9+zZw//r6+vj21x55ZXy6NGj5VdeeUVevXq1PG/ePHnevHk2rro0/PCHP5Rfe+01ecuWLfIHH3wg//CHP5QlSZJfeOEFWZar933RQ911JcvV+958//vfl5cvXy5v2bJFfvPNN+WTTz5Zbmlpkffv3y/LcvW+L//6179kj8cj/+xnP5M3btwoP/TQQ3IoFJIffPBBvk01XYMp0CkCv//97+XRo0fLPp9PPuaYY+SVK1favaSS8+qrr8oAMv5btGiRLMvJ9sYbb7xRbm1tlf1+v3zSSSfJn376qb2LLgF67wkA+b777uPb9Pf3y9/+9rflpqYmORQKyeecc468Z88e+xZdIi6//HJ5zJgxss/nkwcPHiyfdNJJPMiR5ep9X/TQBjrV+t5ceOGF8rBhw2SfzyePGDFCvvDCC+XPPvuM/75a3xdZluUnn3xSnj59uuz3++UpU6bI99xzT9rvq+kaLMmyLNuTSyIIgiAIgigupNEhCIIgCKJioUCHIAiCIIiKhQIdgiAIgiAqFgp0CIIgCIKoWCjQIQiCIAiiYqFAhyAIgiCIioUCHYIgCIIgKhYKdAiCKCmyLONb3/oWmpubIUkS1q5da/eSCIKoYMgwkCCIkvLss89i4cKFWL58OcaPH4+WlhZ4PJ68XvPrX/86Ojo68I9//KMwiyQIomLI7+pCEARhETZ08bjjjrN7KRnE43FIkgSXi5LdBFEp0LeZIIiS8fWvfx3XXHMNtm/fDkmSMHbsWCQSCSxZsgTjxo1DMBjEzJkz8be//Y3vE4/H8e///u/895MnT8Ydd9zBf3/zzTfjL3/5C5544glIkgRJkrB8+XIsX74ckiSho6ODb7t27VpIkoStW7cCAO6//340Njbin//8J6ZNmwa/34/t27cjHA7j+uuvx4gRI1BTU4O5c+di+fLl/HW2bduGs88+G01NTaipqcHhhx+OZ555pthvH0EQOUAZHYIgSsYdd9yBCRMm4J577sGqVavgdruxZMkSPPjgg7j77rsxceJErFixApdccgkGDx6MBQsWIJFIYOTIkXjssccwaNAgvPXWW/jWt76FYcOG4YILLsD111+Pjz/+GF1dXbjvvvsAAM3NzXjrrbeE1tTX14fbbrsNf/rTnzBo0CAMGTIEV199NdavX49ly5Zh+PDhePzxx3H66adj3bp1mDhxIhYvXoxIJIIVK1agpqYG69evR21tbTHfOoIgcoQCHYIgSkZDQwPq6urgdrsxdOhQhMNh/PznP8dLL72EefPmAQDGjx+PN954A3/84x+xYMECeL1e/PSnP+WvMW7cOLz99tv461//igsuuAC1tbUIBoMIh8MYOnSo5TVFo1H84Q9/wMyZMwEA27dvx3333Yft27dj+PDhAIDrr78ezz33HO677z78/Oc/x/bt23HuuefiiCOO4GsmCMKZUKBDEIRtfPbZZ+jr68Mpp5yS9vNIJIJZs2bxfy9duhT/+7//i+3bt6O/vx+RSARHHnlkQdbg8/kwY8YM/u9169YhHo9j0qRJaduFw2EMGjQIAHDttdfiqquuwgsvvICTTz4Z5557btprEAThHCjQIQjCNnp6egAATz/9NEaMGJH2O7/fDwBYtmwZrr/+etx+++2YN28e6urq8Mtf/hLvvPNO1tdmgmJ1Y2k0Gs3YLhgMQpKktDW53W6sWbMGbrc7bVtWnvrGN76B0047DU8//TReeOEFLFmyBLfffjuuueYa0T+dIIgSQYEOQRC2oRYAL1iwQHebN998E8cddxy+/e1v859t2rQpbRufz4d4PJ72s8GDBwMA9uzZg6amJgAQ8uyZNWsW4vE49u/fj/nz5xtuN2rUKFx55ZW48sor8aMf/Qj33nsvBToE4UAo0CEIwjbq6upw/fXX47rrrkMikcDnPvc5dHZ24s0330R9fT0WLVqEiRMn4v/+7//w/PPPY9y4cXjggQewatUqjBs3jr/O2LFj8fzzz+PTTz/FoEGD0NDQgMMOOwyjRo3CzTffjJ/97GfYsGEDbr/9dtM1TZo0CRdffDEuvfRS3H777Zg1axYOHDiAl19+GTNmzMCZZ56J7373uzjjjDMwadIktLe349VXX8XUqVOL+VYRBJEj1F5OEISt/M///A9uvPFGLFmyBFOnTsXpp5+Op59+mgcyV1xxBb7yla/gwgsvxNy5c3Hw4MG07A4AfPOb38TkyZNx9NFHY/DgwXjzzTfh9XrxyCOP4JNPPsGMGTNw22234ZZbbhFa03333YdLL70U3//+9zF58mR8+ctfxqpVqzB69GgAyZb3xYsX8/VOmjQJf/jDHwr7xhAEURDIGZkgCIIgiIqFMjoEQRAEQVQsFOgQBEEQBFGxUKBDEARBEETFQoEOQRAEQRAVCwU6BEEQBEFULBToEARBEARRsVCgQxAEQRBExUKBDkEQBEEQFQsFOgRBEARBVCwU6BAEQRAEUbFQoEMQBEEQRMVCgQ5BEARBEBXL/wewD1c0Y7U3FAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"50% best MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_mape = mape(y_true, y_pred)\n",
    "plt.plot(cur_mape[cur_mape < np.percentile(cur_mape, 55)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"55% best MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mape[cur_mape <= np.percentile(cur_mape,100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 67), dtype=float32, numpy=\n",
       "array([[ 8.25200696e-04, -2.52360152e-03,  1.24429585e-03,\n",
       "         5.61252143e-03,  2.41480279e-03,  6.91283401e-03,\n",
       "        -1.55929942e-04,  5.05245430e-03, -3.45375156e-03,\n",
       "         2.31756223e-03, -5.02947718e-03,  5.21133933e-03,\n",
       "         2.63487943e-03, -1.15680450e-03, -8.61713605e-04,\n",
       "        -4.27721906e-03,  1.65054473e-04,  1.98029215e-03,\n",
       "         1.16372411e-03, -6.18001819e-03,  1.38662616e-03,\n",
       "        -3.87507980e-03, -5.78831602e-03, -4.70064487e-03,\n",
       "        -4.91938740e-03, -9.45061352e-03, -6.37044199e-03,\n",
       "        -1.24200690e-03, -2.50279880e-03,  6.26629405e-03,\n",
       "         7.07075465e-03,  4.37504100e-03,  8.11321661e-06,\n",
       "         6.27311785e-03, -2.45433138e-03,  6.55709300e-04,\n",
       "         1.01655931e-03,  3.92863574e-03, -7.48858880e-03,\n",
       "        -3.09383660e-03, -3.60715576e-03,  3.58439516e-04,\n",
       "         5.01208124e-04,  4.94992966e-03,  4.09077760e-03,\n",
       "        -1.00721011e-03, -6.26226794e-03, -6.27841754e-03,\n",
       "         5.10353828e-03,  4.80458234e-03, -2.42970185e-03,\n",
       "         3.23574082e-03,  4.15166654e-03,  1.97961787e-03,\n",
       "         2.42814887e-03, -2.23055086e-03, -2.55294633e-03,\n",
       "        -3.07056517e-03, -7.46782962e-03,  4.13405150e-03,\n",
       "         4.82963771e-03,  6.89104025e-04, -1.09297456e-04,\n",
       "         3.91600234e-03, -8.97214864e-04, -1.08612701e-03,\n",
       "         4.65779193e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.zeros(67 * 10).reshape(1, 10, 67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=2, 2, 22, (30608, 67)\n",
      "Before prediction: train_X.shape=(18358, 10, 67), train_y.shape=(18358, 67), test_X.shape=(6119, 10, 67), test_y.shape=(6119, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3112 - val_loss: 0.3270\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2915 - val_loss: 0.3111\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2761 - val_loss: 0.2987\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2646 - val_loss: 0.2898\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2564 - val_loss: 0.2830\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2504 - val_loss: 0.2777\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2456 - val_loss: 0.2732\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2415 - val_loss: 0.2694\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2378 - val_loss: 0.2660\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2345 - val_loss: 0.2630\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2314 - val_loss: 0.2603\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2286 - val_loss: 0.2579\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2262 - val_loss: 0.2559\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2241 - val_loss: 0.2541\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2222 - val_loss: 0.2526\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2206 - val_loss: 0.2513\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2191 - val_loss: 0.2500\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2179 - val_loss: 0.2489\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2167 - val_loss: 0.2478\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2156 - val_loss: 0.2470\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2147 - val_loss: 0.2461\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2138 - val_loss: 0.2453\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2129 - val_loss: 0.2444\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2122 - val_loss: 0.2439\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2115 - val_loss: 0.2432\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2109 - val_loss: 0.2427\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2103 - val_loss: 0.2421\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2097 - val_loss: 0.2416\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2092 - val_loss: 0.2410\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2087 - val_loss: 0.2407\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2082 - val_loss: 0.2401\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2397\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2073 - val_loss: 0.2394\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2069 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2065 - val_loss: 0.2386\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2062 - val_loss: 0.2382\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2058 - val_loss: 0.2380\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2055 - val_loss: 0.2376\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2052 - val_loss: 0.2373\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2049 - val_loss: 0.2370\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6119, 67), test_y.shape=(6119, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1578.0531622950014, my average MASE = 2807.2183134542065\n",
      "Cluster 0, 1578.0531622950014\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4317 - val_loss: 1.2280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4299 - val_loss: 1.2276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4282 - val_loss: 1.2273\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4264 - val_loss: 1.2269\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4247 - val_loss: 1.2266\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 1.2263\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 1.2259\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4198 - val_loss: 1.2256\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4182 - val_loss: 1.2253\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4166 - val_loss: 1.2251\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4151 - val_loss: 1.2248\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4135 - val_loss: 1.2245\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4120 - val_loss: 1.2242\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4105 - val_loss: 1.2239\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4089 - val_loss: 1.2236\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4074 - val_loss: 1.2233\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4060 - val_loss: 1.2229\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4045 - val_loss: 1.2226\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 1.2223\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4017 - val_loss: 1.2220\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4004 - val_loss: 1.2216\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3990 - val_loss: 1.2213\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3977 - val_loss: 1.2210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3964 - val_loss: 1.2207\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3951 - val_loss: 1.2204\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3938 - val_loss: 1.2201\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3926 - val_loss: 1.2198\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3914 - val_loss: 1.2195\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3901 - val_loss: 1.2192\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3889 - val_loss: 1.2189\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3877 - val_loss: 1.2186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3866 - val_loss: 1.2184\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 1.2181\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3842 - val_loss: 1.2178\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3831 - val_loss: 1.2175\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 1.2173\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3809 - val_loss: 1.2170\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3798 - val_loss: 1.2167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3787 - val_loss: 1.2165\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3776 - val_loss: 1.2162\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 708619678.5307182, my average MASE = 1911068024.4320867\n",
      "Cluster 1, 708619678.5307182\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=5, 5, 1026, (269, 67)\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5683 - val_loss: 0.4789\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5669 - val_loss: 0.4779\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5656 - val_loss: 0.4770\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5643 - val_loss: 0.4760\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5631 - val_loss: 0.4751\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5619 - val_loss: 0.4743\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5607 - val_loss: 0.4734\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5595 - val_loss: 0.4726\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5584 - val_loss: 0.4718\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5573 - val_loss: 0.4710\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5562 - val_loss: 0.4702\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5552 - val_loss: 0.4694\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5542 - val_loss: 0.4687\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5532 - val_loss: 0.4679\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5522 - val_loss: 0.4672\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5512 - val_loss: 0.4665\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5502 - val_loss: 0.4658\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5493 - val_loss: 0.4651\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5483 - val_loss: 0.4644\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5474 - val_loss: 0.4637\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5465 - val_loss: 0.4630\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5456 - val_loss: 0.4624\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5447 - val_loss: 0.4617\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5438 - val_loss: 0.4611\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5429 - val_loss: 0.4605\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5421 - val_loss: 0.4598\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5412 - val_loss: 0.4592\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5404 - val_loss: 0.4586\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5396 - val_loss: 0.4579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5388 - val_loss: 0.4573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5379 - val_loss: 0.4567\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5371 - val_loss: 0.4561\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5363 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5355 - val_loss: 0.4549\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5348 - val_loss: 0.4543\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5340 - val_loss: 0.4538\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5332 - val_loss: 0.4532\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5324 - val_loss: 0.4526\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5317 - val_loss: 0.4521\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5309 - val_loss: 0.4515\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.40868807431647, my average MASE = 112470179.11258063\n",
      "Cluster 0, 139.40868807431647\n",
      "Before prediction: train_X.shape=(31, 10, 67), train_y.shape=(31, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3364 - val_loss: 0.3469\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3360 - val_loss: 0.3468\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3355 - val_loss: 0.3468\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3350 - val_loss: 0.3467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3346 - val_loss: 0.3466\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3341 - val_loss: 0.3465\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3337 - val_loss: 0.3464\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3332 - val_loss: 0.3463\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3328 - val_loss: 0.3463\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3323 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3319 - val_loss: 0.3461\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3315 - val_loss: 0.3460\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3310 - val_loss: 0.3459\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3306 - val_loss: 0.3458\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3302 - val_loss: 0.3457\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3298 - val_loss: 0.3457\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3294 - val_loss: 0.3456\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3290 - val_loss: 0.3455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3286 - val_loss: 0.3454\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3282 - val_loss: 0.3453\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3278 - val_loss: 0.3453\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3274 - val_loss: 0.3452\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3270 - val_loss: 0.3451\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3267 - val_loss: 0.3450\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3263 - val_loss: 0.3450\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3259 - val_loss: 0.3449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3255 - val_loss: 0.3448\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3252 - val_loss: 0.3448\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3248 - val_loss: 0.3447\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3245 - val_loss: 0.3446\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3242 - val_loss: 0.3445\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3238 - val_loss: 0.3445\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3235 - val_loss: 0.3444\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3231 - val_loss: 0.3443\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3228 - val_loss: 0.3443\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3225 - val_loss: 0.3442\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3222 - val_loss: 0.3441\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3440\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3216 - val_loss: 0.3440\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3213 - val_loss: 0.3439\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3523641.3982873675, my average MASE = 66808534.66599488\n",
      "Cluster 1, 3523641.3982873675\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1130 - val_loss: 0.1021\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1076 - val_loss: 0.1000\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1032 - val_loss: 0.0984\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0995 - val_loss: 0.0974\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0964 - val_loss: 0.0968\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0912 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0889 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0869 - val_loss: 0.0951\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0834 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0804 - val_loss: 0.0940\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0791 - val_loss: 0.0938\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0936\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0934\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0757 - val_loss: 0.0933\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0748 - val_loss: 0.0931\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0739 - val_loss: 0.0930\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0730 - val_loss: 0.0929\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0722 - val_loss: 0.0927\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0926\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0707 - val_loss: 0.0925\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0701 - val_loss: 0.0924\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0694 - val_loss: 0.0923\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0922\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0922\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0677 - val_loss: 0.0922\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0672 - val_loss: 0.0921\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0921\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0663 - val_loss: 0.0920\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0919\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0656 - val_loss: 0.0919\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0918\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0918\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0646 - val_loss: 0.0917\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0638 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0635 - val_loss: 0.0915\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 869790828.2820631, my average MASE = 17262168691.962505\n",
      "Cluster 2, 869790828.2820631\n",
      "Before prediction: train_X.shape=(2219, 10, 67), train_y.shape=(2219, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5462 - val_loss: 0.4045\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5391 - val_loss: 0.4010\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5333 - val_loss: 0.3979\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5281 - val_loss: 0.3951\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5234 - val_loss: 0.3925\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5190 - val_loss: 0.3900\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5147 - val_loss: 0.3877\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5107 - val_loss: 0.3856\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5068 - val_loss: 0.3835\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5031 - val_loss: 0.3816\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4996 - val_loss: 0.3797\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4961 - val_loss: 0.3780\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4928 - val_loss: 0.3763\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4896 - val_loss: 0.3747\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4865 - val_loss: 0.3732\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4835 - val_loss: 0.3717\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4806 - val_loss: 0.3704\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4778 - val_loss: 0.3691\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4750 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4723 - val_loss: 0.3666\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4697 - val_loss: 0.3655\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4672 - val_loss: 0.3644\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4647 - val_loss: 0.3633\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4623 - val_loss: 0.3624\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4600 - val_loss: 0.3614\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4577 - val_loss: 0.3605\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4556 - val_loss: 0.3596\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4535 - val_loss: 0.3588\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4515 - val_loss: 0.3580\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4495 - val_loss: 0.3572\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4476 - val_loss: 0.3564\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4458 - val_loss: 0.3557\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4440 - val_loss: 0.3551\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4423 - val_loss: 0.3544\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4406 - val_loss: 0.3538\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4390 - val_loss: 0.3532\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4374 - val_loss: 0.3525\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4359 - val_loss: 0.3519\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4343 - val_loss: 0.3514\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4329 - val_loss: 0.3508\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 408.78828000932964, my average MASE = 1218.6998180420371\n",
      "Cluster 3, 408.78828000932964\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5668 - val_loss: 0.4468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5648 - val_loss: 0.4459\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5628 - val_loss: 0.4451\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5609 - val_loss: 0.4443\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5589 - val_loss: 0.4435\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5570 - val_loss: 0.4427\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5551 - val_loss: 0.4419\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5533 - val_loss: 0.4412\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5514 - val_loss: 0.4404\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5496 - val_loss: 0.4397\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5478 - val_loss: 0.4389\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5460 - val_loss: 0.4382\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5442 - val_loss: 0.4374\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5425 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5408 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5391 - val_loss: 0.4352\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5374 - val_loss: 0.4344\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5358 - val_loss: 0.4337\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5342 - val_loss: 0.4329\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.4322\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5310 - val_loss: 0.4315\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5295 - val_loss: 0.4308\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5280 - val_loss: 0.4300\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5264 - val_loss: 0.4293\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5250 - val_loss: 0.4286\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5235 - val_loss: 0.4279\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5221 - val_loss: 0.4273\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5207 - val_loss: 0.4266\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5193 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5179 - val_loss: 0.4254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5165 - val_loss: 0.4248\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5151 - val_loss: 0.4241\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5138 - val_loss: 0.4235\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5125 - val_loss: 0.4229\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5112 - val_loss: 0.4223\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5099 - val_loss: 0.4217\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5086 - val_loss: 0.4212\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5073 - val_loss: 0.4206\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5061 - val_loss: 0.4200\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5048 - val_loss: 0.4194\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2631402082.882854, my average MASE = 5288471031.0194235\n",
      "Cluster 4, 2631402082.882854\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=7, 7, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1149 - val_loss: 0.1029\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1092 - val_loss: 0.1008\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1047 - val_loss: 0.0992\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1009 - val_loss: 0.0980\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0972\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0947 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0922 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0899 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0878 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0859 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0842 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0826 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0812 - val_loss: 0.0939\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0799 - val_loss: 0.0936\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0934\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0775 - val_loss: 0.0931\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0929\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0755 - val_loss: 0.0928\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0746 - val_loss: 0.0926\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0737 - val_loss: 0.0924\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0923\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0922\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0921\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0708 - val_loss: 0.0920\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0919\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0696 - val_loss: 0.0918\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0690 - val_loss: 0.0917\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0685 - val_loss: 0.0916\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0680 - val_loss: 0.0916\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0675 - val_loss: 0.0915\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0670 - val_loss: 0.0915\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0666 - val_loss: 0.0915\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0662 - val_loss: 0.0914\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0658 - val_loss: 0.0914\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0654 - val_loss: 0.0913\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0651 - val_loss: 0.0913\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0648 - val_loss: 0.0912\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0645 - val_loss: 0.0912\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0642 - val_loss: 0.0911\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0911\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 1397145651.915293, my average MASE = 8779028319.064796\n",
      "Cluster 0, 1397145651.915293\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4446 - val_loss: 0.4248\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.4440 - val_loss: 0.4245\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4434 - val_loss: 0.4242\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4429 - val_loss: 0.4239\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4423 - val_loss: 0.4236\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4418 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4413 - val_loss: 0.4231\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4408 - val_loss: 0.4228\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4403 - val_loss: 0.4226\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4398 - val_loss: 0.4223\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4393 - val_loss: 0.4221\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4388 - val_loss: 0.4219\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4383 - val_loss: 0.4216\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4378 - val_loss: 0.4214\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4212\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4369 - val_loss: 0.4209\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4364 - val_loss: 0.4207\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4360 - val_loss: 0.4205\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4355 - val_loss: 0.4202\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4351 - val_loss: 0.4200\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4346 - val_loss: 0.4198\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4342 - val_loss: 0.4195\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.4193\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4333 - val_loss: 0.4191\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4329 - val_loss: 0.4189\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4325 - val_loss: 0.4187\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4321 - val_loss: 0.4184\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4317 - val_loss: 0.4182\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4313 - val_loss: 0.4180\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4309 - val_loss: 0.4178\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4305 - val_loss: 0.4176\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4301 - val_loss: 0.4175\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4297 - val_loss: 0.4173\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4293 - val_loss: 0.4171\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4289 - val_loss: 0.4169\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4286 - val_loss: 0.4167\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4282 - val_loss: 0.4165\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4278 - val_loss: 0.4163\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4274 - val_loss: 0.4161\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4271 - val_loss: 0.4159\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 86.00366340249806, my average MASE = 69691247.07168306\n",
      "Cluster 1, 86.00366340249806\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9826 - val_loss: 1.3468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9801 - val_loss: 1.3460\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9776 - val_loss: 1.3453\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9751 - val_loss: 1.3446\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9726 - val_loss: 1.3439\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9701 - val_loss: 1.3432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9677 - val_loss: 1.3425\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9653 - val_loss: 1.3419\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9628 - val_loss: 1.3413\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9604 - val_loss: 1.3408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9580 - val_loss: 1.3402\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9556 - val_loss: 1.3396\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9532 - val_loss: 1.3390\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9508 - val_loss: 1.3384\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9486 - val_loss: 1.3379\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9463 - val_loss: 1.3374\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9440 - val_loss: 1.3368\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9418 - val_loss: 1.3363\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9397 - val_loss: 1.3358\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9375 - val_loss: 1.3352\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9353 - val_loss: 1.3347\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9331 - val_loss: 1.3341\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9309 - val_loss: 1.3337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9287 - val_loss: 1.3332\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9266 - val_loss: 1.3328\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9245 - val_loss: 1.3324\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9224 - val_loss: 1.3321\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9203 - val_loss: 1.3317\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9183 - val_loss: 1.3314\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9162 - val_loss: 1.3311\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9141 - val_loss: 1.3308\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9120 - val_loss: 1.3305\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9100 - val_loss: 1.3303\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9079 - val_loss: 1.3300\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9059 - val_loss: 1.3298\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9039 - val_loss: 1.3295\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9019 - val_loss: 1.3293\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9000 - val_loss: 1.3291\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8981 - val_loss: 1.3288\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8963 - val_loss: 1.3286\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1.6636413128548868, my average MASE = 8.526439257891766\n",
      "Cluster 2, 1.6636413128548868\n",
      "Before prediction: train_X.shape=(177, 10, 67), train_y.shape=(177, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7327 - val_loss: 0.5966\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7311 - val_loss: 0.5956\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7296 - val_loss: 0.5946\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7281 - val_loss: 0.5936\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7266 - val_loss: 0.5927\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7252 - val_loss: 0.5918\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7239 - val_loss: 0.5909\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7225 - val_loss: 0.5901\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7212 - val_loss: 0.5892\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7199 - val_loss: 0.5884\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7186 - val_loss: 0.5875\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7174 - val_loss: 0.5867\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7162 - val_loss: 0.5859\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7150 - val_loss: 0.5852\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7138 - val_loss: 0.5844\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7127 - val_loss: 0.5837\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7116 - val_loss: 0.5829\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7104 - val_loss: 0.5822\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7093 - val_loss: 0.5815\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7082 - val_loss: 0.5808\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7071 - val_loss: 0.5801\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7061 - val_loss: 0.5794\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7050 - val_loss: 0.5788\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7040 - val_loss: 0.5781\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7030 - val_loss: 0.5775\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7020 - val_loss: 0.5768\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7010 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7000 - val_loss: 0.5756\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6990 - val_loss: 0.5750\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6981 - val_loss: 0.5744\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6971 - val_loss: 0.5738\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6962 - val_loss: 0.5732\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6953 - val_loss: 0.5726\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6944 - val_loss: 0.5721\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6935 - val_loss: 0.5715\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6925 - val_loss: 0.5710\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6917 - val_loss: 0.5704\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6908 - val_loss: 0.5699\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6899 - val_loss: 0.5694\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6890 - val_loss: 0.5688\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 148.95203283848892, my average MASE = 195949093.5023566\n",
      "Cluster 3, 148.95203283848892\n",
      "Before prediction: train_X.shape=(59, 10, 67), train_y.shape=(59, 67), test_X.shape=(20, 10, 67), test_y.shape=(20, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4242 - val_loss: 0.4717\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4237 - val_loss: 0.4716\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4715\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4228 - val_loss: 0.4714\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4223 - val_loss: 0.4713\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4219 - val_loss: 0.4712\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4214 - val_loss: 0.4711\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4210 - val_loss: 0.4710\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.4709\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4201 - val_loss: 0.4708\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4197 - val_loss: 0.4707\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4193 - val_loss: 0.4706\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4189 - val_loss: 0.4705\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.4705\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4180 - val_loss: 0.4704\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4176 - val_loss: 0.4703\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4702\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4168 - val_loss: 0.4701\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4164 - val_loss: 0.4700\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4160 - val_loss: 0.4699\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4157 - val_loss: 0.4698\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4153 - val_loss: 0.4698\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4149 - val_loss: 0.4697\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4145 - val_loss: 0.4696\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4141 - val_loss: 0.4695\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4138 - val_loss: 0.4694\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4134 - val_loss: 0.4694\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4130 - val_loss: 0.4693\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4127 - val_loss: 0.4692\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4123 - val_loss: 0.4691\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4119 - val_loss: 0.4690\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4116 - val_loss: 0.4690\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4112 - val_loss: 0.4689\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.4688\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4105 - val_loss: 0.4687\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4101 - val_loss: 0.4687\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4098 - val_loss: 0.4686\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4094 - val_loss: 0.4685\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4091 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4087 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(20, 67), test_y.shape=(20, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 138.4214035546147, my average MASE = 76438634.40084383\n",
      "Cluster 4, 138.4214035546147\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4144 - val_loss: 0.4072\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4116 - val_loss: 0.4056\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4089 - val_loss: 0.4039\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4061 - val_loss: 0.4022\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4034 - val_loss: 0.4005\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4008 - val_loss: 0.3988\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3982 - val_loss: 0.3971\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3957 - val_loss: 0.3954\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3932 - val_loss: 0.3937\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3908 - val_loss: 0.3920\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3885 - val_loss: 0.3903\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3861 - val_loss: 0.3887\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3838 - val_loss: 0.3870\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3816 - val_loss: 0.3854\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3795 - val_loss: 0.3838\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3775 - val_loss: 0.3822\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3755 - val_loss: 0.3807\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3735 - val_loss: 0.3793\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3716 - val_loss: 0.3779\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3697 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3679 - val_loss: 0.3751\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3661 - val_loss: 0.3737\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3644 - val_loss: 0.3723\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3710\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3611 - val_loss: 0.3697\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3594 - val_loss: 0.3684\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3578 - val_loss: 0.3672\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3562 - val_loss: 0.3659\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3547 - val_loss: 0.3646\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3533 - val_loss: 0.3634\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.3621\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3506 - val_loss: 0.3608\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3493 - val_loss: 0.3596\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3481 - val_loss: 0.3583\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3468 - val_loss: 0.3571\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3456 - val_loss: 0.3558\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3443 - val_loss: 0.3546\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3431 - val_loss: 0.3534\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3419 - val_loss: 0.3521\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3407 - val_loss: 0.3509\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 697989181.1057402, my average MASE = 1714132782.1928625\n",
      "Cluster 5, 697989181.1057402\n",
      "Before prediction: train_X.shape=(95, 10, 67), train_y.shape=(95, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3944 - val_loss: 0.3555\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3937 - val_loss: 0.3552\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3930 - val_loss: 0.3549\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3924 - val_loss: 0.3546\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3917 - val_loss: 0.3543\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3910 - val_loss: 0.3540\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3904 - val_loss: 0.3537\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3898 - val_loss: 0.3534\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3892 - val_loss: 0.3532\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3886 - val_loss: 0.3529\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3880 - val_loss: 0.3526\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3874 - val_loss: 0.3523\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3868 - val_loss: 0.3520\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3863 - val_loss: 0.3518\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3857 - val_loss: 0.3515\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3852 - val_loss: 0.3512\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3846 - val_loss: 0.3510\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3841 - val_loss: 0.3507\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3835 - val_loss: 0.3504\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3830 - val_loss: 0.3502\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3825 - val_loss: 0.3499\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3820 - val_loss: 0.3496\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3815 - val_loss: 0.3494\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3810 - val_loss: 0.3491\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3805 - val_loss: 0.3489\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3799 - val_loss: 0.3486\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3795 - val_loss: 0.3484\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3790 - val_loss: 0.3481\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3785 - val_loss: 0.3479\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.3476\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3776 - val_loss: 0.3474\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3771 - val_loss: 0.3471\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3767 - val_loss: 0.3469\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3762 - val_loss: 0.3466\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3758 - val_loss: 0.3464\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3753 - val_loss: 0.3461\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3749 - val_loss: 0.3459\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3745 - val_loss: 0.3456\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3740 - val_loss: 0.3454\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3736 - val_loss: 0.3451\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 265.33452450872096, my average MASE = 56598015.30805221\n",
      "Cluster 6, 265.33452450872096\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=9, 9, 1486, (3, 67)\n",
      "Before prediction: train_X.shape=(97, 10, 67), train_y.shape=(97, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4153 - val_loss: 0.4398\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.4396\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4138 - val_loss: 0.4393\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4131 - val_loss: 0.4391\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4124 - val_loss: 0.4388\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4118 - val_loss: 0.4386\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4111 - val_loss: 0.4383\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4105 - val_loss: 0.4381\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4099 - val_loss: 0.4378\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4093 - val_loss: 0.4376\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4087 - val_loss: 0.4374\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4081 - val_loss: 0.4371\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.4369\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4069 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4064 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4058 - val_loss: 0.4362\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.4360\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4047 - val_loss: 0.4358\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4042 - val_loss: 0.4356\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4037 - val_loss: 0.4353\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4032 - val_loss: 0.4351\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4349\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4022 - val_loss: 0.4347\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4017 - val_loss: 0.4345\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4012 - val_loss: 0.4343\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4007 - val_loss: 0.4341\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4003 - val_loss: 0.4339\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3998 - val_loss: 0.4337\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3993 - val_loss: 0.4335\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3989 - val_loss: 0.4334\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3984 - val_loss: 0.4332\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3980 - val_loss: 0.4330\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3976 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3967 - val_loss: 0.4324\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3963 - val_loss: 0.4322\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4320\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3955 - val_loss: 0.4318\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3950 - val_loss: 0.4316\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.4314\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 106.62824359839709, my average MASE = 181907103.45341906\n",
      "Cluster 0, 106.62824359839709\n",
      "Before prediction: train_X.shape=(1415, 10, 67), train_y.shape=(1415, 67), test_X.shape=(472, 10, 67), test_y.shape=(472, 67)\n",
      "Epoch 1/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.1435 - val_loss: 0.0272\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1388 - val_loss: 0.0264\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1347 - val_loss: 0.0256\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1311 - val_loss: 0.0250\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1278 - val_loss: 0.0244\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1249 - val_loss: 0.0239\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1221 - val_loss: 0.0234\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1196 - val_loss: 0.0231\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.1173 - val_loss: 0.0227\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.1151 - val_loss: 0.0224\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1132 - val_loss: 0.0221\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1113 - val_loss: 0.0220\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1096 - val_loss: 0.0217\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1080 - val_loss: 0.0216\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1065 - val_loss: 0.0214\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1051 - val_loss: 0.0212\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1038 - val_loss: 0.0211\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1026 - val_loss: 0.0209\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1014 - val_loss: 0.0208\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1004 - val_loss: 0.0206\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0993 - val_loss: 0.0206\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0983 - val_loss: 0.0205\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0974 - val_loss: 0.0204\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0965 - val_loss: 0.0202\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0957 - val_loss: 0.0201\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0949 - val_loss: 0.0200\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0941 - val_loss: 0.0200\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0934 - val_loss: 0.0199\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0927 - val_loss: 0.0198\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0920 - val_loss: 0.0197\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0914 - val_loss: 0.0197\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0907 - val_loss: 0.0196\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0902 - val_loss: 0.0195\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0896 - val_loss: 0.0195\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0890 - val_loss: 0.0195\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0885 - val_loss: 0.0194\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0880 - val_loss: 0.0194\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0875 - val_loss: 0.0193\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0871 - val_loss: 0.0194\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0867 - val_loss: 0.0193\n",
      "15/15 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(472, 67), test_y.shape=(472, 67)\n",
      "average MASE = 484561401.3912065, my average MASE = 2109803098.5295365\n",
      "Cluster 1, 484561401.3912065\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4184 - val_loss: 0.4085\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4174 - val_loss: 0.4084\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4165 - val_loss: 0.4083\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4155 - val_loss: 0.4082\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4146 - val_loss: 0.4082\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4136 - val_loss: 0.4081\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4127 - val_loss: 0.4080\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4118 - val_loss: 0.4079\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4109 - val_loss: 0.4078\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4100 - val_loss: 0.4077\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4091 - val_loss: 0.4077\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4083 - val_loss: 0.4076\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4074 - val_loss: 0.4075\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4066 - val_loss: 0.4074\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4057 - val_loss: 0.4074\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4049 - val_loss: 0.4073\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4041 - val_loss: 0.4072\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4033 - val_loss: 0.4071\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4025 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4017 - val_loss: 0.4069\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4009 - val_loss: 0.4069\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4001 - val_loss: 0.4068\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3994 - val_loss: 0.4067\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3986 - val_loss: 0.4066\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3979 - val_loss: 0.4065\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3971 - val_loss: 0.4065\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3964 - val_loss: 0.4064\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3957 - val_loss: 0.4063\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3949 - val_loss: 0.4062\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3942 - val_loss: 0.4062\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3936 - val_loss: 0.4061\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3929 - val_loss: 0.4060\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3922 - val_loss: 0.4059\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4058\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3909 - val_loss: 0.4058\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3902 - val_loss: 0.4057\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3896 - val_loss: 0.4056\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3889 - val_loss: 0.4055\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3883 - val_loss: 0.4055\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3877 - val_loss: 0.4054\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 146.41485105295615, my average MASE = 90287364.09726365\n",
      "Cluster 2, 146.41485105295615\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5429 - val_loss: 0.4489\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5408 - val_loss: 0.4477\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5388 - val_loss: 0.4466\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5367 - val_loss: 0.4454\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5348 - val_loss: 0.4443\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5328 - val_loss: 0.4432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5308 - val_loss: 0.4421\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5289 - val_loss: 0.4410\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5270 - val_loss: 0.4399\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5251 - val_loss: 0.4389\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5232 - val_loss: 0.4378\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5214 - val_loss: 0.4368\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5195 - val_loss: 0.4357\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5177 - val_loss: 0.4347\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5159 - val_loss: 0.4336\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5140 - val_loss: 0.4326\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5123 - val_loss: 0.4316\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5105 - val_loss: 0.4306\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5087 - val_loss: 0.4296\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5069 - val_loss: 0.4287\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5052 - val_loss: 0.4277\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5034 - val_loss: 0.4268\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5017 - val_loss: 0.4258\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5000 - val_loss: 0.4249\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4983 - val_loss: 0.4240\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4967 - val_loss: 0.4230\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4950 - val_loss: 0.4221\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4934 - val_loss: 0.4212\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4918 - val_loss: 0.4204\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4903 - val_loss: 0.4195\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4887 - val_loss: 0.4186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.4177\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4857 - val_loss: 0.4169\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4843 - val_loss: 0.4161\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4828 - val_loss: 0.4152\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4814 - val_loss: 0.4144\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4800 - val_loss: 0.4136\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4786 - val_loss: 0.4127\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4772 - val_loss: 0.4119\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4758 - val_loss: 0.4111\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1177081/3287276626.py:67: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 10))\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3556660081.750684, my average MASE = 7865462670.190711\n",
      "Cluster 3, 3556660081.750684\n",
      "Before prediction: train_X.shape=(173, 10, 67), train_y.shape=(173, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7286 - val_loss: 0.5747\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7270 - val_loss: 0.5740\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7256 - val_loss: 0.5733\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7243 - val_loss: 0.5725\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7229 - val_loss: 0.5718\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7216 - val_loss: 0.5712\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7203 - val_loss: 0.5705\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7190 - val_loss: 0.5698\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7178 - val_loss: 0.5692\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7166 - val_loss: 0.5686\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7154 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7142 - val_loss: 0.5673\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7130 - val_loss: 0.5667\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7119 - val_loss: 0.5662\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7108 - val_loss: 0.5656\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7096 - val_loss: 0.5650\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7086 - val_loss: 0.5645\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7075 - val_loss: 0.5639\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7064 - val_loss: 0.5634\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7054 - val_loss: 0.5629\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7044 - val_loss: 0.5624\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7034 - val_loss: 0.5619\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5614\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7014 - val_loss: 0.5609\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7004 - val_loss: 0.5604\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6995 - val_loss: 0.5599\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6986 - val_loss: 0.5595\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6976 - val_loss: 0.5590\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6967 - val_loss: 0.5585\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6958 - val_loss: 0.5581\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6949 - val_loss: 0.5576\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6940 - val_loss: 0.5571\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6931 - val_loss: 0.5567\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5562\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6914 - val_loss: 0.5558\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6905 - val_loss: 0.5553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6896 - val_loss: 0.5549\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6887 - val_loss: 0.5545\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6879 - val_loss: 0.5540\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5536\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 122.19340890523425, my average MASE = 115345826.80728418\n",
      "Cluster 4, 122.19340890523425\n",
      "Before prediction: train_X.shape=(1562, 10, 67), train_y.shape=(1562, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2392 - val_loss: 0.2772\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2287 - val_loss: 0.2673\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2207 - val_loss: 0.2595\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2144 - val_loss: 0.2534\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2094 - val_loss: 0.2481\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2050 - val_loss: 0.2435\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2013 - val_loss: 0.2394\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1978 - val_loss: 0.2357\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1947 - val_loss: 0.2322\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1919 - val_loss: 0.2289\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1892 - val_loss: 0.2259\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1867 - val_loss: 0.2231\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2204\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1821 - val_loss: 0.2179\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1800 - val_loss: 0.2156\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1761 - val_loss: 0.2114\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1743 - val_loss: 0.2096\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1727 - val_loss: 0.2078\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1712 - val_loss: 0.2062\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1698 - val_loss: 0.2047\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2033\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1672 - val_loss: 0.2020\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1661 - val_loss: 0.2007\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1650 - val_loss: 0.1996\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1640 - val_loss: 0.1985\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1631 - val_loss: 0.1974\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1622 - val_loss: 0.1964\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1614 - val_loss: 0.1954\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1598 - val_loss: 0.1936\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1578 - val_loss: 0.1912\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1572 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1566 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1560 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1554 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1549 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1544 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 151.79409601094594, my average MASE = 3866050940.760538\n",
      "Cluster 5, 151.79409601094594\n",
      "Before prediction: train_X.shape=(83, 10, 67), train_y.shape=(83, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4279 - val_loss: 0.5018\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4270 - val_loss: 0.5012\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4262 - val_loss: 0.5006\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4254 - val_loss: 0.5000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4246 - val_loss: 0.4995\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4239 - val_loss: 0.4989\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4231 - val_loss: 0.4984\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4224 - val_loss: 0.4978\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4217 - val_loss: 0.4973\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4968\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4203 - val_loss: 0.4962\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4197 - val_loss: 0.4958\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4191 - val_loss: 0.4953\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4184 - val_loss: 0.4948\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4178 - val_loss: 0.4943\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4939\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4167 - val_loss: 0.4934\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4161 - val_loss: 0.4930\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4155 - val_loss: 0.4926\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4150 - val_loss: 0.4921\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4144 - val_loss: 0.4917\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4139 - val_loss: 0.4913\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4133 - val_loss: 0.4908\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4128 - val_loss: 0.4904\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4123 - val_loss: 0.4900\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4118 - val_loss: 0.4895\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4113 - val_loss: 0.4891\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4107 - val_loss: 0.4887\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4103 - val_loss: 0.4883\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4098 - val_loss: 0.4879\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4093 - val_loss: 0.4875\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4088 - val_loss: 0.4871\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4083 - val_loss: 0.4867\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4079 - val_loss: 0.4863\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4074 - val_loss: 0.4859\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4069 - val_loss: 0.4855\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4065 - val_loss: 0.4851\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4061 - val_loss: 0.4848\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4056 - val_loss: 0.4844\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4052 - val_loss: 0.4840\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 155.68618683798326, my average MASE = 97738271.39222205\n",
      "Cluster 6, 155.68618683798326\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2911 - val_loss: 0.2917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2907 - val_loss: 0.2915\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2902 - val_loss: 0.2913\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2897 - val_loss: 0.2911\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2892 - val_loss: 0.2909\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2888 - val_loss: 0.2907\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2883 - val_loss: 0.2905\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2878 - val_loss: 0.2903\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2874 - val_loss: 0.2901\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2869 - val_loss: 0.2899\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2865 - val_loss: 0.2898\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2861 - val_loss: 0.2896\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2856 - val_loss: 0.2894\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2852 - val_loss: 0.2892\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2848 - val_loss: 0.2890\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2844 - val_loss: 0.2889\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2840 - val_loss: 0.2887\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2836 - val_loss: 0.2885\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2832 - val_loss: 0.2883\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2828 - val_loss: 0.2882\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2824 - val_loss: 0.2880\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2820 - val_loss: 0.2878\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2816 - val_loss: 0.2877\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2812 - val_loss: 0.2875\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2808 - val_loss: 0.2874\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2804 - val_loss: 0.2872\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2800 - val_loss: 0.2870\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2796 - val_loss: 0.2869\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2793 - val_loss: 0.2867\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2789 - val_loss: 0.2865\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2785 - val_loss: 0.2864\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2781 - val_loss: 0.2862\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2778 - val_loss: 0.2861\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2774 - val_loss: 0.2859\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2770 - val_loss: 0.2858\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2767 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2763 - val_loss: 0.2855\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2759 - val_loss: 0.2853\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2756 - val_loss: 0.2852\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2752 - val_loss: 0.2851\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 112.24086700274312, my average MASE = 119826311.76187374\n",
      "Cluster 8, 112.24086700274312\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=11, 11, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1118 - val_loss: 0.1019\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1064 - val_loss: 0.0996\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1022 - val_loss: 0.0982\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0987 - val_loss: 0.0973\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0956 - val_loss: 0.0966\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0930 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0885 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0866 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0848 - val_loss: 0.0949\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0832 - val_loss: 0.0946\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0818 - val_loss: 0.0944\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0804 - val_loss: 0.0941\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0792 - val_loss: 0.0939\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0780 - val_loss: 0.0937\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0769 - val_loss: 0.0936\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0759 - val_loss: 0.0934\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0749 - val_loss: 0.0933\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0740 - val_loss: 0.0932\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0732 - val_loss: 0.0931\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0724 - val_loss: 0.0929\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0716 - val_loss: 0.0928\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0927\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0926\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0696 - val_loss: 0.0926\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0690 - val_loss: 0.0925\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0924\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0923\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0674 - val_loss: 0.0923\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0922\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0921\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0662 - val_loss: 0.0921\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0658 - val_loss: 0.0920\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0919\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0651 - val_loss: 0.0919\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0648 - val_loss: 0.0918\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0645 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0642 - val_loss: 0.0917\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0637 - val_loss: 0.0916\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 876211806.5152007, my average MASE = 21477700395.128197\n",
      "Cluster 0, 876211806.5152007\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7012 - val_loss: 0.5689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7001 - val_loss: 0.5688\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6990 - val_loss: 0.5687\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6979 - val_loss: 0.5686\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6968 - val_loss: 0.5685\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6958 - val_loss: 0.5684\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6947 - val_loss: 0.5683\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6936 - val_loss: 0.5682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6926 - val_loss: 0.5681\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6916 - val_loss: 0.5680\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6906 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6896 - val_loss: 0.5678\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6887 - val_loss: 0.5677\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6877 - val_loss: 0.5676\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6868 - val_loss: 0.5675\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6859 - val_loss: 0.5674\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6849 - val_loss: 0.5673\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6840 - val_loss: 0.5672\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6831 - val_loss: 0.5671\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6822 - val_loss: 0.5670\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6813 - val_loss: 0.5669\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6805 - val_loss: 0.5668\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6796 - val_loss: 0.5667\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6787 - val_loss: 0.5666\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6779 - val_loss: 0.5665\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6771 - val_loss: 0.5665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6762 - val_loss: 0.5664\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6754 - val_loss: 0.5663\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6746 - val_loss: 0.5662\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6738 - val_loss: 0.5661\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6730 - val_loss: 0.5660\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6722 - val_loss: 0.5659\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6715 - val_loss: 0.5658\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6707 - val_loss: 0.5657\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6699 - val_loss: 0.5656\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6691 - val_loss: 0.5655\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6684 - val_loss: 0.5654\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6676 - val_loss: 0.5653\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6668 - val_loss: 0.5652\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6661 - val_loss: 0.5651\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1104923.1929255812, my average MASE = 35973487.14565515\n",
      "Cluster 1, 1104923.1929255812\n",
      "Before prediction: train_X.shape=(134, 10, 67), train_y.shape=(134, 67), test_X.shape=(45, 10, 67), test_y.shape=(45, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4388 - val_loss: 0.7635\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4381 - val_loss: 0.7630\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4375 - val_loss: 0.7625\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4369 - val_loss: 0.7620\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4363 - val_loss: 0.7616\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4358 - val_loss: 0.7611\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4353 - val_loss: 0.7607\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4348 - val_loss: 0.7603\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4343 - val_loss: 0.7598\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4338 - val_loss: 0.7594\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4333 - val_loss: 0.7590\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4328 - val_loss: 0.7585\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4323 - val_loss: 0.7581\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4318 - val_loss: 0.7576\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4314 - val_loss: 0.7572\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4309 - val_loss: 0.7568\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4305 - val_loss: 0.7564\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4301 - val_loss: 0.7561\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4296 - val_loss: 0.7557\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4292 - val_loss: 0.7554\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4288 - val_loss: 0.7550\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4284 - val_loss: 0.7546\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4280 - val_loss: 0.7543\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4276 - val_loss: 0.7539\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4272 - val_loss: 0.7535\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4268 - val_loss: 0.7532\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4264 - val_loss: 0.7528\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4260 - val_loss: 0.7525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4257 - val_loss: 0.7521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4253 - val_loss: 0.7517\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4249 - val_loss: 0.7514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4245 - val_loss: 0.7511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4242 - val_loss: 0.7508\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4238 - val_loss: 0.7505\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4235 - val_loss: 0.7502\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4231 - val_loss: 0.7499\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4228 - val_loss: 0.7496\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4225 - val_loss: 0.7492\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4221 - val_loss: 0.7489\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4218 - val_loss: 0.7486\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(45, 67), test_y.shape=(45, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 134.01886625392066, my average MASE = 180554408.61752364\n",
      "Cluster 2, 134.01886625392066\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3365 - val_loss: 0.4571\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3346 - val_loss: 0.4566\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3328 - val_loss: 0.4560\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.4555\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3293 - val_loss: 0.4550\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.4544\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3260 - val_loss: 0.4539\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.4534\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3229 - val_loss: 0.4528\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3213 - val_loss: 0.4523\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3197 - val_loss: 0.4518\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3182 - val_loss: 0.4512\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3166 - val_loss: 0.4507\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3152 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3137 - val_loss: 0.4496\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3123 - val_loss: 0.4490\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3109 - val_loss: 0.4485\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3095 - val_loss: 0.4479\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3082 - val_loss: 0.4473\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3070 - val_loss: 0.4468\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3058 - val_loss: 0.4462\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3045 - val_loss: 0.4456\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.4450\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3021 - val_loss: 0.4444\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3009 - val_loss: 0.4438\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2998 - val_loss: 0.4432\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2986 - val_loss: 0.4426\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2974 - val_loss: 0.4420\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2963 - val_loss: 0.4414\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2952 - val_loss: 0.4407\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2940 - val_loss: 0.4401\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2929 - val_loss: 0.4395\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.4389\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2907 - val_loss: 0.4384\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2896 - val_loss: 0.4379\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2885 - val_loss: 0.4373\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2875 - val_loss: 0.4369\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2865 - val_loss: 0.4364\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2854 - val_loss: 0.4359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2844 - val_loss: 0.4355\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.28495017155315366, my average MASE = 0.3992586255016426\n",
      "Cluster 3, 0.28495017155315366\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6320 - val_loss: 1.0222\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6307 - val_loss: 1.0218\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 1.0214\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6284 - val_loss: 1.0211\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6273 - val_loss: 1.0208\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6262 - val_loss: 1.0205\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6252 - val_loss: 1.0201\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6241 - val_loss: 1.0198\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6231 - val_loss: 1.0195\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6221 - val_loss: 1.0192\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6212 - val_loss: 1.0188\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6202 - val_loss: 1.0185\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6193 - val_loss: 1.0182\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6183 - val_loss: 1.0179\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6174 - val_loss: 1.0176\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6166 - val_loss: 1.0172\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6157 - val_loss: 1.0169\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6148 - val_loss: 1.0166\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6139 - val_loss: 1.0162\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6131 - val_loss: 1.0159\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6122 - val_loss: 1.0155\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6114 - val_loss: 1.0152\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6106 - val_loss: 1.0148\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6097 - val_loss: 1.0145\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6089 - val_loss: 1.0141\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6081 - val_loss: 1.0138\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6073 - val_loss: 1.0134\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6066 - val_loss: 1.0131\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6057 - val_loss: 1.0127\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6050 - val_loss: 1.0124\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6042 - val_loss: 1.0121\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6035 - val_loss: 1.0118\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6027 - val_loss: 1.0114\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6020 - val_loss: 1.0111\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6013 - val_loss: 1.0108\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6005 - val_loss: 1.0104\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5998 - val_loss: 1.0101\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5991 - val_loss: 1.0098\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5984 - val_loss: 1.0094\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5977 - val_loss: 1.0091\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 98.33747704062574, my average MASE = 204772160.73570046\n",
      "Cluster 4, 98.33747704062574\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4785 - val_loss: 0.4645\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4760 - val_loss: 0.4629\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4734 - val_loss: 0.4612\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4709 - val_loss: 0.4596\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4684 - val_loss: 0.4580\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4661 - val_loss: 0.4564\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4638 - val_loss: 0.4548\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4615 - val_loss: 0.4532\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4593 - val_loss: 0.4516\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4572 - val_loss: 0.4500\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4551 - val_loss: 0.4484\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4530 - val_loss: 0.4468\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4509 - val_loss: 0.4453\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4489 - val_loss: 0.4438\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4469 - val_loss: 0.4422\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4449 - val_loss: 0.4407\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4429 - val_loss: 0.4393\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4410 - val_loss: 0.4380\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4391 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4371 - val_loss: 0.4354\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4353 - val_loss: 0.4343\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4335 - val_loss: 0.4332\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4317 - val_loss: 0.4322\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4300 - val_loss: 0.4311\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4282 - val_loss: 0.4301\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4265 - val_loss: 0.4291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4248 - val_loss: 0.4281\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 0.4270\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4197 - val_loss: 0.4250\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4181 - val_loss: 0.4240\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4165 - val_loss: 0.4229\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4149 - val_loss: 0.4218\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4134 - val_loss: 0.4208\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4118 - val_loss: 0.4197\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4103 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4088 - val_loss: 0.4176\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.4167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4060 - val_loss: 0.4157\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4046 - val_loss: 0.4148\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 931833756.986838, my average MASE = 2420970654.4710827\n",
      "Cluster 5, 931833756.986838\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4346 - val_loss: 0.4628\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4334 - val_loss: 0.4625\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4323 - val_loss: 0.4621\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4312 - val_loss: 0.4618\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4301 - val_loss: 0.4615\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4290 - val_loss: 0.4612\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4280 - val_loss: 0.4609\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4269 - val_loss: 0.4605\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4259 - val_loss: 0.4602\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4249 - val_loss: 0.4599\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4239 - val_loss: 0.4596\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4228 - val_loss: 0.4593\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4218 - val_loss: 0.4590\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4208 - val_loss: 0.4587\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4198 - val_loss: 0.4584\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4188 - val_loss: 0.4582\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4179 - val_loss: 0.4579\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4169 - val_loss: 0.4576\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4160 - val_loss: 0.4573\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4151 - val_loss: 0.4570\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4141 - val_loss: 0.4567\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4132 - val_loss: 0.4564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4123 - val_loss: 0.4561\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4114 - val_loss: 0.4558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4106 - val_loss: 0.4555\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4097 - val_loss: 0.4552\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4089 - val_loss: 0.4549\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4080 - val_loss: 0.4546\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4072 - val_loss: 0.4544\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4063 - val_loss: 0.4541\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4055 - val_loss: 0.4538\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4047 - val_loss: 0.4536\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4039 - val_loss: 0.4533\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4031 - val_loss: 0.4531\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4023 - val_loss: 0.4529\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4015 - val_loss: 0.4527\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4007 - val_loss: 0.4526\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3999 - val_loss: 0.4524\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3991 - val_loss: 0.4522\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3983 - val_loss: 0.4520\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 806621.4868706047, my average MASE = 27017424.126969155\n",
      "Cluster 6, 806621.4868706047\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8616 - val_loss: 0.8556\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8588 - val_loss: 0.8539\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8561 - val_loss: 0.8522\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8534 - val_loss: 0.8505\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8508 - val_loss: 0.8489\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8484 - val_loss: 0.8472\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8459 - val_loss: 0.8456\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8435 - val_loss: 0.8440\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8412 - val_loss: 0.8424\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8389 - val_loss: 0.8408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8366 - val_loss: 0.8392\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8343 - val_loss: 0.8376\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8320 - val_loss: 0.8361\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8298 - val_loss: 0.8345\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8276 - val_loss: 0.8329\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8254 - val_loss: 0.8314\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8232 - val_loss: 0.8298\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8210 - val_loss: 0.8283\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 0.8267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8168 - val_loss: 0.8253\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8146 - val_loss: 0.8238\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8125 - val_loss: 0.8224\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8104 - val_loss: 0.8210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8084 - val_loss: 0.8197\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8064 - val_loss: 0.8184\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8045 - val_loss: 0.8170\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8025 - val_loss: 0.8157\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8006 - val_loss: 0.8143\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7987 - val_loss: 0.8129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7969 - val_loss: 0.8115\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7950 - val_loss: 0.8102\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7932 - val_loss: 0.8089\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7913 - val_loss: 0.8077\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7894 - val_loss: 0.8065\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7876 - val_loss: 0.8053\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7857 - val_loss: 0.8041\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7839 - val_loss: 0.8030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7821 - val_loss: 0.8019\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7803 - val_loss: 0.8008\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7785 - val_loss: 0.7997\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 964635493.0745914, my average MASE = 2107611139.389815\n",
      "Cluster 7, 964635493.0745914\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3952 - val_loss: 0.3689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3946 - val_loss: 0.3689\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3941 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3935 - val_loss: 0.3687\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3930 - val_loss: 0.3687\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3924 - val_loss: 0.3686\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3919 - val_loss: 0.3685\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3914 - val_loss: 0.3685\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3909 - val_loss: 0.3684\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3903 - val_loss: 0.3684\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3898 - val_loss: 0.3683\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3893 - val_loss: 0.3682\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3888 - val_loss: 0.3682\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3883 - val_loss: 0.3681\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3878 - val_loss: 0.3680\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3873 - val_loss: 0.3680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3869 - val_loss: 0.3679\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3864 - val_loss: 0.3679\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3855 - val_loss: 0.3677\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3850 - val_loss: 0.3677\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3845 - val_loss: 0.3676\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3841 - val_loss: 0.3676\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3836 - val_loss: 0.3675\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3832 - val_loss: 0.3674\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3828 - val_loss: 0.3674\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3823 - val_loss: 0.3673\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3819 - val_loss: 0.3673\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3815 - val_loss: 0.3672\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3811 - val_loss: 0.3672\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3806 - val_loss: 0.3671\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3802 - val_loss: 0.3670\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3798 - val_loss: 0.3670\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.3669\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3790 - val_loss: 0.3669\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3786 - val_loss: 0.3668\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3782 - val_loss: 0.3668\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3778 - val_loss: 0.3667\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3774 - val_loss: 0.3666\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3770 - val_loss: 0.3666\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 51.171495934252626, my average MASE = 30811708.472042836\n",
      "Cluster 8, 51.171495934252626\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4416 - val_loss: 0.4387\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4409 - val_loss: 0.4386\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4402 - val_loss: 0.4384\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4395 - val_loss: 0.4383\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4388 - val_loss: 0.4381\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4382 - val_loss: 0.4380\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4375 - val_loss: 0.4379\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4368 - val_loss: 0.4377\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4362 - val_loss: 0.4376\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4355 - val_loss: 0.4375\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4348 - val_loss: 0.4373\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4342 - val_loss: 0.4372\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4335 - val_loss: 0.4371\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4329 - val_loss: 0.4370\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4323 - val_loss: 0.4368\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4316 - val_loss: 0.4367\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4310 - val_loss: 0.4366\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4304 - val_loss: 0.4365\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4298 - val_loss: 0.4364\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4292 - val_loss: 0.4363\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4286 - val_loss: 0.4362\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4280 - val_loss: 0.4361\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4274 - val_loss: 0.4359\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4268 - val_loss: 0.4358\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4262 - val_loss: 0.4357\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4256 - val_loss: 0.4356\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4250 - val_loss: 0.4355\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4245 - val_loss: 0.4354\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4239 - val_loss: 0.4353\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4352\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4227 - val_loss: 0.4351\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4221 - val_loss: 0.4350\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.4349\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4348\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4204 - val_loss: 0.4347\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4199 - val_loss: 0.4346\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4193 - val_loss: 0.4345\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4187 - val_loss: 0.4345\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4182 - val_loss: 0.4344\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4176 - val_loss: 0.4343\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 67.68630348587587, my average MASE = 34346224.36796317\n",
      "Cluster 9, 67.68630348587587\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=2, 2, 18, (30610, 67)\n",
      "Before prediction: train_X.shape=(18359, 10, 67), train_y.shape=(18359, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3046 - val_loss: 0.3213\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2853 - val_loss: 0.3058\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2698 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2588 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2516 - val_loss: 0.2788\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2460 - val_loss: 0.2736\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2412 - val_loss: 0.2691\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2371 - val_loss: 0.2652\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2335 - val_loss: 0.2618\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2301 - val_loss: 0.2588\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2271 - val_loss: 0.2562\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2243 - val_loss: 0.2538\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2219 - val_loss: 0.2516\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2199 - val_loss: 0.2498\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2181 - val_loss: 0.2483\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2166 - val_loss: 0.2469\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2153 - val_loss: 0.2458\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2142 - val_loss: 0.2448\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2122 - val_loss: 0.2430\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2114 - val_loss: 0.2422\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2106 - val_loss: 0.2414\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2099 - val_loss: 0.2407\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2092 - val_loss: 0.2401\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2086 - val_loss: 0.2395\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2080 - val_loss: 0.2389\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2074 - val_loss: 0.2385\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2069 - val_loss: 0.2380\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2064 - val_loss: 0.2376\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2059 - val_loss: 0.2370\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2054 - val_loss: 0.2367\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2050 - val_loss: 0.2362\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2046 - val_loss: 0.2359\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2042 - val_loss: 0.2356\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2038 - val_loss: 0.2351\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2034 - val_loss: 0.2349\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2031 - val_loss: 0.2345\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2021 - val_loss: 0.2337\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1675.644817755528, my average MASE = 2652.7812514268226\n",
      "Cluster 0, 1675.644817755528\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4228 - val_loss: 1.1321\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4209 - val_loss: 1.1320\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4191 - val_loss: 1.1319\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4173 - val_loss: 1.1318\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 1.1317\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4139 - val_loss: 1.1315\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4122 - val_loss: 1.1314\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4106 - val_loss: 1.1313\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4090 - val_loss: 1.1311\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4075 - val_loss: 1.1310\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4059 - val_loss: 1.1308\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4044 - val_loss: 1.1306\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4030 - val_loss: 1.1304\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4015 - val_loss: 1.1302\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4001 - val_loss: 1.1300\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 1.1298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3973 - val_loss: 1.1296\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3960 - val_loss: 1.1294\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3946 - val_loss: 1.1292\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3933 - val_loss: 1.1290\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 1.1288\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3907 - val_loss: 1.1286\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3895 - val_loss: 1.1283\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3883 - val_loss: 1.1281\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3871 - val_loss: 1.1279\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 1.1277\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3847 - val_loss: 1.1275\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3836 - val_loss: 1.1272\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3825 - val_loss: 1.1270\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3814 - val_loss: 1.1268\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3803 - val_loss: 1.1266\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3792 - val_loss: 1.1264\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3781 - val_loss: 1.1262\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3771 - val_loss: 1.1259\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3761 - val_loss: 1.1257\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3750 - val_loss: 1.1255\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3740 - val_loss: 1.1253\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 1.1251\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3721 - val_loss: 1.1249\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3711 - val_loss: 1.1247\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 993839931.13901, my average MASE = 2723871222.022616\n",
      "Cluster 1, 993839931.13901\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=5, 5, 75, (319, 67)\n",
      "Before prediction: train_X.shape=(185, 10, 67), train_y.shape=(185, 67), test_X.shape=(62, 10, 67), test_y.shape=(62, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6944 - val_loss: 0.6444\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6929 - val_loss: 0.6434\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6914 - val_loss: 0.6425\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6901 - val_loss: 0.6415\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6887 - val_loss: 0.6406\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6874 - val_loss: 0.6397\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6860 - val_loss: 0.6388\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6847 - val_loss: 0.6380\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6834 - val_loss: 0.6372\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6822 - val_loss: 0.6363\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6810 - val_loss: 0.6355\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6798 - val_loss: 0.6347\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.6340\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6775 - val_loss: 0.6332\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.6325\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6753 - val_loss: 0.6318\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6742 - val_loss: 0.6310\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6732 - val_loss: 0.6303\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6721 - val_loss: 0.6296\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6711 - val_loss: 0.6289\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6701 - val_loss: 0.6283\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6692 - val_loss: 0.6276\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6682 - val_loss: 0.6270\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6672 - val_loss: 0.6263\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6663 - val_loss: 0.6257\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6654 - val_loss: 0.6251\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.6244\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6636 - val_loss: 0.6238\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6627 - val_loss: 0.6232\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6618 - val_loss: 0.6226\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6610 - val_loss: 0.6220\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6601 - val_loss: 0.6214\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6593 - val_loss: 0.6208\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6584 - val_loss: 0.6202\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6576 - val_loss: 0.6196\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6568 - val_loss: 0.6191\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6559 - val_loss: 0.6185\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6551 - val_loss: 0.6179\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6543 - val_loss: 0.6173\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6535 - val_loss: 0.6167\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(62, 67), test_y.shape=(62, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 141.38884780958514, my average MASE = 173942620.82410374\n",
      "Cluster 0, 141.38884780958514\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0665 - val_loss: 0.0455\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0607 - val_loss: 0.0424\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0575 - val_loss: 0.0402\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0551 - val_loss: 0.0384\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0531 - val_loss: 0.0370\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0515 - val_loss: 0.0358\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0502 - val_loss: 0.0347\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0491 - val_loss: 0.0338\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0481 - val_loss: 0.0331\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0473 - val_loss: 0.0324\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0466 - val_loss: 0.0319\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0460 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0454 - val_loss: 0.0311\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0449 - val_loss: 0.0307\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0304\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0301\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0437 - val_loss: 0.0299\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0433 - val_loss: 0.0297\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0294\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0292\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0424 - val_loss: 0.0290\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0422 - val_loss: 0.0288\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0420 - val_loss: 0.0287\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0418 - val_loss: 0.0285\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0416 - val_loss: 0.0284\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0414 - val_loss: 0.0283\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0412 - val_loss: 0.0281\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0411 - val_loss: 0.0280\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0279\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0278\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0278\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0277\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0276\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0403 - val_loss: 0.0276\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0275\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0401 - val_loss: 0.0274\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0274\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0273\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0273\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0272\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1157555182.6490364, my average MASE = 73085160895.13536\n",
      "Cluster 1, 1157555182.6490364\n",
      "Before prediction: train_X.shape=(37, 10, 67), train_y.shape=(37, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5516 - val_loss: 0.5380\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5498 - val_loss: 0.5365\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5480 - val_loss: 0.5350\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5462 - val_loss: 0.5335\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5444 - val_loss: 0.5321\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5427 - val_loss: 0.5306\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5410 - val_loss: 0.5292\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5393 - val_loss: 0.5278\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5376 - val_loss: 0.5264\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5360 - val_loss: 0.5250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5343 - val_loss: 0.5237\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5328 - val_loss: 0.5223\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5312 - val_loss: 0.5210\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5297 - val_loss: 0.5197\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5281 - val_loss: 0.5184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5266 - val_loss: 0.5171\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5252 - val_loss: 0.5158\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5237 - val_loss: 0.5146\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5223 - val_loss: 0.5133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5208 - val_loss: 0.5121\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5194 - val_loss: 0.5109\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5181 - val_loss: 0.5098\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5167 - val_loss: 0.5086\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5154 - val_loss: 0.5075\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5141 - val_loss: 0.5063\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5128 - val_loss: 0.5052\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5115 - val_loss: 0.5041\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5103 - val_loss: 0.5031\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5091 - val_loss: 0.5020\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5078 - val_loss: 0.5010\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.5000\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5055 - val_loss: 0.4990\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5043 - val_loss: 0.4980\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5031 - val_loss: 0.4970\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5020 - val_loss: 0.4961\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5008 - val_loss: 0.4952\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.4943\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4986 - val_loss: 0.4934\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4975 - val_loss: 0.4926\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4964 - val_loss: 0.4917\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4324881186.205308, my average MASE = 10393885205.318085\n",
      "Cluster 2, 4324881186.205308\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4066 - val_loss: 0.3845\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4060 - val_loss: 0.3840\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.3836\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4048 - val_loss: 0.3831\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4042 - val_loss: 0.3826\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4036 - val_loss: 0.3822\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 0.3817\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4025 - val_loss: 0.3812\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4019 - val_loss: 0.3808\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4014 - val_loss: 0.3803\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3799\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4003 - val_loss: 0.3795\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3791\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3992 - val_loss: 0.3787\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 0.3783\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3982 - val_loss: 0.3779\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3977 - val_loss: 0.3775\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.3772\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3966 - val_loss: 0.3768\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3764\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3956 - val_loss: 0.3761\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3757\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3946 - val_loss: 0.3754\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3942 - val_loss: 0.3751\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3937 - val_loss: 0.3747\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3932 - val_loss: 0.3744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3927 - val_loss: 0.3741\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3922 - val_loss: 0.3738\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3918 - val_loss: 0.3735\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3913 - val_loss: 0.3732\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3908 - val_loss: 0.3729\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3903 - val_loss: 0.3726\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.3723\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3894 - val_loss: 0.3720\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3890 - val_loss: 0.3718\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3885 - val_loss: 0.3715\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3881 - val_loss: 0.3712\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3877 - val_loss: 0.3709\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3872 - val_loss: 0.3706\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3868 - val_loss: 0.3704\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n",
      "average MASE = 1110146.2653270473, my average MASE = 43278995.990564056\n",
      "Cluster 3, 1110146.2653270473\n",
      "Before prediction: train_X.shape=(25, 10, 67), train_y.shape=(25, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5208 - val_loss: 0.4711\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5196 - val_loss: 0.4707\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5184 - val_loss: 0.4702\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5173 - val_loss: 0.4698\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5161 - val_loss: 0.4694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5150 - val_loss: 0.4690\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4686\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5127 - val_loss: 0.4682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5116 - val_loss: 0.4678\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5105 - val_loss: 0.4675\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5094 - val_loss: 0.4671\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5084 - val_loss: 0.4667\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5073 - val_loss: 0.4664\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5063 - val_loss: 0.4660\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5052 - val_loss: 0.4657\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5042 - val_loss: 0.4654\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5031 - val_loss: 0.4651\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4648\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5011 - val_loss: 0.4645\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5001 - val_loss: 0.4643\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4991 - val_loss: 0.4641\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.4638\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4971 - val_loss: 0.4636\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4962 - val_loss: 0.4634\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.4632\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4942 - val_loss: 0.4629\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4933 - val_loss: 0.4627\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4923 - val_loss: 0.4625\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4914 - val_loss: 0.4623\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4904 - val_loss: 0.4621\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4895 - val_loss: 0.4619\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4886 - val_loss: 0.4617\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4876 - val_loss: 0.4616\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4867 - val_loss: 0.4614\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4858 - val_loss: 0.4613\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4849 - val_loss: 0.4611\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4841 - val_loss: 0.4610\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4608\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4823 - val_loss: 0.4607\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4815 - val_loss: 0.4605\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 111.6892159594304, my average MASE = 112347014.53903662\n",
      "Cluster 4, 111.6892159594304\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=7, 7, 884, (12, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0672 - val_loss: 0.0440\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0611 - val_loss: 0.0410\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0576 - val_loss: 0.0390\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0552 - val_loss: 0.0374\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0533 - val_loss: 0.0361\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0517 - val_loss: 0.0350\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0504 - val_loss: 0.0340\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0493 - val_loss: 0.0332\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0484 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0476 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0469 - val_loss: 0.0313\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0462 - val_loss: 0.0308\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0457 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0447 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0442 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0435 - val_loss: 0.0287\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0285\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0283\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0281\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0280\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0278\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0277\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0275\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0274\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0273\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0411 - val_loss: 0.0271\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0270\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0408 - val_loss: 0.0269\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0268\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0267\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0405 - val_loss: 0.0266\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0403 - val_loss: 0.0265\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0401 - val_loss: 0.0264\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0263\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0399 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1103404601.9868512, my average MASE = 55700347192.937294\n",
      "Cluster 1, 1103404601.9868512\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5205 - val_loss: 0.4218\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5186 - val_loss: 0.4208\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5167 - val_loss: 0.4198\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5148 - val_loss: 0.4189\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5129 - val_loss: 0.4179\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5111 - val_loss: 0.4170\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5093 - val_loss: 0.4161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5074 - val_loss: 0.4152\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5057 - val_loss: 0.4143\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5039 - val_loss: 0.4134\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5022 - val_loss: 0.4125\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5004 - val_loss: 0.4117\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4987 - val_loss: 0.4108\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4971 - val_loss: 0.4100\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4954 - val_loss: 0.4092\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4938 - val_loss: 0.4083\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4922 - val_loss: 0.4075\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4906 - val_loss: 0.4067\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4890 - val_loss: 0.4060\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4875 - val_loss: 0.4052\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4860 - val_loss: 0.4044\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4845 - val_loss: 0.4036\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4830 - val_loss: 0.4028\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4815 - val_loss: 0.4021\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4800 - val_loss: 0.4013\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4771 - val_loss: 0.3999\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4757 - val_loss: 0.3992\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4743 - val_loss: 0.3985\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4730 - val_loss: 0.3978\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4716 - val_loss: 0.3971\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4703 - val_loss: 0.3964\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4689 - val_loss: 0.3958\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.3951\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.3945\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4650 - val_loss: 0.3939\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4637 - val_loss: 0.3932\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4625 - val_loss: 0.3926\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4612 - val_loss: 0.3920\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4600 - val_loss: 0.3913\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3560489905.356454, my average MASE = 9030960108.787361\n",
      "Cluster 2, 3560489905.356454\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3774 - val_loss: 0.3465\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3767 - val_loss: 0.3460\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3759 - val_loss: 0.3456\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3752 - val_loss: 0.3452\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3744 - val_loss: 0.3448\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3737 - val_loss: 0.3444\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 0.3440\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3723 - val_loss: 0.3436\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3716 - val_loss: 0.3432\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3710 - val_loss: 0.3429\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3703 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3696 - val_loss: 0.3421\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.3418\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3683 - val_loss: 0.3415\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3411\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3671 - val_loss: 0.3408\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3665 - val_loss: 0.3405\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3659 - val_loss: 0.3401\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3653 - val_loss: 0.3398\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3647 - val_loss: 0.3395\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3641 - val_loss: 0.3392\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3635 - val_loss: 0.3389\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3630 - val_loss: 0.3386\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.3383\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.3380\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3613 - val_loss: 0.3377\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3608 - val_loss: 0.3374\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3602 - val_loss: 0.3371\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3597 - val_loss: 0.3368\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3592 - val_loss: 0.3365\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3362\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3581 - val_loss: 0.3359\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3576 - val_loss: 0.3356\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3571 - val_loss: 0.3353\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3566 - val_loss: 0.3350\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3561 - val_loss: 0.3347\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3556 - val_loss: 0.3344\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3551 - val_loss: 0.3342\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3546 - val_loss: 0.3339\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3541 - val_loss: 0.3336\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 332.8608286989534, my average MASE = 85442913.95523748\n",
      "Cluster 3, 332.8608286989534\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7187 - val_loss: 0.5712\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7172 - val_loss: 0.5706\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7158 - val_loss: 0.5700\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7145 - val_loss: 0.5694\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7132 - val_loss: 0.5688\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7119 - val_loss: 0.5682\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7107 - val_loss: 0.5677\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7095 - val_loss: 0.5671\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7083 - val_loss: 0.5666\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7071 - val_loss: 0.5660\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7060 - val_loss: 0.5655\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7049 - val_loss: 0.5650\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7038 - val_loss: 0.5646\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7028 - val_loss: 0.5641\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7018 - val_loss: 0.5636\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7008 - val_loss: 0.5631\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6999 - val_loss: 0.5627\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6989 - val_loss: 0.5622\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6980 - val_loss: 0.5618\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6971 - val_loss: 0.5613\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5609\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6953 - val_loss: 0.5604\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6944 - val_loss: 0.5600\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6935 - val_loss: 0.5596\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6927 - val_loss: 0.5592\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6918 - val_loss: 0.5587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6910 - val_loss: 0.5583\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6902 - val_loss: 0.5579\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6894 - val_loss: 0.5576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6886 - val_loss: 0.5572\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6878 - val_loss: 0.5568\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5564\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6862 - val_loss: 0.5560\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6854 - val_loss: 0.5557\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6846 - val_loss: 0.5553\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6839 - val_loss: 0.5549\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6831 - val_loss: 0.5546\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6824 - val_loss: 0.5542\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6816 - val_loss: 0.5538\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6809 - val_loss: 0.5535\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.45484282658396, my average MASE = 350849744.5231373\n",
      "Cluster 4, 139.45484282658396\n",
      "Before prediction: train_X.shape=(133, 10, 67), train_y.shape=(133, 67), test_X.shape=(44, 10, 67), test_y.shape=(44, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4266 - val_loss: 0.6651\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4259 - val_loss: 0.6645\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4253 - val_loss: 0.6639\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4247 - val_loss: 0.6633\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4242 - val_loss: 0.6628\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4236 - val_loss: 0.6623\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4231 - val_loss: 0.6618\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4226 - val_loss: 0.6613\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4221 - val_loss: 0.6608\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4216 - val_loss: 0.6603\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4211 - val_loss: 0.6599\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4206 - val_loss: 0.6594\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4201 - val_loss: 0.6590\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4197 - val_loss: 0.6585\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4192 - val_loss: 0.6581\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4188 - val_loss: 0.6576\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4184 - val_loss: 0.6572\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4180 - val_loss: 0.6568\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4175 - val_loss: 0.6564\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4171 - val_loss: 0.6559\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4167 - val_loss: 0.6554\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4163 - val_loss: 0.6550\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4159 - val_loss: 0.6545\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4155 - val_loss: 0.6541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4151 - val_loss: 0.6537\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4147 - val_loss: 0.6533\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4143 - val_loss: 0.6529\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4139 - val_loss: 0.6525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4135 - val_loss: 0.6521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4131 - val_loss: 0.6518\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4128 - val_loss: 0.6514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4124 - val_loss: 0.6511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4120 - val_loss: 0.6507\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4117 - val_loss: 0.6504\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4114 - val_loss: 0.6501\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4110 - val_loss: 0.6498\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4107 - val_loss: 0.6494\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4103 - val_loss: 0.6491\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4100 - val_loss: 0.6487\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4096 - val_loss: 0.6484\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(44, 67), test_y.shape=(44, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 116.65244791791511, my average MASE = 142786035.78420427\n",
      "Cluster 5, 116.65244791791511\n",
      "Before prediction: train_X.shape=(78, 10, 67), train_y.shape=(78, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4078 - val_loss: 0.4868\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4070 - val_loss: 0.4862\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4062 - val_loss: 0.4856\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4055 - val_loss: 0.4850\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4048 - val_loss: 0.4845\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4041 - val_loss: 0.4839\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.4833\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4828\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4021 - val_loss: 0.4823\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4015 - val_loss: 0.4818\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4008 - val_loss: 0.4813\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4002 - val_loss: 0.4808\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3997 - val_loss: 0.4803\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3991 - val_loss: 0.4798\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3985 - val_loss: 0.4794\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3980 - val_loss: 0.4789\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3974 - val_loss: 0.4785\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3969 - val_loss: 0.4780\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3964 - val_loss: 0.4776\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4772\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3954 - val_loss: 0.4768\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3949 - val_loss: 0.4764\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3944 - val_loss: 0.4760\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.4757\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3934 - val_loss: 0.4753\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3930 - val_loss: 0.4750\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3925 - val_loss: 0.4747\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3921 - val_loss: 0.4743\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3916 - val_loss: 0.4740\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3912 - val_loss: 0.4737\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3907 - val_loss: 0.4733\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3903 - val_loss: 0.4730\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.4727\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3895 - val_loss: 0.4724\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3890 - val_loss: 0.4721\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3886 - val_loss: 0.4718\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4715\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3878 - val_loss: 0.4712\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.4709\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3870 - val_loss: 0.4706\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 221.65144919995234, my average MASE = 102271349.10812314\n",
      "Cluster 6, 221.65144919995234\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=9, 9, 14, (3245, 67)\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1141 - val_loss: 0.1031\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1086 - val_loss: 0.1010\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1042 - val_loss: 0.0995\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1005 - val_loss: 0.0982\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0973 - val_loss: 0.0973\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0945 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0920 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0897 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0877 - val_loss: 0.0950\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0858 - val_loss: 0.0947\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0841 - val_loss: 0.0943\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0826 - val_loss: 0.0941\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0812 - val_loss: 0.0938\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0798 - val_loss: 0.0935\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0786 - val_loss: 0.0933\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0930\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0765 - val_loss: 0.0928\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0755 - val_loss: 0.0926\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0746 - val_loss: 0.0925\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0737 - val_loss: 0.0923\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0729 - val_loss: 0.0921\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0722 - val_loss: 0.0920\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0715 - val_loss: 0.0919\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0708 - val_loss: 0.0917\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0916\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0915\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0691 - val_loss: 0.0914\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0686 - val_loss: 0.0913\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0681 - val_loss: 0.0912\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0676 - val_loss: 0.0911\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0910\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0668 - val_loss: 0.0910\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0664 - val_loss: 0.0909\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0660 - val_loss: 0.0909\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0656 - val_loss: 0.0908\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0653 - val_loss: 0.0908\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0650 - val_loss: 0.0907\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0647 - val_loss: 0.0907\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0644 - val_loss: 0.0907\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0906\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1289233887.8234715, my average MASE = 15636865244.557127\n",
      "Cluster 0, 1289233887.8234715\n",
      "Before prediction: train_X.shape=(29, 10, 67), train_y.shape=(29, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4693 - val_loss: 0.6570\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4687 - val_loss: 0.6567\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4680 - val_loss: 0.6563\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4674 - val_loss: 0.6560\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4668 - val_loss: 0.6557\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4662 - val_loss: 0.6554\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4656 - val_loss: 0.6551\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4650 - val_loss: 0.6548\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4644 - val_loss: 0.6545\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4638 - val_loss: 0.6542\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4633 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4627 - val_loss: 0.6536\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4621 - val_loss: 0.6533\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.6530\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4610 - val_loss: 0.6527\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4605 - val_loss: 0.6524\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4599 - val_loss: 0.6521\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4594 - val_loss: 0.6519\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4588 - val_loss: 0.6516\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4583 - val_loss: 0.6513\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4578 - val_loss: 0.6510\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4573 - val_loss: 0.6508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4568 - val_loss: 0.6505\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4563 - val_loss: 0.6502\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4558 - val_loss: 0.6499\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4553 - val_loss: 0.6496\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4548 - val_loss: 0.6493\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4543 - val_loss: 0.6491\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4538 - val_loss: 0.6488\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4533 - val_loss: 0.6485\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4528 - val_loss: 0.6483\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4524 - val_loss: 0.6480\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4519 - val_loss: 0.6478\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4514 - val_loss: 0.6475\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4510 - val_loss: 0.6473\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4505 - val_loss: 0.6470\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4500 - val_loss: 0.6468\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4496 - val_loss: 0.6465\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4492 - val_loss: 0.6463\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.6460\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 10049120.449906044, my average MASE = 246733533.9412494\n",
      "Cluster 1, 10049120.449906044\n",
      "Before prediction: train_X.shape=(1564, 10, 67), train_y.shape=(1564, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2359 - val_loss: 0.2748\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2264 - val_loss: 0.2656\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2192 - val_loss: 0.2584\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2135 - val_loss: 0.2523\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2087 - val_loss: 0.2471\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2045 - val_loss: 0.2424\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2007 - val_loss: 0.2382\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1973 - val_loss: 0.2342\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1941 - val_loss: 0.2307\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1912 - val_loss: 0.2273\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1884 - val_loss: 0.2242\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1858 - val_loss: 0.2214\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1833 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1810 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1789 - val_loss: 0.2140\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1769 - val_loss: 0.2119\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1750 - val_loss: 0.2100\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1733 - val_loss: 0.2082\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1717 - val_loss: 0.2066\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1702 - val_loss: 0.2051\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1689 - val_loss: 0.2038\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1677 - val_loss: 0.2024\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2012\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2001\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1645 - val_loss: 0.1989\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1979\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1627 - val_loss: 0.1969\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1619 - val_loss: 0.1959\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1611 - val_loss: 0.1950\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1603 - val_loss: 0.1941\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1596 - val_loss: 0.1933\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1589 - val_loss: 0.1925\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1582 - val_loss: 0.1917\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1576 - val_loss: 0.1910\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1570 - val_loss: 0.1903\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1564 - val_loss: 0.1895\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1558 - val_loss: 0.1889\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1553 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1548 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1543 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 187.65491616156584, my average MASE = 1727876346.7517292\n",
      "Cluster 2, 187.65491616156584\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5179 - val_loss: 0.4772\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5158 - val_loss: 0.4757\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4743\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5118 - val_loss: 0.4729\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5098 - val_loss: 0.4715\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5079 - val_loss: 0.4701\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5059 - val_loss: 0.4687\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5040 - val_loss: 0.4673\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4660\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5002 - val_loss: 0.4646\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4984 - val_loss: 0.4633\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4966 - val_loss: 0.4620\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4948 - val_loss: 0.4607\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4931 - val_loss: 0.4594\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4913 - val_loss: 0.4581\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4896 - val_loss: 0.4568\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4879 - val_loss: 0.4555\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4862 - val_loss: 0.4543\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4845 - val_loss: 0.4531\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4828 - val_loss: 0.4518\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4812 - val_loss: 0.4506\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4795 - val_loss: 0.4495\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4779 - val_loss: 0.4483\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4763 - val_loss: 0.4471\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4747 - val_loss: 0.4460\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4731 - val_loss: 0.4449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4716 - val_loss: 0.4438\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4700 - val_loss: 0.4427\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4685 - val_loss: 0.4416\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4670 - val_loss: 0.4405\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4655 - val_loss: 0.4395\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4640 - val_loss: 0.4385\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4626 - val_loss: 0.4374\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4611 - val_loss: 0.4364\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4597 - val_loss: 0.4354\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4582 - val_loss: 0.4344\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4568 - val_loss: 0.4334\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4555 - val_loss: 0.4324\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4541 - val_loss: 0.4314\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4527 - val_loss: 0.4304\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3258333520.23763, my average MASE = 7487984704.271554\n",
      "Cluster 3, 3258333520.23763\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3367 - val_loss: 0.3564\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3362 - val_loss: 0.3564\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3356 - val_loss: 0.3564\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3351 - val_loss: 0.3563\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3346 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3340 - val_loss: 0.3563\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3335 - val_loss: 0.3563\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3330 - val_loss: 0.3562\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3325 - val_loss: 0.3562\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3319 - val_loss: 0.3562\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3314 - val_loss: 0.3561\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3309 - val_loss: 0.3561\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3304 - val_loss: 0.3561\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3560\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3294 - val_loss: 0.3560\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3289 - val_loss: 0.3560\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.3559\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3280 - val_loss: 0.3559\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3275 - val_loss: 0.3559\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3270 - val_loss: 0.3559\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3266 - val_loss: 0.3558\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3261 - val_loss: 0.3558\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3256 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3252 - val_loss: 0.3558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3248 - val_loss: 0.3558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3243 - val_loss: 0.3557\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3239 - val_loss: 0.3557\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.3557\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3230 - val_loss: 0.3557\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3226 - val_loss: 0.3557\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3222 - val_loss: 0.3556\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3218 - val_loss: 0.3556\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3214 - val_loss: 0.3556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3556\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3205 - val_loss: 0.3556\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3201 - val_loss: 0.3556\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.3556\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3193 - val_loss: 0.3555\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3189 - val_loss: 0.3555\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3185 - val_loss: 0.3555\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 544.8910068645505, my average MASE = 25915172.7591836\n",
      "Cluster 4, 544.8910068645505\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5189 - val_loss: 0.8510\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5183 - val_loss: 0.8507\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5176 - val_loss: 0.8503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5170 - val_loss: 0.8500\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5163 - val_loss: 0.8496\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5157 - val_loss: 0.8493\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5151 - val_loss: 0.8490\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5145 - val_loss: 0.8487\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5138 - val_loss: 0.8484\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5132 - val_loss: 0.8481\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5126 - val_loss: 0.8478\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5120 - val_loss: 0.8476\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5114 - val_loss: 0.8473\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5108 - val_loss: 0.8471\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5102 - val_loss: 0.8468\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5096 - val_loss: 0.8466\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5090 - val_loss: 0.8463\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5084 - val_loss: 0.8461\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5078 - val_loss: 0.8458\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5072 - val_loss: 0.8456\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.8454\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5060 - val_loss: 0.8451\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5055 - val_loss: 0.8449\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5049 - val_loss: 0.8447\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5043 - val_loss: 0.8445\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5038 - val_loss: 0.8443\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5032 - val_loss: 0.8441\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5027 - val_loss: 0.8439\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5021 - val_loss: 0.8437\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5016 - val_loss: 0.8435\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5010 - val_loss: 0.8433\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5005 - val_loss: 0.8431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4999 - val_loss: 0.8429\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4994 - val_loss: 0.8428\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4989 - val_loss: 0.8426\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4983 - val_loss: 0.8424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4978 - val_loss: 0.8422\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4973 - val_loss: 0.8420\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4967 - val_loss: 0.8419\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4962 - val_loss: 0.8417\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1963484.3822421303, my average MASE = 64800710.430740915\n",
      "Cluster 5, 1963484.3822421303\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8495 - val_loss: 4.3516\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8473 - val_loss: 4.3510\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8451 - val_loss: 4.3503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8429 - val_loss: 4.3497\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8408 - val_loss: 4.3491\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8386 - val_loss: 4.3485\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8365 - val_loss: 4.3479\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8344 - val_loss: 4.3473\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8323 - val_loss: 4.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8301 - val_loss: 4.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8280 - val_loss: 4.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8259 - val_loss: 4.3451\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8238 - val_loss: 4.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8217 - val_loss: 4.3440\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8197 - val_loss: 4.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8176 - val_loss: 4.3428\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8156 - val_loss: 4.3423\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8136 - val_loss: 4.3417\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8117 - val_loss: 4.3412\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8098 - val_loss: 4.3407\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 4.3403\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8061 - val_loss: 4.3399\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8042 - val_loss: 4.3395\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8023 - val_loss: 4.3390\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8004 - val_loss: 4.3386\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7986 - val_loss: 4.3382\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7967 - val_loss: 4.3378\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7949 - val_loss: 4.3374\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7930 - val_loss: 4.3370\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7912 - val_loss: 4.3365\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7893 - val_loss: 4.3361\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7874 - val_loss: 4.3357\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7856 - val_loss: 4.3353\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7839 - val_loss: 4.3349\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7822 - val_loss: 4.3345\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7805 - val_loss: 4.3341\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7787 - val_loss: 4.3338\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7771 - val_loss: 4.3334\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7754 - val_loss: 4.3330\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7738 - val_loss: 4.3327\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4.116072897890656, my average MASE = 12.21206426084865\n",
      "Cluster 6, 4.116072897890656\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3660 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3652 - val_loss: 0.3455\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3645 - val_loss: 0.3451\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3638 - val_loss: 0.3448\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3632 - val_loss: 0.3445\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3625 - val_loss: 0.3441\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3619 - val_loss: 0.3438\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3435\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3606 - val_loss: 0.3431\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3599 - val_loss: 0.3428\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3593 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3422\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3581 - val_loss: 0.3419\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3576 - val_loss: 0.3416\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3570 - val_loss: 0.3413\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3564 - val_loss: 0.3410\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3558 - val_loss: 0.3407\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3553 - val_loss: 0.3404\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3547 - val_loss: 0.3401\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3542 - val_loss: 0.3398\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3536 - val_loss: 0.3395\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3531 - val_loss: 0.3393\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3526 - val_loss: 0.3390\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3521 - val_loss: 0.3387\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3516 - val_loss: 0.3384\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3511 - val_loss: 0.3382\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3506 - val_loss: 0.3379\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3501 - val_loss: 0.3376\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3496 - val_loss: 0.3373\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3491 - val_loss: 0.3371\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3487 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3482 - val_loss: 0.3366\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3477 - val_loss: 0.3363\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3473 - val_loss: 0.3360\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3464 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3459 - val_loss: 0.3353\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3455 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3451 - val_loss: 0.3348\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3446 - val_loss: 0.3345\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 266.09609302896547, my average MASE = 71685898.00003502\n",
      "Cluster 8, 266.09609302896547\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=11, 11, 663, (11, 67)\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3610 - val_loss: 0.4969\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3601 - val_loss: 0.4969\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3592 - val_loss: 0.4970\n",
      "Epoch 3: early stopping\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.35712691602972574, my average MASE = 0.5241910168311086\n",
      "Cluster 0, 0.35712691602972574\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2752 - val_loss: 0.2714\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2747 - val_loss: 0.2712\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2742 - val_loss: 0.2710\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2737 - val_loss: 0.2707\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2733 - val_loss: 0.2705\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2728 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2723 - val_loss: 0.2701\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2718 - val_loss: 0.2699\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2714 - val_loss: 0.2697\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2709 - val_loss: 0.2695\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2704 - val_loss: 0.2693\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2700 - val_loss: 0.2691\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2695 - val_loss: 0.2690\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2691 - val_loss: 0.2688\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2687 - val_loss: 0.2686\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2682 - val_loss: 0.2684\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2678 - val_loss: 0.2682\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2673 - val_loss: 0.2680\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2669 - val_loss: 0.2678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2665 - val_loss: 0.2676\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2661 - val_loss: 0.2674\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.2672\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2653 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2649 - val_loss: 0.2669\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2645 - val_loss: 0.2667\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2641 - val_loss: 0.2665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2637 - val_loss: 0.2663\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2633 - val_loss: 0.2662\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2629 - val_loss: 0.2660\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2625 - val_loss: 0.2658\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2621 - val_loss: 0.2656\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2618 - val_loss: 0.2655\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2614 - val_loss: 0.2653\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2610 - val_loss: 0.2652\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2606 - val_loss: 0.2650\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2602 - val_loss: 0.2649\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2599 - val_loss: 0.2647\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2595 - val_loss: 0.2646\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2591 - val_loss: 0.2644\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2588 - val_loss: 0.2643\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 114.92828938190037, my average MASE = 64775351.69732988\n",
      "Cluster 1, 114.92828938190037\n",
      "Before prediction: train_X.shape=(21, 10, 67), train_y.shape=(21, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6587 - val_loss: 0.2666\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6569 - val_loss: 0.2655\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6551 - val_loss: 0.2645\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6533 - val_loss: 0.2635\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6515 - val_loss: 0.2624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6497 - val_loss: 0.2614\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6480 - val_loss: 0.2604\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6463 - val_loss: 0.2594\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6446 - val_loss: 0.2584\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6429 - val_loss: 0.2574\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6412 - val_loss: 0.2565\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6395 - val_loss: 0.2555\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6379 - val_loss: 0.2546\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6363 - val_loss: 0.2538\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6346 - val_loss: 0.2529\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6331 - val_loss: 0.2520\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6315 - val_loss: 0.2512\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6300 - val_loss: 0.2504\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6285 - val_loss: 0.2496\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6270 - val_loss: 0.2488\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6255 - val_loss: 0.2480\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6240 - val_loss: 0.2473\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6225 - val_loss: 0.2466\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6211 - val_loss: 0.2458\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6197 - val_loss: 0.2451\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6182 - val_loss: 0.2444\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6168 - val_loss: 0.2437\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6155 - val_loss: 0.2430\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6141 - val_loss: 0.2423\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6127 - val_loss: 0.2416\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6114 - val_loss: 0.2410\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6101 - val_loss: 0.2403\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6088 - val_loss: 0.2397\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6075 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6063 - val_loss: 0.2384\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6050 - val_loss: 0.2378\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6038 - val_loss: 0.2372\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6026 - val_loss: 0.2365\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6014 - val_loss: 0.2359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6002 - val_loss: 0.2353\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 26456338.054780327, my average MASE = 1170397376.6808207\n",
      "Cluster 2, 26456338.054780327\n",
      "Before prediction: train_X.shape=(62, 10, 67), train_y.shape=(62, 67), test_X.shape=(21, 10, 67), test_y.shape=(21, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3828 - val_loss: 0.5067\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3824 - val_loss: 0.5064\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3820 - val_loss: 0.5062\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3816 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3812 - val_loss: 0.5056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3808 - val_loss: 0.5053\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3804 - val_loss: 0.5051\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3801 - val_loss: 0.5048\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3797 - val_loss: 0.5045\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3793 - val_loss: 0.5043\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3790 - val_loss: 0.5040\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3786 - val_loss: 0.5038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3783 - val_loss: 0.5035\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3779 - val_loss: 0.5032\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3776 - val_loss: 0.5030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3772 - val_loss: 0.5027\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3769 - val_loss: 0.5025\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3765 - val_loss: 0.5022\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3762 - val_loss: 0.5020\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3758 - val_loss: 0.5017\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3755 - val_loss: 0.5015\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3752 - val_loss: 0.5012\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3748 - val_loss: 0.5010\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3745 - val_loss: 0.5008\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3742 - val_loss: 0.5005\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3738 - val_loss: 0.5003\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3735 - val_loss: 0.5000\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3732 - val_loss: 0.4998\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3729 - val_loss: 0.4995\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3726 - val_loss: 0.4993\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3722 - val_loss: 0.4991\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3719 - val_loss: 0.4988\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3716 - val_loss: 0.4986\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3713 - val_loss: 0.4984\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3710 - val_loss: 0.4982\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3707 - val_loss: 0.4979\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3704 - val_loss: 0.4977\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3701 - val_loss: 0.4975\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3698 - val_loss: 0.4973\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3695 - val_loss: 0.4971\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(21, 67), test_y.shape=(21, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 88.873907317969, my average MASE = 105114880.66517946\n",
      "Cluster 3, 88.873907317969\n",
      "Before prediction: train_X.shape=(58, 10, 67), train_y.shape=(58, 67), test_X.shape=(19, 10, 67), test_y.shape=(19, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6113 - val_loss: 0.3397\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6107 - val_loss: 0.3395\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6100 - val_loss: 0.3394\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6094 - val_loss: 0.3393\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6087 - val_loss: 0.3392\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6081 - val_loss: 0.3391\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6075 - val_loss: 0.3390\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6069 - val_loss: 0.3389\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6062 - val_loss: 0.3388\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6056 - val_loss: 0.3387\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6050 - val_loss: 0.3386\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6044 - val_loss: 0.3385\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6038 - val_loss: 0.3384\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6032 - val_loss: 0.3383\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6026 - val_loss: 0.3382\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6020 - val_loss: 0.3381\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6014 - val_loss: 0.3380\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6009 - val_loss: 0.3379\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6003 - val_loss: 0.3378\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5997 - val_loss: 0.3377\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5992 - val_loss: 0.3376\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5986 - val_loss: 0.3375\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5981 - val_loss: 0.3374\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5976 - val_loss: 0.3373\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5970 - val_loss: 0.3372\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5965 - val_loss: 0.3372\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5960 - val_loss: 0.3371\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5955 - val_loss: 0.3370\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5949 - val_loss: 0.3369\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5944 - val_loss: 0.3369\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5939 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5934 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5929 - val_loss: 0.3366\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5924 - val_loss: 0.3366\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5919 - val_loss: 0.3365\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5915 - val_loss: 0.3364\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5910 - val_loss: 0.3364\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5905 - val_loss: 0.3363\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5900 - val_loss: 0.3362\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5895 - val_loss: 0.3362\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(19, 67), test_y.shape=(19, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2288977.9462372796, my average MASE = 275894539.3328722\n",
      "Cluster 4, 2288977.9462372796\n",
      "Before prediction: train_X.shape=(22, 10, 67), train_y.shape=(22, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6507 - val_loss: 0.5866\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6499 - val_loss: 0.5864\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6491 - val_loss: 0.5862\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6483 - val_loss: 0.5861\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6475 - val_loss: 0.5859\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6467 - val_loss: 0.5857\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6459 - val_loss: 0.5855\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6451 - val_loss: 0.5854\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6443 - val_loss: 0.5852\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6435 - val_loss: 0.5851\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6427 - val_loss: 0.5849\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6420 - val_loss: 0.5848\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6412 - val_loss: 0.5846\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6405 - val_loss: 0.5844\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6397 - val_loss: 0.5843\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6389 - val_loss: 0.5841\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6382 - val_loss: 0.5840\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6374 - val_loss: 0.5838\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6367 - val_loss: 0.5837\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6359 - val_loss: 0.5836\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6352 - val_loss: 0.5834\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6345 - val_loss: 0.5833\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6337 - val_loss: 0.5832\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6330 - val_loss: 0.5830\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6323 - val_loss: 0.5829\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6316 - val_loss: 0.5827\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6309 - val_loss: 0.5826\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6302 - val_loss: 0.5825\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 0.5824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6288 - val_loss: 0.5822\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6281 - val_loss: 0.5821\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6275 - val_loss: 0.5820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6268 - val_loss: 0.5819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6261 - val_loss: 0.5818\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6254 - val_loss: 0.5816\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6248 - val_loss: 0.5815\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6241 - val_loss: 0.5814\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6235 - val_loss: 0.5813\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6228 - val_loss: 0.5811\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6222 - val_loss: 0.5810\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 56.939779008571485, my average MASE = 37107546.21609385\n",
      "Cluster 5, 56.939779008571485\n",
      "Before prediction: train_X.shape=(4681, 10, 67), train_y.shape=(4681, 67), test_X.shape=(1560, 10, 67), test_y.shape=(1560, 67)\n",
      "Epoch 1/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0785 - val_loss: 0.0245\n",
      "Epoch 2/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0726 - val_loss: 0.0222\n",
      "Epoch 3/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0688 - val_loss: 0.0210\n",
      "Epoch 4/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0661 - val_loss: 0.0201\n",
      "Epoch 5/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0638 - val_loss: 0.0195\n",
      "Epoch 6/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0620 - val_loss: 0.0189\n",
      "Epoch 7/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0604 - val_loss: 0.0185\n",
      "Epoch 8/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0590 - val_loss: 0.0182\n",
      "Epoch 9/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0579 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0569 - val_loss: 0.0176\n",
      "Epoch 11/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0560 - val_loss: 0.0174\n",
      "Epoch 12/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0552 - val_loss: 0.0172\n",
      "Epoch 13/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0545 - val_loss: 0.0171\n",
      "Epoch 14/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0539 - val_loss: 0.0169\n",
      "Epoch 15/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0533 - val_loss: 0.0168\n",
      "Epoch 16/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0528 - val_loss: 0.0167\n",
      "Epoch 17/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0524 - val_loss: 0.0166\n",
      "Epoch 18/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0519 - val_loss: 0.0165\n",
      "Epoch 19/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0516 - val_loss: 0.0165\n",
      "Epoch 20/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0512 - val_loss: 0.0164\n",
      "Epoch 21/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0509 - val_loss: 0.0163\n",
      "Epoch 22/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0505 - val_loss: 0.0163\n",
      "Epoch 23/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0502 - val_loss: 0.0162\n",
      "Epoch 24/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0500 - val_loss: 0.0162\n",
      "Epoch 25/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0497 - val_loss: 0.0161\n",
      "Epoch 26/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0495 - val_loss: 0.0161\n",
      "Epoch 27/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0492 - val_loss: 0.0161\n",
      "Epoch 28/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0490 - val_loss: 0.0160\n",
      "Epoch 29/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0488 - val_loss: 0.0160\n",
      "Epoch 30/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0486 - val_loss: 0.0159\n",
      "Epoch 31/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0485 - val_loss: 0.0159\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0483 - val_loss: 0.0158\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0481 - val_loss: 0.0158\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0480 - val_loss: 0.0158\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0479 - val_loss: 0.0157\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0477 - val_loss: 0.0157\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0476 - val_loss: 0.0157\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0475 - val_loss: 0.0156\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0474 - val_loss: 0.0156\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0473 - val_loss: 0.0156\n",
      "49/49 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1560, 67), test_y.shape=(1560, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 149408746.52177918, my average MASE = 566572768.961764\n",
      "Cluster 6, 149408746.52177918\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5377 - val_loss: 0.4682\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5358 - val_loss: 0.4667\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5339 - val_loss: 0.4653\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5320 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5302 - val_loss: 0.4624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5283 - val_loss: 0.4609\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5265 - val_loss: 0.4595\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5247 - val_loss: 0.4581\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5229 - val_loss: 0.4567\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5211 - val_loss: 0.4554\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5194 - val_loss: 0.4540\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5177 - val_loss: 0.4527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5160 - val_loss: 0.4514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5143 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5126 - val_loss: 0.4488\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5110 - val_loss: 0.4475\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5093 - val_loss: 0.4462\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5077 - val_loss: 0.4450\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5062 - val_loss: 0.4438\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5046 - val_loss: 0.4425\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5030 - val_loss: 0.4413\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5015 - val_loss: 0.4401\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5000 - val_loss: 0.4390\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4985 - val_loss: 0.4378\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4970 - val_loss: 0.4367\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4955 - val_loss: 0.4355\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4940 - val_loss: 0.4344\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4925 - val_loss: 0.4334\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4911 - val_loss: 0.4323\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4897 - val_loss: 0.4312\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4882 - val_loss: 0.4302\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4868 - val_loss: 0.4292\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4854 - val_loss: 0.4281\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4840 - val_loss: 0.4271\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4826 - val_loss: 0.4261\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4813 - val_loss: 0.4251\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4242\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4232\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4772 - val_loss: 0.4223\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4759 - val_loss: 0.4214\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3453236106.5511885, my average MASE = 6985920382.132476\n",
      "Cluster 7, 3453236106.5511885\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3084 - val_loss: 0.3104\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3075 - val_loss: 0.3100\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3066 - val_loss: 0.3095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3058 - val_loss: 0.3091\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3050 - val_loss: 0.3086\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3042 - val_loss: 0.3082\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3034 - val_loss: 0.3077\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3026 - val_loss: 0.3073\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3018 - val_loss: 0.3068\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3010 - val_loss: 0.3064\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3002 - val_loss: 0.3059\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2995 - val_loss: 0.3055\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2987 - val_loss: 0.3051\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2980 - val_loss: 0.3047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2973 - val_loss: 0.3043\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2965 - val_loss: 0.3039\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2958 - val_loss: 0.3035\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2951 - val_loss: 0.3031\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2944 - val_loss: 0.3027\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2937 - val_loss: 0.3024\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2930 - val_loss: 0.3020\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2924 - val_loss: 0.3017\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2917 - val_loss: 0.3014\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2911 - val_loss: 0.3011\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2904 - val_loss: 0.3008\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2898 - val_loss: 0.3006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2891 - val_loss: 0.3003\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2885 - val_loss: 0.3001\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2878 - val_loss: 0.2998\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2872 - val_loss: 0.2996\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2866 - val_loss: 0.2994\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2859 - val_loss: 0.2992\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2853 - val_loss: 0.2990\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2846 - val_loss: 0.2988\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2840 - val_loss: 0.2985\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2834 - val_loss: 0.2983\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2827 - val_loss: 0.2981\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2822 - val_loss: 0.2979\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2816 - val_loss: 0.2977\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2810 - val_loss: 0.2975\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2112740905793214, my average MASE = 0.3813496945040607\n",
      "Cluster 8, 0.2112740905793214\n",
      "Before prediction: train_X.shape=(33, 10, 67), train_y.shape=(33, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5052 - val_loss: 0.6961\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5045 - val_loss: 0.6956\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5038 - val_loss: 0.6950\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5030 - val_loss: 0.6945\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5023 - val_loss: 0.6939\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5016 - val_loss: 0.6934\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5009 - val_loss: 0.6928\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5002 - val_loss: 0.6923\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4995 - val_loss: 0.6918\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4988 - val_loss: 0.6913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.6908\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4975 - val_loss: 0.6903\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4968 - val_loss: 0.6898\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4961 - val_loss: 0.6893\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4955 - val_loss: 0.6888\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4948 - val_loss: 0.6883\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4942 - val_loss: 0.6879\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4935 - val_loss: 0.6874\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4929 - val_loss: 0.6869\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4923 - val_loss: 0.6865\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.6860\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4910 - val_loss: 0.6855\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4904 - val_loss: 0.6851\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4898 - val_loss: 0.6846\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4892 - val_loss: 0.6842\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4886 - val_loss: 0.6837\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4880 - val_loss: 0.6833\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4874 - val_loss: 0.6829\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4868 - val_loss: 0.6824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4863 - val_loss: 0.6820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4857 - val_loss: 0.6816\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4851 - val_loss: 0.6811\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4845 - val_loss: 0.6807\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4840 - val_loss: 0.6803\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4834 - val_loss: 0.6799\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4828 - val_loss: 0.6794\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6790\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4817 - val_loss: 0.6786\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4811 - val_loss: 0.6782\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4806 - val_loss: 0.6778\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 74.79960857799604, my average MASE = 23518054.91533832\n",
      "Cluster 9, 74.79960857799604\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3521 - val_loss: 0.2993\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3508 - val_loss: 0.2987\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3496 - val_loss: 0.2982\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3483 - val_loss: 0.2976\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3470 - val_loss: 0.2971\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3458 - val_loss: 0.2966\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3446 - val_loss: 0.2961\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3435 - val_loss: 0.2957\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3423 - val_loss: 0.2954\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3412 - val_loss: 0.2950\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3400 - val_loss: 0.2946\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3389 - val_loss: 0.2943\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3378 - val_loss: 0.2939\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3368 - val_loss: 0.2935\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3357 - val_loss: 0.2932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3347 - val_loss: 0.2928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3337 - val_loss: 0.2925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3326 - val_loss: 0.2921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3317 - val_loss: 0.2918\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3307 - val_loss: 0.2915\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3298 - val_loss: 0.2912\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3289 - val_loss: 0.2910\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3279 - val_loss: 0.2908\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.2905\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3261 - val_loss: 0.2903\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3252 - val_loss: 0.2901\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3244 - val_loss: 0.2899\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.2897\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3227 - val_loss: 0.2895\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3219 - val_loss: 0.2894\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3211 - val_loss: 0.2892\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3203 - val_loss: 0.2891\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3195 - val_loss: 0.2890\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3187 - val_loss: 0.2889\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3179 - val_loss: 0.2888\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3171 - val_loss: 0.2887\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3163 - val_loss: 0.2886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3155 - val_loss: 0.2886\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.2885\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3139 - val_loss: 0.2885\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.1864435054204945, my average MASE = 0.27675363785512175\n",
      "Cluster 10, 0.1864435054204945\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=2, 2, 18, (30612, 67)\n",
      "Before prediction: train_X.shape=(18361, 10, 67), train_y.shape=(18361, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.3015 - val_loss: 0.3194\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2836 - val_loss: 0.3051\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2695 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2585 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2510 - val_loss: 0.2789\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2456 - val_loss: 0.2737\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2410 - val_loss: 0.2693\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2369 - val_loss: 0.2653\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2332 - val_loss: 0.2616\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2298 - val_loss: 0.2584\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2267 - val_loss: 0.2555\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2238 - val_loss: 0.2531\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2212 - val_loss: 0.2509\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2190 - val_loss: 0.2490\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2172 - val_loss: 0.2474\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2156 - val_loss: 0.2461\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2143 - val_loss: 0.2448\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2120 - val_loss: 0.2428\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2110 - val_loss: 0.2420\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2101 - val_loss: 0.2412\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2092 - val_loss: 0.2404\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2084 - val_loss: 0.2395\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2077 - val_loss: 0.2390\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2070 - val_loss: 0.2383\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2064 - val_loss: 0.2377\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2058 - val_loss: 0.2371\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2052 - val_loss: 0.2365\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2047 - val_loss: 0.2361\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2041 - val_loss: 0.2356\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2352\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2032 - val_loss: 0.2348\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2020 - val_loss: 0.2336\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2016 - val_loss: 0.2332\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2013 - val_loss: 0.2329\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2009 - val_loss: 0.2327\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2006 - val_loss: 0.2324\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2321\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2046.5122369835897, my average MASE = 2805.5341357338157\n",
      "Cluster 0, 2046.5122369835897\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5756 - val_loss: 1.2952\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5738 - val_loss: 1.2950\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5721 - val_loss: 1.2949\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5703 - val_loss: 1.2948\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5686 - val_loss: 1.2947\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5670 - val_loss: 1.2946\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5653 - val_loss: 1.2945\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5637 - val_loss: 1.2944\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5621 - val_loss: 1.2943\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5605 - val_loss: 1.2941\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5589 - val_loss: 1.2940\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5573 - val_loss: 1.2939\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5558 - val_loss: 1.2937\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5542 - val_loss: 1.2936\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5527 - val_loss: 1.2934\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5512 - val_loss: 1.2932\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5497 - val_loss: 1.2930\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 1.2929\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5468 - val_loss: 1.2927\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 1.2925\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5440 - val_loss: 1.2924\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5426 - val_loss: 1.2922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5413 - val_loss: 1.2921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5400 - val_loss: 1.2920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5386 - val_loss: 1.2919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5374 - val_loss: 1.2918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 1.2918\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5349 - val_loss: 1.2917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5337 - val_loss: 1.2916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5325 - val_loss: 1.2915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5314 - val_loss: 1.2914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5302 - val_loss: 1.2912\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5290 - val_loss: 1.2911\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5279 - val_loss: 1.2909\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5268 - val_loss: 1.2907\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5256 - val_loss: 1.2905\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5246 - val_loss: 1.2903\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5235 - val_loss: 1.2902\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5224 - val_loss: 1.2901\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5213 - val_loss: 1.2900\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 950350834.5172157, my average MASE = 2745439088.6097794\n",
      "Cluster 1, 950350834.5172157\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=5, 5, 599, (8, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3119 - val_loss: 0.2829\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3116 - val_loss: 0.2829\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3112 - val_loss: 0.2828\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3109 - val_loss: 0.2828\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3106 - val_loss: 0.2828\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3102 - val_loss: 0.2827\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3099 - val_loss: 0.2827\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3096 - val_loss: 0.2827\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3092 - val_loss: 0.2827\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3089 - val_loss: 0.2826\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3086 - val_loss: 0.2826\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3083 - val_loss: 0.2826\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3080 - val_loss: 0.2826\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3077 - val_loss: 0.2825\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3074 - val_loss: 0.2825\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3070 - val_loss: 0.2825\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3067 - val_loss: 0.2825\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3064 - val_loss: 0.2824\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3061 - val_loss: 0.2824\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3058 - val_loss: 0.2824\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3055 - val_loss: 0.2823\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3052 - val_loss: 0.2823\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3049 - val_loss: 0.2823\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3047 - val_loss: 0.2822\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3044 - val_loss: 0.2822\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3041 - val_loss: 0.2822\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3038 - val_loss: 0.2821\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3035 - val_loss: 0.2821\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3032 - val_loss: 0.2821\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3029 - val_loss: 0.2820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3027 - val_loss: 0.2820\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3024 - val_loss: 0.2820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3021 - val_loss: 0.2819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.2819\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3016 - val_loss: 0.2818\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3013 - val_loss: 0.2818\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3010 - val_loss: 0.2818\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3008 - val_loss: 0.2817\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3005 - val_loss: 0.2817\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3002 - val_loss: 0.2816\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 104.97029321074898, my average MASE = 15924142.879668588\n",
      "Cluster 0, 104.97029321074898\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5420 - val_loss: 0.4071\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5399 - val_loss: 0.4062\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5378 - val_loss: 0.4054\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5357 - val_loss: 0.4045\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5337 - val_loss: 0.4037\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5316 - val_loss: 0.4029\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5296 - val_loss: 0.4021\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5276 - val_loss: 0.4013\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5257 - val_loss: 0.4005\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5237 - val_loss: 0.3998\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5218 - val_loss: 0.3990\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5199 - val_loss: 0.3983\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5179 - val_loss: 0.3975\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5161 - val_loss: 0.3968\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5142 - val_loss: 0.3961\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5124 - val_loss: 0.3954\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5106 - val_loss: 0.3947\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5088 - val_loss: 0.3940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5070 - val_loss: 0.3933\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5052 - val_loss: 0.3926\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5035 - val_loss: 0.3919\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5018 - val_loss: 0.3913\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5001 - val_loss: 0.3906\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4985 - val_loss: 0.3899\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4968 - val_loss: 0.3892\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.3886\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4936 - val_loss: 0.3879\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4920 - val_loss: 0.3873\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4905 - val_loss: 0.3866\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4889 - val_loss: 0.3860\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4874 - val_loss: 0.3853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4858 - val_loss: 0.3847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4843 - val_loss: 0.3840\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4828 - val_loss: 0.3834\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4813 - val_loss: 0.3828\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4798 - val_loss: 0.3821\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4783 - val_loss: 0.3815\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4769 - val_loss: 0.3809\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4754 - val_loss: 0.3803\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4740 - val_loss: 0.3797\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3145368812.0062547, my average MASE = 5974295545.526059\n",
      "Cluster 1, 3145368812.0062547\n",
      "Before prediction: train_X.shape=(2220, 10, 67), train_y.shape=(2220, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.5043 - val_loss: 0.3721\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4967 - val_loss: 0.3684\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4907 - val_loss: 0.3653\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4855 - val_loss: 0.3625\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4810 - val_loss: 0.3601\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4769 - val_loss: 0.3579\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4731 - val_loss: 0.3558\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4695 - val_loss: 0.3540\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4661 - val_loss: 0.3522\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4629 - val_loss: 0.3506\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4598 - val_loss: 0.3490\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4568 - val_loss: 0.3476\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4539 - val_loss: 0.3462\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4510 - val_loss: 0.3448\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4483 - val_loss: 0.3435\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4455 - val_loss: 0.3422\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4429 - val_loss: 0.3410\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4402 - val_loss: 0.3398\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4376 - val_loss: 0.3386\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4351 - val_loss: 0.3375\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4326 - val_loss: 0.3363\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4302 - val_loss: 0.3352\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4278 - val_loss: 0.3342\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4255 - val_loss: 0.3331\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4232 - val_loss: 0.3321\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4211 - val_loss: 0.3311\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4189 - val_loss: 0.3302\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4169 - val_loss: 0.3292\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4149 - val_loss: 0.3284\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4129 - val_loss: 0.3276\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4111 - val_loss: 0.3268\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4093 - val_loss: 0.3260\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4076 - val_loss: 0.3253\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4060 - val_loss: 0.3246\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4044 - val_loss: 0.3240\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4029 - val_loss: 0.3234\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4014 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4000 - val_loss: 0.3222\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3986 - val_loss: 0.3217\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3972 - val_loss: 0.3211\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 487.922050733615, my average MASE = 1880.6635092100216\n",
      "Cluster 2, 487.922050733615\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1089 - val_loss: 0.0991\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1039 - val_loss: 0.0970\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0998 - val_loss: 0.0956\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0965 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0938\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0911 - val_loss: 0.0932\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0889 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0869 - val_loss: 0.0924\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0852 - val_loss: 0.0922\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0836 - val_loss: 0.0920\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0821 - val_loss: 0.0918\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0808 - val_loss: 0.0917\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0795 - val_loss: 0.0915\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0783 - val_loss: 0.0913\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0773 - val_loss: 0.0912\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0763 - val_loss: 0.0910\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0908\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0744 - val_loss: 0.0907\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0736 - val_loss: 0.0905\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0903\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0901\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0900\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0708 - val_loss: 0.0899\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0897\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0696 - val_loss: 0.0896\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0690 - val_loss: 0.0895\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0894\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0680 - val_loss: 0.0893\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0675 - val_loss: 0.0892\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0892\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0666 - val_loss: 0.0891\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0661 - val_loss: 0.0890\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0658 - val_loss: 0.0890\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0654 - val_loss: 0.0889\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0650 - val_loss: 0.0889\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0647 - val_loss: 0.0888\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0644 - val_loss: 0.0888\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0888\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0887\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0636 - val_loss: 0.0887\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1152398695.5185678, my average MASE = 7118534712.468365\n",
      "Cluster 3, 1152398695.5185678\n",
      "Before prediction: train_X.shape=(156, 10, 67), train_y.shape=(156, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5146 - val_loss: 0.4378\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5133 - val_loss: 0.4370\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5122 - val_loss: 0.4361\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5111 - val_loss: 0.4352\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5100 - val_loss: 0.4344\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5089 - val_loss: 0.4335\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5078 - val_loss: 0.4327\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5068 - val_loss: 0.4319\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5057 - val_loss: 0.4311\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4303\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5037 - val_loss: 0.4296\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5028 - val_loss: 0.4288\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5018 - val_loss: 0.4281\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5008 - val_loss: 0.4273\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4999 - val_loss: 0.4266\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4990 - val_loss: 0.4259\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4981 - val_loss: 0.4252\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4972 - val_loss: 0.4245\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4963 - val_loss: 0.4238\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4954 - val_loss: 0.4232\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4945 - val_loss: 0.4225\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4937 - val_loss: 0.4219\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4929 - val_loss: 0.4213\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4920 - val_loss: 0.4207\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4912 - val_loss: 0.4201\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4905 - val_loss: 0.4195\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4897 - val_loss: 0.4189\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4889 - val_loss: 0.4183\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4881 - val_loss: 0.4177\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4874 - val_loss: 0.4172\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4867 - val_loss: 0.4166\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4859 - val_loss: 0.4161\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4852 - val_loss: 0.4155\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4845 - val_loss: 0.4150\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4838 - val_loss: 0.4145\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4831 - val_loss: 0.4139\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4824 - val_loss: 0.4134\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4817 - val_loss: 0.4129\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4811 - val_loss: 0.4124\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4804 - val_loss: 0.4119\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 117.29272898284657, my average MASE = 138077149.3198319\n",
      "Cluster 4, 117.29272898284657\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=7, 7, 49, (317, 67)\n",
      "Before prediction: train_X.shape=(184, 10, 67), train_y.shape=(184, 67), test_X.shape=(61, 10, 67), test_y.shape=(61, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6997 - val_loss: 0.6374\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6982 - val_loss: 0.6363\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6968 - val_loss: 0.6352\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6954 - val_loss: 0.6341\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.6331\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6927 - val_loss: 0.6320\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.6310\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6901 - val_loss: 0.6300\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6889 - val_loss: 0.6290\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6876 - val_loss: 0.6281\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6864 - val_loss: 0.6272\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6852 - val_loss: 0.6262\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6840 - val_loss: 0.6253\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6829 - val_loss: 0.6244\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6818 - val_loss: 0.6235\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6807 - val_loss: 0.6227\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6796 - val_loss: 0.6218\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6785 - val_loss: 0.6210\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6774 - val_loss: 0.6202\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6763 - val_loss: 0.6194\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.6186\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6743 - val_loss: 0.6178\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6733 - val_loss: 0.6171\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6723 - val_loss: 0.6163\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6713 - val_loss: 0.6156\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6704 - val_loss: 0.6149\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6694 - val_loss: 0.6142\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6685 - val_loss: 0.6135\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6676 - val_loss: 0.6127\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6666 - val_loss: 0.6121\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6658 - val_loss: 0.6114\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6649 - val_loss: 0.6107\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6640 - val_loss: 0.6100\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6631 - val_loss: 0.6093\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6622 - val_loss: 0.6086\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6614 - val_loss: 0.6079\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6605 - val_loss: 0.6073\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6597 - val_loss: 0.6066\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6588 - val_loss: 0.6060\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6580 - val_loss: 0.6053\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(61, 67), test_y.shape=(61, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 140.79883300988942, my average MASE = 132025753.41047312\n",
      "Cluster 0, 140.79883300988942\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5180 - val_loss: 0.4305\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5161 - val_loss: 0.4294\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5142 - val_loss: 0.4283\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5123 - val_loss: 0.4272\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5104 - val_loss: 0.4261\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5085 - val_loss: 0.4251\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5067 - val_loss: 0.4241\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5049 - val_loss: 0.4230\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.4221\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5013 - val_loss: 0.4211\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4996 - val_loss: 0.4202\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4978 - val_loss: 0.4193\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4961 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4944 - val_loss: 0.4175\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4927 - val_loss: 0.4166\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4911 - val_loss: 0.4158\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4895 - val_loss: 0.4149\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4879 - val_loss: 0.4141\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4863 - val_loss: 0.4133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4847 - val_loss: 0.4126\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4118\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4816 - val_loss: 0.4110\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4801 - val_loss: 0.4103\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4787 - val_loss: 0.4095\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4772 - val_loss: 0.4088\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4758 - val_loss: 0.4080\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4743 - val_loss: 0.4073\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4729 - val_loss: 0.4066\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4715 - val_loss: 0.4058\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4701 - val_loss: 0.4051\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4687 - val_loss: 0.4044\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4673 - val_loss: 0.4038\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4660 - val_loss: 0.4031\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4646 - val_loss: 0.4024\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4633 - val_loss: 0.4017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4620 - val_loss: 0.4010\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4607 - val_loss: 0.4004\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4594 - val_loss: 0.3997\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4582 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4569 - val_loss: 0.3985\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3225148693.3924103, my average MASE = 6345532768.562708\n",
      "Cluster 1, 3225148693.3924103\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1129 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1075 - val_loss: 0.0981\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1032 - val_loss: 0.0968\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0996 - val_loss: 0.0960\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0965 - val_loss: 0.0953\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0938 - val_loss: 0.0949\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0913 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0892 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0872 - val_loss: 0.0938\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0854 - val_loss: 0.0935\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0838 - val_loss: 0.0933\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0823 - val_loss: 0.0931\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0809 - val_loss: 0.0928\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0796 - val_loss: 0.0926\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0784 - val_loss: 0.0924\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0773 - val_loss: 0.0921\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0762 - val_loss: 0.0919\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0752 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0743 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0734 - val_loss: 0.0913\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0726 - val_loss: 0.0912\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0719 - val_loss: 0.0910\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0907\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0699 - val_loss: 0.0906\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0693 - val_loss: 0.0904\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0687 - val_loss: 0.0903\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0682 - val_loss: 0.0903\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0677 - val_loss: 0.0902\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0901\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0668 - val_loss: 0.0901\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0663 - val_loss: 0.0900\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0899\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0655 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0898\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0648 - val_loss: 0.0897\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0645 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0636 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1209643109.1461504, my average MASE = 20216236756.2103\n",
      "Cluster 2, 1209643109.1461504\n",
      "Before prediction: train_X.shape=(47, 10, 67), train_y.shape=(47, 67), test_X.shape=(16, 10, 67), test_y.shape=(16, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4112 - val_loss: 0.3544\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.3542\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4104 - val_loss: 0.3540\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4100 - val_loss: 0.3538\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4095 - val_loss: 0.3536\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4091 - val_loss: 0.3534\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4087 - val_loss: 0.3533\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4083 - val_loss: 0.3531\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4079 - val_loss: 0.3529\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4075 - val_loss: 0.3527\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4071 - val_loss: 0.3525\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4067 - val_loss: 0.3524\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4063 - val_loss: 0.3522\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4059 - val_loss: 0.3520\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4055 - val_loss: 0.3519\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4051 - val_loss: 0.3517\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4047 - val_loss: 0.3515\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4043 - val_loss: 0.3514\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4039 - val_loss: 0.3512\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3511\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4032 - val_loss: 0.3509\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4028 - val_loss: 0.3508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4024 - val_loss: 0.3506\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4020 - val_loss: 0.3505\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4017 - val_loss: 0.3503\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4009 - val_loss: 0.3501\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4006 - val_loss: 0.3499\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4002 - val_loss: 0.3498\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3999 - val_loss: 0.3497\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.3495\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3992 - val_loss: 0.3494\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.3493\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3985 - val_loss: 0.3492\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3982 - val_loss: 0.3491\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3978 - val_loss: 0.3489\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3975 - val_loss: 0.3488\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3972 - val_loss: 0.3487\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3968 - val_loss: 0.3486\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3965 - val_loss: 0.3485\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(16, 67), test_y.shape=(16, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 66.79284837728264, my average MASE = 54990938.33317367\n",
      "Cluster 3, 66.79284837728264\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5009 - val_loss: 0.4222\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4998 - val_loss: 0.4214\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4988 - val_loss: 0.4207\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4978 - val_loss: 0.4200\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4968 - val_loss: 0.4193\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4958 - val_loss: 0.4186\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4949 - val_loss: 0.4179\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4939 - val_loss: 0.4172\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4930 - val_loss: 0.4165\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4921 - val_loss: 0.4159\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4912 - val_loss: 0.4153\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4903 - val_loss: 0.4146\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4894 - val_loss: 0.4140\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4886 - val_loss: 0.4134\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4877 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4869 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4861 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4853 - val_loss: 0.4111\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4845 - val_loss: 0.4105\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4837 - val_loss: 0.4100\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4829 - val_loss: 0.4094\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4822 - val_loss: 0.4089\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4814 - val_loss: 0.4084\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4807 - val_loss: 0.4078\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4799 - val_loss: 0.4073\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4792 - val_loss: 0.4068\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4785 - val_loss: 0.4063\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4777 - val_loss: 0.4058\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4770 - val_loss: 0.4052\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4763 - val_loss: 0.4047\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4756 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4749 - val_loss: 0.4037\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4742 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4735 - val_loss: 0.4027\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4728 - val_loss: 0.4023\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4721 - val_loss: 0.4018\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4715 - val_loss: 0.4013\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4708 - val_loss: 0.4008\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4701 - val_loss: 0.4003\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4695 - val_loss: 0.3999\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.45341483860946, my average MASE = 95916870.45268953\n",
      "Cluster 4, 127.45341483860946\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2476 - val_loss: 0.2883\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2353 - val_loss: 0.2762\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2258 - val_loss: 0.2666\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2185 - val_loss: 0.2589\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2127 - val_loss: 0.2526\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2078 - val_loss: 0.2473\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2036 - val_loss: 0.2426\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1999 - val_loss: 0.2383\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1966 - val_loss: 0.2346\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1935 - val_loss: 0.2311\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1907 - val_loss: 0.2280\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1881 - val_loss: 0.2251\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1857 - val_loss: 0.2225\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1834 - val_loss: 0.2200\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1813 - val_loss: 0.2178\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1794 - val_loss: 0.2157\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1777 - val_loss: 0.2137\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1760 - val_loss: 0.2120\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1746 - val_loss: 0.2103\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1732 - val_loss: 0.2087\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1719 - val_loss: 0.2072\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1707 - val_loss: 0.2058\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1695 - val_loss: 0.2045\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2032\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1674 - val_loss: 0.2020\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1664 - val_loss: 0.2009\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1655 - val_loss: 0.1998\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1646 - val_loss: 0.1988\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1638 - val_loss: 0.1978\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1630 - val_loss: 0.1968\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1622 - val_loss: 0.1960\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1614 - val_loss: 0.1951\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1607 - val_loss: 0.1943\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1600 - val_loss: 0.1935\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1594 - val_loss: 0.1927\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1587 - val_loss: 0.1920\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1913\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1575 - val_loss: 0.1906\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1570 - val_loss: 0.1899\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1893\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 224.71735313764052, my average MASE = 374017026.3746446\n",
      "Cluster 5, 224.71735313764052\n",
      "Before prediction: train_X.shape=(51, 10, 67), train_y.shape=(51, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4065 - val_loss: 0.3790\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4060 - val_loss: 0.3788\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4055 - val_loss: 0.3787\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4049 - val_loss: 0.3786\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4044 - val_loss: 0.3784\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4038 - val_loss: 0.3783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4033 - val_loss: 0.3782\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4028 - val_loss: 0.3780\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4023 - val_loss: 0.3779\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4018 - val_loss: 0.3778\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4013 - val_loss: 0.3776\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3775\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4003 - val_loss: 0.3774\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3773\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3993 - val_loss: 0.3771\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3988 - val_loss: 0.3770\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3984 - val_loss: 0.3769\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3768\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3975 - val_loss: 0.3767\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3970 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3966 - val_loss: 0.3764\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3763\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3762\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3953 - val_loss: 0.3761\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3949 - val_loss: 0.3760\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3945 - val_loss: 0.3759\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3941 - val_loss: 0.3757\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3937 - val_loss: 0.3756\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3933 - val_loss: 0.3755\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3929 - val_loss: 0.3754\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3925 - val_loss: 0.3753\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3921 - val_loss: 0.3752\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3917 - val_loss: 0.3751\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3913 - val_loss: 0.3750\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3749\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3905 - val_loss: 0.3748\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3902 - val_loss: 0.3747\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3898 - val_loss: 0.3745\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3894 - val_loss: 0.3744\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3891 - val_loss: 0.3743\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 82.26261385879712, my average MASE = 20260153.97451399\n",
      "Cluster 6, 82.26261385879712\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=9, 9, 48, (301, 67)\n",
      "Before prediction: train_X.shape=(174, 10, 67), train_y.shape=(174, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7089 - val_loss: 0.5627\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7074 - val_loss: 0.5619\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7059 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7045 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7031 - val_loss: 0.5598\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7017 - val_loss: 0.5591\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7004 - val_loss: 0.5585\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6991 - val_loss: 0.5578\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6979 - val_loss: 0.5572\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6966 - val_loss: 0.5566\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6954 - val_loss: 0.5559\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.5553\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6930 - val_loss: 0.5548\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6918 - val_loss: 0.5542\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6907 - val_loss: 0.5536\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6895 - val_loss: 0.5531\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6884 - val_loss: 0.5525\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6873 - val_loss: 0.5520\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6863 - val_loss: 0.5515\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6852 - val_loss: 0.5509\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6842 - val_loss: 0.5504\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6831 - val_loss: 0.5499\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6821 - val_loss: 0.5494\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6811 - val_loss: 0.5489\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6801 - val_loss: 0.5484\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6792 - val_loss: 0.5479\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6782 - val_loss: 0.5475\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6772 - val_loss: 0.5470\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.5465\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.5461\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6744 - val_loss: 0.5456\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6735 - val_loss: 0.5452\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6726 - val_loss: 0.5447\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5443\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6707 - val_loss: 0.5439\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6698 - val_loss: 0.5434\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6689 - val_loss: 0.5430\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6680 - val_loss: 0.5426\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6671 - val_loss: 0.5422\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6663 - val_loss: 0.5417\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 144.45290178213432, my average MASE = 192607450.5447097\n",
      "Cluster 0, 144.45290178213432\n",
      "Before prediction: train_X.shape=(86, 10, 67), train_y.shape=(86, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3954 - val_loss: 0.4825\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3947 - val_loss: 0.4820\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3940 - val_loss: 0.4815\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3933 - val_loss: 0.4810\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3927 - val_loss: 0.4806\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3921 - val_loss: 0.4801\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4797\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3909 - val_loss: 0.4793\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3903 - val_loss: 0.4789\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3898 - val_loss: 0.4785\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3892 - val_loss: 0.4781\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3887 - val_loss: 0.4777\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4774\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3877 - val_loss: 0.4770\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3872 - val_loss: 0.4767\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4763\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3862 - val_loss: 0.4760\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.4757\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3853 - val_loss: 0.4753\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3848 - val_loss: 0.4750\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3844 - val_loss: 0.4747\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3840 - val_loss: 0.4744\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3835 - val_loss: 0.4741\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3831 - val_loss: 0.4738\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3827 - val_loss: 0.4735\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3822 - val_loss: 0.4732\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3818 - val_loss: 0.4729\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3814 - val_loss: 0.4726\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3810 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3806 - val_loss: 0.4720\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3802 - val_loss: 0.4717\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3798 - val_loss: 0.4714\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.4711\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3790 - val_loss: 0.4708\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3786 - val_loss: 0.4705\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3783 - val_loss: 0.4703\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3779 - val_loss: 0.4700\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3775 - val_loss: 0.4697\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3771 - val_loss: 0.4695\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3768 - val_loss: 0.4692\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 261.83661307224526, my average MASE = 165152999.01271424\n",
      "Cluster 1, 261.83661307224526\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3860 - val_loss: 0.4764\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3839 - val_loss: 0.4752\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3818 - val_loss: 0.4741\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3798 - val_loss: 0.4730\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3778 - val_loss: 0.4719\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3758 - val_loss: 0.4709\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3738 - val_loss: 0.4699\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3718 - val_loss: 0.4689\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3699 - val_loss: 0.4680\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3680 - val_loss: 0.4670\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4660\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3643 - val_loss: 0.4650\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.4640\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3606 - val_loss: 0.4630\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3588 - val_loss: 0.4620\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3570 - val_loss: 0.4610\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3553 - val_loss: 0.4599\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3535 - val_loss: 0.4588\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3518 - val_loss: 0.4578\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3501 - val_loss: 0.4567\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3484 - val_loss: 0.4557\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.4547\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3452 - val_loss: 0.4537\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3437 - val_loss: 0.4528\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3422 - val_loss: 0.4521\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3407 - val_loss: 0.4513\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.4506\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3378 - val_loss: 0.4498\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3363 - val_loss: 0.4493\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3349 - val_loss: 0.4487\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3336 - val_loss: 0.4481\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3323 - val_loss: 0.4475\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3311 - val_loss: 0.4470\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3299 - val_loss: 0.4464\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3287 - val_loss: 0.4459\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3276 - val_loss: 0.4453\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3264 - val_loss: 0.4447\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3253 - val_loss: 0.4441\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3241 - val_loss: 0.4436\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3231 - val_loss: 0.4430\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.29600762869721386, my average MASE = 0.4272698543687938\n",
      "Cluster 2, 0.29600762869721386\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4866 - val_loss: 0.4310\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4848 - val_loss: 0.4300\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4830 - val_loss: 0.4290\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4812 - val_loss: 0.4280\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.4271\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4777 - val_loss: 0.4261\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4760 - val_loss: 0.4252\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4744 - val_loss: 0.4243\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4727 - val_loss: 0.4235\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4711 - val_loss: 0.4226\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4695 - val_loss: 0.4217\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4679 - val_loss: 0.4209\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4663 - val_loss: 0.4200\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4648 - val_loss: 0.4192\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4633 - val_loss: 0.4184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4618 - val_loss: 0.4175\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4603 - val_loss: 0.4167\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4589 - val_loss: 0.4159\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4574 - val_loss: 0.4150\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4560 - val_loss: 0.4142\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4546 - val_loss: 0.4134\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4532 - val_loss: 0.4126\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4518 - val_loss: 0.4118\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4504 - val_loss: 0.4109\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4491 - val_loss: 0.4101\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4477 - val_loss: 0.4093\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4464 - val_loss: 0.4085\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4451 - val_loss: 0.4077\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4438 - val_loss: 0.4069\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4425 - val_loss: 0.4061\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4412 - val_loss: 0.4053\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4399 - val_loss: 0.4045\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4387 - val_loss: 0.4037\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4029\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4362 - val_loss: 0.4021\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4350 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4337 - val_loss: 0.4006\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4325 - val_loss: 0.3998\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4313 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4301 - val_loss: 0.3983\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3346396028.9972167, my average MASE = 7814754000.575592\n",
      "Cluster 3, 3346396028.9972167\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3142 - val_loss: 0.7771\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3138 - val_loss: 0.7770\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3135 - val_loss: 0.7769\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3131 - val_loss: 0.7768\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3127 - val_loss: 0.7767\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3123 - val_loss: 0.7765\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3119 - val_loss: 0.7764\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3116 - val_loss: 0.7763\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3112 - val_loss: 0.7762\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3108 - val_loss: 0.7761\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3105 - val_loss: 0.7759\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3101 - val_loss: 0.7758\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3097 - val_loss: 0.7757\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3094 - val_loss: 0.7756\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3090 - val_loss: 0.7755\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3087 - val_loss: 0.7754\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3083 - val_loss: 0.7753\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3080 - val_loss: 0.7752\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3076 - val_loss: 0.7751\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3073 - val_loss: 0.7749\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3069 - val_loss: 0.7748\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3066 - val_loss: 0.7747\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3063 - val_loss: 0.7746\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3059 - val_loss: 0.7746\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3056 - val_loss: 0.7745\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3053 - val_loss: 0.7744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3049 - val_loss: 0.7743\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3046 - val_loss: 0.7742\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3043 - val_loss: 0.7741\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3040 - val_loss: 0.7740\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3037 - val_loss: 0.7739\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3033 - val_loss: 0.7739\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3030 - val_loss: 0.7738\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3027 - val_loss: 0.7737\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3024 - val_loss: 0.7736\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3021 - val_loss: 0.7735\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.7734\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3015 - val_loss: 0.7733\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3012 - val_loss: 0.7732\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3009 - val_loss: 0.7731\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 93.69104182165661, my average MASE = 20945629.206220664\n",
      "Cluster 4, 93.69104182165661\n",
      "Before prediction: train_X.shape=(89, 10, 67), train_y.shape=(89, 67), test_X.shape=(30, 10, 67), test_y.shape=(30, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3424 - val_loss: 0.3360\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3416 - val_loss: 0.3355\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3408 - val_loss: 0.3350\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3400 - val_loss: 0.3346\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.3341\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3386 - val_loss: 0.3337\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3379 - val_loss: 0.3333\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3372 - val_loss: 0.3329\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3365 - val_loss: 0.3324\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3358 - val_loss: 0.3320\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3351 - val_loss: 0.3316\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3344 - val_loss: 0.3312\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3338 - val_loss: 0.3309\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3331 - val_loss: 0.3305\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3325 - val_loss: 0.3301\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3319 - val_loss: 0.3297\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3312 - val_loss: 0.3293\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3306 - val_loss: 0.3290\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3300 - val_loss: 0.3286\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3294 - val_loss: 0.3282\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3288 - val_loss: 0.3279\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3282 - val_loss: 0.3275\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3276 - val_loss: 0.3272\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3271 - val_loss: 0.3268\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3265 - val_loss: 0.3265\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3260 - val_loss: 0.3262\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3254 - val_loss: 0.3258\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3249 - val_loss: 0.3255\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3244 - val_loss: 0.3252\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.3249\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3234 - val_loss: 0.3246\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3228 - val_loss: 0.3243\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3223 - val_loss: 0.3240\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3237\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3214 - val_loss: 0.3234\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3231\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3204 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3199 - val_loss: 0.3225\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3195 - val_loss: 0.3222\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3190 - val_loss: 0.3219\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(30, 67), test_y.shape=(30, 67)\n",
      "average MASE = 188.45046029060867, my average MASE = 121680879.21353056\n",
      "Cluster 5, 188.45046029060867\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1120 - val_loss: 0.1007\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0987\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1025 - val_loss: 0.0974\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0990 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0960 - val_loss: 0.0954\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0933 - val_loss: 0.0947\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0942\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0888 - val_loss: 0.0938\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0868 - val_loss: 0.0934\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0931\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0834 - val_loss: 0.0928\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0819 - val_loss: 0.0926\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0806 - val_loss: 0.0923\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0793 - val_loss: 0.0921\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0781 - val_loss: 0.0919\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0770 - val_loss: 0.0917\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0759 - val_loss: 0.0916\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0749 - val_loss: 0.0914\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0740 - val_loss: 0.0912\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0732 - val_loss: 0.0911\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0724 - val_loss: 0.0910\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0716 - val_loss: 0.0909\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0709 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0908\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0695 - val_loss: 0.0907\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0689 - val_loss: 0.0906\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0683 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0678 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0673 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0660 - val_loss: 0.0902\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0901\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0900\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0645 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0637 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0634 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1073797047.1669116, my average MASE = 13075073766.705614\n",
      "Cluster 6, 1073797047.1669116\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2348 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2252 - val_loss: 0.2653\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2178 - val_loss: 0.2575\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2120 - val_loss: 0.2511\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2071 - val_loss: 0.2457\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2029 - val_loss: 0.2409\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1991 - val_loss: 0.2366\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1956 - val_loss: 0.2328\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1924 - val_loss: 0.2293\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1895 - val_loss: 0.2261\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1868 - val_loss: 0.2231\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2203\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1820 - val_loss: 0.2178\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1799 - val_loss: 0.2155\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1762 - val_loss: 0.2114\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1745 - val_loss: 0.2096\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1730 - val_loss: 0.2079\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1715 - val_loss: 0.2063\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1702 - val_loss: 0.2048\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1689 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1678 - val_loss: 0.2020\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1666 - val_loss: 0.2007\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1656 - val_loss: 0.1995\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1646 - val_loss: 0.1984\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1636 - val_loss: 0.1973\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1627 - val_loss: 0.1962\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1619 - val_loss: 0.1952\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1610 - val_loss: 0.1943\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1934\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1595 - val_loss: 0.1925\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1588 - val_loss: 0.1917\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1909\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1574 - val_loss: 0.1901\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1568 - val_loss: 0.1894\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1886\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1556 - val_loss: 0.1880\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1550 - val_loss: 0.1873\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1867\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1539 - val_loss: 0.1860\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 180.26488918007823, my average MASE = 179278352.44392422\n",
      "Cluster 7, 180.26488918007823\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=11, 11, 904, (6, 67)\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3401 - val_loss: 0.3875\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3395 - val_loss: 0.3872\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3390 - val_loss: 0.3870\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3385 - val_loss: 0.3868\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3380 - val_loss: 0.3866\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3375 - val_loss: 0.3863\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3370 - val_loss: 0.3861\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3366 - val_loss: 0.3859\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3361 - val_loss: 0.3856\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3357 - val_loss: 0.3854\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3352 - val_loss: 0.3852\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3348 - val_loss: 0.3850\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3343 - val_loss: 0.3848\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3339 - val_loss: 0.3846\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3335 - val_loss: 0.3844\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3331 - val_loss: 0.3842\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3327 - val_loss: 0.3840\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3323 - val_loss: 0.3837\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3318 - val_loss: 0.3835\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3314 - val_loss: 0.3833\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.3831\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3307 - val_loss: 0.3829\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3303 - val_loss: 0.3827\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3825\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3295 - val_loss: 0.3823\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3292 - val_loss: 0.3821\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3288 - val_loss: 0.3820\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3284 - val_loss: 0.3818\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3281 - val_loss: 0.3816\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.3814\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3274 - val_loss: 0.3812\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.3810\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3267 - val_loss: 0.3808\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3263 - val_loss: 0.3806\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3260 - val_loss: 0.3805\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3257 - val_loss: 0.3803\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3254 - val_loss: 0.3801\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3250 - val_loss: 0.3799\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3247 - val_loss: 0.3798\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.3796\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 122.2598699731945, my average MASE = 164200403.28208458\n",
      "Cluster 0, 122.2598699731945\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5011 - val_loss: 0.7038\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5005 - val_loss: 0.7036\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4998 - val_loss: 0.7034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4991 - val_loss: 0.7032\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4984 - val_loss: 0.7030\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4978 - val_loss: 0.7028\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4971 - val_loss: 0.7026\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4964 - val_loss: 0.7024\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4958 - val_loss: 0.7022\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4951 - val_loss: 0.7020\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4945 - val_loss: 0.7017\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4938 - val_loss: 0.7015\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4932 - val_loss: 0.7014\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4926 - val_loss: 0.7012\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4919 - val_loss: 0.7010\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4913 - val_loss: 0.7008\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4907 - val_loss: 0.7006\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4901 - val_loss: 0.7004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4894 - val_loss: 0.7002\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4888 - val_loss: 0.7000\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4882 - val_loss: 0.6998\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4877 - val_loss: 0.6997\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4871 - val_loss: 0.6995\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4865 - val_loss: 0.6993\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4859 - val_loss: 0.6991\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4853 - val_loss: 0.6989\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4847 - val_loss: 0.6988\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4842 - val_loss: 0.6986\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4836 - val_loss: 0.6984\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4831 - val_loss: 0.6983\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4825 - val_loss: 0.6981\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4820 - val_loss: 0.6979\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4815 - val_loss: 0.6978\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4809 - val_loss: 0.6976\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4804 - val_loss: 0.6974\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4799 - val_loss: 0.6973\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4794 - val_loss: 0.6971\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4789 - val_loss: 0.6970\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4783 - val_loss: 0.6968\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4778 - val_loss: 0.6966\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2966824.6919978233, my average MASE = 79205816.45072892\n",
      "Cluster 1, 2966824.6919978233\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1998 - val_loss: 0.3035\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1993 - val_loss: 0.3034\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1988 - val_loss: 0.3034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1982 - val_loss: 0.3033\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1977 - val_loss: 0.3033\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1972 - val_loss: 0.3032\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1967 - val_loss: 0.3032\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1962 - val_loss: 0.3032\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1957 - val_loss: 0.3031\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1952 - val_loss: 0.3031\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1947 - val_loss: 0.3031\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1942 - val_loss: 0.3031\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1938 - val_loss: 0.3030\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1933 - val_loss: 0.3030\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1928 - val_loss: 0.3030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1924 - val_loss: 0.3030\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1919 - val_loss: 0.3030\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1915 - val_loss: 0.3030\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1911 - val_loss: 0.3030\n",
      "Epoch 19: early stopping\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 130.97936905502368, my average MASE = 132554988.34305501\n",
      "Cluster 2, 130.97936905502368\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4496 - val_loss: 0.4061\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4490 - val_loss: 0.4060\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4484 - val_loss: 0.4058\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4478 - val_loss: 0.4057\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4472 - val_loss: 0.4056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4466 - val_loss: 0.4055\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4461 - val_loss: 0.4054\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4455 - val_loss: 0.4053\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4450 - val_loss: 0.4052\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4444 - val_loss: 0.4051\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4439 - val_loss: 0.4050\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4433 - val_loss: 0.4049\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4428 - val_loss: 0.4048\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4423 - val_loss: 0.4047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4417 - val_loss: 0.4046\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4412 - val_loss: 0.4045\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4407 - val_loss: 0.4044\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4402 - val_loss: 0.4043\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4397 - val_loss: 0.4042\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4041\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4387 - val_loss: 0.4040\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4382 - val_loss: 0.4039\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4377 - val_loss: 0.4038\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4372 - val_loss: 0.4037\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4367 - val_loss: 0.4036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4362 - val_loss: 0.4035\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4357 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4352 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4032\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4343 - val_loss: 0.4031\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4338 - val_loss: 0.4030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4333 - val_loss: 0.4029\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4329 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4028\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4027\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4315 - val_loss: 0.4026\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4311 - val_loss: 0.4025\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4306 - val_loss: 0.4024\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4302 - val_loss: 0.4023\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4297 - val_loss: 0.4022\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1437.7621485075726, my average MASE = 33408169.939470924\n",
      "Cluster 3, 1437.7621485075726\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3791 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3768 - val_loss: 0.4780\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3745 - val_loss: 0.4765\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4750\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3700 - val_loss: 0.4735\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3678 - val_loss: 0.4721\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3657 - val_loss: 0.4707\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3636 - val_loss: 0.4693\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3616 - val_loss: 0.4679\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3595 - val_loss: 0.4665\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3576 - val_loss: 0.4652\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3556 - val_loss: 0.4639\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3537 - val_loss: 0.4626\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.4614\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3500 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3482 - val_loss: 0.4590\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3464 - val_loss: 0.4578\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3447 - val_loss: 0.4567\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3430 - val_loss: 0.4556\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3414 - val_loss: 0.4545\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3398 - val_loss: 0.4534\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3382 - val_loss: 0.4524\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3366 - val_loss: 0.4513\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3351 - val_loss: 0.4504\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3335 - val_loss: 0.4494\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3320 - val_loss: 0.4484\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3305 - val_loss: 0.4475\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3291 - val_loss: 0.4466\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3277 - val_loss: 0.4457\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3263 - val_loss: 0.4448\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3249 - val_loss: 0.4439\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3236 - val_loss: 0.4431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3222 - val_loss: 0.4422\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3209 - val_loss: 0.4413\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.4404\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3184 - val_loss: 0.4395\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3171 - val_loss: 0.4386\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3159 - val_loss: 0.4378\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.4369\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3135 - val_loss: 0.4360\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1399316882.5162897, my average MASE = 3857319737.5045514\n",
      "Cluster 4, 1399316882.5162897\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2312 - val_loss: 0.2708\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2231 - val_loss: 0.2627\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2165 - val_loss: 0.2559\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2110 - val_loss: 0.2500\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2061 - val_loss: 0.2449\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2018 - val_loss: 0.2403\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1979 - val_loss: 0.2361\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1944 - val_loss: 0.2322\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1912 - val_loss: 0.2287\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1882 - val_loss: 0.2255\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1854 - val_loss: 0.2224\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1829 - val_loss: 0.2197\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1806 - val_loss: 0.2172\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1785 - val_loss: 0.2150\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1767 - val_loss: 0.2129\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1750 - val_loss: 0.2110\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1734 - val_loss: 0.2093\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1720 - val_loss: 0.2077\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1707 - val_loss: 0.2061\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1695 - val_loss: 0.2047\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1683 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1672 - val_loss: 0.2021\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1661 - val_loss: 0.2009\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1651 - val_loss: 0.1997\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1641 - val_loss: 0.1986\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1632 - val_loss: 0.1975\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1623 - val_loss: 0.1965\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1615 - val_loss: 0.1955\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1599 - val_loss: 0.1937\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1577 - val_loss: 0.1912\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1570 - val_loss: 0.1904\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1897\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1558 - val_loss: 0.1890\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1552 - val_loss: 0.1883\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1547 - val_loss: 0.1877\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1542 - val_loss: 0.1871\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1537 - val_loss: 0.1864\n",
      "17/17 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n",
      "average MASE = 146.93947390831542, my average MASE = 534465305.08164215\n",
      "Cluster 5, 146.93947390831542\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3864 - val_loss: 0.3280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.3279\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3849 - val_loss: 0.3278\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3842 - val_loss: 0.3277\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3834 - val_loss: 0.3276\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3827 - val_loss: 0.3275\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3820 - val_loss: 0.3274\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3813 - val_loss: 0.3274\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.3273\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3799 - val_loss: 0.3272\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.3272\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3785 - val_loss: 0.3271\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3778 - val_loss: 0.3270\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3772 - val_loss: 0.3270\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3765 - val_loss: 0.3269\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.3269\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3753 - val_loss: 0.3268\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3746 - val_loss: 0.3268\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3740 - val_loss: 0.3267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3734 - val_loss: 0.3266\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3728 - val_loss: 0.3266\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3722 - val_loss: 0.3265\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3717 - val_loss: 0.3265\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3711 - val_loss: 0.3264\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3705 - val_loss: 0.3264\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3699 - val_loss: 0.3263\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3694 - val_loss: 0.3263\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3688 - val_loss: 0.3262\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3682 - val_loss: 0.3262\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3262\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3671 - val_loss: 0.3261\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3666 - val_loss: 0.3261\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3660 - val_loss: 0.3260\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3655 - val_loss: 0.3260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3649 - val_loss: 0.3260\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3643 - val_loss: 0.3259\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3632 - val_loss: 0.3259\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3259\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3621 - val_loss: 0.3259\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 304.5484747914777, my average MASE = 15252291.46578898\n",
      "Cluster 6, 304.5484747914777\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8703 - val_loss: 8.9197\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8672 - val_loss: 8.9197\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8642 - val_loss: 8.9196\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8613 - val_loss: 8.9196\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8586 - val_loss: 8.9196\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8558 - val_loss: 8.9195\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8532 - val_loss: 8.9194\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8506 - val_loss: 8.9194\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8480 - val_loss: 8.9193\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8455 - val_loss: 8.9192\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8431 - val_loss: 8.9192\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8407 - val_loss: 8.9191\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8383 - val_loss: 8.9190\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8360 - val_loss: 8.9189\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8337 - val_loss: 8.9188\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8315 - val_loss: 8.9187\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8293 - val_loss: 8.9187\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8271 - val_loss: 8.9186\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8250 - val_loss: 8.9185\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 8.9184\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8209 - val_loss: 8.9184\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 8.9183\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8170 - val_loss: 8.9182\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8150 - val_loss: 8.9181\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8131 - val_loss: 8.9180\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8113 - val_loss: 8.9179\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8095 - val_loss: 8.9179\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 8.9178\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8062 - val_loss: 8.9177\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8046 - val_loss: 8.9176\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8031 - val_loss: 8.9175\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8016 - val_loss: 8.9175\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8000 - val_loss: 8.9174\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7985 - val_loss: 8.9173\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7970 - val_loss: 8.9172\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7955 - val_loss: 8.9171\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7941 - val_loss: 8.9171\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7927 - val_loss: 8.9170\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7913 - val_loss: 8.9170\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7899 - val_loss: 8.9170\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 192382848.4747458, my average MASE = 882590618.8453726\n",
      "Cluster 7, 192382848.4747458\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1119 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0986\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1024 - val_loss: 0.0973\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0988 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0957 - val_loss: 0.0956\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0930 - val_loss: 0.0950\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0905 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0883 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0863 - val_loss: 0.0937\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0933\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0828 - val_loss: 0.0930\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0813 - val_loss: 0.0928\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0799 - val_loss: 0.0925\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0787 - val_loss: 0.0924\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0775 - val_loss: 0.0922\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0764 - val_loss: 0.0920\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0754 - val_loss: 0.0918\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0744 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0735 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0727 - val_loss: 0.0914\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0719 - val_loss: 0.0913\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0711 - val_loss: 0.0912\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0705 - val_loss: 0.0910\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0909\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0692 - val_loss: 0.0908\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0687 - val_loss: 0.0907\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0677 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0660 - val_loss: 0.0901\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0900\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0653 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0646 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0898\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0897\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0896\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0635 - val_loss: 0.0896\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1222984943.0994627, my average MASE = 34180380931.05725\n",
      "Cluster 8, 1222984943.0994627\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3097 - val_loss: 0.3956\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3089 - val_loss: 0.3954\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3081 - val_loss: 0.3952\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3074 - val_loss: 0.3950\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3066 - val_loss: 0.3948\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3059 - val_loss: 0.3945\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3051 - val_loss: 0.3943\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3044 - val_loss: 0.3941\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3037 - val_loss: 0.3939\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3030 - val_loss: 0.3937\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.3935\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3017 - val_loss: 0.3934\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3010 - val_loss: 0.3933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3003 - val_loss: 0.3931\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2997 - val_loss: 0.3930\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2990 - val_loss: 0.3929\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2984 - val_loss: 0.3927\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2977 - val_loss: 0.3926\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2971 - val_loss: 0.3925\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2965 - val_loss: 0.3924\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2959 - val_loss: 0.3923\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2953 - val_loss: 0.3922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2947 - val_loss: 0.3921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2941 - val_loss: 0.3920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2935 - val_loss: 0.3919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2930 - val_loss: 0.3918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2924 - val_loss: 0.3917\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.3917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2913 - val_loss: 0.3916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2907 - val_loss: 0.3915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2902 - val_loss: 0.3914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2896 - val_loss: 0.3914\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2891 - val_loss: 0.3913\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2885 - val_loss: 0.3912\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2880 - val_loss: 0.3911\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2875 - val_loss: 0.3910\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2870 - val_loss: 0.3909\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2865 - val_loss: 0.3908\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2859 - val_loss: 0.3907\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2854 - val_loss: 0.3907\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 561.7864488366092, my average MASE = 24722978.57949824\n",
      "Cluster 10, 561.7864488366092\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=2, 2, 13, (10045, 67)\n",
      "Before prediction: train_X.shape=(6020, 10, 67), train_y.shape=(6020, 67), test_X.shape=(2007, 10, 67), test_y.shape=(2007, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0647 - val_loss: 0.0484\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0596 - val_loss: 0.0453\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0565 - val_loss: 0.0429\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0542 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0523 - val_loss: 0.0394\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0508 - val_loss: 0.0381\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0495 - val_loss: 0.0370\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0484 - val_loss: 0.0360\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0475 - val_loss: 0.0351\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0467 - val_loss: 0.0344\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0461 - val_loss: 0.0338\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0454 - val_loss: 0.0333\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0328\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0444 - val_loss: 0.0323\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0440 - val_loss: 0.0320\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0435 - val_loss: 0.0316\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0313\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0428 - val_loss: 0.0311\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0308\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0306\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0304\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0415 - val_loss: 0.0303\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0412 - val_loss: 0.0301\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0410 - val_loss: 0.0300\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0298\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0297\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0296\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0294\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0293\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0292\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0397 - val_loss: 0.0291\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0396 - val_loss: 0.0291\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0395 - val_loss: 0.0290\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0394 - val_loss: 0.0289\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0393 - val_loss: 0.0289\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0288\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0287\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0390 - val_loss: 0.0287\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0389 - val_loss: 0.0286\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0388 - val_loss: 0.0286\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2007, 67), test_y.shape=(2007, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 124611449.52884135, my average MASE = 52097635280.213745\n",
      "Cluster 0, 124611449.52884135\n",
      "Before prediction: train_X.shape=(18364, 10, 67), train_y.shape=(18364, 67), test_X.shape=(6121, 10, 67), test_y.shape=(6121, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3019 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2812 - val_loss: 0.3011\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2652 - val_loss: 0.2888\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2545 - val_loss: 0.2808\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2479 - val_loss: 0.2750\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2428 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2385 - val_loss: 0.2663\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2348 - val_loss: 0.2629\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2315 - val_loss: 0.2599\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2283 - val_loss: 0.2570\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2254 - val_loss: 0.2544\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2226 - val_loss: 0.2520\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2201 - val_loss: 0.2499\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2179 - val_loss: 0.2480\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2161 - val_loss: 0.2464\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2145 - val_loss: 0.2449\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2436\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2118 - val_loss: 0.2425\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2107 - val_loss: 0.2414\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2096 - val_loss: 0.2403\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2087 - val_loss: 0.2395\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2387\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2070 - val_loss: 0.2379\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2063 - val_loss: 0.2371\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2056 - val_loss: 0.2364\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2049 - val_loss: 0.2358\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2352\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2038 - val_loss: 0.2346\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2032 - val_loss: 0.2342\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2027 - val_loss: 0.2337\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2023 - val_loss: 0.2332\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2018 - val_loss: 0.2329\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2014 - val_loss: 0.2325\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2321\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2006 - val_loss: 0.2318\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2314\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1999 - val_loss: 0.2311\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1996 - val_loss: 0.2308\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.1993 - val_loss: 0.2305\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1990 - val_loss: 0.2302\n",
      "192/192 [==============================] - 2s 11ms/step\n",
      "predicted_original.shape=(6121, 67), test_y.shape=(6121, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1515.0877642124253, my average MASE = 2752.3099444505265\n",
      "Cluster 1, 1515.0877642124253\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=5, 5, 12, (3253, 67)\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1101 - val_loss: 0.0983\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1050 - val_loss: 0.0966\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1009 - val_loss: 0.0954\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0975 - val_loss: 0.0944\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0945 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0919 - val_loss: 0.0931\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0895 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0923\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0855 - val_loss: 0.0921\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0838 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0915\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0807 - val_loss: 0.0912\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0794 - val_loss: 0.0910\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0782 - val_loss: 0.0908\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0771 - val_loss: 0.0906\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0760 - val_loss: 0.0904\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0750 - val_loss: 0.0902\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0741 - val_loss: 0.0901\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0733 - val_loss: 0.0899\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0725 - val_loss: 0.0898\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0717 - val_loss: 0.0897\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0710 - val_loss: 0.0895\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0704 - val_loss: 0.0895\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0894\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0691 - val_loss: 0.0893\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0686 - val_loss: 0.0892\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0681 - val_loss: 0.0892\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0891\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0671 - val_loss: 0.0891\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0890\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0662 - val_loss: 0.0889\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0658 - val_loss: 0.0889\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0888\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0651 - val_loss: 0.0887\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0647 - val_loss: 0.0887\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0644 - val_loss: 0.0886\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0641 - val_loss: 0.0885\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0638 - val_loss: 0.0885\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0636 - val_loss: 0.0884\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0633 - val_loss: 0.0883\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n",
      "average MASE = 1286975259.8033035, my average MASE = 26869301348.284866\n",
      "Cluster 0, 1286975259.8033035\n",
      "Before prediction: train_X.shape=(2221, 10, 67), train_y.shape=(2221, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5056 - val_loss: 0.3755\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4985 - val_loss: 0.3720\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4926 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4874 - val_loss: 0.3660\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4828 - val_loss: 0.3635\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4785 - val_loss: 0.3611\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4745 - val_loss: 0.3590\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4707 - val_loss: 0.3570\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4671 - val_loss: 0.3552\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4637 - val_loss: 0.3535\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4604 - val_loss: 0.3519\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4572 - val_loss: 0.3504\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4542 - val_loss: 0.3489\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4512 - val_loss: 0.3475\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4483 - val_loss: 0.3462\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4455 - val_loss: 0.3449\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4428 - val_loss: 0.3436\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4401 - val_loss: 0.3424\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4375 - val_loss: 0.3412\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4350 - val_loss: 0.3401\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4325 - val_loss: 0.3390\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4301 - val_loss: 0.3380\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4278 - val_loss: 0.3370\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4255 - val_loss: 0.3360\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4233 - val_loss: 0.3350\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4211 - val_loss: 0.3341\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4190 - val_loss: 0.3332\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4170 - val_loss: 0.3324\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4150 - val_loss: 0.3315\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4131 - val_loss: 0.3307\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4113 - val_loss: 0.3299\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4095 - val_loss: 0.3292\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4078 - val_loss: 0.3285\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4061 - val_loss: 0.3278\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4045 - val_loss: 0.3271\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4030 - val_loss: 0.3265\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4014 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3999 - val_loss: 0.3253\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3985 - val_loss: 0.3247\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3971 - val_loss: 0.3242\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 455.57479189703486, my average MASE = 880.739926655778\n",
      "Cluster 1, 455.57479189703486\n",
      "Before prediction: train_X.shape=(41, 10, 67), train_y.shape=(41, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4961 - val_loss: 0.6170\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4945 - val_loss: 0.6160\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4928 - val_loss: 0.6151\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4912 - val_loss: 0.6141\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4896 - val_loss: 0.6132\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4880 - val_loss: 0.6123\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4864 - val_loss: 0.6114\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4849 - val_loss: 0.6105\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4834 - val_loss: 0.6096\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4818 - val_loss: 0.6088\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4803 - val_loss: 0.6080\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4788 - val_loss: 0.6071\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4774 - val_loss: 0.6063\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4759 - val_loss: 0.6055\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4745 - val_loss: 0.6047\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4731 - val_loss: 0.6040\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4717 - val_loss: 0.6033\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4703 - val_loss: 0.6025\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4689 - val_loss: 0.6018\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4676 - val_loss: 0.6012\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4663 - val_loss: 0.6005\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4649 - val_loss: 0.5998\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4636 - val_loss: 0.5992\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4624 - val_loss: 0.5985\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4611 - val_loss: 0.5979\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4598 - val_loss: 0.5973\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4586 - val_loss: 0.5967\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4574 - val_loss: 0.5961\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4561 - val_loss: 0.5955\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4549 - val_loss: 0.5950\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4537 - val_loss: 0.5944\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4525 - val_loss: 0.5939\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4513 - val_loss: 0.5933\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4501 - val_loss: 0.5928\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4489 - val_loss: 0.5922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4478 - val_loss: 0.5917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4466 - val_loss: 0.5912\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4455 - val_loss: 0.5907\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4443 - val_loss: 0.5902\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4432 - val_loss: 0.5897\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3633974576.8812943, my average MASE = 9316750037.661146\n",
      "Cluster 2, 3633974576.8812943\n",
      "Before prediction: train_X.shape=(158, 10, 67), train_y.shape=(158, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5152 - val_loss: 0.4273\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5139 - val_loss: 0.4265\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5128 - val_loss: 0.4257\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5117 - val_loss: 0.4249\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5105 - val_loss: 0.4241\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5095 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5084 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5074 - val_loss: 0.4219\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5064 - val_loss: 0.4212\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5054 - val_loss: 0.4204\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5044 - val_loss: 0.4197\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5034 - val_loss: 0.4191\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5025 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5015 - val_loss: 0.4178\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5006 - val_loss: 0.4171\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4997 - val_loss: 0.4165\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4988 - val_loss: 0.4159\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4979 - val_loss: 0.4153\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4970 - val_loss: 0.4147\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4961 - val_loss: 0.4141\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4953 - val_loss: 0.4135\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4944 - val_loss: 0.4129\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4936 - val_loss: 0.4123\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4928 - val_loss: 0.4118\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4920 - val_loss: 0.4112\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4912 - val_loss: 0.4107\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4904 - val_loss: 0.4101\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4096\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4889 - val_loss: 0.4091\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4882 - val_loss: 0.4086\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4874 - val_loss: 0.4080\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4867 - val_loss: 0.4075\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4860 - val_loss: 0.4070\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4852 - val_loss: 0.4065\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4845 - val_loss: 0.4060\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4838 - val_loss: 0.4055\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4831 - val_loss: 0.4050\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4045\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4818 - val_loss: 0.4040\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4811 - val_loss: 0.4036\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 113.07393682707622, my average MASE = 188079219.47717956\n",
      "Cluster 3, 113.07393682707622\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7117 - val_loss: 0.7129\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7087 - val_loss: 0.7117\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7057 - val_loss: 0.7104\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7028 - val_loss: 0.7094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7000 - val_loss: 0.7084\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6972 - val_loss: 0.7075\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6945 - val_loss: 0.7066\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6918 - val_loss: 0.7056\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6891 - val_loss: 0.7047\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6865 - val_loss: 0.7037\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6838 - val_loss: 0.7028\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6811 - val_loss: 0.7018\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6785 - val_loss: 0.7009\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6758 - val_loss: 0.6999\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6732 - val_loss: 0.6990\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6706 - val_loss: 0.6981\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6680 - val_loss: 0.6971\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6654 - val_loss: 0.6961\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6628 - val_loss: 0.6951\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6604 - val_loss: 0.6942\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6580 - val_loss: 0.6934\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6556 - val_loss: 0.6926\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6534 - val_loss: 0.6918\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6512 - val_loss: 0.6910\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6491 - val_loss: 0.6902\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6470 - val_loss: 0.6894\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6449 - val_loss: 0.6886\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6429 - val_loss: 0.6877\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6409 - val_loss: 0.6869\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6389 - val_loss: 0.6861\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6369 - val_loss: 0.6853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6350 - val_loss: 0.6847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6332 - val_loss: 0.6841\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6314 - val_loss: 0.6836\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6297 - val_loss: 0.6831\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6280 - val_loss: 0.6827\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6263 - val_loss: 0.6825\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6246 - val_loss: 0.6824\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6229 - val_loss: 0.6823\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6212 - val_loss: 0.6822\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2798887382418345, my average MASE = 0.5334982550486497\n",
      "Cluster 4, 0.2798887382418345\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=7, 7, 431, (13, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(180, 10, 67), train_y.shape=(180, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6852 - val_loss: 0.5575\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6838 - val_loss: 0.5569\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6824 - val_loss: 0.5563\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6811 - val_loss: 0.5557\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6799 - val_loss: 0.5551\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6786 - val_loss: 0.5545\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6774 - val_loss: 0.5540\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6762 - val_loss: 0.5534\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6750 - val_loss: 0.5528\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6739 - val_loss: 0.5523\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6727 - val_loss: 0.5518\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5512\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6705 - val_loss: 0.5507\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6694 - val_loss: 0.5501\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6684 - val_loss: 0.5496\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6673 - val_loss: 0.5491\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6663 - val_loss: 0.5486\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6653 - val_loss: 0.5481\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6643 - val_loss: 0.5475\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6632 - val_loss: 0.5470\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6623 - val_loss: 0.5465\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6613 - val_loss: 0.5461\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6603 - val_loss: 0.5456\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6594 - val_loss: 0.5451\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6584 - val_loss: 0.5446\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6575 - val_loss: 0.5441\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6566 - val_loss: 0.5437\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6557 - val_loss: 0.5432\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6548 - val_loss: 0.5427\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6539 - val_loss: 0.5423\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6531 - val_loss: 0.5418\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6522 - val_loss: 0.5414\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6513 - val_loss: 0.5409\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6505 - val_loss: 0.5405\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6497 - val_loss: 0.5400\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6489 - val_loss: 0.5396\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6480 - val_loss: 0.5392\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6472 - val_loss: 0.5387\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6464 - val_loss: 0.5383\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6456 - val_loss: 0.5379\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 161.0036674860674, my average MASE = 412096886.9283237\n",
      "Cluster 1, 161.0036674860674\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6031 - val_loss: 0.4390\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6002 - val_loss: 0.4369\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5975 - val_loss: 0.4349\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5947 - val_loss: 0.4328\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5919 - val_loss: 0.4307\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5892 - val_loss: 0.4287\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5864 - val_loss: 0.4267\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5838 - val_loss: 0.4248\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5812 - val_loss: 0.4230\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5786 - val_loss: 0.4213\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5761 - val_loss: 0.4196\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5736 - val_loss: 0.4180\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5712 - val_loss: 0.4164\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5687 - val_loss: 0.4148\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5663 - val_loss: 0.4132\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5638 - val_loss: 0.4116\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5614 - val_loss: 0.4101\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5590 - val_loss: 0.4085\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5566 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5542 - val_loss: 0.4054\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5518 - val_loss: 0.4039\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5494 - val_loss: 0.4024\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5471 - val_loss: 0.4008\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5448 - val_loss: 0.3992\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5424 - val_loss: 0.3977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5401 - val_loss: 0.3961\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5378 - val_loss: 0.3945\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5355 - val_loss: 0.3930\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5333 - val_loss: 0.3914\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5310 - val_loss: 0.3898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5288 - val_loss: 0.3883\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5266 - val_loss: 0.3868\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5243 - val_loss: 0.3855\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5221 - val_loss: 0.3842\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5199 - val_loss: 0.3830\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5176 - val_loss: 0.3817\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5154 - val_loss: 0.3804\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5133 - val_loss: 0.3792\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5111 - val_loss: 0.3780\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5089 - val_loss: 0.3770\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.22679251401977166, my average MASE = 0.3179573135228401\n",
      "Cluster 2, 0.22679251401977166\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4783 - val_loss: 0.4457\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4766 - val_loss: 0.4444\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4750 - val_loss: 0.4432\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4734 - val_loss: 0.4420\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4719 - val_loss: 0.4408\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4703 - val_loss: 0.4397\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4687 - val_loss: 0.4385\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4672 - val_loss: 0.4374\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4657 - val_loss: 0.4362\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4642 - val_loss: 0.4351\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4627 - val_loss: 0.4340\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4613 - val_loss: 0.4329\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4598 - val_loss: 0.4318\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4584 - val_loss: 0.4307\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4296\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4555 - val_loss: 0.4286\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4541 - val_loss: 0.4275\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4527 - val_loss: 0.4265\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4513 - val_loss: 0.4255\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4499 - val_loss: 0.4245\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4486 - val_loss: 0.4235\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4472 - val_loss: 0.4225\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4459 - val_loss: 0.4215\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4445 - val_loss: 0.4205\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4432 - val_loss: 0.4195\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4186\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4406 - val_loss: 0.4176\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4167\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4380 - val_loss: 0.4158\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4368 - val_loss: 0.4149\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4355 - val_loss: 0.4139\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4343 - val_loss: 0.4130\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4330 - val_loss: 0.4121\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4318 - val_loss: 0.4112\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4306 - val_loss: 0.4103\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4294 - val_loss: 0.4094\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4282 - val_loss: 0.4085\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4270 - val_loss: 0.4077\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4258 - val_loss: 0.4068\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4246 - val_loss: 0.4059\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3532936323.38913, my average MASE = 7800622104.848636\n",
      "Cluster 3, 3532936323.38913\n",
      "Before prediction: train_X.shape=(152, 10, 67), train_y.shape=(152, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3354 - val_loss: 0.2774\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3344 - val_loss: 0.2769\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3336 - val_loss: 0.2763\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3328 - val_loss: 0.2758\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3320 - val_loss: 0.2753\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3312 - val_loss: 0.2747\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3304 - val_loss: 0.2742\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3297 - val_loss: 0.2737\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3290 - val_loss: 0.2733\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3282 - val_loss: 0.2728\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3275 - val_loss: 0.2723\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3268 - val_loss: 0.2718\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3262 - val_loss: 0.2714\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3255 - val_loss: 0.2709\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3248 - val_loss: 0.2705\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3242 - val_loss: 0.2700\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3235 - val_loss: 0.2696\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3229 - val_loss: 0.2692\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3223 - val_loss: 0.2687\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3217 - val_loss: 0.2683\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3210 - val_loss: 0.2678\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3204 - val_loss: 0.2674\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3198 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3192 - val_loss: 0.2666\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3187 - val_loss: 0.2662\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3181 - val_loss: 0.2658\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3175 - val_loss: 0.2654\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3170 - val_loss: 0.2650\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3164 - val_loss: 0.2647\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3158 - val_loss: 0.2643\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3153 - val_loss: 0.2639\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3148 - val_loss: 0.2635\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3142 - val_loss: 0.2632\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3137 - val_loss: 0.2628\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3132 - val_loss: 0.2624\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3127 - val_loss: 0.2621\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3122 - val_loss: 0.2617\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3117 - val_loss: 0.2614\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3112 - val_loss: 0.2610\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3107 - val_loss: 0.2607\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 185.09520141259705, my average MASE = 132066880.5161765\n",
      "Cluster 4, 185.09520141259705\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0679 - val_loss: 0.0461\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0619 - val_loss: 0.0426\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0586 - val_loss: 0.0401\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0561 - val_loss: 0.0381\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0542 - val_loss: 0.0366\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0527 - val_loss: 0.0352\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0514 - val_loss: 0.0341\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0503 - val_loss: 0.0333\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0312\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0473 - val_loss: 0.0307\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0468 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0463 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0459 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0455 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0452 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0448 - val_loss: 0.0288\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0286\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0443 - val_loss: 0.0284\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0283\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0281\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0436 - val_loss: 0.0279\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0434 - val_loss: 0.0278\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0277\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0276\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0274\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0273\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0426 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0425 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0423 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0422 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0421 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0420 - val_loss: 0.0269\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0419 - val_loss: 0.0268\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0267\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 1042799882.6542007, my average MASE = 20591462481.802387\n",
      "Cluster 5, 1042799882.6542007\n",
      "Before prediction: train_X.shape=(82, 10, 67), train_y.shape=(82, 67), test_X.shape=(27, 10, 67), test_y.shape=(27, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3924 - val_loss: 0.4859\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3915 - val_loss: 0.4852\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3907 - val_loss: 0.4846\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3899 - val_loss: 0.4840\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3891 - val_loss: 0.4835\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3883 - val_loss: 0.4829\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3876 - val_loss: 0.4824\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3868 - val_loss: 0.4818\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3861 - val_loss: 0.4813\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 0.4808\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3847 - val_loss: 0.4802\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3841 - val_loss: 0.4797\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3834 - val_loss: 0.4792\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3828 - val_loss: 0.4787\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3821 - val_loss: 0.4783\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3815 - val_loss: 0.4778\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3809 - val_loss: 0.4773\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3804 - val_loss: 0.4769\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3798 - val_loss: 0.4764\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.4760\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3787 - val_loss: 0.4755\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3781 - val_loss: 0.4751\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4747\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3771 - val_loss: 0.4743\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3766 - val_loss: 0.4738\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3761 - val_loss: 0.4734\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3756 - val_loss: 0.4731\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3751 - val_loss: 0.4727\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3746 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3741 - val_loss: 0.4719\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3737 - val_loss: 0.4715\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3732 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3728 - val_loss: 0.4707\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3723 - val_loss: 0.4703\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3719 - val_loss: 0.4699\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3715 - val_loss: 0.4696\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3710 - val_loss: 0.4692\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3706 - val_loss: 0.4688\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3702 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3698 - val_loss: 0.4681\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(27, 67), test_y.shape=(27, 67)\n",
      "average MASE = 307.7375965485456, my average MASE = 158440912.42565766\n",
      "Cluster 6, 307.7375965485456\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=9, 9, 32, (76, 67)\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4763 - val_loss: 0.4497\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4746 - val_loss: 0.4487\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4729 - val_loss: 0.4477\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4713 - val_loss: 0.4467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4696 - val_loss: 0.4458\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4680 - val_loss: 0.4448\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.4439\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4647 - val_loss: 0.4429\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4631 - val_loss: 0.4420\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.4410\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4600 - val_loss: 0.4401\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4585 - val_loss: 0.4392\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4554 - val_loss: 0.4373\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4539 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4524 - val_loss: 0.4355\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4510 - val_loss: 0.4345\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4495 - val_loss: 0.4336\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4481 - val_loss: 0.4327\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.4319\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4453 - val_loss: 0.4310\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4439 - val_loss: 0.4301\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4425 - val_loss: 0.4293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4412 - val_loss: 0.4284\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4398 - val_loss: 0.4276\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4385 - val_loss: 0.4267\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4371 - val_loss: 0.4259\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4358 - val_loss: 0.4251\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.4243\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4332 - val_loss: 0.4234\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4226\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4307 - val_loss: 0.4218\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4294 - val_loss: 0.4210\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4282 - val_loss: 0.4202\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4270 - val_loss: 0.4195\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4258 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4246 - val_loss: 0.4179\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4234 - val_loss: 0.4172\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4222 - val_loss: 0.4164\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4211 - val_loss: 0.4157\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3502979890.5184355, my average MASE = 5633924620.870799\n",
      "Cluster 0, 3502979890.5184355\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1163 - val_loss: 0.0998\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1111 - val_loss: 0.0974\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1069 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1034 - val_loss: 0.0946\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1003 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0952 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0929 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0909 - val_loss: 0.0914\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0891 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0907\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0859 - val_loss: 0.0904\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0902\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0831 - val_loss: 0.0900\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0808 - val_loss: 0.0896\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0797 - val_loss: 0.0894\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0787 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0778 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0769 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0761 - val_loss: 0.0890\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0889\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0745 - val_loss: 0.0888\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0738 - val_loss: 0.0887\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0731 - val_loss: 0.0886\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0725 - val_loss: 0.0886\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0885\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0713 - val_loss: 0.0885\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0707 - val_loss: 0.0884\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0702 - val_loss: 0.0884\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0697 - val_loss: 0.0883\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0692 - val_loss: 0.0883\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0882\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0683 - val_loss: 0.0882\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0881\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0881\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0880\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0880\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0665 - val_loss: 0.0879\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0662 - val_loss: 0.0879\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1199834821.8603294, my average MASE = 15362171394.25593\n",
      "Cluster 1, 1199834821.8603294\n",
      "Before prediction: train_X.shape=(1567, 10, 67), train_y.shape=(1567, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2378 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2280 - val_loss: 0.2658\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2204 - val_loss: 0.2582\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2142 - val_loss: 0.2520\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2091 - val_loss: 0.2467\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2046 - val_loss: 0.2420\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2006 - val_loss: 0.2378\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1971 - val_loss: 0.2340\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1938 - val_loss: 0.2304\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1908 - val_loss: 0.2272\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1880 - val_loss: 0.2241\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1853 - val_loss: 0.2213\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1829 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1806 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1784 - val_loss: 0.2141\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1765 - val_loss: 0.2121\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1747 - val_loss: 0.2103\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1730 - val_loss: 0.2086\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1715 - val_loss: 0.2071\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1702 - val_loss: 0.2056\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1689 - val_loss: 0.2042\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1677 - val_loss: 0.2029\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2016\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2005\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1645 - val_loss: 0.1993\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1983\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1626 - val_loss: 0.1973\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1618 - val_loss: 0.1962\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1610 - val_loss: 0.1953\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1944\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1594 - val_loss: 0.1935\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1587 - val_loss: 0.1927\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1580 - val_loss: 0.1919\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1573 - val_loss: 0.1911\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1567 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1555 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1550 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1539 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 164.5516081334958, my average MASE = 793528060.8539205\n",
      "Cluster 2, 164.5516081334958\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3929 - val_loss: 0.4650\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 0.4646\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3912 - val_loss: 0.4642\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3904 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3896 - val_loss: 0.4635\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3889 - val_loss: 0.4631\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3881 - val_loss: 0.4627\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3874 - val_loss: 0.4624\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4621\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.4617\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3854 - val_loss: 0.4614\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3847 - val_loss: 0.4611\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3841 - val_loss: 0.4608\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3835 - val_loss: 0.4605\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3829 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3823 - val_loss: 0.4600\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3817 - val_loss: 0.4597\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3812 - val_loss: 0.4594\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.4591\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3800 - val_loss: 0.4588\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3795 - val_loss: 0.4585\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3790 - val_loss: 0.4583\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3785 - val_loss: 0.4580\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.4578\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3775 - val_loss: 0.4575\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3770 - val_loss: 0.4572\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3765 - val_loss: 0.4570\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3761 - val_loss: 0.4567\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3756 - val_loss: 0.4565\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3752 - val_loss: 0.4563\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3747 - val_loss: 0.4560\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3738 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3734 - val_loss: 0.4553\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3730 - val_loss: 0.4551\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3725 - val_loss: 0.4549\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3721 - val_loss: 0.4547\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3717 - val_loss: 0.4545\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3713 - val_loss: 0.4542\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3709 - val_loss: 0.4540\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 177.05816941536048, my average MASE = 104373067.45181417\n",
      "Cluster 3, 177.05816941536048\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4712 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4689 - val_loss: 0.3159\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.3148\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4644 - val_loss: 0.3137\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4621 - val_loss: 0.3125\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4598 - val_loss: 0.3114\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4576 - val_loss: 0.3103\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4553 - val_loss: 0.3092\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4531 - val_loss: 0.3081\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4509 - val_loss: 0.3071\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.3062\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4465 - val_loss: 0.3053\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4444 - val_loss: 0.3044\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4422 - val_loss: 0.3036\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4401 - val_loss: 0.3028\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4379 - val_loss: 0.3020\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4358 - val_loss: 0.3012\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.3004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4317 - val_loss: 0.2996\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4297 - val_loss: 0.2988\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4278 - val_loss: 0.2979\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4259 - val_loss: 0.2970\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4240 - val_loss: 0.2961\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4222 - val_loss: 0.2952\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4204 - val_loss: 0.2943\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4186 - val_loss: 0.2934\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4168 - val_loss: 0.2924\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4151 - val_loss: 0.2915\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4134 - val_loss: 0.2906\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4118 - val_loss: 0.2898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4102 - val_loss: 0.2890\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4086 - val_loss: 0.2883\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4070 - val_loss: 0.2876\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.2869\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4039 - val_loss: 0.2863\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4009 - val_loss: 0.2850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.2845\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3980 - val_loss: 0.2840\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3966 - val_loss: 0.2835\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 254.89087963107983, my average MASE = 19795911.088192035\n",
      "Cluster 5, 254.89087963107983\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(176, 10, 67), train_y.shape=(176, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7010 - val_loss: 0.5674\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6997 - val_loss: 0.5667\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6984 - val_loss: 0.5660\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6972 - val_loss: 0.5654\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6960 - val_loss: 0.5647\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6948 - val_loss: 0.5641\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6937 - val_loss: 0.5635\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6925 - val_loss: 0.5629\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.5623\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6903 - val_loss: 0.5617\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6893 - val_loss: 0.5611\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6882 - val_loss: 0.5605\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6871 - val_loss: 0.5599\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6861 - val_loss: 0.5594\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6851 - val_loss: 0.5588\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6841 - val_loss: 0.5583\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6831 - val_loss: 0.5577\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6821 - val_loss: 0.5572\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6811 - val_loss: 0.5567\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6802 - val_loss: 0.5562\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6792 - val_loss: 0.5556\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6783 - val_loss: 0.5551\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6774 - val_loss: 0.5546\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6765 - val_loss: 0.5541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6756 - val_loss: 0.5536\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6747 - val_loss: 0.5531\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6738 - val_loss: 0.5526\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6729 - val_loss: 0.5521\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6720 - val_loss: 0.5516\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6712 - val_loss: 0.5512\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6703 - val_loss: 0.5507\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6695 - val_loss: 0.5502\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6686 - val_loss: 0.5497\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6678 - val_loss: 0.5493\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6670 - val_loss: 0.5488\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6661 - val_loss: 0.5483\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6653 - val_loss: 0.5479\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.5474\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6637 - val_loss: 0.5469\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6629 - val_loss: 0.5464\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 154.34881195949765, my average MASE = 318959730.30915844\n",
      "Cluster 7, 154.34881195949765\n",
      "Before prediction: train_X.shape=(150, 10, 67), train_y.shape=(150, 67), test_X.shape=(50, 10, 67), test_y.shape=(50, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3127 - val_loss: 0.2620\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3118 - val_loss: 0.2614\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3110 - val_loss: 0.2608\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3103 - val_loss: 0.2603\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3096 - val_loss: 0.2597\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3088 - val_loss: 0.2592\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3081 - val_loss: 0.2587\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3074 - val_loss: 0.2582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3067 - val_loss: 0.2577\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3060 - val_loss: 0.2572\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3054 - val_loss: 0.2567\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3047 - val_loss: 0.2563\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3041 - val_loss: 0.2558\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3035 - val_loss: 0.2554\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3029 - val_loss: 0.2549\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3023 - val_loss: 0.2545\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3017 - val_loss: 0.2541\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3011 - val_loss: 0.2537\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3005 - val_loss: 0.2533\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3000 - val_loss: 0.2529\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2994 - val_loss: 0.2525\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2988 - val_loss: 0.2521\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2983 - val_loss: 0.2517\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2978 - val_loss: 0.2513\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2973 - val_loss: 0.2509\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2967 - val_loss: 0.2505\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2962 - val_loss: 0.2502\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2957 - val_loss: 0.2498\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2952 - val_loss: 0.2494\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2948 - val_loss: 0.2491\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2943 - val_loss: 0.2487\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2938 - val_loss: 0.2484\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2933 - val_loss: 0.2480\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2929 - val_loss: 0.2477\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2924 - val_loss: 0.2473\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2920 - val_loss: 0.2470\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2915 - val_loss: 0.2467\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2911 - val_loss: 0.2463\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2907 - val_loss: 0.2460\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2902 - val_loss: 0.2457\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(50, 67), test_y.shape=(50, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 222.6692241509544, my average MASE = 77008768.33506098\n",
      "Cluster 8, 222.6692241509544\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=11, 11, 435, (11, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4436 - val_loss: 0.3307\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4426 - val_loss: 0.3306\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4417 - val_loss: 0.3306\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4408 - val_loss: 0.3305\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4398 - val_loss: 0.3305\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4389 - val_loss: 0.3304\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4380 - val_loss: 0.3303\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4371 - val_loss: 0.3303\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4362 - val_loss: 0.3302\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4354 - val_loss: 0.3301\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.3301\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4337 - val_loss: 0.3300\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4329 - val_loss: 0.3299\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4320 - val_loss: 0.3299\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4312 - val_loss: 0.3298\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4304 - val_loss: 0.3298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4296 - val_loss: 0.3297\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4288 - val_loss: 0.3296\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4280 - val_loss: 0.3295\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4273 - val_loss: 0.3295\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4265 - val_loss: 0.3294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4258 - val_loss: 0.3293\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4250 - val_loss: 0.3293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4243 - val_loss: 0.3292\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4235 - val_loss: 0.3291\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4228 - val_loss: 0.3291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4221 - val_loss: 0.3290\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4213 - val_loss: 0.3290\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.3289\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4199 - val_loss: 0.3288\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4191 - val_loss: 0.3288\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4184 - val_loss: 0.3287\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4177 - val_loss: 0.3287\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4170 - val_loss: 0.3286\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4163 - val_loss: 0.3286\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 0.3285\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4149 - val_loss: 0.3285\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4143 - val_loss: 0.3285\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4136 - val_loss: 0.3284\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4129 - val_loss: 0.3284\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 623.4242587364998, my average MASE = 13116998.58946489\n",
      "Cluster 0, 623.4242587364998\n",
      "Before prediction: train_X.shape=(18, 10, 67), train_y.shape=(18, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4512 - val_loss: 0.5917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4491 - val_loss: 0.5900\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4470 - val_loss: 0.5884\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4449 - val_loss: 0.5867\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4429 - val_loss: 0.5851\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4408 - val_loss: 0.5835\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.5818\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4369 - val_loss: 0.5802\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4349 - val_loss: 0.5786\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4330 - val_loss: 0.5770\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4311 - val_loss: 0.5755\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4293 - val_loss: 0.5739\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4275 - val_loss: 0.5724\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4257 - val_loss: 0.5709\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4239 - val_loss: 0.5694\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4222 - val_loss: 0.5680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4205 - val_loss: 0.5666\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4188 - val_loss: 0.5652\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4171 - val_loss: 0.5638\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4155 - val_loss: 0.5625\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4139 - val_loss: 0.5611\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4123 - val_loss: 0.5598\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4107 - val_loss: 0.5584\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4092 - val_loss: 0.5571\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4077 - val_loss: 0.5558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4062 - val_loss: 0.5545\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4047 - val_loss: 0.5532\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4032 - val_loss: 0.5519\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4017 - val_loss: 0.5506\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4003 - val_loss: 0.5494\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.5482\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5470\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3960 - val_loss: 0.5458\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.5446\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3933 - val_loss: 0.5435\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3920 - val_loss: 0.5424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3906 - val_loss: 0.5414\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3893 - val_loss: 0.5403\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3881 - val_loss: 0.5393\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3868 - val_loss: 0.5382\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1669347283.8471758, my average MASE = 4344504132.76493\n",
      "Cluster 1, 1669347283.8471758\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0678 - val_loss: 0.0460\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0618 - val_loss: 0.0427\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0585 - val_loss: 0.0404\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0561 - val_loss: 0.0385\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0542 - val_loss: 0.0369\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0527 - val_loss: 0.0355\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0514 - val_loss: 0.0344\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0503 - val_loss: 0.0335\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0327\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0321\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0315\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0473 - val_loss: 0.0310\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0468 - val_loss: 0.0306\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0463 - val_loss: 0.0302\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0458 - val_loss: 0.0299\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0454 - val_loss: 0.0296\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0293\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0447 - val_loss: 0.0291\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0444 - val_loss: 0.0289\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0442 - val_loss: 0.0287\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0439 - val_loss: 0.0285\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0283\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0434 - val_loss: 0.0281\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0430 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0427 - val_loss: 0.0276\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0423 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0419 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0266\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0415 - val_loss: 0.0265\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0264\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0263\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 811440996.3412759, my average MASE = 40052487777.48425\n",
      "Cluster 2, 811440996.3412759\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1986 - val_loss: 0.8095\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1967 - val_loss: 0.8095\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1948 - val_loss: 0.8095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1930 - val_loss: 0.8094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1912 - val_loss: 0.8094\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1894 - val_loss: 0.8094\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1876 - val_loss: 0.8094\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1858 - val_loss: 0.8094\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1840 - val_loss: 0.8094\n",
      "Epoch 9: early stopping\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 72.88641883174732, my average MASE = 50002377.286928184\n",
      "Cluster 3, 72.88641883174732\n",
      "Before prediction: train_X.shape=(87, 10, 67), train_y.shape=(87, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5691 - val_loss: 0.5072\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5682 - val_loss: 0.5068\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5674 - val_loss: 0.5063\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5666 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5659 - val_loss: 0.5055\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5651 - val_loss: 0.5051\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5643 - val_loss: 0.5047\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5636 - val_loss: 0.5042\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5628 - val_loss: 0.5038\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5621 - val_loss: 0.5034\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5614 - val_loss: 0.5030\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5606 - val_loss: 0.5026\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5600 - val_loss: 0.5022\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5592 - val_loss: 0.5018\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5586 - val_loss: 0.5014\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5579 - val_loss: 0.5011\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5572 - val_loss: 0.5007\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5565 - val_loss: 0.5003\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5558 - val_loss: 0.4999\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5552 - val_loss: 0.4996\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5545 - val_loss: 0.4993\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5539 - val_loss: 0.4989\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5532 - val_loss: 0.4986\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5526 - val_loss: 0.4983\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5520 - val_loss: 0.4979\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5513 - val_loss: 0.4976\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5507 - val_loss: 0.4973\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5501 - val_loss: 0.4970\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5495 - val_loss: 0.4967\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5489 - val_loss: 0.4964\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5483 - val_loss: 0.4961\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5477 - val_loss: 0.4958\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5471 - val_loss: 0.4956\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5465 - val_loss: 0.4953\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5459 - val_loss: 0.4950\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5453 - val_loss: 0.4947\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5447 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5442 - val_loss: 0.4942\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.4939\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5430 - val_loss: 0.4936\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 98.29689269118158, my average MASE = 78492579.83265808\n",
      "Cluster 4, 98.29689269118158\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4003 - val_loss: 0.3997\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3997 - val_loss: 0.3991\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3991 - val_loss: 0.3986\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3985 - val_loss: 0.3981\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3976\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3973 - val_loss: 0.3971\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3968 - val_loss: 0.3967\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3962\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3957 - val_loss: 0.3958\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3953\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3946 - val_loss: 0.3949\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3940 - val_loss: 0.3945\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3935 - val_loss: 0.3941\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3930 - val_loss: 0.3937\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3924 - val_loss: 0.3932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3919 - val_loss: 0.3928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3914 - val_loss: 0.3925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3904 - val_loss: 0.3917\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3899 - val_loss: 0.3913\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3894 - val_loss: 0.3909\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3889 - val_loss: 0.3906\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3884 - val_loss: 0.3902\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3879 - val_loss: 0.3898\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3870 - val_loss: 0.3891\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3865 - val_loss: 0.3887\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.3883\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3856 - val_loss: 0.3880\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3851 - val_loss: 0.3876\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3847 - val_loss: 0.3872\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3842 - val_loss: 0.3869\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3838 - val_loss: 0.3865\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3833 - val_loss: 0.3861\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3829 - val_loss: 0.3857\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3824 - val_loss: 0.3853\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 0.3850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3815 - val_loss: 0.3846\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3811 - val_loss: 0.3842\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3807 - val_loss: 0.3838\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 517837.8778283109, my average MASE = 16943290.739345513\n",
      "Cluster 6, 517837.8778283109\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2151 - val_loss: 0.4042\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2146 - val_loss: 0.4041\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2142 - val_loss: 0.4041\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2137 - val_loss: 0.4040\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2133 - val_loss: 0.4040\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2128 - val_loss: 0.4040\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2124 - val_loss: 0.4039\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2119 - val_loss: 0.4039\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2115 - val_loss: 0.4038\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2111 - val_loss: 0.4038\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2107 - val_loss: 0.4038\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2103 - val_loss: 0.4038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2099 - val_loss: 0.4037\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2096 - val_loss: 0.4037\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2092 - val_loss: 0.4037\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2088 - val_loss: 0.4036\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2084 - val_loss: 0.4036\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2081 - val_loss: 0.4036\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2077 - val_loss: 0.4035\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2074 - val_loss: 0.4035\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2070 - val_loss: 0.4035\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2067 - val_loss: 0.4035\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2063 - val_loss: 0.4035\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2060 - val_loss: 0.4034\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2057 - val_loss: 0.4034\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2054 - val_loss: 0.4034\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2050 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2047 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2044 - val_loss: 0.4033\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2041 - val_loss: 0.4033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2038 - val_loss: 0.4032\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2035 - val_loss: 0.4032\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2032 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2029 - val_loss: 0.4031\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2026 - val_loss: 0.4031\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2023 - val_loss: 0.4031\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2020 - val_loss: 0.4030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2017 - val_loss: 0.4030\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2014 - val_loss: 0.4029\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2011 - val_loss: 0.4029\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 181.01448499364625, my average MASE = 73613295.18701741\n",
      "Cluster 7, 181.01448499364625\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2941 - val_loss: 0.3652\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2932 - val_loss: 0.3650\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2923 - val_loss: 0.3648\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2914 - val_loss: 0.3646\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2905 - val_loss: 0.3644\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2897 - val_loss: 0.3641\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2888 - val_loss: 0.3639\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2880 - val_loss: 0.3638\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2872 - val_loss: 0.3636\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2864 - val_loss: 0.3634\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2856 - val_loss: 0.3632\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2848 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2840 - val_loss: 0.3629\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2832 - val_loss: 0.3628\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2824 - val_loss: 0.3626\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2817 - val_loss: 0.3625\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2809 - val_loss: 0.3624\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2802 - val_loss: 0.3622\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2794 - val_loss: 0.3621\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2787 - val_loss: 0.3620\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2780 - val_loss: 0.3619\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2772 - val_loss: 0.3618\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2765 - val_loss: 0.3617\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2758 - val_loss: 0.3616\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2751 - val_loss: 0.3615\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2744 - val_loss: 0.3615\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2738 - val_loss: 0.3614\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2731 - val_loss: 0.3613\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2725 - val_loss: 0.3613\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2718 - val_loss: 0.3612\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2712 - val_loss: 0.3612\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2705 - val_loss: 0.3611\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2699 - val_loss: 0.3611\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2693 - val_loss: 0.3610\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2687 - val_loss: 0.3610\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2681 - val_loss: 0.3610\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2675 - val_loss: 0.3609\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2669 - val_loss: 0.3609\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2663 - val_loss: 0.3608\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.3608\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 679.6913673037432, my average MASE = 68962615.13093176\n",
      "Cluster 9, 679.6913673037432\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=2, 2, 11, (10056, 67)\n",
      "Before prediction: train_X.shape=(6027, 10, 67), train_y.shape=(6027, 67), test_X.shape=(2009, 10, 67), test_y.shape=(2009, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0641 - val_loss: 0.0494\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0590 - val_loss: 0.0459\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0558 - val_loss: 0.0432\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0535 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0516 - val_loss: 0.0393\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0501 - val_loss: 0.0378\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0489 - val_loss: 0.0366\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0478 - val_loss: 0.0357\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0470 - val_loss: 0.0348\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0462 - val_loss: 0.0341\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0455 - val_loss: 0.0335\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0330\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0443 - val_loss: 0.0325\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0321\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0317\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0314\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0311\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0423 - val_loss: 0.0308\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0419 - val_loss: 0.0305\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0303\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0414 - val_loss: 0.0300\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0298\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0296\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0406 - val_loss: 0.0294\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0404 - val_loss: 0.0293\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0403 - val_loss: 0.0291\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0401 - val_loss: 0.0290\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0399 - val_loss: 0.0289\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0397 - val_loss: 0.0287\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0396 - val_loss: 0.0286\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0394 - val_loss: 0.0286\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0393 - val_loss: 0.0285\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0392 - val_loss: 0.0284\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0391 - val_loss: 0.0283\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0389 - val_loss: 0.0282\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0388 - val_loss: 0.0282\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0387 - val_loss: 0.0281\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0386 - val_loss: 0.0281\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0385 - val_loss: 0.0280\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0384 - val_loss: 0.0280\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2009, 67), test_y.shape=(2009, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 137177179.8661396, my average MASE = 15662264218.215044\n",
      "Cluster 0, 137177179.8661396\n",
      "Before prediction: train_X.shape=(18366, 10, 67), train_y.shape=(18366, 67), test_X.shape=(6122, 10, 67), test_y.shape=(6122, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3004 - val_loss: 0.3159\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2809 - val_loss: 0.3004\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2655 - val_loss: 0.2878\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2540 - val_loss: 0.2790\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2465 - val_loss: 0.2727\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2409 - val_loss: 0.2676\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2364 - val_loss: 0.2633\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2324 - val_loss: 0.2598\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2290 - val_loss: 0.2567\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2259 - val_loss: 0.2539\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2230 - val_loss: 0.2514\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2204 - val_loss: 0.2493\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2181 - val_loss: 0.2474\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2161 - val_loss: 0.2457\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2144 - val_loss: 0.2442\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2129 - val_loss: 0.2429\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2115 - val_loss: 0.2418\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2103 - val_loss: 0.2406\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2092 - val_loss: 0.2396\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2083 - val_loss: 0.2386\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2073 - val_loss: 0.2378\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2065 - val_loss: 0.2370\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2057 - val_loss: 0.2363\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2050 - val_loss: 0.2356\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2350\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2344\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2031 - val_loss: 0.2338\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2025 - val_loss: 0.2333\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2020 - val_loss: 0.2328\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2015 - val_loss: 0.2324\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2319\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2006 - val_loss: 0.2314\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2002 - val_loss: 0.2311\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1998 - val_loss: 0.2307\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.1994 - val_loss: 0.2304\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1991 - val_loss: 0.2301\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.1987 - val_loss: 0.2298\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1984 - val_loss: 0.2294\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1981 - val_loss: 0.2291\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1978 - val_loss: 0.2290\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6122, 67), test_y.shape=(6122, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1800.7465590842255, my average MASE = 3633.615501921918\n",
      "Cluster 1, 1800.7465590842255\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=5, 5, 58, (3715, 67)\n",
      "Before prediction: train_X.shape=(2222, 10, 67), train_y.shape=(2222, 67), test_X.shape=(741, 10, 67), test_y.shape=(741, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5001 - val_loss: 0.3691\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4918 - val_loss: 0.3651\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4851 - val_loss: 0.3618\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4795 - val_loss: 0.3589\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4744 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4699 - val_loss: 0.3539\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4657 - val_loss: 0.3517\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4618 - val_loss: 0.3497\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4582 - val_loss: 0.3478\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4548 - val_loss: 0.3460\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4516 - val_loss: 0.3443\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4485 - val_loss: 0.3427\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4455 - val_loss: 0.3412\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4426 - val_loss: 0.3398\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4398 - val_loss: 0.3384\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4370 - val_loss: 0.3370\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4342 - val_loss: 0.3357\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4315 - val_loss: 0.3345\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4289 - val_loss: 0.3332\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4263 - val_loss: 0.3321\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4237 - val_loss: 0.3309\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4213 - val_loss: 0.3298\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4189 - val_loss: 0.3287\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4166 - val_loss: 0.3277\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4143 - val_loss: 0.3266\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4120 - val_loss: 0.3256\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4099 - val_loss: 0.3247\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4079 - val_loss: 0.3238\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4059 - val_loss: 0.3230\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4040 - val_loss: 0.3222\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4022 - val_loss: 0.3214\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4005 - val_loss: 0.3206\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3988 - val_loss: 0.3199\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3972 - val_loss: 0.3193\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3956 - val_loss: 0.3186\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3941 - val_loss: 0.3180\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3927 - val_loss: 0.3175\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3912 - val_loss: 0.3169\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3899 - val_loss: 0.3163\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3885 - val_loss: 0.3158\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(741, 67), test_y.shape=(741, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 461.9721639366225, my average MASE = 1222.9207656733142\n",
      "Cluster 0, 461.9721639366225\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1169 - val_loss: 0.0965\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1118 - val_loss: 0.0947\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1077 - val_loss: 0.0935\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1043 - val_loss: 0.0926\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1013 - val_loss: 0.0919\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0987 - val_loss: 0.0913\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0964 - val_loss: 0.0909\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0942 - val_loss: 0.0906\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0923 - val_loss: 0.0904\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0901\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0890 - val_loss: 0.0899\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0875 - val_loss: 0.0897\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0861 - val_loss: 0.0895\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0849 - val_loss: 0.0894\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0837 - val_loss: 0.0892\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0826 - val_loss: 0.0891\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0816 - val_loss: 0.0889\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0807 - val_loss: 0.0888\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0798 - val_loss: 0.0886\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0790 - val_loss: 0.0885\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0782 - val_loss: 0.0884\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0883\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0881\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0761 - val_loss: 0.0880\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0755 - val_loss: 0.0879\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0749 - val_loss: 0.0878\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0743 - val_loss: 0.0877\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0738 - val_loss: 0.0876\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0732 - val_loss: 0.0875\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0727 - val_loss: 0.0875\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0722 - val_loss: 0.0874\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0718 - val_loss: 0.0874\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0713 - val_loss: 0.0874\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0873\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0705 - val_loss: 0.0873\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0873\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0872\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0695 - val_loss: 0.0872\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0689 - val_loss: 0.0871\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 979857680.8759673, my average MASE = 20246393999.460716\n",
      "Cluster 1, 979857680.8759673\n",
      "Before prediction: train_X.shape=(160, 10, 67), train_y.shape=(160, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5150 - val_loss: 0.4228\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5137 - val_loss: 0.4220\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5125 - val_loss: 0.4212\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5113 - val_loss: 0.4205\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5101 - val_loss: 0.4197\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5090 - val_loss: 0.4189\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5079 - val_loss: 0.4182\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5068 - val_loss: 0.4175\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5058 - val_loss: 0.4168\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4161\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5037 - val_loss: 0.4154\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5026 - val_loss: 0.4148\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5016 - val_loss: 0.4141\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5006 - val_loss: 0.4135\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4997 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4987 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4977 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4968 - val_loss: 0.4110\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4958 - val_loss: 0.4104\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4949 - val_loss: 0.4098\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4940 - val_loss: 0.4092\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4931 - val_loss: 0.4086\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4923 - val_loss: 0.4081\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4914 - val_loss: 0.4075\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4905 - val_loss: 0.4069\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4064\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4888 - val_loss: 0.4059\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4880 - val_loss: 0.4053\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4871 - val_loss: 0.4048\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4863 - val_loss: 0.4043\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4855 - val_loss: 0.4038\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4847 - val_loss: 0.4033\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4840 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4832 - val_loss: 0.4023\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4018\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4817 - val_loss: 0.4013\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4809 - val_loss: 0.4008\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4802 - val_loss: 0.4003\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4795 - val_loss: 0.3998\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4787 - val_loss: 0.3994\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.13783551729924, my average MASE = 51951538.633395046\n",
      "Cluster 2, 127.13783551729924\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8383 - val_loss: 0.5938\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8360 - val_loss: 0.5928\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8338 - val_loss: 0.5919\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8316 - val_loss: 0.5910\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8294 - val_loss: 0.5901\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8272 - val_loss: 0.5891\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8251 - val_loss: 0.5882\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 0.5873\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8208 - val_loss: 0.5864\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8187 - val_loss: 0.5855\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8167 - val_loss: 0.5847\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8146 - val_loss: 0.5838\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8126 - val_loss: 0.5830\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8107 - val_loss: 0.5821\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8087 - val_loss: 0.5812\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8068 - val_loss: 0.5803\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8048 - val_loss: 0.5794\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8029 - val_loss: 0.5786\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8009 - val_loss: 0.5777\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7989 - val_loss: 0.5768\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7970 - val_loss: 0.5760\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7951 - val_loss: 0.5751\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7932 - val_loss: 0.5743\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7913 - val_loss: 0.5735\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7894 - val_loss: 0.5727\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7875 - val_loss: 0.5720\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7857 - val_loss: 0.5712\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7839 - val_loss: 0.5704\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7820 - val_loss: 0.5697\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7802 - val_loss: 0.5690\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7784 - val_loss: 0.5682\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7767 - val_loss: 0.5675\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7749 - val_loss: 0.5668\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7732 - val_loss: 0.5661\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7715 - val_loss: 0.5655\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7698 - val_loss: 0.5648\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7681 - val_loss: 0.5641\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7664 - val_loss: 0.5635\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7647 - val_loss: 0.5629\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7630 - val_loss: 0.5623\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1378.9503839591846, my average MASE = 44152799.2879618\n",
      "Cluster 3, 1378.9503839591846\n",
      "Before prediction: train_X.shape=(44, 10, 67), train_y.shape=(44, 67), test_X.shape=(15, 10, 67), test_y.shape=(15, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5170 - val_loss: 0.7315\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5154 - val_loss: 0.7308\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.7300\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5122 - val_loss: 0.7293\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5107 - val_loss: 0.7285\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5092 - val_loss: 0.7278\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5077 - val_loss: 0.7271\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5062 - val_loss: 0.7264\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5047 - val_loss: 0.7257\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5033 - val_loss: 0.7250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5018 - val_loss: 0.7243\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.7236\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4990 - val_loss: 0.7229\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4977 - val_loss: 0.7222\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4963 - val_loss: 0.7215\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4949 - val_loss: 0.7209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4936 - val_loss: 0.7202\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4923 - val_loss: 0.7196\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4910 - val_loss: 0.7189\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4897 - val_loss: 0.7183\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4884 - val_loss: 0.7177\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.7170\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4859 - val_loss: 0.7164\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4847 - val_loss: 0.7158\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4835 - val_loss: 0.7152\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4823 - val_loss: 0.7146\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4811 - val_loss: 0.7140\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4799 - val_loss: 0.7135\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4788 - val_loss: 0.7129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4776 - val_loss: 0.7123\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4765 - val_loss: 0.7118\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4753 - val_loss: 0.7113\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4742 - val_loss: 0.7107\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4731 - val_loss: 0.7102\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4720 - val_loss: 0.7097\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4709 - val_loss: 0.7092\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4698 - val_loss: 0.7087\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4687 - val_loss: 0.7082\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.7077\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.7073\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(15, 67), test_y.shape=(15, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2846600473.0797715, my average MASE = 8256296780.299102\n",
      "Cluster 4, 2846600473.0797715\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=7, 7, 176, (267, 67)\n",
      "Before prediction: train_X.shape=(154, 10, 67), train_y.shape=(154, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3225 - val_loss: 0.2694\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3217 - val_loss: 0.2689\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3209 - val_loss: 0.2684\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3201 - val_loss: 0.2679\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3194 - val_loss: 0.2674\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3187 - val_loss: 0.2669\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3179 - val_loss: 0.2664\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3172 - val_loss: 0.2659\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3165 - val_loss: 0.2655\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3159 - val_loss: 0.2650\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3152 - val_loss: 0.2646\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3145 - val_loss: 0.2641\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3139 - val_loss: 0.2637\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3133 - val_loss: 0.2633\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3127 - val_loss: 0.2629\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3121 - val_loss: 0.2624\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3115 - val_loss: 0.2620\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3109 - val_loss: 0.2616\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3103 - val_loss: 0.2612\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3098 - val_loss: 0.2609\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3092 - val_loss: 0.2605\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3087 - val_loss: 0.2601\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3081 - val_loss: 0.2598\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3076 - val_loss: 0.2594\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3071 - val_loss: 0.2590\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3066 - val_loss: 0.2587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3061 - val_loss: 0.2584\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3056 - val_loss: 0.2580\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3051 - val_loss: 0.2576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3046 - val_loss: 0.2573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3041 - val_loss: 0.2569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3037 - val_loss: 0.2566\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3032 - val_loss: 0.2563\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3027 - val_loss: 0.2559\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3023 - val_loss: 0.2556\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3018 - val_loss: 0.2553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3013 - val_loss: 0.2550\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3009 - val_loss: 0.2546\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3005 - val_loss: 0.2543\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3000 - val_loss: 0.2540\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 173.3029589389659, my average MASE = 89033224.06135572\n",
      "Cluster 0, 173.3029589389659\n",
      "Before prediction: train_X.shape=(5960, 10, 67), train_y.shape=(5960, 67), test_X.shape=(1987, 10, 67), test_y.shape=(1987, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0675 - val_loss: 0.0464\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0617 - val_loss: 0.0432\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0584 - val_loss: 0.0410\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0560 - val_loss: 0.0393\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0541 - val_loss: 0.0377\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0525 - val_loss: 0.0364\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0512 - val_loss: 0.0353\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0501 - val_loss: 0.0343\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0492 - val_loss: 0.0335\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0484 - val_loss: 0.0327\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0477 - val_loss: 0.0321\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0471 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0466 - val_loss: 0.0310\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0461 - val_loss: 0.0306\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0457 - val_loss: 0.0302\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0453 - val_loss: 0.0299\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0449 - val_loss: 0.0296\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0445 - val_loss: 0.0293\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0442 - val_loss: 0.0291\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0288\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0286\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0284\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0432 - val_loss: 0.0282\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0424 - val_loss: 0.0275\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0421 - val_loss: 0.0272\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0420 - val_loss: 0.0271\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0419 - val_loss: 0.0270\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0417 - val_loss: 0.0269\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0268\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0413 - val_loss: 0.0265\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0412 - val_loss: 0.0264\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0409 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1987, 67), test_y.shape=(1987, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 783030752.0753396, my average MASE = 36192993113.38622\n",
      "Cluster 1, 783030752.0753396\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5458 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.3449\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.3440\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5391 - val_loss: 0.3431\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5369 - val_loss: 0.3422\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5348 - val_loss: 0.3413\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.3405\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5304 - val_loss: 0.3396\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5283 - val_loss: 0.3387\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5261 - val_loss: 0.3379\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5240 - val_loss: 0.3371\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5219 - val_loss: 0.3362\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5198 - val_loss: 0.3354\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5177 - val_loss: 0.3346\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5157 - val_loss: 0.3338\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5137 - val_loss: 0.3330\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5117 - val_loss: 0.3322\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5097 - val_loss: 0.3314\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5078 - val_loss: 0.3308\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5059 - val_loss: 0.3301\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5041 - val_loss: 0.3295\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5022 - val_loss: 0.3290\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.3284\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4986 - val_loss: 0.3279\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4968 - val_loss: 0.3274\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4951 - val_loss: 0.3269\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4933 - val_loss: 0.3264\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.3260\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4900 - val_loss: 0.3257\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4884 - val_loss: 0.3254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4868 - val_loss: 0.3251\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4852 - val_loss: 0.3249\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4836 - val_loss: 0.3247\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4821 - val_loss: 0.3245\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4805 - val_loss: 0.3244\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4790 - val_loss: 0.3242\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4775 - val_loss: 0.3241\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4760 - val_loss: 0.3240\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4745 - val_loss: 0.3239\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4730 - val_loss: 0.3238\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 300.2247881778862, my average MASE = 45822553.10580316\n",
      "Cluster 2, 300.2247881778862\n",
      "Before prediction: train_X.shape=(85, 10, 67), train_y.shape=(85, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3796 - val_loss: 0.4594\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3789 - val_loss: 0.4589\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3782 - val_loss: 0.4585\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4581\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3770 - val_loss: 0.4577\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3764 - val_loss: 0.4573\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.4569\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3753 - val_loss: 0.4565\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3748 - val_loss: 0.4561\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3737 - val_loss: 0.4554\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3732 - val_loss: 0.4550\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3727 - val_loss: 0.4547\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4543\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3717 - val_loss: 0.4540\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3713 - val_loss: 0.4537\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3708 - val_loss: 0.4533\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3703 - val_loss: 0.4530\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3699 - val_loss: 0.4527\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3694 - val_loss: 0.4524\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.4521\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3685 - val_loss: 0.4517\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3681 - val_loss: 0.4514\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3677 - val_loss: 0.4512\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3673 - val_loss: 0.4509\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3669 - val_loss: 0.4506\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3664 - val_loss: 0.4503\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4501\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3657 - val_loss: 0.4498\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3653 - val_loss: 0.4495\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3649 - val_loss: 0.4493\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3645 - val_loss: 0.4490\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3641 - val_loss: 0.4487\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.4485\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3634 - val_loss: 0.4482\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3630 - val_loss: 0.4480\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.4478\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3623 - val_loss: 0.4475\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.4473\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3616 - val_loss: 0.4470\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n",
      "average MASE = 329.8443195642471, my average MASE = 91063731.05477783\n",
      "Cluster 3, 329.8443195642471\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6262 - val_loss: 0.5214\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6239 - val_loss: 0.5202\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6216 - val_loss: 0.5190\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6193 - val_loss: 0.5179\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6170 - val_loss: 0.5167\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6148 - val_loss: 0.5156\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6125 - val_loss: 0.5145\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6102 - val_loss: 0.5134\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6080 - val_loss: 0.5123\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6058 - val_loss: 0.5112\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6036 - val_loss: 0.5101\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6015 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5994 - val_loss: 0.5080\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5973 - val_loss: 0.5070\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5953 - val_loss: 0.5060\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5932 - val_loss: 0.5051\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5912 - val_loss: 0.5041\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5892 - val_loss: 0.5032\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5872 - val_loss: 0.5023\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5853 - val_loss: 0.5015\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5834 - val_loss: 0.5006\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5816 - val_loss: 0.4999\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5799 - val_loss: 0.4991\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5782 - val_loss: 0.4984\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5765 - val_loss: 0.4977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5749 - val_loss: 0.4970\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5732 - val_loss: 0.4963\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5716 - val_loss: 0.4957\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5699 - val_loss: 0.4951\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5683 - val_loss: 0.4946\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5667 - val_loss: 0.4941\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5651 - val_loss: 0.4936\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5635 - val_loss: 0.4931\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5619 - val_loss: 0.4927\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5604 - val_loss: 0.4922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5588 - val_loss: 0.4917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5573 - val_loss: 0.4913\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5557 - val_loss: 0.4909\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5542 - val_loss: 0.4906\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5526 - val_loss: 0.4902\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32309710873507563, my average MASE = 0.5656513264705396\n",
      "Cluster 4, 0.32309710873507563\n",
      "Before prediction: train_X.shape=(43, 10, 67), train_y.shape=(43, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5119 - val_loss: 0.6850\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5101 - val_loss: 0.6839\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5083 - val_loss: 0.6829\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5066 - val_loss: 0.6819\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5048 - val_loss: 0.6808\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.6798\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5014 - val_loss: 0.6788\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.6778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4980 - val_loss: 0.6769\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4964 - val_loss: 0.6759\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4948 - val_loss: 0.6749\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4931 - val_loss: 0.6740\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4915 - val_loss: 0.6730\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4900 - val_loss: 0.6721\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4884 - val_loss: 0.6711\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4869 - val_loss: 0.6702\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4853 - val_loss: 0.6693\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4838 - val_loss: 0.6683\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6674\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4808 - val_loss: 0.6665\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.6656\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4779 - val_loss: 0.6647\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4765 - val_loss: 0.6639\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4751 - val_loss: 0.6630\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4737 - val_loss: 0.6622\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4723 - val_loss: 0.6613\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4710 - val_loss: 0.6605\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4697 - val_loss: 0.6596\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4683 - val_loss: 0.6588\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4670 - val_loss: 0.6580\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4657 - val_loss: 0.6572\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4644 - val_loss: 0.6564\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4631 - val_loss: 0.6556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4619 - val_loss: 0.6548\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4606 - val_loss: 0.6540\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4594 - val_loss: 0.6532\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4581 - val_loss: 0.6525\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4569 - val_loss: 0.6517\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4557 - val_loss: 0.6510\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4545 - val_loss: 0.6502\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2340337256.388025, my average MASE = 7806499481.251814\n",
      "Cluster 5, 2340337256.388025\n",
      "Before prediction: train_X.shape=(181, 10, 67), train_y.shape=(181, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6846 - val_loss: 0.5744\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6833 - val_loss: 0.5737\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6820 - val_loss: 0.5730\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6807 - val_loss: 0.5723\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6795 - val_loss: 0.5716\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6783 - val_loss: 0.5709\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6771 - val_loss: 0.5703\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6760 - val_loss: 0.5696\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6749 - val_loss: 0.5690\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6737 - val_loss: 0.5683\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6727 - val_loss: 0.5677\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6716 - val_loss: 0.5671\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6705 - val_loss: 0.5666\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6695 - val_loss: 0.5660\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6685 - val_loss: 0.5654\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6675 - val_loss: 0.5648\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6664 - val_loss: 0.5643\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6654 - val_loss: 0.5637\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6645 - val_loss: 0.5632\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6635 - val_loss: 0.5626\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6626 - val_loss: 0.5621\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.6616 - val_loss: 0.5615\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6607 - val_loss: 0.5610\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6597 - val_loss: 0.5605\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6588 - val_loss: 0.5600\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6579 - val_loss: 0.5594\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6570 - val_loss: 0.5589\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6561 - val_loss: 0.5584\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6553 - val_loss: 0.5579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6544 - val_loss: 0.5574\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6536 - val_loss: 0.5569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6527 - val_loss: 0.5563\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6519 - val_loss: 0.5558\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6510 - val_loss: 0.5553\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6502 - val_loss: 0.5548\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6493 - val_loss: 0.5543\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6485 - val_loss: 0.5538\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6477 - val_loss: 0.5533\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6468 - val_loss: 0.5528\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6460 - val_loss: 0.5523\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 153.88341287865387, my average MASE = 335532064.75560737\n",
      "Cluster 6, 153.88341287865387\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=9, 9, 3, (61, 67)\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5800 - val_loss: 0.4525\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5784 - val_loss: 0.4515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5768 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5753 - val_loss: 0.4496\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5738 - val_loss: 0.4487\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5722 - val_loss: 0.4477\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5707 - val_loss: 0.4468\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5692 - val_loss: 0.4459\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5678 - val_loss: 0.4450\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5663 - val_loss: 0.4441\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5648 - val_loss: 0.4433\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5634 - val_loss: 0.4424\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5619 - val_loss: 0.4415\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5605 - val_loss: 0.4407\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5590 - val_loss: 0.4398\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5576 - val_loss: 0.4390\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5562 - val_loss: 0.4382\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5548 - val_loss: 0.4374\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5534 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5520 - val_loss: 0.4359\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5507 - val_loss: 0.4352\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5493 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5480 - val_loss: 0.4337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5467 - val_loss: 0.4329\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 0.4322\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5441 - val_loss: 0.4315\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5428 - val_loss: 0.4308\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5415 - val_loss: 0.4301\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5403 - val_loss: 0.4294\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5390 - val_loss: 0.4287\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5378 - val_loss: 0.4280\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5366 - val_loss: 0.4273\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5354 - val_loss: 0.4266\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5342 - val_loss: 0.4260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5330 - val_loss: 0.4253\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5318 - val_loss: 0.4246\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5307 - val_loss: 0.4240\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5295 - val_loss: 0.4234\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5284 - val_loss: 0.4227\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5273 - val_loss: 0.4221\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 35650627.66244785, my average MASE = 4899168813.139491\n",
      "Cluster 0, 35650627.66244785\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7142 - val_loss: 0.5624\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7129 - val_loss: 0.5618\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7116 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7104 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7092 - val_loss: 0.5599\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7080 - val_loss: 0.5593\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7069 - val_loss: 0.5588\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7057 - val_loss: 0.5582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7046 - val_loss: 0.5576\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7035 - val_loss: 0.5571\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5565\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7013 - val_loss: 0.5560\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7002 - val_loss: 0.5555\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6993 - val_loss: 0.5550\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6982 - val_loss: 0.5545\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6972 - val_loss: 0.5540\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5535\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6952 - val_loss: 0.5530\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6942 - val_loss: 0.5525\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6932 - val_loss: 0.5520\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5516\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6913 - val_loss: 0.5511\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6903 - val_loss: 0.5506\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6894 - val_loss: 0.5502\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6885 - val_loss: 0.5498\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6875 - val_loss: 0.5493\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6866 - val_loss: 0.5489\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6857 - val_loss: 0.5485\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6848 - val_loss: 0.5481\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6839 - val_loss: 0.5477\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6830 - val_loss: 0.5472\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6821 - val_loss: 0.5468\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6812 - val_loss: 0.5464\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6803 - val_loss: 0.5460\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6794 - val_loss: 0.5456\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.5452\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6777 - val_loss: 0.5449\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6768 - val_loss: 0.5445\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6759 - val_loss: 0.5441\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6751 - val_loss: 0.5437\n",
      "2/2 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n",
      "average MASE = 167.81473432422789, my average MASE = 220460085.3598021\n",
      "Cluster 1, 167.81473432422789\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4267 - val_loss: 0.6677\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4246 - val_loss: 0.6662\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4226 - val_loss: 0.6647\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4205 - val_loss: 0.6632\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.6618\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4166 - val_loss: 0.6605\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4146 - val_loss: 0.6592\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4127 - val_loss: 0.6578\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4107 - val_loss: 0.6565\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4088 - val_loss: 0.6552\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4070 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4051 - val_loss: 0.6527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4033 - val_loss: 0.6514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4014 - val_loss: 0.6502\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3997 - val_loss: 0.6490\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3979 - val_loss: 0.6478\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3961 - val_loss: 0.6466\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3944 - val_loss: 0.6455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3927 - val_loss: 0.6444\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3910 - val_loss: 0.6433\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3893 - val_loss: 0.6423\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3877 - val_loss: 0.6412\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3861 - val_loss: 0.6402\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3845 - val_loss: 0.6392\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3829 - val_loss: 0.6383\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3814 - val_loss: 0.6374\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3799 - val_loss: 0.6364\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3784 - val_loss: 0.6356\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3769 - val_loss: 0.6347\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3754 - val_loss: 0.6338\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3740 - val_loss: 0.6330\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3725 - val_loss: 0.6322\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3711 - val_loss: 0.6314\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3697 - val_loss: 0.6305\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3683 - val_loss: 0.6297\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3669 - val_loss: 0.6289\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.6281\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3642 - val_loss: 0.6273\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3629 - val_loss: 0.6264\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3616 - val_loss: 0.6256\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1967377505.4498963, my average MASE = 5262000054.755049\n",
      "Cluster 2, 1967377505.4498963\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6328 - val_loss: 0.7373\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6300 - val_loss: 0.7359\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6272 - val_loss: 0.7344\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6245 - val_loss: 0.7330\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6218 - val_loss: 0.7316\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6191 - val_loss: 0.7301\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6164 - val_loss: 0.7287\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6137 - val_loss: 0.7273\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6111 - val_loss: 0.7259\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6085 - val_loss: 0.7245\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6058 - val_loss: 0.7230\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6033 - val_loss: 0.7216\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6009 - val_loss: 0.7202\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5985 - val_loss: 0.7188\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5961 - val_loss: 0.7174\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5938 - val_loss: 0.7159\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5915 - val_loss: 0.7146\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5892 - val_loss: 0.7133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5869 - val_loss: 0.7119\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5847 - val_loss: 0.7106\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5825 - val_loss: 0.7092\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5803 - val_loss: 0.7078\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5781 - val_loss: 0.7064\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5759 - val_loss: 0.7050\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5738 - val_loss: 0.7036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5716 - val_loss: 0.7022\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5695 - val_loss: 0.7009\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5674 - val_loss: 0.6996\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5653 - val_loss: 0.6983\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5632 - val_loss: 0.6971\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5611 - val_loss: 0.6959\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5590 - val_loss: 0.6946\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5569 - val_loss: 0.6934\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5549 - val_loss: 0.6922\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5528 - val_loss: 0.6910\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5509 - val_loss: 0.6898\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5490 - val_loss: 0.6886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5472 - val_loss: 0.6874\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5454 - val_loss: 0.6862\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.6850\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.27232041656941225, my average MASE = 0.501167640234202\n",
      "Cluster 3, 0.27232041656941225\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4602 - val_loss: 0.3734\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4580 - val_loss: 0.3723\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4558 - val_loss: 0.3714\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4536 - val_loss: 0.3704\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4515 - val_loss: 0.3694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4494 - val_loss: 0.3685\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4474 - val_loss: 0.3675\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4454 - val_loss: 0.3666\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4435 - val_loss: 0.3657\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4416 - val_loss: 0.3648\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4397 - val_loss: 0.3640\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4379 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4361 - val_loss: 0.3623\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4344 - val_loss: 0.3616\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4328 - val_loss: 0.3608\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4312 - val_loss: 0.3601\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4296 - val_loss: 0.3594\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4279 - val_loss: 0.3587\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4263 - val_loss: 0.3581\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4247 - val_loss: 0.3575\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4231 - val_loss: 0.3569\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.3564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4200 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4184 - val_loss: 0.3553\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4169 - val_loss: 0.3547\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4154 - val_loss: 0.3542\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4138 - val_loss: 0.3537\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4123 - val_loss: 0.3533\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4109 - val_loss: 0.3528\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4094 - val_loss: 0.3524\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4080 - val_loss: 0.3520\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4066 - val_loss: 0.3516\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4053 - val_loss: 0.3512\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4039 - val_loss: 0.3508\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4026 - val_loss: 0.3505\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4000 - val_loss: 0.3498\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3987 - val_loss: 0.3495\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3974 - val_loss: 0.3492\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3490\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 363.8540679781247, my average MASE = 17706113.36217601\n",
      "Cluster 4, 363.8540679781247\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4172 - val_loss: 0.5128\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4165 - val_loss: 0.5124\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4158 - val_loss: 0.5121\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4151 - val_loss: 0.5117\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.5113\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4139 - val_loss: 0.5110\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4132 - val_loss: 0.5107\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4126 - val_loss: 0.5103\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4120 - val_loss: 0.5100\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4114 - val_loss: 0.5096\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4108 - val_loss: 0.5093\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4102 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4097 - val_loss: 0.5086\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4091 - val_loss: 0.5083\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4085 - val_loss: 0.5080\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4080 - val_loss: 0.5077\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.5074\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4069 - val_loss: 0.5071\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4064 - val_loss: 0.5068\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4059 - val_loss: 0.5065\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.5062\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4048 - val_loss: 0.5059\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4043 - val_loss: 0.5056\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4038 - val_loss: 0.5053\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.5051\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4029 - val_loss: 0.5048\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4019 - val_loss: 0.5042\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4014 - val_loss: 0.5039\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4010 - val_loss: 0.5036\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4005 - val_loss: 0.5033\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4000 - val_loss: 0.5030\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3996 - val_loss: 0.5028\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3991 - val_loss: 0.5025\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3987 - val_loss: 0.5022\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3983 - val_loss: 0.5019\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3978 - val_loss: 0.5016\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5013\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3969 - val_loss: 0.5011\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3965 - val_loss: 0.5008\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 210.04101539413423, my average MASE = 60624707.44207928\n",
      "Cluster 5, 210.04101539413423\n",
      "Before prediction: train_X.shape=(104, 10, 67), train_y.shape=(104, 67), test_X.shape=(35, 10, 67), test_y.shape=(35, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3090 - val_loss: 0.2755\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3084 - val_loss: 0.2752\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3078 - val_loss: 0.2749\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3072 - val_loss: 0.2745\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3066 - val_loss: 0.2742\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3061 - val_loss: 0.2739\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3055 - val_loss: 0.2736\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3049 - val_loss: 0.2733\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3044 - val_loss: 0.2730\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3039 - val_loss: 0.2727\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.2724\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3028 - val_loss: 0.2722\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.2719\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3018 - val_loss: 0.2716\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3013 - val_loss: 0.2713\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3008 - val_loss: 0.2711\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3003 - val_loss: 0.2708\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2998 - val_loss: 0.2705\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2994 - val_loss: 0.2703\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2989 - val_loss: 0.2700\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2984 - val_loss: 0.2698\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2980 - val_loss: 0.2695\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2975 - val_loss: 0.2693\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2971 - val_loss: 0.2690\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2966 - val_loss: 0.2688\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2962 - val_loss: 0.2686\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2958 - val_loss: 0.2683\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2953 - val_loss: 0.2681\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2949 - val_loss: 0.2678\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2945 - val_loss: 0.2676\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2941 - val_loss: 0.2674\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2937 - val_loss: 0.2671\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2933 - val_loss: 0.2669\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2929 - val_loss: 0.2667\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2925 - val_loss: 0.2664\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2921 - val_loss: 0.2662\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2917 - val_loss: 0.2660\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2913 - val_loss: 0.2658\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2909 - val_loss: 0.2656\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2906 - val_loss: 0.2654\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(35, 67), test_y.shape=(35, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 554.2347835476104, my average MASE = 43885073.200175166\n",
      "Cluster 6, 554.2347835476104\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6507 - val_loss: 0.5207\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6481 - val_loss: 0.5200\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6456 - val_loss: 0.5192\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6431 - val_loss: 0.5184\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6407 - val_loss: 0.5176\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6383 - val_loss: 0.5169\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6360 - val_loss: 0.5161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6338 - val_loss: 0.5154\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6316 - val_loss: 0.5147\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6293 - val_loss: 0.5140\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6271 - val_loss: 0.5133\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6249 - val_loss: 0.5126\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6227 - val_loss: 0.5119\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6206 - val_loss: 0.5112\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6185 - val_loss: 0.5105\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6164 - val_loss: 0.5099\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6145 - val_loss: 0.5093\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6125 - val_loss: 0.5087\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6107 - val_loss: 0.5082\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6088 - val_loss: 0.5076\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6069 - val_loss: 0.5071\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6051 - val_loss: 0.5067\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6032 - val_loss: 0.5062\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6014 - val_loss: 0.5058\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5996 - val_loss: 0.5053\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5978 - val_loss: 0.5049\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5959 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5941 - val_loss: 0.5040\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5923 - val_loss: 0.5036\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5905 - val_loss: 0.5033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5888 - val_loss: 0.5030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5871 - val_loss: 0.5027\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5853 - val_loss: 0.5024\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5837 - val_loss: 0.5021\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5822 - val_loss: 0.5017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5806 - val_loss: 0.5014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5791 - val_loss: 0.5011\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5775 - val_loss: 0.5009\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5760 - val_loss: 0.5006\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5745 - val_loss: 0.5004\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2390672605525707, my average MASE = 0.4689912396588464\n",
      "Cluster 7, 0.2390672605525707\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1191 - val_loss: 0.0992\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1138 - val_loss: 0.0972\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1096 - val_loss: 0.0959\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1060 - val_loss: 0.0949\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1029 - val_loss: 0.0942\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1002 - val_loss: 0.0935\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0977 - val_loss: 0.0930\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0955 - val_loss: 0.0925\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0916 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0899 - val_loss: 0.0913\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0884 - val_loss: 0.0909\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0870 - val_loss: 0.0906\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0856 - val_loss: 0.0903\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0844 - val_loss: 0.0900\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0833 - val_loss: 0.0898\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0896\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0812 - val_loss: 0.0894\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0803 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0778 - val_loss: 0.0887\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0771 - val_loss: 0.0886\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0764 - val_loss: 0.0885\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0757 - val_loss: 0.0884\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0751 - val_loss: 0.0883\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0745 - val_loss: 0.0882\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0739 - val_loss: 0.0881\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0880\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0879\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0723 - val_loss: 0.0879\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0878\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0877\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0711 - val_loss: 0.0876\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0707 - val_loss: 0.0876\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0703 - val_loss: 0.0875\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0700 - val_loss: 0.0874\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0873\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0694 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 1385618831.00148, my average MASE = 22365614226.60064\n",
      "Cluster 8, 1385618831.00148\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=11, 11, 68, (49, 67)\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5560 - val_loss: 0.4967\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5553 - val_loss: 0.4965\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5546 - val_loss: 0.4963\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5538 - val_loss: 0.4961\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5531 - val_loss: 0.4960\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5524 - val_loss: 0.4958\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5517 - val_loss: 0.4956\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5510 - val_loss: 0.4955\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5503 - val_loss: 0.4953\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5496 - val_loss: 0.4952\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5489 - val_loss: 0.4950\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 0.4949\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5476 - val_loss: 0.4947\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5469 - val_loss: 0.4946\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5463 - val_loss: 0.4945\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5456 - val_loss: 0.4943\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5450 - val_loss: 0.4942\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5443 - val_loss: 0.4940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5437 - val_loss: 0.4939\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5431 - val_loss: 0.4938\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5425 - val_loss: 0.4936\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5419 - val_loss: 0.4935\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.4934\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5407 - val_loss: 0.4933\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5401 - val_loss: 0.4932\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5395 - val_loss: 0.4930\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5389 - val_loss: 0.4929\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5384 - val_loss: 0.4928\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5378 - val_loss: 0.4927\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5372 - val_loss: 0.4926\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5367 - val_loss: 0.4925\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 0.4923\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5356 - val_loss: 0.4922\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5351 - val_loss: 0.4921\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5345 - val_loss: 0.4920\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5340 - val_loss: 0.4919\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5335 - val_loss: 0.4918\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5329 - val_loss: 0.4917\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5324 - val_loss: 0.4915\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5319 - val_loss: 0.4914\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 62.874751666083846, my average MASE = 63681940.89448814\n",
      "Cluster 0, 62.874751666083846\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3794 - val_loss: 0.4534\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3770 - val_loss: 0.4520\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3747 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3724 - val_loss: 0.4494\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3701 - val_loss: 0.4481\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3678 - val_loss: 0.4468\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.4455\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3634 - val_loss: 0.4443\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3612 - val_loss: 0.4430\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3591 - val_loss: 0.4418\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3571 - val_loss: 0.4406\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3551 - val_loss: 0.4394\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3531 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3511 - val_loss: 0.4371\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3492 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3473 - val_loss: 0.4348\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3454 - val_loss: 0.4337\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3436 - val_loss: 0.4326\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3418 - val_loss: 0.4315\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3400 - val_loss: 0.4305\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3382 - val_loss: 0.4294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3365 - val_loss: 0.4284\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3349 - val_loss: 0.4273\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3332 - val_loss: 0.4263\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3316 - val_loss: 0.4253\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3300 - val_loss: 0.4243\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.4233\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3269 - val_loss: 0.4224\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3254 - val_loss: 0.4214\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.4205\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3224 - val_loss: 0.4196\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.4186\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3195 - val_loss: 0.4177\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3181 - val_loss: 0.4168\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3166 - val_loss: 0.4159\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3153 - val_loss: 0.4151\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3139 - val_loss: 0.4142\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3125 - val_loss: 0.4134\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3112 - val_loss: 0.4125\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3098 - val_loss: 0.4117\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1188796320.3185039, my average MASE = 2779981174.701244\n",
      "Cluster 1, 1188796320.3185039\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6283 - val_loss: 0.6105\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6261 - val_loss: 0.6091\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6239 - val_loss: 0.6076\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6218 - val_loss: 0.6062\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6196 - val_loss: 0.6047\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6175 - val_loss: 0.6033\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6153 - val_loss: 0.6018\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6132 - val_loss: 0.6004\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6110 - val_loss: 0.5990\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6089 - val_loss: 0.5976\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6067 - val_loss: 0.5961\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6046 - val_loss: 0.5947\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6026 - val_loss: 0.5933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6005 - val_loss: 0.5919\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5985 - val_loss: 0.5905\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5964 - val_loss: 0.5891\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5944 - val_loss: 0.5877\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5923 - val_loss: 0.5866\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5903 - val_loss: 0.5854\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5882 - val_loss: 0.5842\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5861 - val_loss: 0.5831\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5841 - val_loss: 0.5819\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5820 - val_loss: 0.5808\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5799 - val_loss: 0.5796\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5778 - val_loss: 0.5784\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5758 - val_loss: 0.5773\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5737 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5717 - val_loss: 0.5751\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5697 - val_loss: 0.5740\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5676 - val_loss: 0.5731\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5656 - val_loss: 0.5721\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5636 - val_loss: 0.5712\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5616 - val_loss: 0.5703\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5597 - val_loss: 0.5694\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5577 - val_loss: 0.5686\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5558 - val_loss: 0.5678\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5538 - val_loss: 0.5670\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5519 - val_loss: 0.5663\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5499 - val_loss: 0.5655\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5480 - val_loss: 0.5647\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32481366416229096, my average MASE = 0.6312112420260654\n",
      "Cluster 2, 0.32481366416229096\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4564 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4555 - val_loss: 0.4793\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4547 - val_loss: 0.4791\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4538 - val_loss: 0.4788\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4529 - val_loss: 0.4786\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4521 - val_loss: 0.4783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4512 - val_loss: 0.4781\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4504 - val_loss: 0.4778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4496 - val_loss: 0.4776\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4487 - val_loss: 0.4773\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4479 - val_loss: 0.4771\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4471 - val_loss: 0.4768\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4463 - val_loss: 0.4766\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4455 - val_loss: 0.4763\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4447 - val_loss: 0.4760\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4439 - val_loss: 0.4758\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4431 - val_loss: 0.4755\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4423 - val_loss: 0.4753\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4415 - val_loss: 0.4750\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4407 - val_loss: 0.4747\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4400 - val_loss: 0.4745\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4742\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4385 - val_loss: 0.4739\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4377 - val_loss: 0.4736\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4370 - val_loss: 0.4733\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4362 - val_loss: 0.4730\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4355 - val_loss: 0.4727\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4724\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4341 - val_loss: 0.4721\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4334 - val_loss: 0.4717\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4327 - val_loss: 0.4714\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4320 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4313 - val_loss: 0.4708\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4307 - val_loss: 0.4705\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4300 - val_loss: 0.4701\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4293 - val_loss: 0.4698\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4286 - val_loss: 0.4694\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4280 - val_loss: 0.4691\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4273 - val_loss: 0.4688\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4266 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1418783.6078857174, my average MASE = 35875462.94910899\n",
      "Cluster 3, 1418783.6078857174\n",
      "Before prediction: train_X.shape=(27, 10, 67), train_y.shape=(27, 67), test_X.shape=(9, 10, 67), test_y.shape=(9, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3810 - val_loss: 0.3926\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3805 - val_loss: 0.3924\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3799 - val_loss: 0.3923\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3794 - val_loss: 0.3921\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3789 - val_loss: 0.3920\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3784 - val_loss: 0.3918\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3779 - val_loss: 0.3917\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3774 - val_loss: 0.3916\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3769 - val_loss: 0.3914\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3764 - val_loss: 0.3913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3759 - val_loss: 0.3911\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3754 - val_loss: 0.3910\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3749 - val_loss: 0.3909\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3744 - val_loss: 0.3907\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3739 - val_loss: 0.3906\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3734 - val_loss: 0.3905\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3729 - val_loss: 0.3903\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3725 - val_loss: 0.3902\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3720 - val_loss: 0.3901\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3715 - val_loss: 0.3900\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3711 - val_loss: 0.3899\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3706 - val_loss: 0.3898\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3701 - val_loss: 0.3896\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3697 - val_loss: 0.3895\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3692 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3688 - val_loss: 0.3893\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3683 - val_loss: 0.3892\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3679 - val_loss: 0.3891\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3674 - val_loss: 0.3890\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3670 - val_loss: 0.3889\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3666 - val_loss: 0.3888\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3661 - val_loss: 0.3887\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3657 - val_loss: 0.3886\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3653 - val_loss: 0.3885\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3648 - val_loss: 0.3884\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3644 - val_loss: 0.3883\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3640 - val_loss: 0.3882\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3636 - val_loss: 0.3881\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3632 - val_loss: 0.3880\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3627 - val_loss: 0.3879\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(9, 67), test_y.shape=(9, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 73.99923698083529, my average MASE = 28273926.299095076\n",
      "Cluster 4, 73.99923698083529\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1188 - val_loss: 0.0994\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1133 - val_loss: 0.0973\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1090 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1053 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1021 - val_loss: 0.0936\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0993 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0969 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0946 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0893 - val_loss: 0.0908\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0878 - val_loss: 0.0906\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0864 - val_loss: 0.0903\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0852 - val_loss: 0.0901\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0841 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0830 - val_loss: 0.0897\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0820 - val_loss: 0.0895\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0811 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0802 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0888\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0772 - val_loss: 0.0887\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0886\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0759 - val_loss: 0.0885\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0753 - val_loss: 0.0884\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0747 - val_loss: 0.0884\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0742 - val_loss: 0.0883\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0737 - val_loss: 0.0882\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0881\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0881\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0724 - val_loss: 0.0880\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0720 - val_loss: 0.0880\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0716 - val_loss: 0.0879\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0879\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0879\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0878\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0877\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0699 - val_loss: 0.0877\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0877\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 772933595.2163092, my average MASE = 33112652144.926693\n",
      "Cluster 5, 772933595.2163092\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6742 - val_loss: 0.5426\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6711 - val_loss: 0.5410\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6680 - val_loss: 0.5395\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6649 - val_loss: 0.5381\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6619 - val_loss: 0.5366\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6589 - val_loss: 0.5352\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6560 - val_loss: 0.5338\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6532 - val_loss: 0.5324\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6503 - val_loss: 0.5310\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6475 - val_loss: 0.5296\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6447 - val_loss: 0.5282\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6420 - val_loss: 0.5269\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6393 - val_loss: 0.5255\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6367 - val_loss: 0.5242\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6340 - val_loss: 0.5229\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6314 - val_loss: 0.5216\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6289 - val_loss: 0.5203\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6264 - val_loss: 0.5190\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6240 - val_loss: 0.5178\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6215 - val_loss: 0.5165\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6191 - val_loss: 0.5153\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6168 - val_loss: 0.5141\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6145 - val_loss: 0.5128\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6122 - val_loss: 0.5115\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6098 - val_loss: 0.5102\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6076 - val_loss: 0.5089\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6054 - val_loss: 0.5076\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6033 - val_loss: 0.5062\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6011 - val_loss: 0.5049\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5989 - val_loss: 0.5035\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5968 - val_loss: 0.5022\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5947 - val_loss: 0.5009\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5928 - val_loss: 0.4996\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5908 - val_loss: 0.4982\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5889 - val_loss: 0.4969\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5869 - val_loss: 0.4956\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5850 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5831 - val_loss: 0.4932\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5812 - val_loss: 0.4921\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5794 - val_loss: 0.4911\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.24234404135098125, my average MASE = 0.42071116848846357\n",
      "Cluster 6, 0.24234404135098125\n",
      "Before prediction: train_X.shape=(50, 10, 67), train_y.shape=(50, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4441 - val_loss: 0.4379\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4435 - val_loss: 0.4378\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4430 - val_loss: 0.4376\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4425 - val_loss: 0.4374\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4372\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4414 - val_loss: 0.4371\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4409 - val_loss: 0.4369\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4404 - val_loss: 0.4367\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4398 - val_loss: 0.4366\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4364\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.4362\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4383 - val_loss: 0.4361\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4378 - val_loss: 0.4359\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4373 - val_loss: 0.4357\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4368 - val_loss: 0.4356\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4363 - val_loss: 0.4354\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4358 - val_loss: 0.4352\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4353 - val_loss: 0.4351\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4348 - val_loss: 0.4349\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4343 - val_loss: 0.4348\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4339 - val_loss: 0.4346\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4334 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4329 - val_loss: 0.4343\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4341\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4320 - val_loss: 0.4340\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4315 - val_loss: 0.4338\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4310 - val_loss: 0.4337\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4306 - val_loss: 0.4335\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4301 - val_loss: 0.4334\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4296 - val_loss: 0.4332\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4292 - val_loss: 0.4331\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4287 - val_loss: 0.4329\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4283 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4278 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4274 - val_loss: 0.4325\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4269 - val_loss: 0.4323\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4265 - val_loss: 0.4322\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4261 - val_loss: 0.4320\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4256 - val_loss: 0.4319\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4252 - val_loss: 0.4317\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 191.2474349797922, my average MASE = 74799483.45709221\n",
      "Cluster 7, 191.2474349797922\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2212 - val_loss: 0.1239\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2202 - val_loss: 0.1236\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2192 - val_loss: 0.1233\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2183 - val_loss: 0.1230\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2174 - val_loss: 0.1228\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2165 - val_loss: 0.1225\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2156 - val_loss: 0.1223\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2147 - val_loss: 0.1221\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2138 - val_loss: 0.1219\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2129 - val_loss: 0.1217\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2120 - val_loss: 0.1215\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2111 - val_loss: 0.1213\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2102 - val_loss: 0.1212\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2093 - val_loss: 0.1211\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2085 - val_loss: 0.1210\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2076 - val_loss: 0.1209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2068 - val_loss: 0.1208\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2059 - val_loss: 0.1207\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2051 - val_loss: 0.1207\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2042 - val_loss: 0.1206\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2034 - val_loss: 0.1206\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2026 - val_loss: 0.1205\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2018 - val_loss: 0.1204\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2010 - val_loss: 0.1204\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2002 - val_loss: 0.1203\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1995 - val_loss: 0.1203\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1987 - val_loss: 0.1203\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1980 - val_loss: 0.1203\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1973 - val_loss: 0.1203\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1965 - val_loss: 0.1203\n",
      "Epoch 30: early stopping\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.15391611936993946, my average MASE = 0.29566028544300293\n",
      "Cluster 8, 0.15391611936993946\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5076 - val_loss: 0.4286\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5055 - val_loss: 0.4276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5036 - val_loss: 0.4266\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5017 - val_loss: 0.4256\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4998 - val_loss: 0.4246\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4980 - val_loss: 0.4236\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4962 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4944 - val_loss: 0.4217\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4926 - val_loss: 0.4208\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4908 - val_loss: 0.4199\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4890 - val_loss: 0.4191\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4871 - val_loss: 0.4182\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4853 - val_loss: 0.4173\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4835 - val_loss: 0.4164\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4817 - val_loss: 0.4156\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4148\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4782 - val_loss: 0.4140\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4765 - val_loss: 0.4133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4749 - val_loss: 0.4126\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4732 - val_loss: 0.4118\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4717 - val_loss: 0.4111\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4701 - val_loss: 0.4104\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4686 - val_loss: 0.4097\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4671 - val_loss: 0.4089\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4656 - val_loss: 0.4082\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4641 - val_loss: 0.4075\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4627 - val_loss: 0.4068\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4613 - val_loss: 0.4061\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4600 - val_loss: 0.4054\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4587 - val_loss: 0.4048\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4573 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4560 - val_loss: 0.4036\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4546 - val_loss: 0.4030\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4533 - val_loss: 0.4025\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4520 - val_loss: 0.4019\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4506 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4493 - val_loss: 0.4009\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4480 - val_loss: 0.4004\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.3999\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4454 - val_loss: 0.3994\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2425229695624874, my average MASE = 0.5232189989788755\n",
      "Cluster 9, 0.2425229695624874\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4116 - val_loss: 0.3522\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4095 - val_loss: 0.3515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.3508\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4055 - val_loss: 0.3501\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3494\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4016 - val_loss: 0.3488\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3996 - val_loss: 0.3481\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3977 - val_loss: 0.3475\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3920 - val_loss: 0.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3902 - val_loss: 0.3450\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3884 - val_loss: 0.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3865 - val_loss: 0.3439\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3847 - val_loss: 0.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3829 - val_loss: 0.3430\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3811 - val_loss: 0.3425\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3793 - val_loss: 0.3420\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3776 - val_loss: 0.3416\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3759 - val_loss: 0.3411\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3742 - val_loss: 0.3407\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3725 - val_loss: 0.3402\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3708 - val_loss: 0.3398\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3692 - val_loss: 0.3394\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3675 - val_loss: 0.3390\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3659 - val_loss: 0.3386\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3644 - val_loss: 0.3382\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3628 - val_loss: 0.3379\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3376\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3597 - val_loss: 0.3373\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3583 - val_loss: 0.3370\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3568 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3554 - val_loss: 0.3364\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3540 - val_loss: 0.3361\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3526 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3512 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3498 - val_loss: 0.3352\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3484 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3471 - val_loss: 0.3347\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3457 - val_loss: 0.3344\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 624.4867423423187, my average MASE = 18127046.32229549\n",
      "Cluster 10, 624.4867423423187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maes = defaultdict(lambda: [])\n",
    "mases = defaultdict(lambda: [])\n",
    "mapes = defaultdict(lambda: [])\n",
    "answers = {}\n",
    "bad_values = np.zeros(dataset.shape[1])\n",
    "\n",
    "dif=True\n",
    "\n",
    "for window_size in window_sizes_for_clustering:\n",
    "    for N_clusters in Ns_clusters:\n",
    "        dataset_windows, dataset_y = Forecasting.create_windows(dataset, window_size=window_size)\n",
    "        clusters_labels = Clustering.KMeans_for_windows(dataset_windows, W=window_size, N_clusters=N_clusters, max_iter=50)\n",
    "        print(f\"{clusters_labels.shape=}\")\n",
    "        datasets_clusters = Clustering.flatten_from_interceting_windows(dataset_windows, clusters_labels, W=window_size, \\\n",
    "                N_clusters=N_clusters)\n",
    "        # list of list of ndarrays [N_i, Q], dataset_clusters[cluster_num][i] - i-th part of dataset for cluster_num\n",
    "\n",
    "        print(f\"{N_clusters=}, {len(datasets_clusters)}, {len(datasets_clusters[0])}, {datasets_clusters[0][0].shape}\")\n",
    "        ###window_size for model\n",
    "        errors = [1] * N_clusters\n",
    "        for cluster_num in range(N_clusters):\n",
    "            sc = Forecasting.MyStandardScaler(dif=dif)\n",
    "            #datasets_clusters[cluster_num] - list of [N_i, Q] ndarrays\n",
    "            sc.fit(datasets_clusters[cluster_num])\n",
    "            prepared_data = sc.transform(datasets_clusters[cluster_num])\n",
    "            data_X, data_y = Forecasting.create_windows(prepared_data, window_size=10)\n",
    "            #data_X - list of [N_i-W, W, Q] ndarrays\n",
    "            train_X, train_y, valid_X, valid_y, test_X, test_y, ind = Forecasting.split_to_train_test(data_X, data_y, part_of_test=0.2, part_of_valid=0.2)\n",
    "            #ndarrays [N_i, W, Q] or [N_i, Q]\n",
    "            ind = np.array(ind) + window_size\n",
    "            print(f\"Before prediction: {train_X.shape=}, {train_y.shape=}, {test_X.shape=}, {test_y.shape=}\")\n",
    "            try:\n",
    "                assert(len(test_X.shape) == 3 and test_X.shape[0] > 0)\n",
    "                assert(len(valid_X.shape) == 3 and valid_X.shape[0] > 0)\n",
    "                assert(len(train_X.shape) == 3 and train_X.shape[0] > 0)\n",
    "            except AssertionError:\n",
    "                print(f\"FAIL - {test_X.shape=}, {valid_X.shape=}, {train_X.shape=}\")\n",
    "                errors[cluster_num] = np.Inf\n",
    "                continue\n",
    "            model, history = Forecasting.learn(train_X, train_y, valid_X=valid_X, valid_y=valid_y)\n",
    "            predicted = model.predict(test_X)\n",
    "            predicted_original = sc.inverse_transform(predicted)[0]\n",
    "            #inverse_trasform returns list of ndarrays \n",
    "            # if dif:\n",
    "                #константа при дифференцировании\n",
    "                # predicted_original = sc.add_first_element(predicted_original, ind)[0]\n",
    "            print(f\"{predicted_original.shape=}, {test_y.shape=}\")\n",
    "\n",
    "            #calc all metrics\n",
    "            cur_mae = mae(test_y, predicted_original, multioutput='raw_values')\n",
    "#             error_out = mase(test_y, predicted_original, y_train=test_y)\n",
    "#             error_in = mase(test_y, predicted_original, y_train=train_y)\n",
    "            # cur_mase = mase(test_y, predicted_original, y_train=test_y)\n",
    "            cur_mape = mape(test_y, predicted_original)\n",
    "            cur_mase = Forecasting.my_mase(test_y, predicted_original, multioutput='raw_values')\n",
    "            maes[(window_size, N_clusters)].append(cur_mae)\n",
    "#             mases[(window_size, N_clusters)].append((error_in, error_out))\n",
    "            mapes[(window_size, N_clusters)].append(cur_mape)\n",
    "#             errors[cluster_num] = mase_uni(test_y, predicted_original, y_train=test_y)\n",
    "            tmp_bad = cur_mase > np.percentile(cur_mase, 90)\n",
    "            bad_values += tmp_bad\n",
    "            cur_mase[tmp_bad] = -1\n",
    "#             errors[cluster_num] = Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')\n",
    "            errors[cluster_num] = np.mean(cur_mase[~tmp_bad])\n",
    "            \n",
    "            #show all metrics\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.suptitle(f\"K={N_clusters}, W={window_size}, C={cluster_num}\")\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(cur_mae, color=\"green\", label=\"library\")\n",
    "            plt.plot(Forecasting.my_mae(test_y, predicted_original, multioutput='raw_values'), color=\"red\", label=\"custom\")\n",
    "            plt.title(\"MAE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "#             plt.plot(error_in, label=\"library, in\")\n",
    "#             plt.plot(error_out, label=\"library, out\")\n",
    "            plt.plot(cur_mase, label=\"custom, out\")\n",
    "            plt.title(\"MASE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(cur_mape)\n",
    "            plt.title(\"MAPE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f\"plots/Dataset2/K={N_clusters}  W={window_size} C={cluster_num}.png\")\n",
    "#             plt.show()    \n",
    "            plt.clf()\n",
    "            # print(f\"{cur_mae=}, {cur_mase=}, {cur_mape=}\")\n",
    "            # my_mase = mase()\n",
    "            # print(f\"MASE in_sample = {error_in}, MASE out_sample = {error_out}\")\n",
    "            print(f\"average MASE = {errors[cluster_num]}, my average MASE = {Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')}\")\n",
    "            print(f\"Cluster {cluster_num}, {errors[cluster_num]}\")\n",
    "        answers[(window_size, N_clusters)] = errors\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.suptitle(f\"K={N_clusters}, W={window_size}\")\n",
    "        plt.subplot(2, 2, 1)\n",
    "\n",
    "        plt.bar(np.arange(N_clusters), [np.sum(clusters_labels == i) for i in range(N_clusters)], color='blue')\n",
    "        plt.title(\"Размеры кластеров\")\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.bar(np.arange(N_clusters), [len(datasets_clusters[i]) for i in range(N_clusters)], color=\"green\")\n",
    "        plt.title(\"Количество непрерывных отрезков\")\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.bar(np.arange(N_clusters), errors, color=\"red\")\n",
    "        plt.title(\"MASE на тесте каждого из кластеров\")\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        plt.table(cellText= [[f\"{x:.2f}\"] for x in errors],\n",
    "                      rowLabels=list(range(N_clusters)),\n",
    "                      loc='center')\n",
    "#         plt.show()\n",
    "        plt.savefig(f\"plots/Dataset2/method1: {N_clusters=}  W={window_size}.png\")\n",
    "        #         plt.show()\n",
    "        plt.clf()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.bar(np.arange(bad_values.shape[0]), bad_values)\n",
    "plt.title(\"Количество раз, когда переменная имела максимум MASE\")\n",
    "plt.savefig(f\"plots/Dataset2/bad_values.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([ 2,  4,  7,  8, 11, 14, 18, 21, 23, 25, 28, 30, 33, 37, 39, 43, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 5)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33,\n",
      "       39, 48, 50, 53, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 28, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 33, 37, 39,\n",
      "       41, 43, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 9)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 30, 31, 33, 35, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 12, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 23, 25, 26, 28, 30, 39, 41, 42, 48,\n",
      "       51, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(3, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 13, 14, 15, 18, 21, 23, 25, 26, 28, 30, 33,\n",
      "       37, 39, 41, 42, 44, 48, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 5)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 26, 28, 30, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 7)\n",
      "     (array([ 2, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 35, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 9)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 23, 25, 28, 30, 31, 33, 35, 39,\n",
      "       41, 43, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(3, 11)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 37, 39, 44, 48,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 2)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 12, 14, 18, 21, 23, 25, 30, 31, 33, 37, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 5)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 31, 39, 60, 61,\n",
      "       62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(5, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 16, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 23, 25, 28, 30, 33, 35, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "(5, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 14, 15, 16, 18, 19, 21, 23, 25, 27, 28, 30,\n",
      "       39, 42, 44, 47, 48, 52, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 15, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35,\n",
      "       37, 39, 60, 61, 62, 63, 65]),)\n",
      "(5, 11)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 28, 30, 31, 33, 39,\n",
      "       41, 42, 49, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(10, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 11, 13, 14, 18, 21, 23, 25, 28, 30, 31, 33,\n",
      "       35, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 5)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 22, 23, 25, 28, 30, 31, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 7)\n",
      "     (array([ 2,  4,  8,  9, 14, 16, 18, 19, 30, 58, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "(10, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 23, 24, 25, 26, 28, 30, 31,\n",
      "       33, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(10, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 12, 14, 18, 21, 22, 23, 25, 28, 30, 39, 56, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in maes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in mases.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c[0] < 1)}, {np.where(val_c[1] < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([14, 18, 25, 30, 31, 33, 35, 37, 43]),)\n",
      "     (array([14, 30]),)\n",
      "(1, 5)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(1, 7)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 11, 14]),)\n",
      "     (array([14]),)\n",
      "(1, 9)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 4,  8, 14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14, 60, 61]),)\n",
      "(1, 11)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(3, 2)\n",
      "     (array([ 4, 14, 18, 30, 31, 33, 35, 37, 42, 62]),)\n",
      "     (array([14, 30]),)\n",
      "(3, 5)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(3, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61]),)\n",
      "(3, 9)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 28, 39, 62]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 19, 30]),)\n",
      "(3, 11)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 23, 28, 39, 62, 65]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "(5, 2)\n",
      "     (array([12, 14, 18, 30, 31, 33, 35, 37, 60, 62, 65]),)\n",
      "     (array([14, 30]),)\n",
      "(5, 5)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "(5, 7)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 9, 11, 14, 18, 19, 21, 23, 25, 30, 39, 42, 44, 47, 52, 60, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 11)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 21, 23, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "(10, 2)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "(10, 5)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 14]),)\n",
      "(10, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 11)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in mapes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
