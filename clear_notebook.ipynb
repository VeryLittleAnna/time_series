{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 01:44:45.805437: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-18 01:44:45.805464: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSet2.csv\", sep=\";\")#, parse_dates=['Timestamp']) #, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "df = data.groupby(data.index // K).mean() #усреднение\n",
    "df_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError, MeanAbsolutePercentageError\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mase = MeanAbsoluteScaledError(multioutput='raw_values')\n",
    "mase_uni = MeanAbsoluteScaledError(multioutput='uniform_average')\n",
    "mape = MeanAbsolutePercentageError(multioutput='raw_values')\n",
    "# mae = MeanAbsoluteError()\n",
    "\n",
    "\n",
    "#if ‘raw_values’, returns a full set of errors in case of multioutput input. If ‘uniform_average’, errors of all outputs are averaged with uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 67)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_np[:, :]\n",
    "# dataset = np.concatenate((dataset[:, :8], dataset[:, 9:]), axis=1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**__Отбор признаков на минималках__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удаление константных\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(0.001)\n",
    "dataset1 = selector.fit_transform(dataset) \n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 14}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(range(67)) - set(selector.get_feature_names_out(input_features=np.arange(dataset.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset[:, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(dataset[:, 8], color=\"green\")\n",
    "plt.plot(np.concatenate((dataset[:32714, 8], dataset[32717:, 8])))\n",
    "plt.title(\"consumption_09\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00292  0.00733  0.754974 1.658794 1.956544]\n",
      "[32714, 375379, 1, 1, 1]\n",
      "Изменение только в [[32713]\n",
      " [32714]\n",
      " [32715]\n",
      " [32716]]\n"
     ]
    }
   ],
   "source": [
    "values = np.unique(dataset[:, 8])\n",
    "print(values)\n",
    "print([len(np.argwhere(dataset[:, 8] == val)) for val in values])\n",
    "print(f\"Изменение только в {np.argwhere(dataset[1:, 8] - dataset[:-1, 8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Эти датчики пока выкинем из-за константности: ** \n",
    "\n",
    "8: consumption_09\n",
    "\n",
    "14 : consumption_07 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('consumption_07', 'consumption_09')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[15], columns[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f67ab432f50>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset[7])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import correlate\n",
    "# a = np.array([np.sin(x + 1) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 2) for x in range(10)])\n",
    "# c = correlate(a, b, mode=\"full\") #mode='same'\n",
    "# plt.plot(a, label=\"a\")\n",
    "# plt.plot(b, label=\"b\")\n",
    "# plt.plot(c, label=\"correlation\")\n",
    "# plt.legend()\n",
    "# c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "#еще не поняла до конца\n",
    "from sklearn.feature_selection import f_regression\n",
    "for i in range(1):\n",
    "    X = np.concatenate((dataset[:, :i], dataset[:, i + 1:]), axis=1)\n",
    "    y = dataset[:, i]\n",
    "    res = f_regression(X, y)\n",
    "    print(res[0].shape)\n",
    "    # plt.plot(res[0], label=\"f_statistics\")\n",
    "    # # plt.plot(res[1], label=\"p_values\")\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([np.sin(x) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 1) + 1 for x in range(10)])\n",
    "# c = np.array([np.sin(x + 0.1) for x in range(10)])\n",
    "\n",
    "# f_regression(a[:, None], b), f_regression(a[:, None], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прогнозирование**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "window_sizes_for_clustering = 10\n",
    "# X, y = dataset[:-window_sizes_for_clustering, ...], dataset[window_sizes_for_clustering:, ...]\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "n_split = round(0.2 * dataset.shape[0])\n",
    "dataset_train, dataset_test = dataset[:-n_split, ...], dataset[-n_split:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((326477, 65), (81619, 65))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes_for_clustering = [5, 10, 15] #1, 3\n",
    "Ns_clusters = [7, 9, 11] #2, 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns_clusters = [2]\n",
    "window_sizes_for_clustering = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, M, Q = 100, 100, 2\n",
    "# dataset_train = np.column_stack([[np.sin(x / 25) for x in range(N)], [0.01 + np.sin(x / 25)*1.01 for x in range(N)]])\n",
    "# dataset_test = np.column_stack([[np.sin(x / 25) for x in range(M)], [0.01 + np.sin(x / 25)*1.01 for x in range(M)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326477, 65)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# Переделать split_to_train_test чтобы возвращало маску 0 - train, 1 - valid, 2 - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_windows.shape=(326470, 7, 65)\n",
      "N_clusters=2\n",
      "dataset_windows.shape=(326466, 1, 12, 65), labels.shape=(326466,)\n",
      "meow:  [(308661, 12, 65), (17805, 12, 65)]\n",
      "All: 308661\n",
      "In transform data.shape=(308661, 12, 65), dif=True\n",
      "result_data.shape=(308661, 12, 65)\n",
      "prepared_data.shape=(308661, 12, 65)\n",
      "clusters_X[cluster_num].shape=(308661, 12, 65), prepared_X.shape=(308661, 11, 65), prepared_y.shape=(308661, 65)\n",
      "-> 308661\n",
      "In split_to_train_test: dataset_X.shape=(308661, 11, 65), dataset_y.shape=(308661, 65)\n",
      "-> 185197, 61732, 61732, 308661\n",
      "Before prediction: train_X.shape=(185197, 11, 65), train_y.shape=(185197, 65), test_X.shape=(61732, 11, 65), test_y.shape=(61732, 65)\n",
      "Before learn: train_X.shape=(185197, 11, 65), train_y.shape=(185197, 65), valid_X.shape=(61732, 11, 65), valid_y.shape=(61732, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 16:20:09.980772: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 529663420 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2894/2894 [==============================] - ETA: 0s - loss: 558.1885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 16:21:11.196828: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 176553520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2894/2894 [==============================] - 68s 24ms/step - loss: 558.1885 - val_loss: 557.1378\n",
      "  17/1930 [..............................] - ETA: 13s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 16:21:20.290178: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 176553520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1930/1930 [==============================] - 14s 7ms/step\n",
      "In calc_results: 185197, 61732, 61732, sum = 308661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 16:21:52.582694: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1765540920 exceeds 10% of free system memory.\n",
      "2022-12-18 16:22:01.858847: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 882770460 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: 17805\n",
      "In transform data.shape=(17805, 12, 65), dif=True\n",
      "result_data.shape=(17805, 12, 65)\n",
      "prepared_data.shape=(17805, 12, 65)\n",
      "clusters_X[cluster_num].shape=(17805, 12, 65), prepared_X.shape=(17805, 11, 65), prepared_y.shape=(17805, 65)\n",
      "-> 17805\n",
      "In split_to_train_test: dataset_X.shape=(17805, 11, 65), dataset_y.shape=(17805, 65)\n",
      "-> 10683, 3561, 3561, 17805\n",
      "Before prediction: train_X.shape=(10683, 11, 65), train_y.shape=(10683, 65), test_X.shape=(3561, 11, 65), test_y.shape=(3561, 65)\n",
      "Before learn: train_X.shape=(10683, 11, 65), train_y.shape=(10683, 65), valid_X.shape=(3561, 11, 65), valid_y.shape=(3561, 65)\n",
      "167/167 [==============================] - 7s 38ms/step - loss: 12464693025177600.0000 - val_loss: 12688867769450496.0000\n",
      "112/112 [==============================] - 1s 12ms/step\n",
      "In calc_results: 10683, 3561, 3561, sum = 17805\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"N_clusters\":Ns_clusters, \"window_size_for_clustering\":window_sizes_for_clustering, \"dif\":True}\n",
    "models, model_mase = Forecasting.try_parameters(parameters, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [<keras.engine.sequential.Sequential at 0x7f679c6c5de0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f67240c7eb0>],\n",
       " 'scalers': [<Forecasting.MyStandardScaler at 0x7f67af1162c0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f67b51ee860>],\n",
       " 'clusters_model': KMeans(init='random', max_iter=1, n_clusters=2)}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/0/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models['models'])):\n",
    "    models['models'][i].save(\"models/\"+str(i))\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "tmp_model = keras.models.load_model('models/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530569945.8690366"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_model = models[\"clusters_model\"]\n",
    "forecasting_models = models['models']\n",
    "scalers = models['scalers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_sizes_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.shape=(81619, 65), dataset_windows.shape=(81612, 455), cluster_nums.shape=(81612,), 7\n",
      "After pad: dataset.shape=(81619, 65), cluster_nums.shape=(81619,)\n",
      "dataset_windows.shape=(81609, 1, 11, 65)\n",
      "cluster_nums.shape=(81609,)\n",
      "cur_windows.shape=(79277, 11, 65)\n",
      "cluster_num=0, len(scalers)=2\n",
      "In transform data.shape=(79277, 11, 65), dif=True\n",
      "result_data.shape=(79277, 11, 65)\n",
      "cur_windows.shape=(79277, 11, 65)\n",
      "cur_windows.shape=(2332, 11, 65)\n",
      "cluster_num=1, len(scalers)=2\n",
      "In transform data.shape=(2332, 11, 65), dif=True\n",
      "result_data.shape=(2332, 11, 65)\n",
      "cur_windows.shape=(2332, 11, 65)\n"
     ]
    }
   ],
   "source": [
    "window_size_for_clustering = clusters_model.cluster_centers_.shape[-1] // dataset_test.shape[-1]\n",
    "y_pred, results = Forecasting.predict_through_clusters(dataset_test, clusters_model, forecasting_models, scalers, window_size_clustering=window_size_for_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape=(81609, 65), dataset_test.shape=(81619, 65)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{y_pred.shape=}, {dataset_test.shape=}\")\n",
    "y_true = dataset_test[-y_pred.shape[0]:]\n",
    "results[:, :dataset.shape[-1]] = y_true\n",
    "cur_mase = Forecasting.my_mase(y_true, y_pred, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"50% best MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_mape = mape(y_true, y_pred)\n",
    "plt.plot(cur_mape[cur_mape < np.percentile(cur_mape, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"50% best MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mape[cur_mape <= np.percentile(cur_mape,100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 67), dtype=float32, numpy=\n",
       "array([[ 8.25200696e-04, -2.52360152e-03,  1.24429585e-03,\n",
       "         5.61252143e-03,  2.41480279e-03,  6.91283401e-03,\n",
       "        -1.55929942e-04,  5.05245430e-03, -3.45375156e-03,\n",
       "         2.31756223e-03, -5.02947718e-03,  5.21133933e-03,\n",
       "         2.63487943e-03, -1.15680450e-03, -8.61713605e-04,\n",
       "        -4.27721906e-03,  1.65054473e-04,  1.98029215e-03,\n",
       "         1.16372411e-03, -6.18001819e-03,  1.38662616e-03,\n",
       "        -3.87507980e-03, -5.78831602e-03, -4.70064487e-03,\n",
       "        -4.91938740e-03, -9.45061352e-03, -6.37044199e-03,\n",
       "        -1.24200690e-03, -2.50279880e-03,  6.26629405e-03,\n",
       "         7.07075465e-03,  4.37504100e-03,  8.11321661e-06,\n",
       "         6.27311785e-03, -2.45433138e-03,  6.55709300e-04,\n",
       "         1.01655931e-03,  3.92863574e-03, -7.48858880e-03,\n",
       "        -3.09383660e-03, -3.60715576e-03,  3.58439516e-04,\n",
       "         5.01208124e-04,  4.94992966e-03,  4.09077760e-03,\n",
       "        -1.00721011e-03, -6.26226794e-03, -6.27841754e-03,\n",
       "         5.10353828e-03,  4.80458234e-03, -2.42970185e-03,\n",
       "         3.23574082e-03,  4.15166654e-03,  1.97961787e-03,\n",
       "         2.42814887e-03, -2.23055086e-03, -2.55294633e-03,\n",
       "        -3.07056517e-03, -7.46782962e-03,  4.13405150e-03,\n",
       "         4.82963771e-03,  6.89104025e-04, -1.09297456e-04,\n",
       "         3.91600234e-03, -8.97214864e-04, -1.08612701e-03,\n",
       "         4.65779193e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.zeros(67 * 10).reshape(1, 10, 67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=2, 2, 22, (30608, 67)\n",
      "Before prediction: train_X.shape=(18358, 10, 67), train_y.shape=(18358, 67), test_X.shape=(6119, 10, 67), test_y.shape=(6119, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3112 - val_loss: 0.3270\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2915 - val_loss: 0.3111\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2761 - val_loss: 0.2987\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2646 - val_loss: 0.2898\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2564 - val_loss: 0.2830\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2504 - val_loss: 0.2777\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2456 - val_loss: 0.2732\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2415 - val_loss: 0.2694\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2378 - val_loss: 0.2660\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2345 - val_loss: 0.2630\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2314 - val_loss: 0.2603\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2286 - val_loss: 0.2579\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2262 - val_loss: 0.2559\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2241 - val_loss: 0.2541\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2222 - val_loss: 0.2526\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2206 - val_loss: 0.2513\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2191 - val_loss: 0.2500\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2179 - val_loss: 0.2489\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2167 - val_loss: 0.2478\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2156 - val_loss: 0.2470\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2147 - val_loss: 0.2461\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2138 - val_loss: 0.2453\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2129 - val_loss: 0.2444\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2122 - val_loss: 0.2439\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2115 - val_loss: 0.2432\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2109 - val_loss: 0.2427\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2103 - val_loss: 0.2421\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2097 - val_loss: 0.2416\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2092 - val_loss: 0.2410\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2087 - val_loss: 0.2407\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2082 - val_loss: 0.2401\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2397\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2073 - val_loss: 0.2394\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2069 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2065 - val_loss: 0.2386\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2062 - val_loss: 0.2382\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2058 - val_loss: 0.2380\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2055 - val_loss: 0.2376\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2052 - val_loss: 0.2373\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2049 - val_loss: 0.2370\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6119, 67), test_y.shape=(6119, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1578.0531622950014, my average MASE = 2807.2183134542065\n",
      "Cluster 0, 1578.0531622950014\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4317 - val_loss: 1.2280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4299 - val_loss: 1.2276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4282 - val_loss: 1.2273\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4264 - val_loss: 1.2269\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4247 - val_loss: 1.2266\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 1.2263\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 1.2259\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4198 - val_loss: 1.2256\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4182 - val_loss: 1.2253\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4166 - val_loss: 1.2251\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4151 - val_loss: 1.2248\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4135 - val_loss: 1.2245\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4120 - val_loss: 1.2242\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4105 - val_loss: 1.2239\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4089 - val_loss: 1.2236\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4074 - val_loss: 1.2233\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4060 - val_loss: 1.2229\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4045 - val_loss: 1.2226\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 1.2223\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4017 - val_loss: 1.2220\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4004 - val_loss: 1.2216\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3990 - val_loss: 1.2213\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3977 - val_loss: 1.2210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3964 - val_loss: 1.2207\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3951 - val_loss: 1.2204\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3938 - val_loss: 1.2201\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3926 - val_loss: 1.2198\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3914 - val_loss: 1.2195\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3901 - val_loss: 1.2192\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3889 - val_loss: 1.2189\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3877 - val_loss: 1.2186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3866 - val_loss: 1.2184\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 1.2181\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3842 - val_loss: 1.2178\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3831 - val_loss: 1.2175\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 1.2173\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3809 - val_loss: 1.2170\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3798 - val_loss: 1.2167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3787 - val_loss: 1.2165\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3776 - val_loss: 1.2162\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 708619678.5307182, my average MASE = 1911068024.4320867\n",
      "Cluster 1, 708619678.5307182\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=5, 5, 1026, (269, 67)\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5683 - val_loss: 0.4789\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5669 - val_loss: 0.4779\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5656 - val_loss: 0.4770\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5643 - val_loss: 0.4760\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5631 - val_loss: 0.4751\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5619 - val_loss: 0.4743\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5607 - val_loss: 0.4734\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5595 - val_loss: 0.4726\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5584 - val_loss: 0.4718\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5573 - val_loss: 0.4710\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5562 - val_loss: 0.4702\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5552 - val_loss: 0.4694\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5542 - val_loss: 0.4687\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5532 - val_loss: 0.4679\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5522 - val_loss: 0.4672\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5512 - val_loss: 0.4665\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5502 - val_loss: 0.4658\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5493 - val_loss: 0.4651\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5483 - val_loss: 0.4644\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5474 - val_loss: 0.4637\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5465 - val_loss: 0.4630\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5456 - val_loss: 0.4624\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5447 - val_loss: 0.4617\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5438 - val_loss: 0.4611\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5429 - val_loss: 0.4605\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5421 - val_loss: 0.4598\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5412 - val_loss: 0.4592\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5404 - val_loss: 0.4586\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5396 - val_loss: 0.4579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5388 - val_loss: 0.4573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5379 - val_loss: 0.4567\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5371 - val_loss: 0.4561\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5363 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5355 - val_loss: 0.4549\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5348 - val_loss: 0.4543\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5340 - val_loss: 0.4538\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5332 - val_loss: 0.4532\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5324 - val_loss: 0.4526\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5317 - val_loss: 0.4521\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5309 - val_loss: 0.4515\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.40868807431647, my average MASE = 112470179.11258063\n",
      "Cluster 0, 139.40868807431647\n",
      "Before prediction: train_X.shape=(31, 10, 67), train_y.shape=(31, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3364 - val_loss: 0.3469\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3360 - val_loss: 0.3468\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3355 - val_loss: 0.3468\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3350 - val_loss: 0.3467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3346 - val_loss: 0.3466\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3341 - val_loss: 0.3465\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3337 - val_loss: 0.3464\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3332 - val_loss: 0.3463\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3328 - val_loss: 0.3463\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3323 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3319 - val_loss: 0.3461\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3315 - val_loss: 0.3460\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3310 - val_loss: 0.3459\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3306 - val_loss: 0.3458\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3302 - val_loss: 0.3457\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3298 - val_loss: 0.3457\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3294 - val_loss: 0.3456\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3290 - val_loss: 0.3455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3286 - val_loss: 0.3454\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3282 - val_loss: 0.3453\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3278 - val_loss: 0.3453\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3274 - val_loss: 0.3452\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3270 - val_loss: 0.3451\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3267 - val_loss: 0.3450\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3263 - val_loss: 0.3450\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3259 - val_loss: 0.3449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3255 - val_loss: 0.3448\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3252 - val_loss: 0.3448\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3248 - val_loss: 0.3447\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3245 - val_loss: 0.3446\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3242 - val_loss: 0.3445\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3238 - val_loss: 0.3445\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3235 - val_loss: 0.3444\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3231 - val_loss: 0.3443\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3228 - val_loss: 0.3443\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3225 - val_loss: 0.3442\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3222 - val_loss: 0.3441\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3440\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3216 - val_loss: 0.3440\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3213 - val_loss: 0.3439\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3523641.3982873675, my average MASE = 66808534.66599488\n",
      "Cluster 1, 3523641.3982873675\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1130 - val_loss: 0.1021\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1076 - val_loss: 0.1000\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1032 - val_loss: 0.0984\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0995 - val_loss: 0.0974\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0964 - val_loss: 0.0968\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0912 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0889 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0869 - val_loss: 0.0951\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0834 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0804 - val_loss: 0.0940\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0791 - val_loss: 0.0938\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0936\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0934\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0757 - val_loss: 0.0933\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0748 - val_loss: 0.0931\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0739 - val_loss: 0.0930\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0730 - val_loss: 0.0929\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0722 - val_loss: 0.0927\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0926\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0707 - val_loss: 0.0925\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0701 - val_loss: 0.0924\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0694 - val_loss: 0.0923\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0922\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0922\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0677 - val_loss: 0.0922\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0672 - val_loss: 0.0921\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0921\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0663 - val_loss: 0.0920\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0919\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0656 - val_loss: 0.0919\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0918\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0918\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0646 - val_loss: 0.0917\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0638 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0635 - val_loss: 0.0915\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 869790828.2820631, my average MASE = 17262168691.962505\n",
      "Cluster 2, 869790828.2820631\n",
      "Before prediction: train_X.shape=(2219, 10, 67), train_y.shape=(2219, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5462 - val_loss: 0.4045\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5391 - val_loss: 0.4010\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5333 - val_loss: 0.3979\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5281 - val_loss: 0.3951\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5234 - val_loss: 0.3925\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5190 - val_loss: 0.3900\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5147 - val_loss: 0.3877\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5107 - val_loss: 0.3856\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5068 - val_loss: 0.3835\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5031 - val_loss: 0.3816\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4996 - val_loss: 0.3797\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4961 - val_loss: 0.3780\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4928 - val_loss: 0.3763\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4896 - val_loss: 0.3747\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4865 - val_loss: 0.3732\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4835 - val_loss: 0.3717\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4806 - val_loss: 0.3704\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4778 - val_loss: 0.3691\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4750 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4723 - val_loss: 0.3666\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4697 - val_loss: 0.3655\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4672 - val_loss: 0.3644\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4647 - val_loss: 0.3633\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4623 - val_loss: 0.3624\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4600 - val_loss: 0.3614\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4577 - val_loss: 0.3605\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4556 - val_loss: 0.3596\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4535 - val_loss: 0.3588\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4515 - val_loss: 0.3580\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4495 - val_loss: 0.3572\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4476 - val_loss: 0.3564\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4458 - val_loss: 0.3557\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4440 - val_loss: 0.3551\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4423 - val_loss: 0.3544\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4406 - val_loss: 0.3538\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4390 - val_loss: 0.3532\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4374 - val_loss: 0.3525\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4359 - val_loss: 0.3519\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4343 - val_loss: 0.3514\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4329 - val_loss: 0.3508\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 408.78828000932964, my average MASE = 1218.6998180420371\n",
      "Cluster 3, 408.78828000932964\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5668 - val_loss: 0.4468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5648 - val_loss: 0.4459\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5628 - val_loss: 0.4451\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5609 - val_loss: 0.4443\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5589 - val_loss: 0.4435\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5570 - val_loss: 0.4427\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5551 - val_loss: 0.4419\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5533 - val_loss: 0.4412\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5514 - val_loss: 0.4404\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5496 - val_loss: 0.4397\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5478 - val_loss: 0.4389\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5460 - val_loss: 0.4382\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5442 - val_loss: 0.4374\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5425 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5408 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5391 - val_loss: 0.4352\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5374 - val_loss: 0.4344\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5358 - val_loss: 0.4337\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5342 - val_loss: 0.4329\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.4322\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5310 - val_loss: 0.4315\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5295 - val_loss: 0.4308\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5280 - val_loss: 0.4300\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5264 - val_loss: 0.4293\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5250 - val_loss: 0.4286\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5235 - val_loss: 0.4279\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5221 - val_loss: 0.4273\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5207 - val_loss: 0.4266\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5193 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5179 - val_loss: 0.4254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5165 - val_loss: 0.4248\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5151 - val_loss: 0.4241\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5138 - val_loss: 0.4235\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5125 - val_loss: 0.4229\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5112 - val_loss: 0.4223\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5099 - val_loss: 0.4217\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5086 - val_loss: 0.4212\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5073 - val_loss: 0.4206\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5061 - val_loss: 0.4200\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5048 - val_loss: 0.4194\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2631402082.882854, my average MASE = 5288471031.0194235\n",
      "Cluster 4, 2631402082.882854\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=7, 7, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1149 - val_loss: 0.1029\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1092 - val_loss: 0.1008\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1047 - val_loss: 0.0992\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1009 - val_loss: 0.0980\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0972\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0947 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0922 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0899 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0878 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0859 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0842 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0826 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0812 - val_loss: 0.0939\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0799 - val_loss: 0.0936\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0934\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0775 - val_loss: 0.0931\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0929\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0755 - val_loss: 0.0928\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0746 - val_loss: 0.0926\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0737 - val_loss: 0.0924\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0923\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0922\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0921\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0708 - val_loss: 0.0920\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0919\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0696 - val_loss: 0.0918\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0690 - val_loss: 0.0917\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0685 - val_loss: 0.0916\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0680 - val_loss: 0.0916\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0675 - val_loss: 0.0915\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0670 - val_loss: 0.0915\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0666 - val_loss: 0.0915\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0662 - val_loss: 0.0914\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0658 - val_loss: 0.0914\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0654 - val_loss: 0.0913\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0651 - val_loss: 0.0913\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0648 - val_loss: 0.0912\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0645 - val_loss: 0.0912\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0642 - val_loss: 0.0911\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0911\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 1397145651.915293, my average MASE = 8779028319.064796\n",
      "Cluster 0, 1397145651.915293\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4446 - val_loss: 0.4248\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.4440 - val_loss: 0.4245\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4434 - val_loss: 0.4242\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4429 - val_loss: 0.4239\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4423 - val_loss: 0.4236\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4418 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4413 - val_loss: 0.4231\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4408 - val_loss: 0.4228\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4403 - val_loss: 0.4226\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4398 - val_loss: 0.4223\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4393 - val_loss: 0.4221\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4388 - val_loss: 0.4219\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4383 - val_loss: 0.4216\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4378 - val_loss: 0.4214\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4212\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4369 - val_loss: 0.4209\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4364 - val_loss: 0.4207\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4360 - val_loss: 0.4205\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4355 - val_loss: 0.4202\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4351 - val_loss: 0.4200\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4346 - val_loss: 0.4198\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4342 - val_loss: 0.4195\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.4193\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4333 - val_loss: 0.4191\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4329 - val_loss: 0.4189\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4325 - val_loss: 0.4187\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4321 - val_loss: 0.4184\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4317 - val_loss: 0.4182\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4313 - val_loss: 0.4180\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4309 - val_loss: 0.4178\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4305 - val_loss: 0.4176\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4301 - val_loss: 0.4175\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4297 - val_loss: 0.4173\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4293 - val_loss: 0.4171\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4289 - val_loss: 0.4169\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4286 - val_loss: 0.4167\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4282 - val_loss: 0.4165\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4278 - val_loss: 0.4163\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4274 - val_loss: 0.4161\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4271 - val_loss: 0.4159\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 86.00366340249806, my average MASE = 69691247.07168306\n",
      "Cluster 1, 86.00366340249806\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9826 - val_loss: 1.3468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9801 - val_loss: 1.3460\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9776 - val_loss: 1.3453\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9751 - val_loss: 1.3446\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9726 - val_loss: 1.3439\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9701 - val_loss: 1.3432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9677 - val_loss: 1.3425\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9653 - val_loss: 1.3419\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9628 - val_loss: 1.3413\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9604 - val_loss: 1.3408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9580 - val_loss: 1.3402\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9556 - val_loss: 1.3396\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9532 - val_loss: 1.3390\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9508 - val_loss: 1.3384\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9486 - val_loss: 1.3379\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9463 - val_loss: 1.3374\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9440 - val_loss: 1.3368\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9418 - val_loss: 1.3363\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9397 - val_loss: 1.3358\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9375 - val_loss: 1.3352\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9353 - val_loss: 1.3347\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9331 - val_loss: 1.3341\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9309 - val_loss: 1.3337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9287 - val_loss: 1.3332\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9266 - val_loss: 1.3328\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9245 - val_loss: 1.3324\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9224 - val_loss: 1.3321\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9203 - val_loss: 1.3317\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9183 - val_loss: 1.3314\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9162 - val_loss: 1.3311\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9141 - val_loss: 1.3308\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9120 - val_loss: 1.3305\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9100 - val_loss: 1.3303\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9079 - val_loss: 1.3300\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9059 - val_loss: 1.3298\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9039 - val_loss: 1.3295\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9019 - val_loss: 1.3293\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9000 - val_loss: 1.3291\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8981 - val_loss: 1.3288\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8963 - val_loss: 1.3286\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1.6636413128548868, my average MASE = 8.526439257891766\n",
      "Cluster 2, 1.6636413128548868\n",
      "Before prediction: train_X.shape=(177, 10, 67), train_y.shape=(177, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7327 - val_loss: 0.5966\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7311 - val_loss: 0.5956\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7296 - val_loss: 0.5946\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7281 - val_loss: 0.5936\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7266 - val_loss: 0.5927\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7252 - val_loss: 0.5918\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7239 - val_loss: 0.5909\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7225 - val_loss: 0.5901\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7212 - val_loss: 0.5892\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7199 - val_loss: 0.5884\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7186 - val_loss: 0.5875\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7174 - val_loss: 0.5867\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7162 - val_loss: 0.5859\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7150 - val_loss: 0.5852\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7138 - val_loss: 0.5844\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7127 - val_loss: 0.5837\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7116 - val_loss: 0.5829\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7104 - val_loss: 0.5822\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7093 - val_loss: 0.5815\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7082 - val_loss: 0.5808\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7071 - val_loss: 0.5801\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7061 - val_loss: 0.5794\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7050 - val_loss: 0.5788\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7040 - val_loss: 0.5781\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7030 - val_loss: 0.5775\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7020 - val_loss: 0.5768\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7010 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7000 - val_loss: 0.5756\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6990 - val_loss: 0.5750\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6981 - val_loss: 0.5744\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6971 - val_loss: 0.5738\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6962 - val_loss: 0.5732\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6953 - val_loss: 0.5726\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6944 - val_loss: 0.5721\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6935 - val_loss: 0.5715\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6925 - val_loss: 0.5710\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6917 - val_loss: 0.5704\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6908 - val_loss: 0.5699\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6899 - val_loss: 0.5694\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6890 - val_loss: 0.5688\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 148.95203283848892, my average MASE = 195949093.5023566\n",
      "Cluster 3, 148.95203283848892\n",
      "Before prediction: train_X.shape=(59, 10, 67), train_y.shape=(59, 67), test_X.shape=(20, 10, 67), test_y.shape=(20, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4242 - val_loss: 0.4717\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4237 - val_loss: 0.4716\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4715\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4228 - val_loss: 0.4714\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4223 - val_loss: 0.4713\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4219 - val_loss: 0.4712\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4214 - val_loss: 0.4711\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4210 - val_loss: 0.4710\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.4709\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4201 - val_loss: 0.4708\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4197 - val_loss: 0.4707\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4193 - val_loss: 0.4706\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4189 - val_loss: 0.4705\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.4705\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4180 - val_loss: 0.4704\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4176 - val_loss: 0.4703\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4702\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4168 - val_loss: 0.4701\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4164 - val_loss: 0.4700\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4160 - val_loss: 0.4699\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4157 - val_loss: 0.4698\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4153 - val_loss: 0.4698\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4149 - val_loss: 0.4697\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4145 - val_loss: 0.4696\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4141 - val_loss: 0.4695\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4138 - val_loss: 0.4694\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4134 - val_loss: 0.4694\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4130 - val_loss: 0.4693\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4127 - val_loss: 0.4692\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4123 - val_loss: 0.4691\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4119 - val_loss: 0.4690\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4116 - val_loss: 0.4690\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4112 - val_loss: 0.4689\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.4688\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4105 - val_loss: 0.4687\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4101 - val_loss: 0.4687\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4098 - val_loss: 0.4686\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4094 - val_loss: 0.4685\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4091 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4087 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(20, 67), test_y.shape=(20, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 138.4214035546147, my average MASE = 76438634.40084383\n",
      "Cluster 4, 138.4214035546147\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4144 - val_loss: 0.4072\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4116 - val_loss: 0.4056\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4089 - val_loss: 0.4039\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4061 - val_loss: 0.4022\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4034 - val_loss: 0.4005\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4008 - val_loss: 0.3988\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3982 - val_loss: 0.3971\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3957 - val_loss: 0.3954\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3932 - val_loss: 0.3937\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3908 - val_loss: 0.3920\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3885 - val_loss: 0.3903\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3861 - val_loss: 0.3887\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3838 - val_loss: 0.3870\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3816 - val_loss: 0.3854\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3795 - val_loss: 0.3838\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3775 - val_loss: 0.3822\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3755 - val_loss: 0.3807\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3735 - val_loss: 0.3793\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3716 - val_loss: 0.3779\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3697 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3679 - val_loss: 0.3751\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3661 - val_loss: 0.3737\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3644 - val_loss: 0.3723\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3710\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3611 - val_loss: 0.3697\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3594 - val_loss: 0.3684\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3578 - val_loss: 0.3672\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3562 - val_loss: 0.3659\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3547 - val_loss: 0.3646\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3533 - val_loss: 0.3634\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.3621\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3506 - val_loss: 0.3608\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3493 - val_loss: 0.3596\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3481 - val_loss: 0.3583\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3468 - val_loss: 0.3571\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3456 - val_loss: 0.3558\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3443 - val_loss: 0.3546\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3431 - val_loss: 0.3534\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3419 - val_loss: 0.3521\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3407 - val_loss: 0.3509\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 697989181.1057402, my average MASE = 1714132782.1928625\n",
      "Cluster 5, 697989181.1057402\n",
      "Before prediction: train_X.shape=(95, 10, 67), train_y.shape=(95, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3944 - val_loss: 0.3555\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3937 - val_loss: 0.3552\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3930 - val_loss: 0.3549\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3924 - val_loss: 0.3546\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3917 - val_loss: 0.3543\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3910 - val_loss: 0.3540\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3904 - val_loss: 0.3537\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3898 - val_loss: 0.3534\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3892 - val_loss: 0.3532\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3886 - val_loss: 0.3529\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3880 - val_loss: 0.3526\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3874 - val_loss: 0.3523\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3868 - val_loss: 0.3520\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3863 - val_loss: 0.3518\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3857 - val_loss: 0.3515\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3852 - val_loss: 0.3512\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3846 - val_loss: 0.3510\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3841 - val_loss: 0.3507\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3835 - val_loss: 0.3504\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3830 - val_loss: 0.3502\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3825 - val_loss: 0.3499\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3820 - val_loss: 0.3496\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3815 - val_loss: 0.3494\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3810 - val_loss: 0.3491\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3805 - val_loss: 0.3489\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3799 - val_loss: 0.3486\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3795 - val_loss: 0.3484\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3790 - val_loss: 0.3481\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3785 - val_loss: 0.3479\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.3476\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3776 - val_loss: 0.3474\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3771 - val_loss: 0.3471\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3767 - val_loss: 0.3469\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3762 - val_loss: 0.3466\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3758 - val_loss: 0.3464\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3753 - val_loss: 0.3461\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3749 - val_loss: 0.3459\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3745 - val_loss: 0.3456\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3740 - val_loss: 0.3454\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3736 - val_loss: 0.3451\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 265.33452450872096, my average MASE = 56598015.30805221\n",
      "Cluster 6, 265.33452450872096\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=9, 9, 1486, (3, 67)\n",
      "Before prediction: train_X.shape=(97, 10, 67), train_y.shape=(97, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4153 - val_loss: 0.4398\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.4396\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4138 - val_loss: 0.4393\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4131 - val_loss: 0.4391\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4124 - val_loss: 0.4388\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4118 - val_loss: 0.4386\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4111 - val_loss: 0.4383\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4105 - val_loss: 0.4381\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4099 - val_loss: 0.4378\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4093 - val_loss: 0.4376\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4087 - val_loss: 0.4374\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4081 - val_loss: 0.4371\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.4369\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4069 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4064 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4058 - val_loss: 0.4362\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.4360\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4047 - val_loss: 0.4358\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4042 - val_loss: 0.4356\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4037 - val_loss: 0.4353\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4032 - val_loss: 0.4351\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4349\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4022 - val_loss: 0.4347\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4017 - val_loss: 0.4345\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4012 - val_loss: 0.4343\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4007 - val_loss: 0.4341\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4003 - val_loss: 0.4339\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3998 - val_loss: 0.4337\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3993 - val_loss: 0.4335\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3989 - val_loss: 0.4334\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3984 - val_loss: 0.4332\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3980 - val_loss: 0.4330\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3976 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3967 - val_loss: 0.4324\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3963 - val_loss: 0.4322\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4320\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3955 - val_loss: 0.4318\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3950 - val_loss: 0.4316\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.4314\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 106.62824359839709, my average MASE = 181907103.45341906\n",
      "Cluster 0, 106.62824359839709\n",
      "Before prediction: train_X.shape=(1415, 10, 67), train_y.shape=(1415, 67), test_X.shape=(472, 10, 67), test_y.shape=(472, 67)\n",
      "Epoch 1/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.1435 - val_loss: 0.0272\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1388 - val_loss: 0.0264\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1347 - val_loss: 0.0256\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1311 - val_loss: 0.0250\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1278 - val_loss: 0.0244\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1249 - val_loss: 0.0239\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1221 - val_loss: 0.0234\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1196 - val_loss: 0.0231\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.1173 - val_loss: 0.0227\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.1151 - val_loss: 0.0224\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1132 - val_loss: 0.0221\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1113 - val_loss: 0.0220\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1096 - val_loss: 0.0217\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1080 - val_loss: 0.0216\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1065 - val_loss: 0.0214\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1051 - val_loss: 0.0212\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1038 - val_loss: 0.0211\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1026 - val_loss: 0.0209\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1014 - val_loss: 0.0208\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1004 - val_loss: 0.0206\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0993 - val_loss: 0.0206\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0983 - val_loss: 0.0205\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0974 - val_loss: 0.0204\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0965 - val_loss: 0.0202\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0957 - val_loss: 0.0201\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0949 - val_loss: 0.0200\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0941 - val_loss: 0.0200\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0934 - val_loss: 0.0199\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0927 - val_loss: 0.0198\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0920 - val_loss: 0.0197\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0914 - val_loss: 0.0197\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0907 - val_loss: 0.0196\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0902 - val_loss: 0.0195\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0896 - val_loss: 0.0195\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0890 - val_loss: 0.0195\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0885 - val_loss: 0.0194\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0880 - val_loss: 0.0194\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0875 - val_loss: 0.0193\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0871 - val_loss: 0.0194\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0867 - val_loss: 0.0193\n",
      "15/15 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(472, 67), test_y.shape=(472, 67)\n",
      "average MASE = 484561401.3912065, my average MASE = 2109803098.5295365\n",
      "Cluster 1, 484561401.3912065\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4184 - val_loss: 0.4085\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4174 - val_loss: 0.4084\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4165 - val_loss: 0.4083\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4155 - val_loss: 0.4082\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4146 - val_loss: 0.4082\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4136 - val_loss: 0.4081\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4127 - val_loss: 0.4080\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4118 - val_loss: 0.4079\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4109 - val_loss: 0.4078\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4100 - val_loss: 0.4077\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4091 - val_loss: 0.4077\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4083 - val_loss: 0.4076\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4074 - val_loss: 0.4075\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4066 - val_loss: 0.4074\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4057 - val_loss: 0.4074\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4049 - val_loss: 0.4073\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4041 - val_loss: 0.4072\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4033 - val_loss: 0.4071\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4025 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4017 - val_loss: 0.4069\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4009 - val_loss: 0.4069\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4001 - val_loss: 0.4068\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3994 - val_loss: 0.4067\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3986 - val_loss: 0.4066\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3979 - val_loss: 0.4065\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3971 - val_loss: 0.4065\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3964 - val_loss: 0.4064\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3957 - val_loss: 0.4063\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3949 - val_loss: 0.4062\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3942 - val_loss: 0.4062\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3936 - val_loss: 0.4061\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3929 - val_loss: 0.4060\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3922 - val_loss: 0.4059\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4058\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3909 - val_loss: 0.4058\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3902 - val_loss: 0.4057\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3896 - val_loss: 0.4056\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3889 - val_loss: 0.4055\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3883 - val_loss: 0.4055\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3877 - val_loss: 0.4054\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 146.41485105295615, my average MASE = 90287364.09726365\n",
      "Cluster 2, 146.41485105295615\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5429 - val_loss: 0.4489\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5408 - val_loss: 0.4477\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5388 - val_loss: 0.4466\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5367 - val_loss: 0.4454\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5348 - val_loss: 0.4443\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5328 - val_loss: 0.4432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5308 - val_loss: 0.4421\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5289 - val_loss: 0.4410\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5270 - val_loss: 0.4399\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5251 - val_loss: 0.4389\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5232 - val_loss: 0.4378\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5214 - val_loss: 0.4368\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5195 - val_loss: 0.4357\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5177 - val_loss: 0.4347\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5159 - val_loss: 0.4336\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5140 - val_loss: 0.4326\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5123 - val_loss: 0.4316\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5105 - val_loss: 0.4306\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5087 - val_loss: 0.4296\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5069 - val_loss: 0.4287\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5052 - val_loss: 0.4277\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5034 - val_loss: 0.4268\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5017 - val_loss: 0.4258\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5000 - val_loss: 0.4249\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4983 - val_loss: 0.4240\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4967 - val_loss: 0.4230\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4950 - val_loss: 0.4221\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4934 - val_loss: 0.4212\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4918 - val_loss: 0.4204\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4903 - val_loss: 0.4195\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4887 - val_loss: 0.4186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.4177\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4857 - val_loss: 0.4169\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4843 - val_loss: 0.4161\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4828 - val_loss: 0.4152\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4814 - val_loss: 0.4144\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4800 - val_loss: 0.4136\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4786 - val_loss: 0.4127\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4772 - val_loss: 0.4119\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4758 - val_loss: 0.4111\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1177081/3287276626.py:67: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 10))\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3556660081.750684, my average MASE = 7865462670.190711\n",
      "Cluster 3, 3556660081.750684\n",
      "Before prediction: train_X.shape=(173, 10, 67), train_y.shape=(173, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7286 - val_loss: 0.5747\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7270 - val_loss: 0.5740\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7256 - val_loss: 0.5733\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7243 - val_loss: 0.5725\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7229 - val_loss: 0.5718\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7216 - val_loss: 0.5712\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7203 - val_loss: 0.5705\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7190 - val_loss: 0.5698\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7178 - val_loss: 0.5692\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7166 - val_loss: 0.5686\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7154 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7142 - val_loss: 0.5673\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7130 - val_loss: 0.5667\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7119 - val_loss: 0.5662\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7108 - val_loss: 0.5656\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7096 - val_loss: 0.5650\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7086 - val_loss: 0.5645\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7075 - val_loss: 0.5639\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7064 - val_loss: 0.5634\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7054 - val_loss: 0.5629\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7044 - val_loss: 0.5624\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7034 - val_loss: 0.5619\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5614\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7014 - val_loss: 0.5609\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7004 - val_loss: 0.5604\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6995 - val_loss: 0.5599\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6986 - val_loss: 0.5595\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6976 - val_loss: 0.5590\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6967 - val_loss: 0.5585\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6958 - val_loss: 0.5581\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6949 - val_loss: 0.5576\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6940 - val_loss: 0.5571\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6931 - val_loss: 0.5567\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5562\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6914 - val_loss: 0.5558\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6905 - val_loss: 0.5553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6896 - val_loss: 0.5549\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6887 - val_loss: 0.5545\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6879 - val_loss: 0.5540\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5536\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 122.19340890523425, my average MASE = 115345826.80728418\n",
      "Cluster 4, 122.19340890523425\n",
      "Before prediction: train_X.shape=(1562, 10, 67), train_y.shape=(1562, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2392 - val_loss: 0.2772\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2287 - val_loss: 0.2673\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2207 - val_loss: 0.2595\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2144 - val_loss: 0.2534\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2094 - val_loss: 0.2481\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2050 - val_loss: 0.2435\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2013 - val_loss: 0.2394\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1978 - val_loss: 0.2357\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1947 - val_loss: 0.2322\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1919 - val_loss: 0.2289\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1892 - val_loss: 0.2259\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1867 - val_loss: 0.2231\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2204\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1821 - val_loss: 0.2179\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1800 - val_loss: 0.2156\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1761 - val_loss: 0.2114\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1743 - val_loss: 0.2096\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1727 - val_loss: 0.2078\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1712 - val_loss: 0.2062\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1698 - val_loss: 0.2047\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2033\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1672 - val_loss: 0.2020\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1661 - val_loss: 0.2007\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1650 - val_loss: 0.1996\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1640 - val_loss: 0.1985\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1631 - val_loss: 0.1974\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1622 - val_loss: 0.1964\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1614 - val_loss: 0.1954\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1598 - val_loss: 0.1936\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1578 - val_loss: 0.1912\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1572 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1566 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1560 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1554 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1549 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1544 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 151.79409601094594, my average MASE = 3866050940.760538\n",
      "Cluster 5, 151.79409601094594\n",
      "Before prediction: train_X.shape=(83, 10, 67), train_y.shape=(83, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4279 - val_loss: 0.5018\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4270 - val_loss: 0.5012\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4262 - val_loss: 0.5006\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4254 - val_loss: 0.5000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4246 - val_loss: 0.4995\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4239 - val_loss: 0.4989\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4231 - val_loss: 0.4984\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4224 - val_loss: 0.4978\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4217 - val_loss: 0.4973\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4968\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4203 - val_loss: 0.4962\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4197 - val_loss: 0.4958\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4191 - val_loss: 0.4953\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4184 - val_loss: 0.4948\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4178 - val_loss: 0.4943\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4939\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4167 - val_loss: 0.4934\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4161 - val_loss: 0.4930\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4155 - val_loss: 0.4926\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4150 - val_loss: 0.4921\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4144 - val_loss: 0.4917\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4139 - val_loss: 0.4913\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4133 - val_loss: 0.4908\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4128 - val_loss: 0.4904\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4123 - val_loss: 0.4900\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4118 - val_loss: 0.4895\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4113 - val_loss: 0.4891\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4107 - val_loss: 0.4887\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4103 - val_loss: 0.4883\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4098 - val_loss: 0.4879\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4093 - val_loss: 0.4875\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4088 - val_loss: 0.4871\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4083 - val_loss: 0.4867\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4079 - val_loss: 0.4863\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4074 - val_loss: 0.4859\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4069 - val_loss: 0.4855\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4065 - val_loss: 0.4851\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4061 - val_loss: 0.4848\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4056 - val_loss: 0.4844\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4052 - val_loss: 0.4840\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 155.68618683798326, my average MASE = 97738271.39222205\n",
      "Cluster 6, 155.68618683798326\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2911 - val_loss: 0.2917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2907 - val_loss: 0.2915\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2902 - val_loss: 0.2913\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2897 - val_loss: 0.2911\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2892 - val_loss: 0.2909\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2888 - val_loss: 0.2907\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2883 - val_loss: 0.2905\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2878 - val_loss: 0.2903\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2874 - val_loss: 0.2901\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2869 - val_loss: 0.2899\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2865 - val_loss: 0.2898\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2861 - val_loss: 0.2896\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2856 - val_loss: 0.2894\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2852 - val_loss: 0.2892\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2848 - val_loss: 0.2890\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2844 - val_loss: 0.2889\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2840 - val_loss: 0.2887\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2836 - val_loss: 0.2885\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2832 - val_loss: 0.2883\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2828 - val_loss: 0.2882\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2824 - val_loss: 0.2880\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2820 - val_loss: 0.2878\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2816 - val_loss: 0.2877\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2812 - val_loss: 0.2875\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2808 - val_loss: 0.2874\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2804 - val_loss: 0.2872\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2800 - val_loss: 0.2870\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2796 - val_loss: 0.2869\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2793 - val_loss: 0.2867\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2789 - val_loss: 0.2865\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2785 - val_loss: 0.2864\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2781 - val_loss: 0.2862\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2778 - val_loss: 0.2861\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2774 - val_loss: 0.2859\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2770 - val_loss: 0.2858\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2767 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2763 - val_loss: 0.2855\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2759 - val_loss: 0.2853\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2756 - val_loss: 0.2852\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2752 - val_loss: 0.2851\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 112.24086700274312, my average MASE = 119826311.76187374\n",
      "Cluster 8, 112.24086700274312\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=11, 11, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1118 - val_loss: 0.1019\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1064 - val_loss: 0.0996\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1022 - val_loss: 0.0982\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0987 - val_loss: 0.0973\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0956 - val_loss: 0.0966\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0930 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0885 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0866 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0848 - val_loss: 0.0949\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0832 - val_loss: 0.0946\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0818 - val_loss: 0.0944\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0804 - val_loss: 0.0941\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0792 - val_loss: 0.0939\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0780 - val_loss: 0.0937\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0769 - val_loss: 0.0936\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0759 - val_loss: 0.0934\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0749 - val_loss: 0.0933\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0740 - val_loss: 0.0932\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0732 - val_loss: 0.0931\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0724 - val_loss: 0.0929\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0716 - val_loss: 0.0928\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0927\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0926\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0696 - val_loss: 0.0926\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0690 - val_loss: 0.0925\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0924\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0923\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0674 - val_loss: 0.0923\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0922\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0921\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0662 - val_loss: 0.0921\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0658 - val_loss: 0.0920\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0919\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0651 - val_loss: 0.0919\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0648 - val_loss: 0.0918\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0645 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0642 - val_loss: 0.0917\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0637 - val_loss: 0.0916\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 876211806.5152007, my average MASE = 21477700395.128197\n",
      "Cluster 0, 876211806.5152007\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7012 - val_loss: 0.5689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7001 - val_loss: 0.5688\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6990 - val_loss: 0.5687\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6979 - val_loss: 0.5686\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6968 - val_loss: 0.5685\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6958 - val_loss: 0.5684\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6947 - val_loss: 0.5683\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6936 - val_loss: 0.5682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6926 - val_loss: 0.5681\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6916 - val_loss: 0.5680\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6906 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6896 - val_loss: 0.5678\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6887 - val_loss: 0.5677\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6877 - val_loss: 0.5676\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6868 - val_loss: 0.5675\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6859 - val_loss: 0.5674\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6849 - val_loss: 0.5673\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6840 - val_loss: 0.5672\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6831 - val_loss: 0.5671\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6822 - val_loss: 0.5670\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6813 - val_loss: 0.5669\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6805 - val_loss: 0.5668\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6796 - val_loss: 0.5667\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6787 - val_loss: 0.5666\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6779 - val_loss: 0.5665\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6771 - val_loss: 0.5665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6762 - val_loss: 0.5664\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6754 - val_loss: 0.5663\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6746 - val_loss: 0.5662\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6738 - val_loss: 0.5661\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6730 - val_loss: 0.5660\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6722 - val_loss: 0.5659\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6715 - val_loss: 0.5658\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6707 - val_loss: 0.5657\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6699 - val_loss: 0.5656\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6691 - val_loss: 0.5655\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6684 - val_loss: 0.5654\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6676 - val_loss: 0.5653\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6668 - val_loss: 0.5652\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6661 - val_loss: 0.5651\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1104923.1929255812, my average MASE = 35973487.14565515\n",
      "Cluster 1, 1104923.1929255812\n",
      "Before prediction: train_X.shape=(134, 10, 67), train_y.shape=(134, 67), test_X.shape=(45, 10, 67), test_y.shape=(45, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4388 - val_loss: 0.7635\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4381 - val_loss: 0.7630\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4375 - val_loss: 0.7625\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4369 - val_loss: 0.7620\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4363 - val_loss: 0.7616\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4358 - val_loss: 0.7611\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4353 - val_loss: 0.7607\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4348 - val_loss: 0.7603\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4343 - val_loss: 0.7598\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4338 - val_loss: 0.7594\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4333 - val_loss: 0.7590\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4328 - val_loss: 0.7585\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4323 - val_loss: 0.7581\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4318 - val_loss: 0.7576\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4314 - val_loss: 0.7572\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4309 - val_loss: 0.7568\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4305 - val_loss: 0.7564\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4301 - val_loss: 0.7561\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4296 - val_loss: 0.7557\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4292 - val_loss: 0.7554\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4288 - val_loss: 0.7550\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4284 - val_loss: 0.7546\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4280 - val_loss: 0.7543\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4276 - val_loss: 0.7539\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4272 - val_loss: 0.7535\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4268 - val_loss: 0.7532\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4264 - val_loss: 0.7528\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4260 - val_loss: 0.7525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4257 - val_loss: 0.7521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4253 - val_loss: 0.7517\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4249 - val_loss: 0.7514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4245 - val_loss: 0.7511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4242 - val_loss: 0.7508\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4238 - val_loss: 0.7505\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4235 - val_loss: 0.7502\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4231 - val_loss: 0.7499\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4228 - val_loss: 0.7496\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4225 - val_loss: 0.7492\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4221 - val_loss: 0.7489\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4218 - val_loss: 0.7486\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(45, 67), test_y.shape=(45, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 134.01886625392066, my average MASE = 180554408.61752364\n",
      "Cluster 2, 134.01886625392066\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3365 - val_loss: 0.4571\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3346 - val_loss: 0.4566\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3328 - val_loss: 0.4560\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.4555\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3293 - val_loss: 0.4550\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.4544\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3260 - val_loss: 0.4539\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.4534\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3229 - val_loss: 0.4528\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3213 - val_loss: 0.4523\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3197 - val_loss: 0.4518\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3182 - val_loss: 0.4512\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3166 - val_loss: 0.4507\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3152 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3137 - val_loss: 0.4496\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3123 - val_loss: 0.4490\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3109 - val_loss: 0.4485\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3095 - val_loss: 0.4479\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3082 - val_loss: 0.4473\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3070 - val_loss: 0.4468\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3058 - val_loss: 0.4462\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3045 - val_loss: 0.4456\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.4450\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3021 - val_loss: 0.4444\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3009 - val_loss: 0.4438\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2998 - val_loss: 0.4432\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2986 - val_loss: 0.4426\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2974 - val_loss: 0.4420\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2963 - val_loss: 0.4414\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2952 - val_loss: 0.4407\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2940 - val_loss: 0.4401\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2929 - val_loss: 0.4395\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.4389\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2907 - val_loss: 0.4384\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2896 - val_loss: 0.4379\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2885 - val_loss: 0.4373\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2875 - val_loss: 0.4369\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2865 - val_loss: 0.4364\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2854 - val_loss: 0.4359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2844 - val_loss: 0.4355\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.28495017155315366, my average MASE = 0.3992586255016426\n",
      "Cluster 3, 0.28495017155315366\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6320 - val_loss: 1.0222\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6307 - val_loss: 1.0218\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 1.0214\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6284 - val_loss: 1.0211\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6273 - val_loss: 1.0208\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6262 - val_loss: 1.0205\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6252 - val_loss: 1.0201\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6241 - val_loss: 1.0198\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6231 - val_loss: 1.0195\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6221 - val_loss: 1.0192\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6212 - val_loss: 1.0188\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6202 - val_loss: 1.0185\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6193 - val_loss: 1.0182\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6183 - val_loss: 1.0179\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6174 - val_loss: 1.0176\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6166 - val_loss: 1.0172\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6157 - val_loss: 1.0169\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6148 - val_loss: 1.0166\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6139 - val_loss: 1.0162\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6131 - val_loss: 1.0159\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6122 - val_loss: 1.0155\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6114 - val_loss: 1.0152\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6106 - val_loss: 1.0148\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6097 - val_loss: 1.0145\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6089 - val_loss: 1.0141\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6081 - val_loss: 1.0138\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6073 - val_loss: 1.0134\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6066 - val_loss: 1.0131\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6057 - val_loss: 1.0127\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6050 - val_loss: 1.0124\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6042 - val_loss: 1.0121\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6035 - val_loss: 1.0118\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6027 - val_loss: 1.0114\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6020 - val_loss: 1.0111\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6013 - val_loss: 1.0108\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6005 - val_loss: 1.0104\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5998 - val_loss: 1.0101\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5991 - val_loss: 1.0098\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5984 - val_loss: 1.0094\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5977 - val_loss: 1.0091\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 98.33747704062574, my average MASE = 204772160.73570046\n",
      "Cluster 4, 98.33747704062574\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4785 - val_loss: 0.4645\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4760 - val_loss: 0.4629\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4734 - val_loss: 0.4612\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4709 - val_loss: 0.4596\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4684 - val_loss: 0.4580\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4661 - val_loss: 0.4564\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4638 - val_loss: 0.4548\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4615 - val_loss: 0.4532\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4593 - val_loss: 0.4516\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4572 - val_loss: 0.4500\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4551 - val_loss: 0.4484\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4530 - val_loss: 0.4468\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4509 - val_loss: 0.4453\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4489 - val_loss: 0.4438\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4469 - val_loss: 0.4422\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4449 - val_loss: 0.4407\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4429 - val_loss: 0.4393\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4410 - val_loss: 0.4380\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4391 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4371 - val_loss: 0.4354\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4353 - val_loss: 0.4343\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4335 - val_loss: 0.4332\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4317 - val_loss: 0.4322\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4300 - val_loss: 0.4311\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4282 - val_loss: 0.4301\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4265 - val_loss: 0.4291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4248 - val_loss: 0.4281\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 0.4270\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4197 - val_loss: 0.4250\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4181 - val_loss: 0.4240\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4165 - val_loss: 0.4229\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4149 - val_loss: 0.4218\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4134 - val_loss: 0.4208\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4118 - val_loss: 0.4197\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4103 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4088 - val_loss: 0.4176\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.4167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4060 - val_loss: 0.4157\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4046 - val_loss: 0.4148\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 931833756.986838, my average MASE = 2420970654.4710827\n",
      "Cluster 5, 931833756.986838\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4346 - val_loss: 0.4628\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4334 - val_loss: 0.4625\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4323 - val_loss: 0.4621\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4312 - val_loss: 0.4618\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4301 - val_loss: 0.4615\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4290 - val_loss: 0.4612\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4280 - val_loss: 0.4609\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4269 - val_loss: 0.4605\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4259 - val_loss: 0.4602\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4249 - val_loss: 0.4599\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4239 - val_loss: 0.4596\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4228 - val_loss: 0.4593\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4218 - val_loss: 0.4590\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4208 - val_loss: 0.4587\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4198 - val_loss: 0.4584\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4188 - val_loss: 0.4582\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4179 - val_loss: 0.4579\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4169 - val_loss: 0.4576\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4160 - val_loss: 0.4573\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4151 - val_loss: 0.4570\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4141 - val_loss: 0.4567\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4132 - val_loss: 0.4564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4123 - val_loss: 0.4561\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4114 - val_loss: 0.4558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4106 - val_loss: 0.4555\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4097 - val_loss: 0.4552\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4089 - val_loss: 0.4549\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4080 - val_loss: 0.4546\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4072 - val_loss: 0.4544\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4063 - val_loss: 0.4541\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4055 - val_loss: 0.4538\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4047 - val_loss: 0.4536\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4039 - val_loss: 0.4533\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4031 - val_loss: 0.4531\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4023 - val_loss: 0.4529\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4015 - val_loss: 0.4527\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4007 - val_loss: 0.4526\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3999 - val_loss: 0.4524\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3991 - val_loss: 0.4522\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3983 - val_loss: 0.4520\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 806621.4868706047, my average MASE = 27017424.126969155\n",
      "Cluster 6, 806621.4868706047\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8616 - val_loss: 0.8556\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8588 - val_loss: 0.8539\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8561 - val_loss: 0.8522\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8534 - val_loss: 0.8505\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8508 - val_loss: 0.8489\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8484 - val_loss: 0.8472\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8459 - val_loss: 0.8456\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8435 - val_loss: 0.8440\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8412 - val_loss: 0.8424\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8389 - val_loss: 0.8408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8366 - val_loss: 0.8392\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8343 - val_loss: 0.8376\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8320 - val_loss: 0.8361\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8298 - val_loss: 0.8345\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8276 - val_loss: 0.8329\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8254 - val_loss: 0.8314\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8232 - val_loss: 0.8298\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8210 - val_loss: 0.8283\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 0.8267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8168 - val_loss: 0.8253\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8146 - val_loss: 0.8238\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8125 - val_loss: 0.8224\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8104 - val_loss: 0.8210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8084 - val_loss: 0.8197\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8064 - val_loss: 0.8184\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8045 - val_loss: 0.8170\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8025 - val_loss: 0.8157\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8006 - val_loss: 0.8143\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7987 - val_loss: 0.8129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7969 - val_loss: 0.8115\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7950 - val_loss: 0.8102\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7932 - val_loss: 0.8089\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7913 - val_loss: 0.8077\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7894 - val_loss: 0.8065\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7876 - val_loss: 0.8053\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7857 - val_loss: 0.8041\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7839 - val_loss: 0.8030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7821 - val_loss: 0.8019\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7803 - val_loss: 0.8008\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7785 - val_loss: 0.7997\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 964635493.0745914, my average MASE = 2107611139.389815\n",
      "Cluster 7, 964635493.0745914\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3952 - val_loss: 0.3689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3946 - val_loss: 0.3689\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3941 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3935 - val_loss: 0.3687\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3930 - val_loss: 0.3687\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3924 - val_loss: 0.3686\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3919 - val_loss: 0.3685\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3914 - val_loss: 0.3685\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3909 - val_loss: 0.3684\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3903 - val_loss: 0.3684\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3898 - val_loss: 0.3683\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3893 - val_loss: 0.3682\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3888 - val_loss: 0.3682\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3883 - val_loss: 0.3681\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3878 - val_loss: 0.3680\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3873 - val_loss: 0.3680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3869 - val_loss: 0.3679\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3864 - val_loss: 0.3679\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3855 - val_loss: 0.3677\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3850 - val_loss: 0.3677\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3845 - val_loss: 0.3676\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3841 - val_loss: 0.3676\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3836 - val_loss: 0.3675\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3832 - val_loss: 0.3674\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3828 - val_loss: 0.3674\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3823 - val_loss: 0.3673\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3819 - val_loss: 0.3673\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3815 - val_loss: 0.3672\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3811 - val_loss: 0.3672\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3806 - val_loss: 0.3671\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3802 - val_loss: 0.3670\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3798 - val_loss: 0.3670\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.3669\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3790 - val_loss: 0.3669\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3786 - val_loss: 0.3668\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3782 - val_loss: 0.3668\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3778 - val_loss: 0.3667\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3774 - val_loss: 0.3666\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3770 - val_loss: 0.3666\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 51.171495934252626, my average MASE = 30811708.472042836\n",
      "Cluster 8, 51.171495934252626\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4416 - val_loss: 0.4387\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4409 - val_loss: 0.4386\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4402 - val_loss: 0.4384\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4395 - val_loss: 0.4383\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4388 - val_loss: 0.4381\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4382 - val_loss: 0.4380\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4375 - val_loss: 0.4379\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4368 - val_loss: 0.4377\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4362 - val_loss: 0.4376\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4355 - val_loss: 0.4375\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4348 - val_loss: 0.4373\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4342 - val_loss: 0.4372\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4335 - val_loss: 0.4371\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4329 - val_loss: 0.4370\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4323 - val_loss: 0.4368\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4316 - val_loss: 0.4367\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4310 - val_loss: 0.4366\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4304 - val_loss: 0.4365\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4298 - val_loss: 0.4364\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4292 - val_loss: 0.4363\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4286 - val_loss: 0.4362\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4280 - val_loss: 0.4361\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4274 - val_loss: 0.4359\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4268 - val_loss: 0.4358\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4262 - val_loss: 0.4357\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4256 - val_loss: 0.4356\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4250 - val_loss: 0.4355\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4245 - val_loss: 0.4354\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4239 - val_loss: 0.4353\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4352\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4227 - val_loss: 0.4351\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4221 - val_loss: 0.4350\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.4349\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4348\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4204 - val_loss: 0.4347\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4199 - val_loss: 0.4346\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4193 - val_loss: 0.4345\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4187 - val_loss: 0.4345\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4182 - val_loss: 0.4344\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4176 - val_loss: 0.4343\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 67.68630348587587, my average MASE = 34346224.36796317\n",
      "Cluster 9, 67.68630348587587\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=2, 2, 18, (30610, 67)\n",
      "Before prediction: train_X.shape=(18359, 10, 67), train_y.shape=(18359, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3046 - val_loss: 0.3213\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2853 - val_loss: 0.3058\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2698 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2588 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2516 - val_loss: 0.2788\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2460 - val_loss: 0.2736\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2412 - val_loss: 0.2691\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2371 - val_loss: 0.2652\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2335 - val_loss: 0.2618\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2301 - val_loss: 0.2588\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2271 - val_loss: 0.2562\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2243 - val_loss: 0.2538\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2219 - val_loss: 0.2516\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2199 - val_loss: 0.2498\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2181 - val_loss: 0.2483\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2166 - val_loss: 0.2469\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2153 - val_loss: 0.2458\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2142 - val_loss: 0.2448\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2122 - val_loss: 0.2430\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2114 - val_loss: 0.2422\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2106 - val_loss: 0.2414\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2099 - val_loss: 0.2407\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2092 - val_loss: 0.2401\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2086 - val_loss: 0.2395\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2080 - val_loss: 0.2389\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2074 - val_loss: 0.2385\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2069 - val_loss: 0.2380\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2064 - val_loss: 0.2376\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2059 - val_loss: 0.2370\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2054 - val_loss: 0.2367\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2050 - val_loss: 0.2362\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2046 - val_loss: 0.2359\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2042 - val_loss: 0.2356\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2038 - val_loss: 0.2351\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2034 - val_loss: 0.2349\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2031 - val_loss: 0.2345\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2021 - val_loss: 0.2337\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1675.644817755528, my average MASE = 2652.7812514268226\n",
      "Cluster 0, 1675.644817755528\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4228 - val_loss: 1.1321\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4209 - val_loss: 1.1320\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4191 - val_loss: 1.1319\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4173 - val_loss: 1.1318\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 1.1317\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4139 - val_loss: 1.1315\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4122 - val_loss: 1.1314\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4106 - val_loss: 1.1313\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4090 - val_loss: 1.1311\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4075 - val_loss: 1.1310\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4059 - val_loss: 1.1308\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4044 - val_loss: 1.1306\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4030 - val_loss: 1.1304\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4015 - val_loss: 1.1302\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4001 - val_loss: 1.1300\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 1.1298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3973 - val_loss: 1.1296\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3960 - val_loss: 1.1294\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3946 - val_loss: 1.1292\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3933 - val_loss: 1.1290\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 1.1288\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3907 - val_loss: 1.1286\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3895 - val_loss: 1.1283\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3883 - val_loss: 1.1281\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3871 - val_loss: 1.1279\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 1.1277\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3847 - val_loss: 1.1275\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3836 - val_loss: 1.1272\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3825 - val_loss: 1.1270\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3814 - val_loss: 1.1268\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3803 - val_loss: 1.1266\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3792 - val_loss: 1.1264\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3781 - val_loss: 1.1262\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3771 - val_loss: 1.1259\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3761 - val_loss: 1.1257\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3750 - val_loss: 1.1255\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3740 - val_loss: 1.1253\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 1.1251\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3721 - val_loss: 1.1249\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3711 - val_loss: 1.1247\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 993839931.13901, my average MASE = 2723871222.022616\n",
      "Cluster 1, 993839931.13901\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=5, 5, 75, (319, 67)\n",
      "Before prediction: train_X.shape=(185, 10, 67), train_y.shape=(185, 67), test_X.shape=(62, 10, 67), test_y.shape=(62, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6944 - val_loss: 0.6444\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6929 - val_loss: 0.6434\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6914 - val_loss: 0.6425\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6901 - val_loss: 0.6415\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6887 - val_loss: 0.6406\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6874 - val_loss: 0.6397\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6860 - val_loss: 0.6388\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6847 - val_loss: 0.6380\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6834 - val_loss: 0.6372\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6822 - val_loss: 0.6363\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6810 - val_loss: 0.6355\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6798 - val_loss: 0.6347\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.6340\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6775 - val_loss: 0.6332\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.6325\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6753 - val_loss: 0.6318\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6742 - val_loss: 0.6310\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6732 - val_loss: 0.6303\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6721 - val_loss: 0.6296\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6711 - val_loss: 0.6289\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6701 - val_loss: 0.6283\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6692 - val_loss: 0.6276\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6682 - val_loss: 0.6270\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6672 - val_loss: 0.6263\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6663 - val_loss: 0.6257\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6654 - val_loss: 0.6251\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.6244\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6636 - val_loss: 0.6238\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6627 - val_loss: 0.6232\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6618 - val_loss: 0.6226\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6610 - val_loss: 0.6220\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6601 - val_loss: 0.6214\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6593 - val_loss: 0.6208\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6584 - val_loss: 0.6202\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6576 - val_loss: 0.6196\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6568 - val_loss: 0.6191\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6559 - val_loss: 0.6185\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6551 - val_loss: 0.6179\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6543 - val_loss: 0.6173\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6535 - val_loss: 0.6167\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(62, 67), test_y.shape=(62, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 141.38884780958514, my average MASE = 173942620.82410374\n",
      "Cluster 0, 141.38884780958514\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0665 - val_loss: 0.0455\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0607 - val_loss: 0.0424\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0575 - val_loss: 0.0402\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0551 - val_loss: 0.0384\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0531 - val_loss: 0.0370\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0515 - val_loss: 0.0358\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0502 - val_loss: 0.0347\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0491 - val_loss: 0.0338\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0481 - val_loss: 0.0331\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0473 - val_loss: 0.0324\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0466 - val_loss: 0.0319\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0460 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0454 - val_loss: 0.0311\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0449 - val_loss: 0.0307\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0304\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0301\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0437 - val_loss: 0.0299\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0433 - val_loss: 0.0297\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0294\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0292\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0424 - val_loss: 0.0290\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0422 - val_loss: 0.0288\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0420 - val_loss: 0.0287\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0418 - val_loss: 0.0285\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0416 - val_loss: 0.0284\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0414 - val_loss: 0.0283\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0412 - val_loss: 0.0281\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0411 - val_loss: 0.0280\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0279\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0278\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0278\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0277\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0276\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0403 - val_loss: 0.0276\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0275\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0401 - val_loss: 0.0274\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0274\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0273\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0273\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0272\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1157555182.6490364, my average MASE = 73085160895.13536\n",
      "Cluster 1, 1157555182.6490364\n",
      "Before prediction: train_X.shape=(37, 10, 67), train_y.shape=(37, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5516 - val_loss: 0.5380\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5498 - val_loss: 0.5365\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5480 - val_loss: 0.5350\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5462 - val_loss: 0.5335\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5444 - val_loss: 0.5321\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5427 - val_loss: 0.5306\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5410 - val_loss: 0.5292\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5393 - val_loss: 0.5278\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5376 - val_loss: 0.5264\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5360 - val_loss: 0.5250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5343 - val_loss: 0.5237\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5328 - val_loss: 0.5223\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5312 - val_loss: 0.5210\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5297 - val_loss: 0.5197\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5281 - val_loss: 0.5184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5266 - val_loss: 0.5171\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5252 - val_loss: 0.5158\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5237 - val_loss: 0.5146\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5223 - val_loss: 0.5133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5208 - val_loss: 0.5121\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5194 - val_loss: 0.5109\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5181 - val_loss: 0.5098\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5167 - val_loss: 0.5086\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5154 - val_loss: 0.5075\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5141 - val_loss: 0.5063\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5128 - val_loss: 0.5052\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5115 - val_loss: 0.5041\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5103 - val_loss: 0.5031\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5091 - val_loss: 0.5020\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5078 - val_loss: 0.5010\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.5000\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5055 - val_loss: 0.4990\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5043 - val_loss: 0.4980\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5031 - val_loss: 0.4970\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5020 - val_loss: 0.4961\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5008 - val_loss: 0.4952\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.4943\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4986 - val_loss: 0.4934\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4975 - val_loss: 0.4926\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4964 - val_loss: 0.4917\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4324881186.205308, my average MASE = 10393885205.318085\n",
      "Cluster 2, 4324881186.205308\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4066 - val_loss: 0.3845\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4060 - val_loss: 0.3840\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.3836\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4048 - val_loss: 0.3831\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4042 - val_loss: 0.3826\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4036 - val_loss: 0.3822\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 0.3817\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4025 - val_loss: 0.3812\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4019 - val_loss: 0.3808\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4014 - val_loss: 0.3803\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3799\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4003 - val_loss: 0.3795\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3791\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3992 - val_loss: 0.3787\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 0.3783\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3982 - val_loss: 0.3779\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3977 - val_loss: 0.3775\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.3772\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3966 - val_loss: 0.3768\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3764\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3956 - val_loss: 0.3761\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3757\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3946 - val_loss: 0.3754\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3942 - val_loss: 0.3751\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3937 - val_loss: 0.3747\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3932 - val_loss: 0.3744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3927 - val_loss: 0.3741\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3922 - val_loss: 0.3738\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3918 - val_loss: 0.3735\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3913 - val_loss: 0.3732\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3908 - val_loss: 0.3729\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3903 - val_loss: 0.3726\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.3723\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3894 - val_loss: 0.3720\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3890 - val_loss: 0.3718\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3885 - val_loss: 0.3715\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3881 - val_loss: 0.3712\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3877 - val_loss: 0.3709\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3872 - val_loss: 0.3706\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3868 - val_loss: 0.3704\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n",
      "average MASE = 1110146.2653270473, my average MASE = 43278995.990564056\n",
      "Cluster 3, 1110146.2653270473\n",
      "Before prediction: train_X.shape=(25, 10, 67), train_y.shape=(25, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5208 - val_loss: 0.4711\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5196 - val_loss: 0.4707\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5184 - val_loss: 0.4702\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5173 - val_loss: 0.4698\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5161 - val_loss: 0.4694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5150 - val_loss: 0.4690\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4686\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5127 - val_loss: 0.4682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5116 - val_loss: 0.4678\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5105 - val_loss: 0.4675\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5094 - val_loss: 0.4671\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5084 - val_loss: 0.4667\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5073 - val_loss: 0.4664\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5063 - val_loss: 0.4660\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5052 - val_loss: 0.4657\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5042 - val_loss: 0.4654\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5031 - val_loss: 0.4651\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4648\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5011 - val_loss: 0.4645\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5001 - val_loss: 0.4643\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4991 - val_loss: 0.4641\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.4638\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4971 - val_loss: 0.4636\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4962 - val_loss: 0.4634\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.4632\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4942 - val_loss: 0.4629\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4933 - val_loss: 0.4627\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4923 - val_loss: 0.4625\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4914 - val_loss: 0.4623\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4904 - val_loss: 0.4621\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4895 - val_loss: 0.4619\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4886 - val_loss: 0.4617\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4876 - val_loss: 0.4616\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4867 - val_loss: 0.4614\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4858 - val_loss: 0.4613\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4849 - val_loss: 0.4611\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4841 - val_loss: 0.4610\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4608\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4823 - val_loss: 0.4607\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4815 - val_loss: 0.4605\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 111.6892159594304, my average MASE = 112347014.53903662\n",
      "Cluster 4, 111.6892159594304\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=7, 7, 884, (12, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0672 - val_loss: 0.0440\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0611 - val_loss: 0.0410\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0576 - val_loss: 0.0390\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0552 - val_loss: 0.0374\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0533 - val_loss: 0.0361\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0517 - val_loss: 0.0350\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0504 - val_loss: 0.0340\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0493 - val_loss: 0.0332\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0484 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0476 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0469 - val_loss: 0.0313\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0462 - val_loss: 0.0308\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0457 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0447 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0442 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0435 - val_loss: 0.0287\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0285\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0283\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0281\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0280\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0278\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0277\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0275\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0274\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0273\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0411 - val_loss: 0.0271\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0270\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0408 - val_loss: 0.0269\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0268\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0267\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0405 - val_loss: 0.0266\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0403 - val_loss: 0.0265\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0401 - val_loss: 0.0264\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0263\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0399 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1103404601.9868512, my average MASE = 55700347192.937294\n",
      "Cluster 1, 1103404601.9868512\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5205 - val_loss: 0.4218\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5186 - val_loss: 0.4208\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5167 - val_loss: 0.4198\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5148 - val_loss: 0.4189\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5129 - val_loss: 0.4179\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5111 - val_loss: 0.4170\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5093 - val_loss: 0.4161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5074 - val_loss: 0.4152\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5057 - val_loss: 0.4143\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5039 - val_loss: 0.4134\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5022 - val_loss: 0.4125\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5004 - val_loss: 0.4117\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4987 - val_loss: 0.4108\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4971 - val_loss: 0.4100\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4954 - val_loss: 0.4092\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4938 - val_loss: 0.4083\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4922 - val_loss: 0.4075\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4906 - val_loss: 0.4067\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4890 - val_loss: 0.4060\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4875 - val_loss: 0.4052\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4860 - val_loss: 0.4044\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4845 - val_loss: 0.4036\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4830 - val_loss: 0.4028\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4815 - val_loss: 0.4021\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4800 - val_loss: 0.4013\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4771 - val_loss: 0.3999\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4757 - val_loss: 0.3992\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4743 - val_loss: 0.3985\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4730 - val_loss: 0.3978\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4716 - val_loss: 0.3971\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4703 - val_loss: 0.3964\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4689 - val_loss: 0.3958\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.3951\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.3945\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4650 - val_loss: 0.3939\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4637 - val_loss: 0.3932\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4625 - val_loss: 0.3926\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4612 - val_loss: 0.3920\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4600 - val_loss: 0.3913\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3560489905.356454, my average MASE = 9030960108.787361\n",
      "Cluster 2, 3560489905.356454\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3774 - val_loss: 0.3465\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3767 - val_loss: 0.3460\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3759 - val_loss: 0.3456\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3752 - val_loss: 0.3452\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3744 - val_loss: 0.3448\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3737 - val_loss: 0.3444\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 0.3440\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3723 - val_loss: 0.3436\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3716 - val_loss: 0.3432\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3710 - val_loss: 0.3429\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3703 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3696 - val_loss: 0.3421\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.3418\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3683 - val_loss: 0.3415\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3411\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3671 - val_loss: 0.3408\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3665 - val_loss: 0.3405\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3659 - val_loss: 0.3401\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3653 - val_loss: 0.3398\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3647 - val_loss: 0.3395\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3641 - val_loss: 0.3392\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3635 - val_loss: 0.3389\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3630 - val_loss: 0.3386\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.3383\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.3380\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3613 - val_loss: 0.3377\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3608 - val_loss: 0.3374\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3602 - val_loss: 0.3371\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3597 - val_loss: 0.3368\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3592 - val_loss: 0.3365\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3362\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3581 - val_loss: 0.3359\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3576 - val_loss: 0.3356\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3571 - val_loss: 0.3353\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3566 - val_loss: 0.3350\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3561 - val_loss: 0.3347\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3556 - val_loss: 0.3344\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3551 - val_loss: 0.3342\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3546 - val_loss: 0.3339\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3541 - val_loss: 0.3336\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 332.8608286989534, my average MASE = 85442913.95523748\n",
      "Cluster 3, 332.8608286989534\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7187 - val_loss: 0.5712\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7172 - val_loss: 0.5706\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7158 - val_loss: 0.5700\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7145 - val_loss: 0.5694\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7132 - val_loss: 0.5688\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7119 - val_loss: 0.5682\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7107 - val_loss: 0.5677\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7095 - val_loss: 0.5671\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7083 - val_loss: 0.5666\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7071 - val_loss: 0.5660\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7060 - val_loss: 0.5655\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7049 - val_loss: 0.5650\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7038 - val_loss: 0.5646\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7028 - val_loss: 0.5641\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7018 - val_loss: 0.5636\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7008 - val_loss: 0.5631\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6999 - val_loss: 0.5627\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6989 - val_loss: 0.5622\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6980 - val_loss: 0.5618\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6971 - val_loss: 0.5613\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5609\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6953 - val_loss: 0.5604\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6944 - val_loss: 0.5600\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6935 - val_loss: 0.5596\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6927 - val_loss: 0.5592\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6918 - val_loss: 0.5587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6910 - val_loss: 0.5583\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6902 - val_loss: 0.5579\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6894 - val_loss: 0.5576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6886 - val_loss: 0.5572\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6878 - val_loss: 0.5568\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5564\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6862 - val_loss: 0.5560\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6854 - val_loss: 0.5557\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6846 - val_loss: 0.5553\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6839 - val_loss: 0.5549\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6831 - val_loss: 0.5546\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6824 - val_loss: 0.5542\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6816 - val_loss: 0.5538\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6809 - val_loss: 0.5535\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.45484282658396, my average MASE = 350849744.5231373\n",
      "Cluster 4, 139.45484282658396\n",
      "Before prediction: train_X.shape=(133, 10, 67), train_y.shape=(133, 67), test_X.shape=(44, 10, 67), test_y.shape=(44, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4266 - val_loss: 0.6651\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4259 - val_loss: 0.6645\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4253 - val_loss: 0.6639\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4247 - val_loss: 0.6633\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4242 - val_loss: 0.6628\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4236 - val_loss: 0.6623\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4231 - val_loss: 0.6618\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4226 - val_loss: 0.6613\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4221 - val_loss: 0.6608\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4216 - val_loss: 0.6603\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4211 - val_loss: 0.6599\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4206 - val_loss: 0.6594\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4201 - val_loss: 0.6590\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4197 - val_loss: 0.6585\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4192 - val_loss: 0.6581\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4188 - val_loss: 0.6576\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4184 - val_loss: 0.6572\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4180 - val_loss: 0.6568\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4175 - val_loss: 0.6564\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4171 - val_loss: 0.6559\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4167 - val_loss: 0.6554\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4163 - val_loss: 0.6550\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4159 - val_loss: 0.6545\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4155 - val_loss: 0.6541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4151 - val_loss: 0.6537\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4147 - val_loss: 0.6533\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4143 - val_loss: 0.6529\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4139 - val_loss: 0.6525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4135 - val_loss: 0.6521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4131 - val_loss: 0.6518\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4128 - val_loss: 0.6514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4124 - val_loss: 0.6511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4120 - val_loss: 0.6507\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4117 - val_loss: 0.6504\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4114 - val_loss: 0.6501\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4110 - val_loss: 0.6498\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4107 - val_loss: 0.6494\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4103 - val_loss: 0.6491\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4100 - val_loss: 0.6487\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4096 - val_loss: 0.6484\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(44, 67), test_y.shape=(44, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 116.65244791791511, my average MASE = 142786035.78420427\n",
      "Cluster 5, 116.65244791791511\n",
      "Before prediction: train_X.shape=(78, 10, 67), train_y.shape=(78, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4078 - val_loss: 0.4868\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4070 - val_loss: 0.4862\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4062 - val_loss: 0.4856\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4055 - val_loss: 0.4850\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4048 - val_loss: 0.4845\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4041 - val_loss: 0.4839\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.4833\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4828\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4021 - val_loss: 0.4823\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4015 - val_loss: 0.4818\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4008 - val_loss: 0.4813\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4002 - val_loss: 0.4808\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3997 - val_loss: 0.4803\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3991 - val_loss: 0.4798\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3985 - val_loss: 0.4794\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3980 - val_loss: 0.4789\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3974 - val_loss: 0.4785\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3969 - val_loss: 0.4780\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3964 - val_loss: 0.4776\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4772\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3954 - val_loss: 0.4768\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3949 - val_loss: 0.4764\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3944 - val_loss: 0.4760\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.4757\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3934 - val_loss: 0.4753\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3930 - val_loss: 0.4750\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3925 - val_loss: 0.4747\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3921 - val_loss: 0.4743\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3916 - val_loss: 0.4740\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3912 - val_loss: 0.4737\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3907 - val_loss: 0.4733\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3903 - val_loss: 0.4730\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.4727\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3895 - val_loss: 0.4724\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3890 - val_loss: 0.4721\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3886 - val_loss: 0.4718\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4715\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3878 - val_loss: 0.4712\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.4709\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3870 - val_loss: 0.4706\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 221.65144919995234, my average MASE = 102271349.10812314\n",
      "Cluster 6, 221.65144919995234\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=9, 9, 14, (3245, 67)\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1141 - val_loss: 0.1031\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1086 - val_loss: 0.1010\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1042 - val_loss: 0.0995\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1005 - val_loss: 0.0982\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0973 - val_loss: 0.0973\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0945 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0920 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0897 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0877 - val_loss: 0.0950\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0858 - val_loss: 0.0947\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0841 - val_loss: 0.0943\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0826 - val_loss: 0.0941\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0812 - val_loss: 0.0938\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0798 - val_loss: 0.0935\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0786 - val_loss: 0.0933\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0930\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0765 - val_loss: 0.0928\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0755 - val_loss: 0.0926\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0746 - val_loss: 0.0925\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0737 - val_loss: 0.0923\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0729 - val_loss: 0.0921\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0722 - val_loss: 0.0920\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0715 - val_loss: 0.0919\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0708 - val_loss: 0.0917\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0916\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0915\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0691 - val_loss: 0.0914\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0686 - val_loss: 0.0913\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0681 - val_loss: 0.0912\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0676 - val_loss: 0.0911\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0910\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0668 - val_loss: 0.0910\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0664 - val_loss: 0.0909\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0660 - val_loss: 0.0909\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0656 - val_loss: 0.0908\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0653 - val_loss: 0.0908\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0650 - val_loss: 0.0907\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0647 - val_loss: 0.0907\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0644 - val_loss: 0.0907\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0906\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1289233887.8234715, my average MASE = 15636865244.557127\n",
      "Cluster 0, 1289233887.8234715\n",
      "Before prediction: train_X.shape=(29, 10, 67), train_y.shape=(29, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4693 - val_loss: 0.6570\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4687 - val_loss: 0.6567\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4680 - val_loss: 0.6563\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4674 - val_loss: 0.6560\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4668 - val_loss: 0.6557\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4662 - val_loss: 0.6554\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4656 - val_loss: 0.6551\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4650 - val_loss: 0.6548\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4644 - val_loss: 0.6545\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4638 - val_loss: 0.6542\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4633 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4627 - val_loss: 0.6536\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4621 - val_loss: 0.6533\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.6530\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4610 - val_loss: 0.6527\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4605 - val_loss: 0.6524\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4599 - val_loss: 0.6521\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4594 - val_loss: 0.6519\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4588 - val_loss: 0.6516\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4583 - val_loss: 0.6513\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4578 - val_loss: 0.6510\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4573 - val_loss: 0.6508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4568 - val_loss: 0.6505\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4563 - val_loss: 0.6502\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4558 - val_loss: 0.6499\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4553 - val_loss: 0.6496\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4548 - val_loss: 0.6493\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4543 - val_loss: 0.6491\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4538 - val_loss: 0.6488\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4533 - val_loss: 0.6485\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4528 - val_loss: 0.6483\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4524 - val_loss: 0.6480\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4519 - val_loss: 0.6478\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4514 - val_loss: 0.6475\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4510 - val_loss: 0.6473\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4505 - val_loss: 0.6470\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4500 - val_loss: 0.6468\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4496 - val_loss: 0.6465\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4492 - val_loss: 0.6463\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.6460\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 10049120.449906044, my average MASE = 246733533.9412494\n",
      "Cluster 1, 10049120.449906044\n",
      "Before prediction: train_X.shape=(1564, 10, 67), train_y.shape=(1564, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2359 - val_loss: 0.2748\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2264 - val_loss: 0.2656\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2192 - val_loss: 0.2584\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2135 - val_loss: 0.2523\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2087 - val_loss: 0.2471\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2045 - val_loss: 0.2424\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2007 - val_loss: 0.2382\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1973 - val_loss: 0.2342\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1941 - val_loss: 0.2307\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1912 - val_loss: 0.2273\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1884 - val_loss: 0.2242\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1858 - val_loss: 0.2214\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1833 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1810 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1789 - val_loss: 0.2140\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1769 - val_loss: 0.2119\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1750 - val_loss: 0.2100\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1733 - val_loss: 0.2082\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1717 - val_loss: 0.2066\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1702 - val_loss: 0.2051\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1689 - val_loss: 0.2038\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1677 - val_loss: 0.2024\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2012\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2001\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1645 - val_loss: 0.1989\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1979\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1627 - val_loss: 0.1969\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1619 - val_loss: 0.1959\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1611 - val_loss: 0.1950\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1603 - val_loss: 0.1941\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1596 - val_loss: 0.1933\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1589 - val_loss: 0.1925\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1582 - val_loss: 0.1917\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1576 - val_loss: 0.1910\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1570 - val_loss: 0.1903\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1564 - val_loss: 0.1895\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1558 - val_loss: 0.1889\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1553 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1548 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1543 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 187.65491616156584, my average MASE = 1727876346.7517292\n",
      "Cluster 2, 187.65491616156584\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5179 - val_loss: 0.4772\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5158 - val_loss: 0.4757\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4743\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5118 - val_loss: 0.4729\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5098 - val_loss: 0.4715\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5079 - val_loss: 0.4701\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5059 - val_loss: 0.4687\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5040 - val_loss: 0.4673\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4660\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5002 - val_loss: 0.4646\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4984 - val_loss: 0.4633\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4966 - val_loss: 0.4620\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4948 - val_loss: 0.4607\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4931 - val_loss: 0.4594\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4913 - val_loss: 0.4581\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4896 - val_loss: 0.4568\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4879 - val_loss: 0.4555\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4862 - val_loss: 0.4543\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4845 - val_loss: 0.4531\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4828 - val_loss: 0.4518\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4812 - val_loss: 0.4506\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4795 - val_loss: 0.4495\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4779 - val_loss: 0.4483\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4763 - val_loss: 0.4471\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4747 - val_loss: 0.4460\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4731 - val_loss: 0.4449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4716 - val_loss: 0.4438\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4700 - val_loss: 0.4427\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4685 - val_loss: 0.4416\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4670 - val_loss: 0.4405\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4655 - val_loss: 0.4395\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4640 - val_loss: 0.4385\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4626 - val_loss: 0.4374\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4611 - val_loss: 0.4364\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4597 - val_loss: 0.4354\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4582 - val_loss: 0.4344\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4568 - val_loss: 0.4334\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4555 - val_loss: 0.4324\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4541 - val_loss: 0.4314\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4527 - val_loss: 0.4304\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3258333520.23763, my average MASE = 7487984704.271554\n",
      "Cluster 3, 3258333520.23763\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3367 - val_loss: 0.3564\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3362 - val_loss: 0.3564\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3356 - val_loss: 0.3564\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3351 - val_loss: 0.3563\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3346 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3340 - val_loss: 0.3563\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3335 - val_loss: 0.3563\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3330 - val_loss: 0.3562\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3325 - val_loss: 0.3562\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3319 - val_loss: 0.3562\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3314 - val_loss: 0.3561\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3309 - val_loss: 0.3561\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3304 - val_loss: 0.3561\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3560\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3294 - val_loss: 0.3560\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3289 - val_loss: 0.3560\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.3559\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3280 - val_loss: 0.3559\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3275 - val_loss: 0.3559\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3270 - val_loss: 0.3559\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3266 - val_loss: 0.3558\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3261 - val_loss: 0.3558\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3256 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3252 - val_loss: 0.3558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3248 - val_loss: 0.3558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3243 - val_loss: 0.3557\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3239 - val_loss: 0.3557\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.3557\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3230 - val_loss: 0.3557\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3226 - val_loss: 0.3557\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3222 - val_loss: 0.3556\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3218 - val_loss: 0.3556\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3214 - val_loss: 0.3556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3556\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3205 - val_loss: 0.3556\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3201 - val_loss: 0.3556\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.3556\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3193 - val_loss: 0.3555\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3189 - val_loss: 0.3555\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3185 - val_loss: 0.3555\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 544.8910068645505, my average MASE = 25915172.7591836\n",
      "Cluster 4, 544.8910068645505\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5189 - val_loss: 0.8510\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5183 - val_loss: 0.8507\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5176 - val_loss: 0.8503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5170 - val_loss: 0.8500\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5163 - val_loss: 0.8496\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5157 - val_loss: 0.8493\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5151 - val_loss: 0.8490\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5145 - val_loss: 0.8487\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5138 - val_loss: 0.8484\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5132 - val_loss: 0.8481\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5126 - val_loss: 0.8478\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5120 - val_loss: 0.8476\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5114 - val_loss: 0.8473\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5108 - val_loss: 0.8471\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5102 - val_loss: 0.8468\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5096 - val_loss: 0.8466\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5090 - val_loss: 0.8463\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5084 - val_loss: 0.8461\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5078 - val_loss: 0.8458\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5072 - val_loss: 0.8456\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.8454\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5060 - val_loss: 0.8451\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5055 - val_loss: 0.8449\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5049 - val_loss: 0.8447\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5043 - val_loss: 0.8445\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5038 - val_loss: 0.8443\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5032 - val_loss: 0.8441\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5027 - val_loss: 0.8439\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5021 - val_loss: 0.8437\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5016 - val_loss: 0.8435\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5010 - val_loss: 0.8433\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5005 - val_loss: 0.8431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4999 - val_loss: 0.8429\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4994 - val_loss: 0.8428\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4989 - val_loss: 0.8426\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4983 - val_loss: 0.8424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4978 - val_loss: 0.8422\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4973 - val_loss: 0.8420\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4967 - val_loss: 0.8419\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4962 - val_loss: 0.8417\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1963484.3822421303, my average MASE = 64800710.430740915\n",
      "Cluster 5, 1963484.3822421303\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8495 - val_loss: 4.3516\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8473 - val_loss: 4.3510\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8451 - val_loss: 4.3503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8429 - val_loss: 4.3497\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8408 - val_loss: 4.3491\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8386 - val_loss: 4.3485\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8365 - val_loss: 4.3479\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8344 - val_loss: 4.3473\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8323 - val_loss: 4.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8301 - val_loss: 4.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8280 - val_loss: 4.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8259 - val_loss: 4.3451\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8238 - val_loss: 4.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8217 - val_loss: 4.3440\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8197 - val_loss: 4.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8176 - val_loss: 4.3428\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8156 - val_loss: 4.3423\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8136 - val_loss: 4.3417\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8117 - val_loss: 4.3412\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8098 - val_loss: 4.3407\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 4.3403\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8061 - val_loss: 4.3399\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8042 - val_loss: 4.3395\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8023 - val_loss: 4.3390\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8004 - val_loss: 4.3386\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7986 - val_loss: 4.3382\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7967 - val_loss: 4.3378\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7949 - val_loss: 4.3374\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7930 - val_loss: 4.3370\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7912 - val_loss: 4.3365\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7893 - val_loss: 4.3361\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7874 - val_loss: 4.3357\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7856 - val_loss: 4.3353\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7839 - val_loss: 4.3349\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7822 - val_loss: 4.3345\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7805 - val_loss: 4.3341\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7787 - val_loss: 4.3338\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7771 - val_loss: 4.3334\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7754 - val_loss: 4.3330\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7738 - val_loss: 4.3327\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4.116072897890656, my average MASE = 12.21206426084865\n",
      "Cluster 6, 4.116072897890656\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3660 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3652 - val_loss: 0.3455\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3645 - val_loss: 0.3451\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3638 - val_loss: 0.3448\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3632 - val_loss: 0.3445\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3625 - val_loss: 0.3441\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3619 - val_loss: 0.3438\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3435\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3606 - val_loss: 0.3431\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3599 - val_loss: 0.3428\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3593 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3422\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3581 - val_loss: 0.3419\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3576 - val_loss: 0.3416\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3570 - val_loss: 0.3413\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3564 - val_loss: 0.3410\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3558 - val_loss: 0.3407\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3553 - val_loss: 0.3404\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3547 - val_loss: 0.3401\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3542 - val_loss: 0.3398\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3536 - val_loss: 0.3395\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3531 - val_loss: 0.3393\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3526 - val_loss: 0.3390\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3521 - val_loss: 0.3387\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3516 - val_loss: 0.3384\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3511 - val_loss: 0.3382\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3506 - val_loss: 0.3379\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3501 - val_loss: 0.3376\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3496 - val_loss: 0.3373\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3491 - val_loss: 0.3371\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3487 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3482 - val_loss: 0.3366\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3477 - val_loss: 0.3363\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3473 - val_loss: 0.3360\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3464 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3459 - val_loss: 0.3353\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3455 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3451 - val_loss: 0.3348\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3446 - val_loss: 0.3345\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 266.09609302896547, my average MASE = 71685898.00003502\n",
      "Cluster 8, 266.09609302896547\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=11, 11, 663, (11, 67)\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3610 - val_loss: 0.4969\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3601 - val_loss: 0.4969\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3592 - val_loss: 0.4970\n",
      "Epoch 3: early stopping\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.35712691602972574, my average MASE = 0.5241910168311086\n",
      "Cluster 0, 0.35712691602972574\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2752 - val_loss: 0.2714\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2747 - val_loss: 0.2712\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2742 - val_loss: 0.2710\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2737 - val_loss: 0.2707\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2733 - val_loss: 0.2705\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2728 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2723 - val_loss: 0.2701\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2718 - val_loss: 0.2699\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2714 - val_loss: 0.2697\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2709 - val_loss: 0.2695\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2704 - val_loss: 0.2693\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2700 - val_loss: 0.2691\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2695 - val_loss: 0.2690\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2691 - val_loss: 0.2688\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2687 - val_loss: 0.2686\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2682 - val_loss: 0.2684\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2678 - val_loss: 0.2682\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2673 - val_loss: 0.2680\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2669 - val_loss: 0.2678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2665 - val_loss: 0.2676\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2661 - val_loss: 0.2674\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.2672\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2653 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2649 - val_loss: 0.2669\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2645 - val_loss: 0.2667\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2641 - val_loss: 0.2665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2637 - val_loss: 0.2663\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2633 - val_loss: 0.2662\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2629 - val_loss: 0.2660\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2625 - val_loss: 0.2658\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2621 - val_loss: 0.2656\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2618 - val_loss: 0.2655\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2614 - val_loss: 0.2653\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2610 - val_loss: 0.2652\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2606 - val_loss: 0.2650\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2602 - val_loss: 0.2649\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2599 - val_loss: 0.2647\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2595 - val_loss: 0.2646\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2591 - val_loss: 0.2644\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2588 - val_loss: 0.2643\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 114.92828938190037, my average MASE = 64775351.69732988\n",
      "Cluster 1, 114.92828938190037\n",
      "Before prediction: train_X.shape=(21, 10, 67), train_y.shape=(21, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6587 - val_loss: 0.2666\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6569 - val_loss: 0.2655\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6551 - val_loss: 0.2645\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6533 - val_loss: 0.2635\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6515 - val_loss: 0.2624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6497 - val_loss: 0.2614\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6480 - val_loss: 0.2604\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6463 - val_loss: 0.2594\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6446 - val_loss: 0.2584\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6429 - val_loss: 0.2574\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6412 - val_loss: 0.2565\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6395 - val_loss: 0.2555\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6379 - val_loss: 0.2546\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6363 - val_loss: 0.2538\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6346 - val_loss: 0.2529\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6331 - val_loss: 0.2520\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6315 - val_loss: 0.2512\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6300 - val_loss: 0.2504\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6285 - val_loss: 0.2496\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6270 - val_loss: 0.2488\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6255 - val_loss: 0.2480\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6240 - val_loss: 0.2473\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6225 - val_loss: 0.2466\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6211 - val_loss: 0.2458\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6197 - val_loss: 0.2451\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6182 - val_loss: 0.2444\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6168 - val_loss: 0.2437\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6155 - val_loss: 0.2430\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6141 - val_loss: 0.2423\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6127 - val_loss: 0.2416\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6114 - val_loss: 0.2410\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6101 - val_loss: 0.2403\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6088 - val_loss: 0.2397\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6075 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6063 - val_loss: 0.2384\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6050 - val_loss: 0.2378\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6038 - val_loss: 0.2372\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6026 - val_loss: 0.2365\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6014 - val_loss: 0.2359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6002 - val_loss: 0.2353\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 26456338.054780327, my average MASE = 1170397376.6808207\n",
      "Cluster 2, 26456338.054780327\n",
      "Before prediction: train_X.shape=(62, 10, 67), train_y.shape=(62, 67), test_X.shape=(21, 10, 67), test_y.shape=(21, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3828 - val_loss: 0.5067\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3824 - val_loss: 0.5064\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3820 - val_loss: 0.5062\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3816 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3812 - val_loss: 0.5056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3808 - val_loss: 0.5053\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3804 - val_loss: 0.5051\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3801 - val_loss: 0.5048\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3797 - val_loss: 0.5045\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3793 - val_loss: 0.5043\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3790 - val_loss: 0.5040\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3786 - val_loss: 0.5038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3783 - val_loss: 0.5035\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3779 - val_loss: 0.5032\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3776 - val_loss: 0.5030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3772 - val_loss: 0.5027\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3769 - val_loss: 0.5025\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3765 - val_loss: 0.5022\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3762 - val_loss: 0.5020\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3758 - val_loss: 0.5017\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3755 - val_loss: 0.5015\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3752 - val_loss: 0.5012\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3748 - val_loss: 0.5010\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3745 - val_loss: 0.5008\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3742 - val_loss: 0.5005\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3738 - val_loss: 0.5003\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3735 - val_loss: 0.5000\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3732 - val_loss: 0.4998\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3729 - val_loss: 0.4995\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3726 - val_loss: 0.4993\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3722 - val_loss: 0.4991\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3719 - val_loss: 0.4988\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3716 - val_loss: 0.4986\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3713 - val_loss: 0.4984\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3710 - val_loss: 0.4982\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3707 - val_loss: 0.4979\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3704 - val_loss: 0.4977\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3701 - val_loss: 0.4975\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3698 - val_loss: 0.4973\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3695 - val_loss: 0.4971\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(21, 67), test_y.shape=(21, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 88.873907317969, my average MASE = 105114880.66517946\n",
      "Cluster 3, 88.873907317969\n",
      "Before prediction: train_X.shape=(58, 10, 67), train_y.shape=(58, 67), test_X.shape=(19, 10, 67), test_y.shape=(19, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6113 - val_loss: 0.3397\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6107 - val_loss: 0.3395\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6100 - val_loss: 0.3394\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6094 - val_loss: 0.3393\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6087 - val_loss: 0.3392\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6081 - val_loss: 0.3391\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6075 - val_loss: 0.3390\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6069 - val_loss: 0.3389\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6062 - val_loss: 0.3388\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6056 - val_loss: 0.3387\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6050 - val_loss: 0.3386\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6044 - val_loss: 0.3385\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6038 - val_loss: 0.3384\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6032 - val_loss: 0.3383\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6026 - val_loss: 0.3382\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6020 - val_loss: 0.3381\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6014 - val_loss: 0.3380\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6009 - val_loss: 0.3379\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6003 - val_loss: 0.3378\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5997 - val_loss: 0.3377\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5992 - val_loss: 0.3376\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5986 - val_loss: 0.3375\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5981 - val_loss: 0.3374\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5976 - val_loss: 0.3373\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5970 - val_loss: 0.3372\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5965 - val_loss: 0.3372\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5960 - val_loss: 0.3371\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5955 - val_loss: 0.3370\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5949 - val_loss: 0.3369\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5944 - val_loss: 0.3369\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5939 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5934 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5929 - val_loss: 0.3366\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5924 - val_loss: 0.3366\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5919 - val_loss: 0.3365\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5915 - val_loss: 0.3364\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5910 - val_loss: 0.3364\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5905 - val_loss: 0.3363\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5900 - val_loss: 0.3362\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5895 - val_loss: 0.3362\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(19, 67), test_y.shape=(19, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2288977.9462372796, my average MASE = 275894539.3328722\n",
      "Cluster 4, 2288977.9462372796\n",
      "Before prediction: train_X.shape=(22, 10, 67), train_y.shape=(22, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6507 - val_loss: 0.5866\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6499 - val_loss: 0.5864\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6491 - val_loss: 0.5862\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6483 - val_loss: 0.5861\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6475 - val_loss: 0.5859\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6467 - val_loss: 0.5857\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6459 - val_loss: 0.5855\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6451 - val_loss: 0.5854\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6443 - val_loss: 0.5852\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6435 - val_loss: 0.5851\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6427 - val_loss: 0.5849\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6420 - val_loss: 0.5848\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6412 - val_loss: 0.5846\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6405 - val_loss: 0.5844\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6397 - val_loss: 0.5843\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6389 - val_loss: 0.5841\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6382 - val_loss: 0.5840\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6374 - val_loss: 0.5838\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6367 - val_loss: 0.5837\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6359 - val_loss: 0.5836\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6352 - val_loss: 0.5834\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6345 - val_loss: 0.5833\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6337 - val_loss: 0.5832\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6330 - val_loss: 0.5830\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6323 - val_loss: 0.5829\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6316 - val_loss: 0.5827\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6309 - val_loss: 0.5826\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6302 - val_loss: 0.5825\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 0.5824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6288 - val_loss: 0.5822\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6281 - val_loss: 0.5821\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6275 - val_loss: 0.5820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6268 - val_loss: 0.5819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6261 - val_loss: 0.5818\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6254 - val_loss: 0.5816\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6248 - val_loss: 0.5815\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6241 - val_loss: 0.5814\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6235 - val_loss: 0.5813\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6228 - val_loss: 0.5811\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6222 - val_loss: 0.5810\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 56.939779008571485, my average MASE = 37107546.21609385\n",
      "Cluster 5, 56.939779008571485\n",
      "Before prediction: train_X.shape=(4681, 10, 67), train_y.shape=(4681, 67), test_X.shape=(1560, 10, 67), test_y.shape=(1560, 67)\n",
      "Epoch 1/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0785 - val_loss: 0.0245\n",
      "Epoch 2/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0726 - val_loss: 0.0222\n",
      "Epoch 3/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0688 - val_loss: 0.0210\n",
      "Epoch 4/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0661 - val_loss: 0.0201\n",
      "Epoch 5/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0638 - val_loss: 0.0195\n",
      "Epoch 6/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0620 - val_loss: 0.0189\n",
      "Epoch 7/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0604 - val_loss: 0.0185\n",
      "Epoch 8/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0590 - val_loss: 0.0182\n",
      "Epoch 9/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0579 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0569 - val_loss: 0.0176\n",
      "Epoch 11/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0560 - val_loss: 0.0174\n",
      "Epoch 12/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0552 - val_loss: 0.0172\n",
      "Epoch 13/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0545 - val_loss: 0.0171\n",
      "Epoch 14/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0539 - val_loss: 0.0169\n",
      "Epoch 15/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0533 - val_loss: 0.0168\n",
      "Epoch 16/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0528 - val_loss: 0.0167\n",
      "Epoch 17/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0524 - val_loss: 0.0166\n",
      "Epoch 18/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0519 - val_loss: 0.0165\n",
      "Epoch 19/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0516 - val_loss: 0.0165\n",
      "Epoch 20/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0512 - val_loss: 0.0164\n",
      "Epoch 21/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0509 - val_loss: 0.0163\n",
      "Epoch 22/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0505 - val_loss: 0.0163\n",
      "Epoch 23/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0502 - val_loss: 0.0162\n",
      "Epoch 24/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0500 - val_loss: 0.0162\n",
      "Epoch 25/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0497 - val_loss: 0.0161\n",
      "Epoch 26/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0495 - val_loss: 0.0161\n",
      "Epoch 27/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0492 - val_loss: 0.0161\n",
      "Epoch 28/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0490 - val_loss: 0.0160\n",
      "Epoch 29/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0488 - val_loss: 0.0160\n",
      "Epoch 30/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0486 - val_loss: 0.0159\n",
      "Epoch 31/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0485 - val_loss: 0.0159\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0483 - val_loss: 0.0158\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0481 - val_loss: 0.0158\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0480 - val_loss: 0.0158\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0479 - val_loss: 0.0157\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0477 - val_loss: 0.0157\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0476 - val_loss: 0.0157\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0475 - val_loss: 0.0156\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0474 - val_loss: 0.0156\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0473 - val_loss: 0.0156\n",
      "49/49 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1560, 67), test_y.shape=(1560, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 149408746.52177918, my average MASE = 566572768.961764\n",
      "Cluster 6, 149408746.52177918\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5377 - val_loss: 0.4682\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5358 - val_loss: 0.4667\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5339 - val_loss: 0.4653\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5320 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5302 - val_loss: 0.4624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5283 - val_loss: 0.4609\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5265 - val_loss: 0.4595\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5247 - val_loss: 0.4581\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5229 - val_loss: 0.4567\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5211 - val_loss: 0.4554\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5194 - val_loss: 0.4540\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5177 - val_loss: 0.4527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5160 - val_loss: 0.4514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5143 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5126 - val_loss: 0.4488\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5110 - val_loss: 0.4475\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5093 - val_loss: 0.4462\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5077 - val_loss: 0.4450\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5062 - val_loss: 0.4438\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5046 - val_loss: 0.4425\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5030 - val_loss: 0.4413\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5015 - val_loss: 0.4401\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5000 - val_loss: 0.4390\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4985 - val_loss: 0.4378\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4970 - val_loss: 0.4367\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4955 - val_loss: 0.4355\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4940 - val_loss: 0.4344\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4925 - val_loss: 0.4334\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4911 - val_loss: 0.4323\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4897 - val_loss: 0.4312\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4882 - val_loss: 0.4302\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4868 - val_loss: 0.4292\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4854 - val_loss: 0.4281\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4840 - val_loss: 0.4271\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4826 - val_loss: 0.4261\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4813 - val_loss: 0.4251\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4242\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4232\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4772 - val_loss: 0.4223\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4759 - val_loss: 0.4214\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3453236106.5511885, my average MASE = 6985920382.132476\n",
      "Cluster 7, 3453236106.5511885\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3084 - val_loss: 0.3104\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3075 - val_loss: 0.3100\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3066 - val_loss: 0.3095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3058 - val_loss: 0.3091\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3050 - val_loss: 0.3086\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3042 - val_loss: 0.3082\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3034 - val_loss: 0.3077\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3026 - val_loss: 0.3073\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3018 - val_loss: 0.3068\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3010 - val_loss: 0.3064\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3002 - val_loss: 0.3059\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2995 - val_loss: 0.3055\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2987 - val_loss: 0.3051\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2980 - val_loss: 0.3047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2973 - val_loss: 0.3043\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2965 - val_loss: 0.3039\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2958 - val_loss: 0.3035\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2951 - val_loss: 0.3031\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2944 - val_loss: 0.3027\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2937 - val_loss: 0.3024\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2930 - val_loss: 0.3020\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2924 - val_loss: 0.3017\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2917 - val_loss: 0.3014\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2911 - val_loss: 0.3011\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2904 - val_loss: 0.3008\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2898 - val_loss: 0.3006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2891 - val_loss: 0.3003\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2885 - val_loss: 0.3001\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2878 - val_loss: 0.2998\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2872 - val_loss: 0.2996\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2866 - val_loss: 0.2994\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2859 - val_loss: 0.2992\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2853 - val_loss: 0.2990\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2846 - val_loss: 0.2988\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2840 - val_loss: 0.2985\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2834 - val_loss: 0.2983\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2827 - val_loss: 0.2981\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2822 - val_loss: 0.2979\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2816 - val_loss: 0.2977\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2810 - val_loss: 0.2975\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2112740905793214, my average MASE = 0.3813496945040607\n",
      "Cluster 8, 0.2112740905793214\n",
      "Before prediction: train_X.shape=(33, 10, 67), train_y.shape=(33, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5052 - val_loss: 0.6961\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5045 - val_loss: 0.6956\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5038 - val_loss: 0.6950\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5030 - val_loss: 0.6945\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5023 - val_loss: 0.6939\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5016 - val_loss: 0.6934\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5009 - val_loss: 0.6928\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5002 - val_loss: 0.6923\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4995 - val_loss: 0.6918\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4988 - val_loss: 0.6913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.6908\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4975 - val_loss: 0.6903\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4968 - val_loss: 0.6898\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4961 - val_loss: 0.6893\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4955 - val_loss: 0.6888\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4948 - val_loss: 0.6883\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4942 - val_loss: 0.6879\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4935 - val_loss: 0.6874\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4929 - val_loss: 0.6869\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4923 - val_loss: 0.6865\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.6860\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4910 - val_loss: 0.6855\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4904 - val_loss: 0.6851\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4898 - val_loss: 0.6846\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4892 - val_loss: 0.6842\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4886 - val_loss: 0.6837\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4880 - val_loss: 0.6833\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4874 - val_loss: 0.6829\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4868 - val_loss: 0.6824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4863 - val_loss: 0.6820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4857 - val_loss: 0.6816\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4851 - val_loss: 0.6811\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4845 - val_loss: 0.6807\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4840 - val_loss: 0.6803\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4834 - val_loss: 0.6799\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4828 - val_loss: 0.6794\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6790\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4817 - val_loss: 0.6786\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4811 - val_loss: 0.6782\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4806 - val_loss: 0.6778\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 74.79960857799604, my average MASE = 23518054.91533832\n",
      "Cluster 9, 74.79960857799604\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3521 - val_loss: 0.2993\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3508 - val_loss: 0.2987\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3496 - val_loss: 0.2982\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3483 - val_loss: 0.2976\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3470 - val_loss: 0.2971\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3458 - val_loss: 0.2966\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3446 - val_loss: 0.2961\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3435 - val_loss: 0.2957\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3423 - val_loss: 0.2954\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3412 - val_loss: 0.2950\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3400 - val_loss: 0.2946\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3389 - val_loss: 0.2943\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3378 - val_loss: 0.2939\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3368 - val_loss: 0.2935\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3357 - val_loss: 0.2932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3347 - val_loss: 0.2928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3337 - val_loss: 0.2925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3326 - val_loss: 0.2921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3317 - val_loss: 0.2918\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3307 - val_loss: 0.2915\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3298 - val_loss: 0.2912\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3289 - val_loss: 0.2910\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3279 - val_loss: 0.2908\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.2905\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3261 - val_loss: 0.2903\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3252 - val_loss: 0.2901\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3244 - val_loss: 0.2899\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.2897\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3227 - val_loss: 0.2895\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3219 - val_loss: 0.2894\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3211 - val_loss: 0.2892\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3203 - val_loss: 0.2891\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3195 - val_loss: 0.2890\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3187 - val_loss: 0.2889\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3179 - val_loss: 0.2888\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3171 - val_loss: 0.2887\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3163 - val_loss: 0.2886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3155 - val_loss: 0.2886\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.2885\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3139 - val_loss: 0.2885\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.1864435054204945, my average MASE = 0.27675363785512175\n",
      "Cluster 10, 0.1864435054204945\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=2, 2, 18, (30612, 67)\n",
      "Before prediction: train_X.shape=(18361, 10, 67), train_y.shape=(18361, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.3015 - val_loss: 0.3194\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2836 - val_loss: 0.3051\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2695 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2585 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2510 - val_loss: 0.2789\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2456 - val_loss: 0.2737\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2410 - val_loss: 0.2693\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2369 - val_loss: 0.2653\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2332 - val_loss: 0.2616\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2298 - val_loss: 0.2584\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2267 - val_loss: 0.2555\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2238 - val_loss: 0.2531\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2212 - val_loss: 0.2509\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2190 - val_loss: 0.2490\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2172 - val_loss: 0.2474\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2156 - val_loss: 0.2461\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2143 - val_loss: 0.2448\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2120 - val_loss: 0.2428\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2110 - val_loss: 0.2420\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2101 - val_loss: 0.2412\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2092 - val_loss: 0.2404\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2084 - val_loss: 0.2395\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2077 - val_loss: 0.2390\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2070 - val_loss: 0.2383\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2064 - val_loss: 0.2377\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2058 - val_loss: 0.2371\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2052 - val_loss: 0.2365\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2047 - val_loss: 0.2361\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2041 - val_loss: 0.2356\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2352\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2032 - val_loss: 0.2348\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2020 - val_loss: 0.2336\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2016 - val_loss: 0.2332\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2013 - val_loss: 0.2329\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2009 - val_loss: 0.2327\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2006 - val_loss: 0.2324\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2321\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2046.5122369835897, my average MASE = 2805.5341357338157\n",
      "Cluster 0, 2046.5122369835897\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5756 - val_loss: 1.2952\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5738 - val_loss: 1.2950\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5721 - val_loss: 1.2949\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5703 - val_loss: 1.2948\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5686 - val_loss: 1.2947\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5670 - val_loss: 1.2946\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5653 - val_loss: 1.2945\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5637 - val_loss: 1.2944\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5621 - val_loss: 1.2943\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5605 - val_loss: 1.2941\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5589 - val_loss: 1.2940\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5573 - val_loss: 1.2939\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5558 - val_loss: 1.2937\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5542 - val_loss: 1.2936\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5527 - val_loss: 1.2934\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5512 - val_loss: 1.2932\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5497 - val_loss: 1.2930\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 1.2929\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5468 - val_loss: 1.2927\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 1.2925\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5440 - val_loss: 1.2924\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5426 - val_loss: 1.2922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5413 - val_loss: 1.2921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5400 - val_loss: 1.2920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5386 - val_loss: 1.2919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5374 - val_loss: 1.2918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 1.2918\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5349 - val_loss: 1.2917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5337 - val_loss: 1.2916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5325 - val_loss: 1.2915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5314 - val_loss: 1.2914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5302 - val_loss: 1.2912\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5290 - val_loss: 1.2911\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5279 - val_loss: 1.2909\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5268 - val_loss: 1.2907\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5256 - val_loss: 1.2905\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5246 - val_loss: 1.2903\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5235 - val_loss: 1.2902\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5224 - val_loss: 1.2901\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5213 - val_loss: 1.2900\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 950350834.5172157, my average MASE = 2745439088.6097794\n",
      "Cluster 1, 950350834.5172157\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=5, 5, 599, (8, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3119 - val_loss: 0.2829\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3116 - val_loss: 0.2829\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3112 - val_loss: 0.2828\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3109 - val_loss: 0.2828\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3106 - val_loss: 0.2828\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3102 - val_loss: 0.2827\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3099 - val_loss: 0.2827\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3096 - val_loss: 0.2827\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3092 - val_loss: 0.2827\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3089 - val_loss: 0.2826\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3086 - val_loss: 0.2826\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3083 - val_loss: 0.2826\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3080 - val_loss: 0.2826\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3077 - val_loss: 0.2825\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3074 - val_loss: 0.2825\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3070 - val_loss: 0.2825\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3067 - val_loss: 0.2825\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3064 - val_loss: 0.2824\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3061 - val_loss: 0.2824\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3058 - val_loss: 0.2824\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3055 - val_loss: 0.2823\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3052 - val_loss: 0.2823\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3049 - val_loss: 0.2823\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3047 - val_loss: 0.2822\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3044 - val_loss: 0.2822\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3041 - val_loss: 0.2822\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3038 - val_loss: 0.2821\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3035 - val_loss: 0.2821\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3032 - val_loss: 0.2821\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3029 - val_loss: 0.2820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3027 - val_loss: 0.2820\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3024 - val_loss: 0.2820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3021 - val_loss: 0.2819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.2819\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3016 - val_loss: 0.2818\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3013 - val_loss: 0.2818\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3010 - val_loss: 0.2818\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3008 - val_loss: 0.2817\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3005 - val_loss: 0.2817\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3002 - val_loss: 0.2816\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 104.97029321074898, my average MASE = 15924142.879668588\n",
      "Cluster 0, 104.97029321074898\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5420 - val_loss: 0.4071\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5399 - val_loss: 0.4062\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5378 - val_loss: 0.4054\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5357 - val_loss: 0.4045\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5337 - val_loss: 0.4037\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5316 - val_loss: 0.4029\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5296 - val_loss: 0.4021\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5276 - val_loss: 0.4013\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5257 - val_loss: 0.4005\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5237 - val_loss: 0.3998\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5218 - val_loss: 0.3990\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5199 - val_loss: 0.3983\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5179 - val_loss: 0.3975\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5161 - val_loss: 0.3968\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5142 - val_loss: 0.3961\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5124 - val_loss: 0.3954\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5106 - val_loss: 0.3947\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5088 - val_loss: 0.3940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5070 - val_loss: 0.3933\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5052 - val_loss: 0.3926\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5035 - val_loss: 0.3919\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5018 - val_loss: 0.3913\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5001 - val_loss: 0.3906\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4985 - val_loss: 0.3899\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4968 - val_loss: 0.3892\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.3886\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4936 - val_loss: 0.3879\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4920 - val_loss: 0.3873\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4905 - val_loss: 0.3866\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4889 - val_loss: 0.3860\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4874 - val_loss: 0.3853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4858 - val_loss: 0.3847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4843 - val_loss: 0.3840\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4828 - val_loss: 0.3834\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4813 - val_loss: 0.3828\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4798 - val_loss: 0.3821\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4783 - val_loss: 0.3815\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4769 - val_loss: 0.3809\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4754 - val_loss: 0.3803\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4740 - val_loss: 0.3797\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3145368812.0062547, my average MASE = 5974295545.526059\n",
      "Cluster 1, 3145368812.0062547\n",
      "Before prediction: train_X.shape=(2220, 10, 67), train_y.shape=(2220, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.5043 - val_loss: 0.3721\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4967 - val_loss: 0.3684\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4907 - val_loss: 0.3653\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4855 - val_loss: 0.3625\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4810 - val_loss: 0.3601\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4769 - val_loss: 0.3579\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4731 - val_loss: 0.3558\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4695 - val_loss: 0.3540\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4661 - val_loss: 0.3522\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4629 - val_loss: 0.3506\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4598 - val_loss: 0.3490\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4568 - val_loss: 0.3476\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4539 - val_loss: 0.3462\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4510 - val_loss: 0.3448\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4483 - val_loss: 0.3435\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4455 - val_loss: 0.3422\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4429 - val_loss: 0.3410\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4402 - val_loss: 0.3398\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4376 - val_loss: 0.3386\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4351 - val_loss: 0.3375\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4326 - val_loss: 0.3363\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4302 - val_loss: 0.3352\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4278 - val_loss: 0.3342\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4255 - val_loss: 0.3331\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4232 - val_loss: 0.3321\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4211 - val_loss: 0.3311\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4189 - val_loss: 0.3302\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4169 - val_loss: 0.3292\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4149 - val_loss: 0.3284\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4129 - val_loss: 0.3276\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4111 - val_loss: 0.3268\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4093 - val_loss: 0.3260\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4076 - val_loss: 0.3253\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4060 - val_loss: 0.3246\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4044 - val_loss: 0.3240\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4029 - val_loss: 0.3234\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4014 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4000 - val_loss: 0.3222\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3986 - val_loss: 0.3217\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3972 - val_loss: 0.3211\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 487.922050733615, my average MASE = 1880.6635092100216\n",
      "Cluster 2, 487.922050733615\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1089 - val_loss: 0.0991\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1039 - val_loss: 0.0970\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0998 - val_loss: 0.0956\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0965 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0938\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0911 - val_loss: 0.0932\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0889 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0869 - val_loss: 0.0924\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0852 - val_loss: 0.0922\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0836 - val_loss: 0.0920\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0821 - val_loss: 0.0918\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0808 - val_loss: 0.0917\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0795 - val_loss: 0.0915\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0783 - val_loss: 0.0913\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0773 - val_loss: 0.0912\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0763 - val_loss: 0.0910\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0908\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0744 - val_loss: 0.0907\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0736 - val_loss: 0.0905\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0903\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0901\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0900\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0708 - val_loss: 0.0899\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0897\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0696 - val_loss: 0.0896\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0690 - val_loss: 0.0895\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0894\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0680 - val_loss: 0.0893\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0675 - val_loss: 0.0892\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0892\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0666 - val_loss: 0.0891\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0661 - val_loss: 0.0890\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0658 - val_loss: 0.0890\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0654 - val_loss: 0.0889\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0650 - val_loss: 0.0889\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0647 - val_loss: 0.0888\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0644 - val_loss: 0.0888\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0888\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0887\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0636 - val_loss: 0.0887\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1152398695.5185678, my average MASE = 7118534712.468365\n",
      "Cluster 3, 1152398695.5185678\n",
      "Before prediction: train_X.shape=(156, 10, 67), train_y.shape=(156, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5146 - val_loss: 0.4378\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5133 - val_loss: 0.4370\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5122 - val_loss: 0.4361\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5111 - val_loss: 0.4352\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5100 - val_loss: 0.4344\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5089 - val_loss: 0.4335\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5078 - val_loss: 0.4327\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5068 - val_loss: 0.4319\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5057 - val_loss: 0.4311\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4303\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5037 - val_loss: 0.4296\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5028 - val_loss: 0.4288\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5018 - val_loss: 0.4281\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5008 - val_loss: 0.4273\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4999 - val_loss: 0.4266\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4990 - val_loss: 0.4259\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4981 - val_loss: 0.4252\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4972 - val_loss: 0.4245\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4963 - val_loss: 0.4238\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4954 - val_loss: 0.4232\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4945 - val_loss: 0.4225\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4937 - val_loss: 0.4219\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4929 - val_loss: 0.4213\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4920 - val_loss: 0.4207\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4912 - val_loss: 0.4201\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4905 - val_loss: 0.4195\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4897 - val_loss: 0.4189\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4889 - val_loss: 0.4183\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4881 - val_loss: 0.4177\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4874 - val_loss: 0.4172\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4867 - val_loss: 0.4166\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4859 - val_loss: 0.4161\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4852 - val_loss: 0.4155\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4845 - val_loss: 0.4150\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4838 - val_loss: 0.4145\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4831 - val_loss: 0.4139\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4824 - val_loss: 0.4134\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4817 - val_loss: 0.4129\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4811 - val_loss: 0.4124\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4804 - val_loss: 0.4119\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 117.29272898284657, my average MASE = 138077149.3198319\n",
      "Cluster 4, 117.29272898284657\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=7, 7, 49, (317, 67)\n",
      "Before prediction: train_X.shape=(184, 10, 67), train_y.shape=(184, 67), test_X.shape=(61, 10, 67), test_y.shape=(61, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6997 - val_loss: 0.6374\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6982 - val_loss: 0.6363\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6968 - val_loss: 0.6352\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6954 - val_loss: 0.6341\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.6331\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6927 - val_loss: 0.6320\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.6310\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6901 - val_loss: 0.6300\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6889 - val_loss: 0.6290\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6876 - val_loss: 0.6281\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6864 - val_loss: 0.6272\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6852 - val_loss: 0.6262\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6840 - val_loss: 0.6253\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6829 - val_loss: 0.6244\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6818 - val_loss: 0.6235\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6807 - val_loss: 0.6227\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6796 - val_loss: 0.6218\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6785 - val_loss: 0.6210\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6774 - val_loss: 0.6202\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6763 - val_loss: 0.6194\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.6186\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6743 - val_loss: 0.6178\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6733 - val_loss: 0.6171\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6723 - val_loss: 0.6163\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6713 - val_loss: 0.6156\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6704 - val_loss: 0.6149\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6694 - val_loss: 0.6142\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6685 - val_loss: 0.6135\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6676 - val_loss: 0.6127\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6666 - val_loss: 0.6121\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6658 - val_loss: 0.6114\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6649 - val_loss: 0.6107\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6640 - val_loss: 0.6100\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6631 - val_loss: 0.6093\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6622 - val_loss: 0.6086\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6614 - val_loss: 0.6079\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6605 - val_loss: 0.6073\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6597 - val_loss: 0.6066\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6588 - val_loss: 0.6060\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6580 - val_loss: 0.6053\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(61, 67), test_y.shape=(61, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 140.79883300988942, my average MASE = 132025753.41047312\n",
      "Cluster 0, 140.79883300988942\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5180 - val_loss: 0.4305\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5161 - val_loss: 0.4294\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5142 - val_loss: 0.4283\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5123 - val_loss: 0.4272\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5104 - val_loss: 0.4261\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5085 - val_loss: 0.4251\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5067 - val_loss: 0.4241\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5049 - val_loss: 0.4230\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.4221\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5013 - val_loss: 0.4211\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4996 - val_loss: 0.4202\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4978 - val_loss: 0.4193\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4961 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4944 - val_loss: 0.4175\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4927 - val_loss: 0.4166\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4911 - val_loss: 0.4158\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4895 - val_loss: 0.4149\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4879 - val_loss: 0.4141\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4863 - val_loss: 0.4133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4847 - val_loss: 0.4126\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4118\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4816 - val_loss: 0.4110\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4801 - val_loss: 0.4103\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4787 - val_loss: 0.4095\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4772 - val_loss: 0.4088\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4758 - val_loss: 0.4080\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4743 - val_loss: 0.4073\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4729 - val_loss: 0.4066\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4715 - val_loss: 0.4058\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4701 - val_loss: 0.4051\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4687 - val_loss: 0.4044\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4673 - val_loss: 0.4038\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4660 - val_loss: 0.4031\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4646 - val_loss: 0.4024\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4633 - val_loss: 0.4017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4620 - val_loss: 0.4010\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4607 - val_loss: 0.4004\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4594 - val_loss: 0.3997\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4582 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4569 - val_loss: 0.3985\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3225148693.3924103, my average MASE = 6345532768.562708\n",
      "Cluster 1, 3225148693.3924103\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1129 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1075 - val_loss: 0.0981\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1032 - val_loss: 0.0968\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0996 - val_loss: 0.0960\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0965 - val_loss: 0.0953\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0938 - val_loss: 0.0949\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0913 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0892 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0872 - val_loss: 0.0938\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0854 - val_loss: 0.0935\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0838 - val_loss: 0.0933\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0823 - val_loss: 0.0931\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0809 - val_loss: 0.0928\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0796 - val_loss: 0.0926\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0784 - val_loss: 0.0924\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0773 - val_loss: 0.0921\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0762 - val_loss: 0.0919\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0752 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0743 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0734 - val_loss: 0.0913\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0726 - val_loss: 0.0912\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0719 - val_loss: 0.0910\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0907\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0699 - val_loss: 0.0906\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0693 - val_loss: 0.0904\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0687 - val_loss: 0.0903\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0682 - val_loss: 0.0903\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0677 - val_loss: 0.0902\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0901\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0668 - val_loss: 0.0901\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0663 - val_loss: 0.0900\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0899\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0655 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0898\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0648 - val_loss: 0.0897\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0645 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0636 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1209643109.1461504, my average MASE = 20216236756.2103\n",
      "Cluster 2, 1209643109.1461504\n",
      "Before prediction: train_X.shape=(47, 10, 67), train_y.shape=(47, 67), test_X.shape=(16, 10, 67), test_y.shape=(16, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4112 - val_loss: 0.3544\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.3542\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4104 - val_loss: 0.3540\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4100 - val_loss: 0.3538\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4095 - val_loss: 0.3536\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4091 - val_loss: 0.3534\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4087 - val_loss: 0.3533\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4083 - val_loss: 0.3531\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4079 - val_loss: 0.3529\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4075 - val_loss: 0.3527\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4071 - val_loss: 0.3525\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4067 - val_loss: 0.3524\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4063 - val_loss: 0.3522\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4059 - val_loss: 0.3520\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4055 - val_loss: 0.3519\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4051 - val_loss: 0.3517\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4047 - val_loss: 0.3515\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4043 - val_loss: 0.3514\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4039 - val_loss: 0.3512\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3511\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4032 - val_loss: 0.3509\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4028 - val_loss: 0.3508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4024 - val_loss: 0.3506\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4020 - val_loss: 0.3505\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4017 - val_loss: 0.3503\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4009 - val_loss: 0.3501\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4006 - val_loss: 0.3499\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4002 - val_loss: 0.3498\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3999 - val_loss: 0.3497\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.3495\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3992 - val_loss: 0.3494\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.3493\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3985 - val_loss: 0.3492\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3982 - val_loss: 0.3491\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3978 - val_loss: 0.3489\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3975 - val_loss: 0.3488\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3972 - val_loss: 0.3487\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3968 - val_loss: 0.3486\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3965 - val_loss: 0.3485\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(16, 67), test_y.shape=(16, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 66.79284837728264, my average MASE = 54990938.33317367\n",
      "Cluster 3, 66.79284837728264\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5009 - val_loss: 0.4222\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4998 - val_loss: 0.4214\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4988 - val_loss: 0.4207\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4978 - val_loss: 0.4200\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4968 - val_loss: 0.4193\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4958 - val_loss: 0.4186\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4949 - val_loss: 0.4179\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4939 - val_loss: 0.4172\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4930 - val_loss: 0.4165\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4921 - val_loss: 0.4159\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4912 - val_loss: 0.4153\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4903 - val_loss: 0.4146\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4894 - val_loss: 0.4140\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4886 - val_loss: 0.4134\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4877 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4869 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4861 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4853 - val_loss: 0.4111\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4845 - val_loss: 0.4105\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4837 - val_loss: 0.4100\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4829 - val_loss: 0.4094\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4822 - val_loss: 0.4089\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4814 - val_loss: 0.4084\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4807 - val_loss: 0.4078\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4799 - val_loss: 0.4073\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4792 - val_loss: 0.4068\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4785 - val_loss: 0.4063\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4777 - val_loss: 0.4058\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4770 - val_loss: 0.4052\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4763 - val_loss: 0.4047\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4756 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4749 - val_loss: 0.4037\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4742 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4735 - val_loss: 0.4027\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4728 - val_loss: 0.4023\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4721 - val_loss: 0.4018\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4715 - val_loss: 0.4013\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4708 - val_loss: 0.4008\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4701 - val_loss: 0.4003\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4695 - val_loss: 0.3999\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.45341483860946, my average MASE = 95916870.45268953\n",
      "Cluster 4, 127.45341483860946\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2476 - val_loss: 0.2883\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2353 - val_loss: 0.2762\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2258 - val_loss: 0.2666\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2185 - val_loss: 0.2589\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2127 - val_loss: 0.2526\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2078 - val_loss: 0.2473\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2036 - val_loss: 0.2426\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1999 - val_loss: 0.2383\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1966 - val_loss: 0.2346\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1935 - val_loss: 0.2311\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1907 - val_loss: 0.2280\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1881 - val_loss: 0.2251\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1857 - val_loss: 0.2225\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1834 - val_loss: 0.2200\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1813 - val_loss: 0.2178\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1794 - val_loss: 0.2157\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1777 - val_loss: 0.2137\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1760 - val_loss: 0.2120\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1746 - val_loss: 0.2103\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1732 - val_loss: 0.2087\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1719 - val_loss: 0.2072\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1707 - val_loss: 0.2058\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1695 - val_loss: 0.2045\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2032\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1674 - val_loss: 0.2020\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1664 - val_loss: 0.2009\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1655 - val_loss: 0.1998\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1646 - val_loss: 0.1988\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1638 - val_loss: 0.1978\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1630 - val_loss: 0.1968\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1622 - val_loss: 0.1960\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1614 - val_loss: 0.1951\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1607 - val_loss: 0.1943\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1600 - val_loss: 0.1935\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1594 - val_loss: 0.1927\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1587 - val_loss: 0.1920\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1913\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1575 - val_loss: 0.1906\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1570 - val_loss: 0.1899\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1893\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 224.71735313764052, my average MASE = 374017026.3746446\n",
      "Cluster 5, 224.71735313764052\n",
      "Before prediction: train_X.shape=(51, 10, 67), train_y.shape=(51, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4065 - val_loss: 0.3790\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4060 - val_loss: 0.3788\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4055 - val_loss: 0.3787\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4049 - val_loss: 0.3786\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4044 - val_loss: 0.3784\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4038 - val_loss: 0.3783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4033 - val_loss: 0.3782\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4028 - val_loss: 0.3780\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4023 - val_loss: 0.3779\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4018 - val_loss: 0.3778\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4013 - val_loss: 0.3776\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3775\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4003 - val_loss: 0.3774\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3773\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3993 - val_loss: 0.3771\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3988 - val_loss: 0.3770\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3984 - val_loss: 0.3769\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3768\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3975 - val_loss: 0.3767\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3970 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3966 - val_loss: 0.3764\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3763\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3762\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3953 - val_loss: 0.3761\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3949 - val_loss: 0.3760\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3945 - val_loss: 0.3759\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3941 - val_loss: 0.3757\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3937 - val_loss: 0.3756\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3933 - val_loss: 0.3755\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3929 - val_loss: 0.3754\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3925 - val_loss: 0.3753\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3921 - val_loss: 0.3752\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3917 - val_loss: 0.3751\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3913 - val_loss: 0.3750\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3749\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3905 - val_loss: 0.3748\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3902 - val_loss: 0.3747\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3898 - val_loss: 0.3745\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3894 - val_loss: 0.3744\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3891 - val_loss: 0.3743\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 82.26261385879712, my average MASE = 20260153.97451399\n",
      "Cluster 6, 82.26261385879712\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=9, 9, 48, (301, 67)\n",
      "Before prediction: train_X.shape=(174, 10, 67), train_y.shape=(174, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7089 - val_loss: 0.5627\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7074 - val_loss: 0.5619\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7059 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7045 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7031 - val_loss: 0.5598\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7017 - val_loss: 0.5591\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7004 - val_loss: 0.5585\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6991 - val_loss: 0.5578\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6979 - val_loss: 0.5572\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6966 - val_loss: 0.5566\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6954 - val_loss: 0.5559\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.5553\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6930 - val_loss: 0.5548\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6918 - val_loss: 0.5542\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6907 - val_loss: 0.5536\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6895 - val_loss: 0.5531\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6884 - val_loss: 0.5525\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6873 - val_loss: 0.5520\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6863 - val_loss: 0.5515\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6852 - val_loss: 0.5509\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6842 - val_loss: 0.5504\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6831 - val_loss: 0.5499\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6821 - val_loss: 0.5494\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6811 - val_loss: 0.5489\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6801 - val_loss: 0.5484\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6792 - val_loss: 0.5479\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6782 - val_loss: 0.5475\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6772 - val_loss: 0.5470\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.5465\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.5461\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6744 - val_loss: 0.5456\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6735 - val_loss: 0.5452\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6726 - val_loss: 0.5447\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5443\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6707 - val_loss: 0.5439\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6698 - val_loss: 0.5434\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6689 - val_loss: 0.5430\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6680 - val_loss: 0.5426\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6671 - val_loss: 0.5422\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6663 - val_loss: 0.5417\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 144.45290178213432, my average MASE = 192607450.5447097\n",
      "Cluster 0, 144.45290178213432\n",
      "Before prediction: train_X.shape=(86, 10, 67), train_y.shape=(86, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3954 - val_loss: 0.4825\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3947 - val_loss: 0.4820\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3940 - val_loss: 0.4815\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3933 - val_loss: 0.4810\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3927 - val_loss: 0.4806\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3921 - val_loss: 0.4801\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4797\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3909 - val_loss: 0.4793\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3903 - val_loss: 0.4789\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3898 - val_loss: 0.4785\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3892 - val_loss: 0.4781\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3887 - val_loss: 0.4777\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4774\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3877 - val_loss: 0.4770\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3872 - val_loss: 0.4767\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4763\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3862 - val_loss: 0.4760\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.4757\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3853 - val_loss: 0.4753\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3848 - val_loss: 0.4750\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3844 - val_loss: 0.4747\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3840 - val_loss: 0.4744\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3835 - val_loss: 0.4741\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3831 - val_loss: 0.4738\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3827 - val_loss: 0.4735\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3822 - val_loss: 0.4732\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3818 - val_loss: 0.4729\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3814 - val_loss: 0.4726\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3810 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3806 - val_loss: 0.4720\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3802 - val_loss: 0.4717\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3798 - val_loss: 0.4714\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.4711\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3790 - val_loss: 0.4708\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3786 - val_loss: 0.4705\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3783 - val_loss: 0.4703\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3779 - val_loss: 0.4700\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3775 - val_loss: 0.4697\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3771 - val_loss: 0.4695\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3768 - val_loss: 0.4692\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 261.83661307224526, my average MASE = 165152999.01271424\n",
      "Cluster 1, 261.83661307224526\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3860 - val_loss: 0.4764\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3839 - val_loss: 0.4752\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3818 - val_loss: 0.4741\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3798 - val_loss: 0.4730\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3778 - val_loss: 0.4719\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3758 - val_loss: 0.4709\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3738 - val_loss: 0.4699\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3718 - val_loss: 0.4689\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3699 - val_loss: 0.4680\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3680 - val_loss: 0.4670\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4660\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3643 - val_loss: 0.4650\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.4640\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3606 - val_loss: 0.4630\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3588 - val_loss: 0.4620\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3570 - val_loss: 0.4610\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3553 - val_loss: 0.4599\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3535 - val_loss: 0.4588\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3518 - val_loss: 0.4578\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3501 - val_loss: 0.4567\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3484 - val_loss: 0.4557\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.4547\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3452 - val_loss: 0.4537\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3437 - val_loss: 0.4528\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3422 - val_loss: 0.4521\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3407 - val_loss: 0.4513\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.4506\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3378 - val_loss: 0.4498\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3363 - val_loss: 0.4493\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3349 - val_loss: 0.4487\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3336 - val_loss: 0.4481\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3323 - val_loss: 0.4475\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3311 - val_loss: 0.4470\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3299 - val_loss: 0.4464\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3287 - val_loss: 0.4459\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3276 - val_loss: 0.4453\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3264 - val_loss: 0.4447\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3253 - val_loss: 0.4441\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3241 - val_loss: 0.4436\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3231 - val_loss: 0.4430\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.29600762869721386, my average MASE = 0.4272698543687938\n",
      "Cluster 2, 0.29600762869721386\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4866 - val_loss: 0.4310\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4848 - val_loss: 0.4300\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4830 - val_loss: 0.4290\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4812 - val_loss: 0.4280\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.4271\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4777 - val_loss: 0.4261\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4760 - val_loss: 0.4252\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4744 - val_loss: 0.4243\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4727 - val_loss: 0.4235\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4711 - val_loss: 0.4226\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4695 - val_loss: 0.4217\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4679 - val_loss: 0.4209\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4663 - val_loss: 0.4200\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4648 - val_loss: 0.4192\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4633 - val_loss: 0.4184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4618 - val_loss: 0.4175\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4603 - val_loss: 0.4167\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4589 - val_loss: 0.4159\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4574 - val_loss: 0.4150\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4560 - val_loss: 0.4142\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4546 - val_loss: 0.4134\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4532 - val_loss: 0.4126\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4518 - val_loss: 0.4118\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4504 - val_loss: 0.4109\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4491 - val_loss: 0.4101\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4477 - val_loss: 0.4093\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4464 - val_loss: 0.4085\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4451 - val_loss: 0.4077\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4438 - val_loss: 0.4069\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4425 - val_loss: 0.4061\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4412 - val_loss: 0.4053\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4399 - val_loss: 0.4045\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4387 - val_loss: 0.4037\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4029\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4362 - val_loss: 0.4021\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4350 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4337 - val_loss: 0.4006\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4325 - val_loss: 0.3998\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4313 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4301 - val_loss: 0.3983\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3346396028.9972167, my average MASE = 7814754000.575592\n",
      "Cluster 3, 3346396028.9972167\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3142 - val_loss: 0.7771\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3138 - val_loss: 0.7770\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3135 - val_loss: 0.7769\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3131 - val_loss: 0.7768\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3127 - val_loss: 0.7767\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3123 - val_loss: 0.7765\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3119 - val_loss: 0.7764\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3116 - val_loss: 0.7763\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3112 - val_loss: 0.7762\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3108 - val_loss: 0.7761\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3105 - val_loss: 0.7759\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3101 - val_loss: 0.7758\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3097 - val_loss: 0.7757\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3094 - val_loss: 0.7756\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3090 - val_loss: 0.7755\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3087 - val_loss: 0.7754\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3083 - val_loss: 0.7753\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3080 - val_loss: 0.7752\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3076 - val_loss: 0.7751\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3073 - val_loss: 0.7749\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3069 - val_loss: 0.7748\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3066 - val_loss: 0.7747\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3063 - val_loss: 0.7746\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3059 - val_loss: 0.7746\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3056 - val_loss: 0.7745\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3053 - val_loss: 0.7744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3049 - val_loss: 0.7743\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3046 - val_loss: 0.7742\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3043 - val_loss: 0.7741\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3040 - val_loss: 0.7740\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3037 - val_loss: 0.7739\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3033 - val_loss: 0.7739\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3030 - val_loss: 0.7738\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3027 - val_loss: 0.7737\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3024 - val_loss: 0.7736\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3021 - val_loss: 0.7735\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.7734\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3015 - val_loss: 0.7733\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3012 - val_loss: 0.7732\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3009 - val_loss: 0.7731\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 93.69104182165661, my average MASE = 20945629.206220664\n",
      "Cluster 4, 93.69104182165661\n",
      "Before prediction: train_X.shape=(89, 10, 67), train_y.shape=(89, 67), test_X.shape=(30, 10, 67), test_y.shape=(30, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3424 - val_loss: 0.3360\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3416 - val_loss: 0.3355\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3408 - val_loss: 0.3350\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3400 - val_loss: 0.3346\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.3341\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3386 - val_loss: 0.3337\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3379 - val_loss: 0.3333\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3372 - val_loss: 0.3329\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3365 - val_loss: 0.3324\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3358 - val_loss: 0.3320\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3351 - val_loss: 0.3316\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3344 - val_loss: 0.3312\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3338 - val_loss: 0.3309\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3331 - val_loss: 0.3305\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3325 - val_loss: 0.3301\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3319 - val_loss: 0.3297\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3312 - val_loss: 0.3293\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3306 - val_loss: 0.3290\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3300 - val_loss: 0.3286\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3294 - val_loss: 0.3282\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3288 - val_loss: 0.3279\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3282 - val_loss: 0.3275\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3276 - val_loss: 0.3272\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3271 - val_loss: 0.3268\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3265 - val_loss: 0.3265\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3260 - val_loss: 0.3262\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3254 - val_loss: 0.3258\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3249 - val_loss: 0.3255\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3244 - val_loss: 0.3252\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.3249\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3234 - val_loss: 0.3246\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3228 - val_loss: 0.3243\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3223 - val_loss: 0.3240\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3237\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3214 - val_loss: 0.3234\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3231\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3204 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3199 - val_loss: 0.3225\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3195 - val_loss: 0.3222\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3190 - val_loss: 0.3219\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(30, 67), test_y.shape=(30, 67)\n",
      "average MASE = 188.45046029060867, my average MASE = 121680879.21353056\n",
      "Cluster 5, 188.45046029060867\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1120 - val_loss: 0.1007\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0987\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1025 - val_loss: 0.0974\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0990 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0960 - val_loss: 0.0954\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0933 - val_loss: 0.0947\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0942\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0888 - val_loss: 0.0938\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0868 - val_loss: 0.0934\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0931\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0834 - val_loss: 0.0928\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0819 - val_loss: 0.0926\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0806 - val_loss: 0.0923\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0793 - val_loss: 0.0921\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0781 - val_loss: 0.0919\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0770 - val_loss: 0.0917\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0759 - val_loss: 0.0916\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0749 - val_loss: 0.0914\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0740 - val_loss: 0.0912\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0732 - val_loss: 0.0911\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0724 - val_loss: 0.0910\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0716 - val_loss: 0.0909\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0709 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0908\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0695 - val_loss: 0.0907\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0689 - val_loss: 0.0906\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0683 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0678 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0673 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0660 - val_loss: 0.0902\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0901\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0900\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0645 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0637 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0634 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1073797047.1669116, my average MASE = 13075073766.705614\n",
      "Cluster 6, 1073797047.1669116\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2348 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2252 - val_loss: 0.2653\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2178 - val_loss: 0.2575\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2120 - val_loss: 0.2511\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2071 - val_loss: 0.2457\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2029 - val_loss: 0.2409\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1991 - val_loss: 0.2366\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1956 - val_loss: 0.2328\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1924 - val_loss: 0.2293\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1895 - val_loss: 0.2261\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1868 - val_loss: 0.2231\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2203\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1820 - val_loss: 0.2178\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1799 - val_loss: 0.2155\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1762 - val_loss: 0.2114\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1745 - val_loss: 0.2096\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1730 - val_loss: 0.2079\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1715 - val_loss: 0.2063\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1702 - val_loss: 0.2048\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1689 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1678 - val_loss: 0.2020\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1666 - val_loss: 0.2007\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1656 - val_loss: 0.1995\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1646 - val_loss: 0.1984\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1636 - val_loss: 0.1973\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1627 - val_loss: 0.1962\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1619 - val_loss: 0.1952\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1610 - val_loss: 0.1943\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1934\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1595 - val_loss: 0.1925\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1588 - val_loss: 0.1917\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1909\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1574 - val_loss: 0.1901\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1568 - val_loss: 0.1894\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1886\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1556 - val_loss: 0.1880\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1550 - val_loss: 0.1873\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1867\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1539 - val_loss: 0.1860\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 180.26488918007823, my average MASE = 179278352.44392422\n",
      "Cluster 7, 180.26488918007823\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=11, 11, 904, (6, 67)\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3401 - val_loss: 0.3875\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3395 - val_loss: 0.3872\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3390 - val_loss: 0.3870\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3385 - val_loss: 0.3868\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3380 - val_loss: 0.3866\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3375 - val_loss: 0.3863\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3370 - val_loss: 0.3861\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3366 - val_loss: 0.3859\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3361 - val_loss: 0.3856\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3357 - val_loss: 0.3854\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3352 - val_loss: 0.3852\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3348 - val_loss: 0.3850\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3343 - val_loss: 0.3848\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3339 - val_loss: 0.3846\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3335 - val_loss: 0.3844\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3331 - val_loss: 0.3842\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3327 - val_loss: 0.3840\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3323 - val_loss: 0.3837\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3318 - val_loss: 0.3835\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3314 - val_loss: 0.3833\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.3831\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3307 - val_loss: 0.3829\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3303 - val_loss: 0.3827\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3825\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3295 - val_loss: 0.3823\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3292 - val_loss: 0.3821\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3288 - val_loss: 0.3820\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3284 - val_loss: 0.3818\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3281 - val_loss: 0.3816\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.3814\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3274 - val_loss: 0.3812\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.3810\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3267 - val_loss: 0.3808\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3263 - val_loss: 0.3806\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3260 - val_loss: 0.3805\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3257 - val_loss: 0.3803\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3254 - val_loss: 0.3801\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3250 - val_loss: 0.3799\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3247 - val_loss: 0.3798\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.3796\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 122.2598699731945, my average MASE = 164200403.28208458\n",
      "Cluster 0, 122.2598699731945\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5011 - val_loss: 0.7038\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5005 - val_loss: 0.7036\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4998 - val_loss: 0.7034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4991 - val_loss: 0.7032\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4984 - val_loss: 0.7030\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4978 - val_loss: 0.7028\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4971 - val_loss: 0.7026\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4964 - val_loss: 0.7024\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4958 - val_loss: 0.7022\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4951 - val_loss: 0.7020\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4945 - val_loss: 0.7017\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4938 - val_loss: 0.7015\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4932 - val_loss: 0.7014\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4926 - val_loss: 0.7012\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4919 - val_loss: 0.7010\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4913 - val_loss: 0.7008\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4907 - val_loss: 0.7006\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4901 - val_loss: 0.7004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4894 - val_loss: 0.7002\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4888 - val_loss: 0.7000\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4882 - val_loss: 0.6998\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4877 - val_loss: 0.6997\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4871 - val_loss: 0.6995\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4865 - val_loss: 0.6993\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4859 - val_loss: 0.6991\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4853 - val_loss: 0.6989\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4847 - val_loss: 0.6988\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4842 - val_loss: 0.6986\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4836 - val_loss: 0.6984\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4831 - val_loss: 0.6983\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4825 - val_loss: 0.6981\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4820 - val_loss: 0.6979\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4815 - val_loss: 0.6978\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4809 - val_loss: 0.6976\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4804 - val_loss: 0.6974\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4799 - val_loss: 0.6973\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4794 - val_loss: 0.6971\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4789 - val_loss: 0.6970\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4783 - val_loss: 0.6968\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4778 - val_loss: 0.6966\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2966824.6919978233, my average MASE = 79205816.45072892\n",
      "Cluster 1, 2966824.6919978233\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1998 - val_loss: 0.3035\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1993 - val_loss: 0.3034\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1988 - val_loss: 0.3034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1982 - val_loss: 0.3033\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1977 - val_loss: 0.3033\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1972 - val_loss: 0.3032\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1967 - val_loss: 0.3032\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1962 - val_loss: 0.3032\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1957 - val_loss: 0.3031\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1952 - val_loss: 0.3031\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1947 - val_loss: 0.3031\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1942 - val_loss: 0.3031\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1938 - val_loss: 0.3030\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1933 - val_loss: 0.3030\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1928 - val_loss: 0.3030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1924 - val_loss: 0.3030\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1919 - val_loss: 0.3030\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1915 - val_loss: 0.3030\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1911 - val_loss: 0.3030\n",
      "Epoch 19: early stopping\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 130.97936905502368, my average MASE = 132554988.34305501\n",
      "Cluster 2, 130.97936905502368\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4496 - val_loss: 0.4061\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4490 - val_loss: 0.4060\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4484 - val_loss: 0.4058\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4478 - val_loss: 0.4057\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4472 - val_loss: 0.4056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4466 - val_loss: 0.4055\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4461 - val_loss: 0.4054\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4455 - val_loss: 0.4053\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4450 - val_loss: 0.4052\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4444 - val_loss: 0.4051\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4439 - val_loss: 0.4050\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4433 - val_loss: 0.4049\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4428 - val_loss: 0.4048\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4423 - val_loss: 0.4047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4417 - val_loss: 0.4046\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4412 - val_loss: 0.4045\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4407 - val_loss: 0.4044\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4402 - val_loss: 0.4043\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4397 - val_loss: 0.4042\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4041\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4387 - val_loss: 0.4040\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4382 - val_loss: 0.4039\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4377 - val_loss: 0.4038\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4372 - val_loss: 0.4037\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4367 - val_loss: 0.4036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4362 - val_loss: 0.4035\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4357 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4352 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4032\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4343 - val_loss: 0.4031\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4338 - val_loss: 0.4030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4333 - val_loss: 0.4029\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4329 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4028\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4027\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4315 - val_loss: 0.4026\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4311 - val_loss: 0.4025\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4306 - val_loss: 0.4024\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4302 - val_loss: 0.4023\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4297 - val_loss: 0.4022\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1437.7621485075726, my average MASE = 33408169.939470924\n",
      "Cluster 3, 1437.7621485075726\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3791 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3768 - val_loss: 0.4780\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3745 - val_loss: 0.4765\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4750\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3700 - val_loss: 0.4735\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3678 - val_loss: 0.4721\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3657 - val_loss: 0.4707\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3636 - val_loss: 0.4693\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3616 - val_loss: 0.4679\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3595 - val_loss: 0.4665\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3576 - val_loss: 0.4652\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3556 - val_loss: 0.4639\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3537 - val_loss: 0.4626\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.4614\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3500 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3482 - val_loss: 0.4590\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3464 - val_loss: 0.4578\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3447 - val_loss: 0.4567\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3430 - val_loss: 0.4556\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3414 - val_loss: 0.4545\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3398 - val_loss: 0.4534\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3382 - val_loss: 0.4524\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3366 - val_loss: 0.4513\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3351 - val_loss: 0.4504\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3335 - val_loss: 0.4494\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3320 - val_loss: 0.4484\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3305 - val_loss: 0.4475\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3291 - val_loss: 0.4466\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3277 - val_loss: 0.4457\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3263 - val_loss: 0.4448\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3249 - val_loss: 0.4439\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3236 - val_loss: 0.4431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3222 - val_loss: 0.4422\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3209 - val_loss: 0.4413\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.4404\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3184 - val_loss: 0.4395\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3171 - val_loss: 0.4386\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3159 - val_loss: 0.4378\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.4369\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3135 - val_loss: 0.4360\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1399316882.5162897, my average MASE = 3857319737.5045514\n",
      "Cluster 4, 1399316882.5162897\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2312 - val_loss: 0.2708\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2231 - val_loss: 0.2627\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2165 - val_loss: 0.2559\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2110 - val_loss: 0.2500\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2061 - val_loss: 0.2449\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2018 - val_loss: 0.2403\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1979 - val_loss: 0.2361\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1944 - val_loss: 0.2322\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1912 - val_loss: 0.2287\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1882 - val_loss: 0.2255\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1854 - val_loss: 0.2224\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1829 - val_loss: 0.2197\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1806 - val_loss: 0.2172\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1785 - val_loss: 0.2150\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1767 - val_loss: 0.2129\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1750 - val_loss: 0.2110\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1734 - val_loss: 0.2093\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1720 - val_loss: 0.2077\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1707 - val_loss: 0.2061\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1695 - val_loss: 0.2047\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1683 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1672 - val_loss: 0.2021\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1661 - val_loss: 0.2009\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1651 - val_loss: 0.1997\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1641 - val_loss: 0.1986\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1632 - val_loss: 0.1975\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1623 - val_loss: 0.1965\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1615 - val_loss: 0.1955\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1599 - val_loss: 0.1937\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1577 - val_loss: 0.1912\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1570 - val_loss: 0.1904\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1897\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1558 - val_loss: 0.1890\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1552 - val_loss: 0.1883\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1547 - val_loss: 0.1877\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1542 - val_loss: 0.1871\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1537 - val_loss: 0.1864\n",
      "17/17 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n",
      "average MASE = 146.93947390831542, my average MASE = 534465305.08164215\n",
      "Cluster 5, 146.93947390831542\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3864 - val_loss: 0.3280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.3279\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3849 - val_loss: 0.3278\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3842 - val_loss: 0.3277\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3834 - val_loss: 0.3276\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3827 - val_loss: 0.3275\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3820 - val_loss: 0.3274\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3813 - val_loss: 0.3274\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.3273\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3799 - val_loss: 0.3272\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.3272\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3785 - val_loss: 0.3271\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3778 - val_loss: 0.3270\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3772 - val_loss: 0.3270\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3765 - val_loss: 0.3269\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.3269\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3753 - val_loss: 0.3268\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3746 - val_loss: 0.3268\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3740 - val_loss: 0.3267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3734 - val_loss: 0.3266\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3728 - val_loss: 0.3266\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3722 - val_loss: 0.3265\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3717 - val_loss: 0.3265\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3711 - val_loss: 0.3264\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3705 - val_loss: 0.3264\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3699 - val_loss: 0.3263\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3694 - val_loss: 0.3263\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3688 - val_loss: 0.3262\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3682 - val_loss: 0.3262\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3262\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3671 - val_loss: 0.3261\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3666 - val_loss: 0.3261\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3660 - val_loss: 0.3260\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3655 - val_loss: 0.3260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3649 - val_loss: 0.3260\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3643 - val_loss: 0.3259\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3632 - val_loss: 0.3259\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3259\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3621 - val_loss: 0.3259\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 304.5484747914777, my average MASE = 15252291.46578898\n",
      "Cluster 6, 304.5484747914777\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8703 - val_loss: 8.9197\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8672 - val_loss: 8.9197\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8642 - val_loss: 8.9196\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8613 - val_loss: 8.9196\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8586 - val_loss: 8.9196\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8558 - val_loss: 8.9195\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8532 - val_loss: 8.9194\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8506 - val_loss: 8.9194\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8480 - val_loss: 8.9193\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8455 - val_loss: 8.9192\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8431 - val_loss: 8.9192\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8407 - val_loss: 8.9191\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8383 - val_loss: 8.9190\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8360 - val_loss: 8.9189\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8337 - val_loss: 8.9188\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8315 - val_loss: 8.9187\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8293 - val_loss: 8.9187\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8271 - val_loss: 8.9186\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8250 - val_loss: 8.9185\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 8.9184\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8209 - val_loss: 8.9184\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 8.9183\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8170 - val_loss: 8.9182\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8150 - val_loss: 8.9181\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8131 - val_loss: 8.9180\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8113 - val_loss: 8.9179\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8095 - val_loss: 8.9179\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 8.9178\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8062 - val_loss: 8.9177\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8046 - val_loss: 8.9176\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8031 - val_loss: 8.9175\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8016 - val_loss: 8.9175\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8000 - val_loss: 8.9174\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7985 - val_loss: 8.9173\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7970 - val_loss: 8.9172\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7955 - val_loss: 8.9171\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7941 - val_loss: 8.9171\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7927 - val_loss: 8.9170\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7913 - val_loss: 8.9170\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7899 - val_loss: 8.9170\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 192382848.4747458, my average MASE = 882590618.8453726\n",
      "Cluster 7, 192382848.4747458\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1119 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0986\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1024 - val_loss: 0.0973\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0988 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0957 - val_loss: 0.0956\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0930 - val_loss: 0.0950\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0905 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0883 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0863 - val_loss: 0.0937\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0933\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0828 - val_loss: 0.0930\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0813 - val_loss: 0.0928\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0799 - val_loss: 0.0925\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0787 - val_loss: 0.0924\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0775 - val_loss: 0.0922\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0764 - val_loss: 0.0920\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0754 - val_loss: 0.0918\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0744 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0735 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0727 - val_loss: 0.0914\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0719 - val_loss: 0.0913\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0711 - val_loss: 0.0912\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0705 - val_loss: 0.0910\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0909\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0692 - val_loss: 0.0908\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0687 - val_loss: 0.0907\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0677 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0660 - val_loss: 0.0901\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0900\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0653 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0646 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0898\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0897\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0896\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0635 - val_loss: 0.0896\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1222984943.0994627, my average MASE = 34180380931.05725\n",
      "Cluster 8, 1222984943.0994627\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3097 - val_loss: 0.3956\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3089 - val_loss: 0.3954\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3081 - val_loss: 0.3952\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3074 - val_loss: 0.3950\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3066 - val_loss: 0.3948\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3059 - val_loss: 0.3945\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3051 - val_loss: 0.3943\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3044 - val_loss: 0.3941\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3037 - val_loss: 0.3939\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3030 - val_loss: 0.3937\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.3935\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3017 - val_loss: 0.3934\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3010 - val_loss: 0.3933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3003 - val_loss: 0.3931\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2997 - val_loss: 0.3930\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2990 - val_loss: 0.3929\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2984 - val_loss: 0.3927\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2977 - val_loss: 0.3926\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2971 - val_loss: 0.3925\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2965 - val_loss: 0.3924\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2959 - val_loss: 0.3923\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2953 - val_loss: 0.3922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2947 - val_loss: 0.3921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2941 - val_loss: 0.3920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2935 - val_loss: 0.3919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2930 - val_loss: 0.3918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2924 - val_loss: 0.3917\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.3917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2913 - val_loss: 0.3916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2907 - val_loss: 0.3915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2902 - val_loss: 0.3914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2896 - val_loss: 0.3914\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2891 - val_loss: 0.3913\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2885 - val_loss: 0.3912\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2880 - val_loss: 0.3911\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2875 - val_loss: 0.3910\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2870 - val_loss: 0.3909\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2865 - val_loss: 0.3908\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2859 - val_loss: 0.3907\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2854 - val_loss: 0.3907\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 561.7864488366092, my average MASE = 24722978.57949824\n",
      "Cluster 10, 561.7864488366092\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=2, 2, 13, (10045, 67)\n",
      "Before prediction: train_X.shape=(6020, 10, 67), train_y.shape=(6020, 67), test_X.shape=(2007, 10, 67), test_y.shape=(2007, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0647 - val_loss: 0.0484\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0596 - val_loss: 0.0453\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0565 - val_loss: 0.0429\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0542 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0523 - val_loss: 0.0394\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0508 - val_loss: 0.0381\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0495 - val_loss: 0.0370\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0484 - val_loss: 0.0360\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0475 - val_loss: 0.0351\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0467 - val_loss: 0.0344\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0461 - val_loss: 0.0338\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0454 - val_loss: 0.0333\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0328\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0444 - val_loss: 0.0323\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0440 - val_loss: 0.0320\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0435 - val_loss: 0.0316\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0313\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0428 - val_loss: 0.0311\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0308\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0306\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0304\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0415 - val_loss: 0.0303\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0412 - val_loss: 0.0301\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0410 - val_loss: 0.0300\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0298\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0297\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0296\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0294\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0293\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0292\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0397 - val_loss: 0.0291\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0396 - val_loss: 0.0291\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0395 - val_loss: 0.0290\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0394 - val_loss: 0.0289\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0393 - val_loss: 0.0289\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0288\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0287\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0390 - val_loss: 0.0287\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0389 - val_loss: 0.0286\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0388 - val_loss: 0.0286\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2007, 67), test_y.shape=(2007, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 124611449.52884135, my average MASE = 52097635280.213745\n",
      "Cluster 0, 124611449.52884135\n",
      "Before prediction: train_X.shape=(18364, 10, 67), train_y.shape=(18364, 67), test_X.shape=(6121, 10, 67), test_y.shape=(6121, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3019 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2812 - val_loss: 0.3011\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2652 - val_loss: 0.2888\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2545 - val_loss: 0.2808\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2479 - val_loss: 0.2750\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2428 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2385 - val_loss: 0.2663\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2348 - val_loss: 0.2629\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2315 - val_loss: 0.2599\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2283 - val_loss: 0.2570\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2254 - val_loss: 0.2544\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2226 - val_loss: 0.2520\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2201 - val_loss: 0.2499\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2179 - val_loss: 0.2480\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2161 - val_loss: 0.2464\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2145 - val_loss: 0.2449\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2436\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2118 - val_loss: 0.2425\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2107 - val_loss: 0.2414\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2096 - val_loss: 0.2403\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2087 - val_loss: 0.2395\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2387\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2070 - val_loss: 0.2379\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2063 - val_loss: 0.2371\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2056 - val_loss: 0.2364\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2049 - val_loss: 0.2358\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2352\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2038 - val_loss: 0.2346\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2032 - val_loss: 0.2342\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2027 - val_loss: 0.2337\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2023 - val_loss: 0.2332\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2018 - val_loss: 0.2329\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2014 - val_loss: 0.2325\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2321\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2006 - val_loss: 0.2318\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2314\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1999 - val_loss: 0.2311\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1996 - val_loss: 0.2308\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.1993 - val_loss: 0.2305\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1990 - val_loss: 0.2302\n",
      "192/192 [==============================] - 2s 11ms/step\n",
      "predicted_original.shape=(6121, 67), test_y.shape=(6121, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1515.0877642124253, my average MASE = 2752.3099444505265\n",
      "Cluster 1, 1515.0877642124253\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=5, 5, 12, (3253, 67)\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1101 - val_loss: 0.0983\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1050 - val_loss: 0.0966\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1009 - val_loss: 0.0954\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0975 - val_loss: 0.0944\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0945 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0919 - val_loss: 0.0931\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0895 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0923\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0855 - val_loss: 0.0921\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0838 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0915\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0807 - val_loss: 0.0912\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0794 - val_loss: 0.0910\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0782 - val_loss: 0.0908\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0771 - val_loss: 0.0906\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0760 - val_loss: 0.0904\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0750 - val_loss: 0.0902\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0741 - val_loss: 0.0901\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0733 - val_loss: 0.0899\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0725 - val_loss: 0.0898\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0717 - val_loss: 0.0897\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0710 - val_loss: 0.0895\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0704 - val_loss: 0.0895\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0894\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0691 - val_loss: 0.0893\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0686 - val_loss: 0.0892\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0681 - val_loss: 0.0892\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0891\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0671 - val_loss: 0.0891\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0890\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0662 - val_loss: 0.0889\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0658 - val_loss: 0.0889\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0888\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0651 - val_loss: 0.0887\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0647 - val_loss: 0.0887\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0644 - val_loss: 0.0886\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0641 - val_loss: 0.0885\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0638 - val_loss: 0.0885\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0636 - val_loss: 0.0884\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0633 - val_loss: 0.0883\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n",
      "average MASE = 1286975259.8033035, my average MASE = 26869301348.284866\n",
      "Cluster 0, 1286975259.8033035\n",
      "Before prediction: train_X.shape=(2221, 10, 67), train_y.shape=(2221, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5056 - val_loss: 0.3755\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4985 - val_loss: 0.3720\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4926 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4874 - val_loss: 0.3660\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4828 - val_loss: 0.3635\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4785 - val_loss: 0.3611\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4745 - val_loss: 0.3590\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4707 - val_loss: 0.3570\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4671 - val_loss: 0.3552\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4637 - val_loss: 0.3535\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4604 - val_loss: 0.3519\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4572 - val_loss: 0.3504\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4542 - val_loss: 0.3489\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4512 - val_loss: 0.3475\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4483 - val_loss: 0.3462\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4455 - val_loss: 0.3449\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4428 - val_loss: 0.3436\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4401 - val_loss: 0.3424\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4375 - val_loss: 0.3412\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4350 - val_loss: 0.3401\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4325 - val_loss: 0.3390\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4301 - val_loss: 0.3380\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4278 - val_loss: 0.3370\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4255 - val_loss: 0.3360\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4233 - val_loss: 0.3350\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4211 - val_loss: 0.3341\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4190 - val_loss: 0.3332\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4170 - val_loss: 0.3324\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4150 - val_loss: 0.3315\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4131 - val_loss: 0.3307\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4113 - val_loss: 0.3299\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4095 - val_loss: 0.3292\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4078 - val_loss: 0.3285\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4061 - val_loss: 0.3278\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4045 - val_loss: 0.3271\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4030 - val_loss: 0.3265\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4014 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3999 - val_loss: 0.3253\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3985 - val_loss: 0.3247\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3971 - val_loss: 0.3242\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 455.57479189703486, my average MASE = 880.739926655778\n",
      "Cluster 1, 455.57479189703486\n",
      "Before prediction: train_X.shape=(41, 10, 67), train_y.shape=(41, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4961 - val_loss: 0.6170\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4945 - val_loss: 0.6160\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4928 - val_loss: 0.6151\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4912 - val_loss: 0.6141\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4896 - val_loss: 0.6132\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4880 - val_loss: 0.6123\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4864 - val_loss: 0.6114\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4849 - val_loss: 0.6105\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4834 - val_loss: 0.6096\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4818 - val_loss: 0.6088\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4803 - val_loss: 0.6080\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4788 - val_loss: 0.6071\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4774 - val_loss: 0.6063\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4759 - val_loss: 0.6055\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4745 - val_loss: 0.6047\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4731 - val_loss: 0.6040\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4717 - val_loss: 0.6033\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4703 - val_loss: 0.6025\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4689 - val_loss: 0.6018\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4676 - val_loss: 0.6012\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4663 - val_loss: 0.6005\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4649 - val_loss: 0.5998\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4636 - val_loss: 0.5992\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4624 - val_loss: 0.5985\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4611 - val_loss: 0.5979\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4598 - val_loss: 0.5973\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4586 - val_loss: 0.5967\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4574 - val_loss: 0.5961\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4561 - val_loss: 0.5955\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4549 - val_loss: 0.5950\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4537 - val_loss: 0.5944\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4525 - val_loss: 0.5939\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4513 - val_loss: 0.5933\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4501 - val_loss: 0.5928\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4489 - val_loss: 0.5922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4478 - val_loss: 0.5917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4466 - val_loss: 0.5912\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4455 - val_loss: 0.5907\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4443 - val_loss: 0.5902\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4432 - val_loss: 0.5897\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3633974576.8812943, my average MASE = 9316750037.661146\n",
      "Cluster 2, 3633974576.8812943\n",
      "Before prediction: train_X.shape=(158, 10, 67), train_y.shape=(158, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5152 - val_loss: 0.4273\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5139 - val_loss: 0.4265\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5128 - val_loss: 0.4257\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5117 - val_loss: 0.4249\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5105 - val_loss: 0.4241\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5095 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5084 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5074 - val_loss: 0.4219\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5064 - val_loss: 0.4212\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5054 - val_loss: 0.4204\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5044 - val_loss: 0.4197\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5034 - val_loss: 0.4191\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5025 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5015 - val_loss: 0.4178\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5006 - val_loss: 0.4171\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4997 - val_loss: 0.4165\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4988 - val_loss: 0.4159\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4979 - val_loss: 0.4153\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4970 - val_loss: 0.4147\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4961 - val_loss: 0.4141\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4953 - val_loss: 0.4135\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4944 - val_loss: 0.4129\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4936 - val_loss: 0.4123\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4928 - val_loss: 0.4118\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4920 - val_loss: 0.4112\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4912 - val_loss: 0.4107\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4904 - val_loss: 0.4101\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4096\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4889 - val_loss: 0.4091\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4882 - val_loss: 0.4086\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4874 - val_loss: 0.4080\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4867 - val_loss: 0.4075\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4860 - val_loss: 0.4070\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4852 - val_loss: 0.4065\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4845 - val_loss: 0.4060\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4838 - val_loss: 0.4055\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4831 - val_loss: 0.4050\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4045\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4818 - val_loss: 0.4040\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4811 - val_loss: 0.4036\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 113.07393682707622, my average MASE = 188079219.47717956\n",
      "Cluster 3, 113.07393682707622\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7117 - val_loss: 0.7129\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7087 - val_loss: 0.7117\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7057 - val_loss: 0.7104\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7028 - val_loss: 0.7094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7000 - val_loss: 0.7084\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6972 - val_loss: 0.7075\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6945 - val_loss: 0.7066\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6918 - val_loss: 0.7056\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6891 - val_loss: 0.7047\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6865 - val_loss: 0.7037\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6838 - val_loss: 0.7028\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6811 - val_loss: 0.7018\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6785 - val_loss: 0.7009\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6758 - val_loss: 0.6999\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6732 - val_loss: 0.6990\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6706 - val_loss: 0.6981\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6680 - val_loss: 0.6971\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6654 - val_loss: 0.6961\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6628 - val_loss: 0.6951\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6604 - val_loss: 0.6942\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6580 - val_loss: 0.6934\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6556 - val_loss: 0.6926\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6534 - val_loss: 0.6918\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6512 - val_loss: 0.6910\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6491 - val_loss: 0.6902\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6470 - val_loss: 0.6894\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6449 - val_loss: 0.6886\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6429 - val_loss: 0.6877\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6409 - val_loss: 0.6869\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6389 - val_loss: 0.6861\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6369 - val_loss: 0.6853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6350 - val_loss: 0.6847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6332 - val_loss: 0.6841\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6314 - val_loss: 0.6836\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6297 - val_loss: 0.6831\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6280 - val_loss: 0.6827\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6263 - val_loss: 0.6825\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6246 - val_loss: 0.6824\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6229 - val_loss: 0.6823\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6212 - val_loss: 0.6822\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2798887382418345, my average MASE = 0.5334982550486497\n",
      "Cluster 4, 0.2798887382418345\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=7, 7, 431, (13, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(180, 10, 67), train_y.shape=(180, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6852 - val_loss: 0.5575\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6838 - val_loss: 0.5569\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6824 - val_loss: 0.5563\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6811 - val_loss: 0.5557\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6799 - val_loss: 0.5551\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6786 - val_loss: 0.5545\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6774 - val_loss: 0.5540\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6762 - val_loss: 0.5534\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6750 - val_loss: 0.5528\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6739 - val_loss: 0.5523\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6727 - val_loss: 0.5518\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5512\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6705 - val_loss: 0.5507\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6694 - val_loss: 0.5501\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6684 - val_loss: 0.5496\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6673 - val_loss: 0.5491\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6663 - val_loss: 0.5486\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6653 - val_loss: 0.5481\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6643 - val_loss: 0.5475\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6632 - val_loss: 0.5470\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6623 - val_loss: 0.5465\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6613 - val_loss: 0.5461\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6603 - val_loss: 0.5456\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6594 - val_loss: 0.5451\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6584 - val_loss: 0.5446\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6575 - val_loss: 0.5441\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6566 - val_loss: 0.5437\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6557 - val_loss: 0.5432\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6548 - val_loss: 0.5427\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6539 - val_loss: 0.5423\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6531 - val_loss: 0.5418\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6522 - val_loss: 0.5414\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6513 - val_loss: 0.5409\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6505 - val_loss: 0.5405\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6497 - val_loss: 0.5400\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6489 - val_loss: 0.5396\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6480 - val_loss: 0.5392\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6472 - val_loss: 0.5387\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6464 - val_loss: 0.5383\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6456 - val_loss: 0.5379\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 161.0036674860674, my average MASE = 412096886.9283237\n",
      "Cluster 1, 161.0036674860674\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6031 - val_loss: 0.4390\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6002 - val_loss: 0.4369\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5975 - val_loss: 0.4349\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5947 - val_loss: 0.4328\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5919 - val_loss: 0.4307\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5892 - val_loss: 0.4287\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5864 - val_loss: 0.4267\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5838 - val_loss: 0.4248\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5812 - val_loss: 0.4230\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5786 - val_loss: 0.4213\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5761 - val_loss: 0.4196\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5736 - val_loss: 0.4180\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5712 - val_loss: 0.4164\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5687 - val_loss: 0.4148\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5663 - val_loss: 0.4132\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5638 - val_loss: 0.4116\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5614 - val_loss: 0.4101\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5590 - val_loss: 0.4085\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5566 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5542 - val_loss: 0.4054\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5518 - val_loss: 0.4039\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5494 - val_loss: 0.4024\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5471 - val_loss: 0.4008\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5448 - val_loss: 0.3992\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5424 - val_loss: 0.3977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5401 - val_loss: 0.3961\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5378 - val_loss: 0.3945\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5355 - val_loss: 0.3930\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5333 - val_loss: 0.3914\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5310 - val_loss: 0.3898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5288 - val_loss: 0.3883\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5266 - val_loss: 0.3868\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5243 - val_loss: 0.3855\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5221 - val_loss: 0.3842\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5199 - val_loss: 0.3830\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5176 - val_loss: 0.3817\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5154 - val_loss: 0.3804\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5133 - val_loss: 0.3792\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5111 - val_loss: 0.3780\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5089 - val_loss: 0.3770\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.22679251401977166, my average MASE = 0.3179573135228401\n",
      "Cluster 2, 0.22679251401977166\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4783 - val_loss: 0.4457\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4766 - val_loss: 0.4444\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4750 - val_loss: 0.4432\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4734 - val_loss: 0.4420\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4719 - val_loss: 0.4408\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4703 - val_loss: 0.4397\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4687 - val_loss: 0.4385\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4672 - val_loss: 0.4374\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4657 - val_loss: 0.4362\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4642 - val_loss: 0.4351\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4627 - val_loss: 0.4340\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4613 - val_loss: 0.4329\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4598 - val_loss: 0.4318\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4584 - val_loss: 0.4307\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4296\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4555 - val_loss: 0.4286\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4541 - val_loss: 0.4275\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4527 - val_loss: 0.4265\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4513 - val_loss: 0.4255\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4499 - val_loss: 0.4245\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4486 - val_loss: 0.4235\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4472 - val_loss: 0.4225\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4459 - val_loss: 0.4215\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4445 - val_loss: 0.4205\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4432 - val_loss: 0.4195\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4186\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4406 - val_loss: 0.4176\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4167\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4380 - val_loss: 0.4158\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4368 - val_loss: 0.4149\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4355 - val_loss: 0.4139\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4343 - val_loss: 0.4130\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4330 - val_loss: 0.4121\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4318 - val_loss: 0.4112\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4306 - val_loss: 0.4103\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4294 - val_loss: 0.4094\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4282 - val_loss: 0.4085\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4270 - val_loss: 0.4077\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4258 - val_loss: 0.4068\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4246 - val_loss: 0.4059\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3532936323.38913, my average MASE = 7800622104.848636\n",
      "Cluster 3, 3532936323.38913\n",
      "Before prediction: train_X.shape=(152, 10, 67), train_y.shape=(152, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3354 - val_loss: 0.2774\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3344 - val_loss: 0.2769\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3336 - val_loss: 0.2763\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3328 - val_loss: 0.2758\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3320 - val_loss: 0.2753\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3312 - val_loss: 0.2747\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3304 - val_loss: 0.2742\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3297 - val_loss: 0.2737\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3290 - val_loss: 0.2733\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3282 - val_loss: 0.2728\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3275 - val_loss: 0.2723\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3268 - val_loss: 0.2718\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3262 - val_loss: 0.2714\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3255 - val_loss: 0.2709\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3248 - val_loss: 0.2705\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3242 - val_loss: 0.2700\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3235 - val_loss: 0.2696\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3229 - val_loss: 0.2692\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3223 - val_loss: 0.2687\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3217 - val_loss: 0.2683\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3210 - val_loss: 0.2678\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3204 - val_loss: 0.2674\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3198 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3192 - val_loss: 0.2666\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3187 - val_loss: 0.2662\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3181 - val_loss: 0.2658\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3175 - val_loss: 0.2654\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3170 - val_loss: 0.2650\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3164 - val_loss: 0.2647\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3158 - val_loss: 0.2643\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3153 - val_loss: 0.2639\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3148 - val_loss: 0.2635\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3142 - val_loss: 0.2632\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3137 - val_loss: 0.2628\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3132 - val_loss: 0.2624\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3127 - val_loss: 0.2621\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3122 - val_loss: 0.2617\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3117 - val_loss: 0.2614\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3112 - val_loss: 0.2610\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3107 - val_loss: 0.2607\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 185.09520141259705, my average MASE = 132066880.5161765\n",
      "Cluster 4, 185.09520141259705\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0679 - val_loss: 0.0461\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0619 - val_loss: 0.0426\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0586 - val_loss: 0.0401\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0561 - val_loss: 0.0381\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0542 - val_loss: 0.0366\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0527 - val_loss: 0.0352\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0514 - val_loss: 0.0341\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0503 - val_loss: 0.0333\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0312\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0473 - val_loss: 0.0307\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0468 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0463 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0459 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0455 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0452 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0448 - val_loss: 0.0288\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0286\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0443 - val_loss: 0.0284\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0283\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0281\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0436 - val_loss: 0.0279\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0434 - val_loss: 0.0278\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0277\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0276\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0274\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0273\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0426 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0425 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0423 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0422 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0421 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0420 - val_loss: 0.0269\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0419 - val_loss: 0.0268\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0267\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 1042799882.6542007, my average MASE = 20591462481.802387\n",
      "Cluster 5, 1042799882.6542007\n",
      "Before prediction: train_X.shape=(82, 10, 67), train_y.shape=(82, 67), test_X.shape=(27, 10, 67), test_y.shape=(27, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3924 - val_loss: 0.4859\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3915 - val_loss: 0.4852\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3907 - val_loss: 0.4846\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3899 - val_loss: 0.4840\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3891 - val_loss: 0.4835\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3883 - val_loss: 0.4829\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3876 - val_loss: 0.4824\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3868 - val_loss: 0.4818\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3861 - val_loss: 0.4813\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 0.4808\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3847 - val_loss: 0.4802\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3841 - val_loss: 0.4797\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3834 - val_loss: 0.4792\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3828 - val_loss: 0.4787\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3821 - val_loss: 0.4783\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3815 - val_loss: 0.4778\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3809 - val_loss: 0.4773\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3804 - val_loss: 0.4769\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3798 - val_loss: 0.4764\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.4760\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3787 - val_loss: 0.4755\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3781 - val_loss: 0.4751\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4747\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3771 - val_loss: 0.4743\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3766 - val_loss: 0.4738\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3761 - val_loss: 0.4734\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3756 - val_loss: 0.4731\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3751 - val_loss: 0.4727\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3746 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3741 - val_loss: 0.4719\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3737 - val_loss: 0.4715\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3732 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3728 - val_loss: 0.4707\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3723 - val_loss: 0.4703\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3719 - val_loss: 0.4699\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3715 - val_loss: 0.4696\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3710 - val_loss: 0.4692\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3706 - val_loss: 0.4688\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3702 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3698 - val_loss: 0.4681\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(27, 67), test_y.shape=(27, 67)\n",
      "average MASE = 307.7375965485456, my average MASE = 158440912.42565766\n",
      "Cluster 6, 307.7375965485456\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=9, 9, 32, (76, 67)\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4763 - val_loss: 0.4497\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4746 - val_loss: 0.4487\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4729 - val_loss: 0.4477\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4713 - val_loss: 0.4467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4696 - val_loss: 0.4458\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4680 - val_loss: 0.4448\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.4439\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4647 - val_loss: 0.4429\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4631 - val_loss: 0.4420\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.4410\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4600 - val_loss: 0.4401\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4585 - val_loss: 0.4392\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4554 - val_loss: 0.4373\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4539 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4524 - val_loss: 0.4355\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4510 - val_loss: 0.4345\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4495 - val_loss: 0.4336\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4481 - val_loss: 0.4327\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.4319\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4453 - val_loss: 0.4310\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4439 - val_loss: 0.4301\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4425 - val_loss: 0.4293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4412 - val_loss: 0.4284\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4398 - val_loss: 0.4276\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4385 - val_loss: 0.4267\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4371 - val_loss: 0.4259\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4358 - val_loss: 0.4251\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.4243\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4332 - val_loss: 0.4234\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4226\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4307 - val_loss: 0.4218\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4294 - val_loss: 0.4210\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4282 - val_loss: 0.4202\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4270 - val_loss: 0.4195\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4258 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4246 - val_loss: 0.4179\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4234 - val_loss: 0.4172\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4222 - val_loss: 0.4164\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4211 - val_loss: 0.4157\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3502979890.5184355, my average MASE = 5633924620.870799\n",
      "Cluster 0, 3502979890.5184355\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1163 - val_loss: 0.0998\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1111 - val_loss: 0.0974\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1069 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1034 - val_loss: 0.0946\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1003 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0952 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0929 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0909 - val_loss: 0.0914\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0891 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0907\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0859 - val_loss: 0.0904\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0902\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0831 - val_loss: 0.0900\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0808 - val_loss: 0.0896\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0797 - val_loss: 0.0894\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0787 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0778 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0769 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0761 - val_loss: 0.0890\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0889\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0745 - val_loss: 0.0888\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0738 - val_loss: 0.0887\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0731 - val_loss: 0.0886\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0725 - val_loss: 0.0886\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0885\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0713 - val_loss: 0.0885\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0707 - val_loss: 0.0884\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0702 - val_loss: 0.0884\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0697 - val_loss: 0.0883\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0692 - val_loss: 0.0883\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0882\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0683 - val_loss: 0.0882\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0881\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0881\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0880\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0880\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0665 - val_loss: 0.0879\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0662 - val_loss: 0.0879\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1199834821.8603294, my average MASE = 15362171394.25593\n",
      "Cluster 1, 1199834821.8603294\n",
      "Before prediction: train_X.shape=(1567, 10, 67), train_y.shape=(1567, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2378 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2280 - val_loss: 0.2658\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2204 - val_loss: 0.2582\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2142 - val_loss: 0.2520\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2091 - val_loss: 0.2467\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2046 - val_loss: 0.2420\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2006 - val_loss: 0.2378\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1971 - val_loss: 0.2340\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1938 - val_loss: 0.2304\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1908 - val_loss: 0.2272\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1880 - val_loss: 0.2241\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1853 - val_loss: 0.2213\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1829 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1806 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1784 - val_loss: 0.2141\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1765 - val_loss: 0.2121\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1747 - val_loss: 0.2103\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1730 - val_loss: 0.2086\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1715 - val_loss: 0.2071\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1702 - val_loss: 0.2056\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1689 - val_loss: 0.2042\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1677 - val_loss: 0.2029\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2016\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2005\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1645 - val_loss: 0.1993\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1983\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1626 - val_loss: 0.1973\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1618 - val_loss: 0.1962\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1610 - val_loss: 0.1953\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1944\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1594 - val_loss: 0.1935\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1587 - val_loss: 0.1927\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1580 - val_loss: 0.1919\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1573 - val_loss: 0.1911\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1567 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1555 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1550 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1539 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 164.5516081334958, my average MASE = 793528060.8539205\n",
      "Cluster 2, 164.5516081334958\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3929 - val_loss: 0.4650\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 0.4646\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3912 - val_loss: 0.4642\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3904 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3896 - val_loss: 0.4635\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3889 - val_loss: 0.4631\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3881 - val_loss: 0.4627\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3874 - val_loss: 0.4624\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4621\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.4617\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3854 - val_loss: 0.4614\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3847 - val_loss: 0.4611\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3841 - val_loss: 0.4608\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3835 - val_loss: 0.4605\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3829 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3823 - val_loss: 0.4600\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3817 - val_loss: 0.4597\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3812 - val_loss: 0.4594\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.4591\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3800 - val_loss: 0.4588\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3795 - val_loss: 0.4585\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3790 - val_loss: 0.4583\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3785 - val_loss: 0.4580\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.4578\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3775 - val_loss: 0.4575\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3770 - val_loss: 0.4572\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3765 - val_loss: 0.4570\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3761 - val_loss: 0.4567\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3756 - val_loss: 0.4565\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3752 - val_loss: 0.4563\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3747 - val_loss: 0.4560\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3738 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3734 - val_loss: 0.4553\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3730 - val_loss: 0.4551\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3725 - val_loss: 0.4549\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3721 - val_loss: 0.4547\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3717 - val_loss: 0.4545\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3713 - val_loss: 0.4542\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3709 - val_loss: 0.4540\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 177.05816941536048, my average MASE = 104373067.45181417\n",
      "Cluster 3, 177.05816941536048\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4712 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4689 - val_loss: 0.3159\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.3148\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4644 - val_loss: 0.3137\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4621 - val_loss: 0.3125\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4598 - val_loss: 0.3114\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4576 - val_loss: 0.3103\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4553 - val_loss: 0.3092\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4531 - val_loss: 0.3081\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4509 - val_loss: 0.3071\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.3062\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4465 - val_loss: 0.3053\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4444 - val_loss: 0.3044\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4422 - val_loss: 0.3036\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4401 - val_loss: 0.3028\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4379 - val_loss: 0.3020\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4358 - val_loss: 0.3012\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.3004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4317 - val_loss: 0.2996\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4297 - val_loss: 0.2988\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4278 - val_loss: 0.2979\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4259 - val_loss: 0.2970\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4240 - val_loss: 0.2961\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4222 - val_loss: 0.2952\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4204 - val_loss: 0.2943\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4186 - val_loss: 0.2934\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4168 - val_loss: 0.2924\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4151 - val_loss: 0.2915\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4134 - val_loss: 0.2906\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4118 - val_loss: 0.2898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4102 - val_loss: 0.2890\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4086 - val_loss: 0.2883\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4070 - val_loss: 0.2876\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.2869\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4039 - val_loss: 0.2863\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4009 - val_loss: 0.2850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.2845\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3980 - val_loss: 0.2840\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3966 - val_loss: 0.2835\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 254.89087963107983, my average MASE = 19795911.088192035\n",
      "Cluster 5, 254.89087963107983\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(176, 10, 67), train_y.shape=(176, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7010 - val_loss: 0.5674\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6997 - val_loss: 0.5667\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6984 - val_loss: 0.5660\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6972 - val_loss: 0.5654\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6960 - val_loss: 0.5647\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6948 - val_loss: 0.5641\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6937 - val_loss: 0.5635\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6925 - val_loss: 0.5629\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.5623\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6903 - val_loss: 0.5617\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6893 - val_loss: 0.5611\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6882 - val_loss: 0.5605\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6871 - val_loss: 0.5599\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6861 - val_loss: 0.5594\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6851 - val_loss: 0.5588\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6841 - val_loss: 0.5583\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6831 - val_loss: 0.5577\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6821 - val_loss: 0.5572\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6811 - val_loss: 0.5567\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6802 - val_loss: 0.5562\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6792 - val_loss: 0.5556\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6783 - val_loss: 0.5551\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6774 - val_loss: 0.5546\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6765 - val_loss: 0.5541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6756 - val_loss: 0.5536\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6747 - val_loss: 0.5531\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6738 - val_loss: 0.5526\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6729 - val_loss: 0.5521\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6720 - val_loss: 0.5516\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6712 - val_loss: 0.5512\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6703 - val_loss: 0.5507\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6695 - val_loss: 0.5502\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6686 - val_loss: 0.5497\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6678 - val_loss: 0.5493\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6670 - val_loss: 0.5488\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6661 - val_loss: 0.5483\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6653 - val_loss: 0.5479\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.5474\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6637 - val_loss: 0.5469\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6629 - val_loss: 0.5464\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 154.34881195949765, my average MASE = 318959730.30915844\n",
      "Cluster 7, 154.34881195949765\n",
      "Before prediction: train_X.shape=(150, 10, 67), train_y.shape=(150, 67), test_X.shape=(50, 10, 67), test_y.shape=(50, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3127 - val_loss: 0.2620\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3118 - val_loss: 0.2614\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3110 - val_loss: 0.2608\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3103 - val_loss: 0.2603\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3096 - val_loss: 0.2597\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3088 - val_loss: 0.2592\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3081 - val_loss: 0.2587\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3074 - val_loss: 0.2582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3067 - val_loss: 0.2577\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3060 - val_loss: 0.2572\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3054 - val_loss: 0.2567\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3047 - val_loss: 0.2563\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3041 - val_loss: 0.2558\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3035 - val_loss: 0.2554\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3029 - val_loss: 0.2549\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3023 - val_loss: 0.2545\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3017 - val_loss: 0.2541\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3011 - val_loss: 0.2537\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3005 - val_loss: 0.2533\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3000 - val_loss: 0.2529\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2994 - val_loss: 0.2525\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2988 - val_loss: 0.2521\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2983 - val_loss: 0.2517\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2978 - val_loss: 0.2513\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2973 - val_loss: 0.2509\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2967 - val_loss: 0.2505\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2962 - val_loss: 0.2502\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2957 - val_loss: 0.2498\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2952 - val_loss: 0.2494\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2948 - val_loss: 0.2491\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2943 - val_loss: 0.2487\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2938 - val_loss: 0.2484\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2933 - val_loss: 0.2480\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2929 - val_loss: 0.2477\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2924 - val_loss: 0.2473\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2920 - val_loss: 0.2470\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2915 - val_loss: 0.2467\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2911 - val_loss: 0.2463\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2907 - val_loss: 0.2460\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2902 - val_loss: 0.2457\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(50, 67), test_y.shape=(50, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 222.6692241509544, my average MASE = 77008768.33506098\n",
      "Cluster 8, 222.6692241509544\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=11, 11, 435, (11, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4436 - val_loss: 0.3307\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4426 - val_loss: 0.3306\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4417 - val_loss: 0.3306\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4408 - val_loss: 0.3305\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4398 - val_loss: 0.3305\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4389 - val_loss: 0.3304\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4380 - val_loss: 0.3303\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4371 - val_loss: 0.3303\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4362 - val_loss: 0.3302\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4354 - val_loss: 0.3301\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.3301\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4337 - val_loss: 0.3300\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4329 - val_loss: 0.3299\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4320 - val_loss: 0.3299\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4312 - val_loss: 0.3298\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4304 - val_loss: 0.3298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4296 - val_loss: 0.3297\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4288 - val_loss: 0.3296\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4280 - val_loss: 0.3295\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4273 - val_loss: 0.3295\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4265 - val_loss: 0.3294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4258 - val_loss: 0.3293\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4250 - val_loss: 0.3293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4243 - val_loss: 0.3292\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4235 - val_loss: 0.3291\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4228 - val_loss: 0.3291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4221 - val_loss: 0.3290\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4213 - val_loss: 0.3290\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.3289\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4199 - val_loss: 0.3288\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4191 - val_loss: 0.3288\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4184 - val_loss: 0.3287\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4177 - val_loss: 0.3287\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4170 - val_loss: 0.3286\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4163 - val_loss: 0.3286\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 0.3285\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4149 - val_loss: 0.3285\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4143 - val_loss: 0.3285\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4136 - val_loss: 0.3284\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4129 - val_loss: 0.3284\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 623.4242587364998, my average MASE = 13116998.58946489\n",
      "Cluster 0, 623.4242587364998\n",
      "Before prediction: train_X.shape=(18, 10, 67), train_y.shape=(18, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4512 - val_loss: 0.5917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4491 - val_loss: 0.5900\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4470 - val_loss: 0.5884\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4449 - val_loss: 0.5867\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4429 - val_loss: 0.5851\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4408 - val_loss: 0.5835\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.5818\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4369 - val_loss: 0.5802\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4349 - val_loss: 0.5786\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4330 - val_loss: 0.5770\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4311 - val_loss: 0.5755\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4293 - val_loss: 0.5739\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4275 - val_loss: 0.5724\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4257 - val_loss: 0.5709\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4239 - val_loss: 0.5694\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4222 - val_loss: 0.5680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4205 - val_loss: 0.5666\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4188 - val_loss: 0.5652\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4171 - val_loss: 0.5638\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4155 - val_loss: 0.5625\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4139 - val_loss: 0.5611\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4123 - val_loss: 0.5598\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4107 - val_loss: 0.5584\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4092 - val_loss: 0.5571\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4077 - val_loss: 0.5558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4062 - val_loss: 0.5545\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4047 - val_loss: 0.5532\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4032 - val_loss: 0.5519\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4017 - val_loss: 0.5506\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4003 - val_loss: 0.5494\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.5482\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5470\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3960 - val_loss: 0.5458\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.5446\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3933 - val_loss: 0.5435\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3920 - val_loss: 0.5424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3906 - val_loss: 0.5414\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3893 - val_loss: 0.5403\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3881 - val_loss: 0.5393\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3868 - val_loss: 0.5382\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1669347283.8471758, my average MASE = 4344504132.76493\n",
      "Cluster 1, 1669347283.8471758\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0678 - val_loss: 0.0460\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0618 - val_loss: 0.0427\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0585 - val_loss: 0.0404\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0561 - val_loss: 0.0385\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0542 - val_loss: 0.0369\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0527 - val_loss: 0.0355\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0514 - val_loss: 0.0344\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0503 - val_loss: 0.0335\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0327\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0321\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0315\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0473 - val_loss: 0.0310\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0468 - val_loss: 0.0306\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0463 - val_loss: 0.0302\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0458 - val_loss: 0.0299\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0454 - val_loss: 0.0296\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0293\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0447 - val_loss: 0.0291\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0444 - val_loss: 0.0289\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0442 - val_loss: 0.0287\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0439 - val_loss: 0.0285\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0283\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0434 - val_loss: 0.0281\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0430 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0427 - val_loss: 0.0276\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0423 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0419 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0266\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0415 - val_loss: 0.0265\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0264\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0263\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 811440996.3412759, my average MASE = 40052487777.48425\n",
      "Cluster 2, 811440996.3412759\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1986 - val_loss: 0.8095\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1967 - val_loss: 0.8095\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1948 - val_loss: 0.8095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1930 - val_loss: 0.8094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1912 - val_loss: 0.8094\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1894 - val_loss: 0.8094\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1876 - val_loss: 0.8094\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1858 - val_loss: 0.8094\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1840 - val_loss: 0.8094\n",
      "Epoch 9: early stopping\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 72.88641883174732, my average MASE = 50002377.286928184\n",
      "Cluster 3, 72.88641883174732\n",
      "Before prediction: train_X.shape=(87, 10, 67), train_y.shape=(87, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5691 - val_loss: 0.5072\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5682 - val_loss: 0.5068\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5674 - val_loss: 0.5063\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5666 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5659 - val_loss: 0.5055\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5651 - val_loss: 0.5051\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5643 - val_loss: 0.5047\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5636 - val_loss: 0.5042\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5628 - val_loss: 0.5038\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5621 - val_loss: 0.5034\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5614 - val_loss: 0.5030\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5606 - val_loss: 0.5026\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5600 - val_loss: 0.5022\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5592 - val_loss: 0.5018\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5586 - val_loss: 0.5014\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5579 - val_loss: 0.5011\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5572 - val_loss: 0.5007\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5565 - val_loss: 0.5003\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5558 - val_loss: 0.4999\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5552 - val_loss: 0.4996\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5545 - val_loss: 0.4993\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5539 - val_loss: 0.4989\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5532 - val_loss: 0.4986\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5526 - val_loss: 0.4983\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5520 - val_loss: 0.4979\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5513 - val_loss: 0.4976\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5507 - val_loss: 0.4973\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5501 - val_loss: 0.4970\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5495 - val_loss: 0.4967\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5489 - val_loss: 0.4964\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5483 - val_loss: 0.4961\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5477 - val_loss: 0.4958\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5471 - val_loss: 0.4956\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5465 - val_loss: 0.4953\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5459 - val_loss: 0.4950\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5453 - val_loss: 0.4947\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5447 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5442 - val_loss: 0.4942\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.4939\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5430 - val_loss: 0.4936\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 98.29689269118158, my average MASE = 78492579.83265808\n",
      "Cluster 4, 98.29689269118158\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4003 - val_loss: 0.3997\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3997 - val_loss: 0.3991\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3991 - val_loss: 0.3986\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3985 - val_loss: 0.3981\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3976\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3973 - val_loss: 0.3971\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3968 - val_loss: 0.3967\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3962\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3957 - val_loss: 0.3958\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3953\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3946 - val_loss: 0.3949\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3940 - val_loss: 0.3945\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3935 - val_loss: 0.3941\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3930 - val_loss: 0.3937\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3924 - val_loss: 0.3932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3919 - val_loss: 0.3928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3914 - val_loss: 0.3925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3904 - val_loss: 0.3917\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3899 - val_loss: 0.3913\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3894 - val_loss: 0.3909\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3889 - val_loss: 0.3906\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3884 - val_loss: 0.3902\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3879 - val_loss: 0.3898\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3870 - val_loss: 0.3891\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3865 - val_loss: 0.3887\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.3883\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3856 - val_loss: 0.3880\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3851 - val_loss: 0.3876\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3847 - val_loss: 0.3872\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3842 - val_loss: 0.3869\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3838 - val_loss: 0.3865\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3833 - val_loss: 0.3861\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3829 - val_loss: 0.3857\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3824 - val_loss: 0.3853\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 0.3850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3815 - val_loss: 0.3846\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3811 - val_loss: 0.3842\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3807 - val_loss: 0.3838\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 517837.8778283109, my average MASE = 16943290.739345513\n",
      "Cluster 6, 517837.8778283109\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2151 - val_loss: 0.4042\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2146 - val_loss: 0.4041\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2142 - val_loss: 0.4041\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2137 - val_loss: 0.4040\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2133 - val_loss: 0.4040\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2128 - val_loss: 0.4040\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2124 - val_loss: 0.4039\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2119 - val_loss: 0.4039\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2115 - val_loss: 0.4038\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2111 - val_loss: 0.4038\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2107 - val_loss: 0.4038\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2103 - val_loss: 0.4038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2099 - val_loss: 0.4037\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2096 - val_loss: 0.4037\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2092 - val_loss: 0.4037\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2088 - val_loss: 0.4036\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2084 - val_loss: 0.4036\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2081 - val_loss: 0.4036\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2077 - val_loss: 0.4035\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2074 - val_loss: 0.4035\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2070 - val_loss: 0.4035\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2067 - val_loss: 0.4035\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2063 - val_loss: 0.4035\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2060 - val_loss: 0.4034\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2057 - val_loss: 0.4034\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2054 - val_loss: 0.4034\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2050 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2047 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2044 - val_loss: 0.4033\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2041 - val_loss: 0.4033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2038 - val_loss: 0.4032\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2035 - val_loss: 0.4032\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2032 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2029 - val_loss: 0.4031\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2026 - val_loss: 0.4031\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2023 - val_loss: 0.4031\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2020 - val_loss: 0.4030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2017 - val_loss: 0.4030\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2014 - val_loss: 0.4029\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2011 - val_loss: 0.4029\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 181.01448499364625, my average MASE = 73613295.18701741\n",
      "Cluster 7, 181.01448499364625\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2941 - val_loss: 0.3652\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2932 - val_loss: 0.3650\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2923 - val_loss: 0.3648\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2914 - val_loss: 0.3646\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2905 - val_loss: 0.3644\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2897 - val_loss: 0.3641\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2888 - val_loss: 0.3639\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2880 - val_loss: 0.3638\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2872 - val_loss: 0.3636\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2864 - val_loss: 0.3634\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2856 - val_loss: 0.3632\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2848 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2840 - val_loss: 0.3629\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2832 - val_loss: 0.3628\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2824 - val_loss: 0.3626\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2817 - val_loss: 0.3625\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2809 - val_loss: 0.3624\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2802 - val_loss: 0.3622\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2794 - val_loss: 0.3621\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2787 - val_loss: 0.3620\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2780 - val_loss: 0.3619\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2772 - val_loss: 0.3618\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2765 - val_loss: 0.3617\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2758 - val_loss: 0.3616\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2751 - val_loss: 0.3615\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2744 - val_loss: 0.3615\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2738 - val_loss: 0.3614\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2731 - val_loss: 0.3613\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2725 - val_loss: 0.3613\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2718 - val_loss: 0.3612\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2712 - val_loss: 0.3612\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2705 - val_loss: 0.3611\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2699 - val_loss: 0.3611\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2693 - val_loss: 0.3610\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2687 - val_loss: 0.3610\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2681 - val_loss: 0.3610\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2675 - val_loss: 0.3609\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2669 - val_loss: 0.3609\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2663 - val_loss: 0.3608\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.3608\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 679.6913673037432, my average MASE = 68962615.13093176\n",
      "Cluster 9, 679.6913673037432\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=2, 2, 11, (10056, 67)\n",
      "Before prediction: train_X.shape=(6027, 10, 67), train_y.shape=(6027, 67), test_X.shape=(2009, 10, 67), test_y.shape=(2009, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0641 - val_loss: 0.0494\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0590 - val_loss: 0.0459\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0558 - val_loss: 0.0432\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0535 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0516 - val_loss: 0.0393\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0501 - val_loss: 0.0378\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0489 - val_loss: 0.0366\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0478 - val_loss: 0.0357\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0470 - val_loss: 0.0348\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0462 - val_loss: 0.0341\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0455 - val_loss: 0.0335\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0330\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0443 - val_loss: 0.0325\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0321\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0317\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0314\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0311\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0423 - val_loss: 0.0308\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0419 - val_loss: 0.0305\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0303\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0414 - val_loss: 0.0300\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0298\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0296\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0406 - val_loss: 0.0294\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0404 - val_loss: 0.0293\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0403 - val_loss: 0.0291\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0401 - val_loss: 0.0290\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0399 - val_loss: 0.0289\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0397 - val_loss: 0.0287\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0396 - val_loss: 0.0286\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0394 - val_loss: 0.0286\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0393 - val_loss: 0.0285\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0392 - val_loss: 0.0284\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0391 - val_loss: 0.0283\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0389 - val_loss: 0.0282\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0388 - val_loss: 0.0282\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0387 - val_loss: 0.0281\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0386 - val_loss: 0.0281\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0385 - val_loss: 0.0280\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0384 - val_loss: 0.0280\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2009, 67), test_y.shape=(2009, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 137177179.8661396, my average MASE = 15662264218.215044\n",
      "Cluster 0, 137177179.8661396\n",
      "Before prediction: train_X.shape=(18366, 10, 67), train_y.shape=(18366, 67), test_X.shape=(6122, 10, 67), test_y.shape=(6122, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3004 - val_loss: 0.3159\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2809 - val_loss: 0.3004\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2655 - val_loss: 0.2878\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2540 - val_loss: 0.2790\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2465 - val_loss: 0.2727\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2409 - val_loss: 0.2676\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2364 - val_loss: 0.2633\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2324 - val_loss: 0.2598\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2290 - val_loss: 0.2567\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2259 - val_loss: 0.2539\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2230 - val_loss: 0.2514\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2204 - val_loss: 0.2493\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2181 - val_loss: 0.2474\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2161 - val_loss: 0.2457\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2144 - val_loss: 0.2442\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2129 - val_loss: 0.2429\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2115 - val_loss: 0.2418\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2103 - val_loss: 0.2406\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2092 - val_loss: 0.2396\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2083 - val_loss: 0.2386\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2073 - val_loss: 0.2378\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2065 - val_loss: 0.2370\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2057 - val_loss: 0.2363\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2050 - val_loss: 0.2356\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2350\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2344\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2031 - val_loss: 0.2338\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2025 - val_loss: 0.2333\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2020 - val_loss: 0.2328\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2015 - val_loss: 0.2324\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2319\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2006 - val_loss: 0.2314\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2002 - val_loss: 0.2311\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1998 - val_loss: 0.2307\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.1994 - val_loss: 0.2304\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1991 - val_loss: 0.2301\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.1987 - val_loss: 0.2298\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1984 - val_loss: 0.2294\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1981 - val_loss: 0.2291\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1978 - val_loss: 0.2290\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6122, 67), test_y.shape=(6122, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1800.7465590842255, my average MASE = 3633.615501921918\n",
      "Cluster 1, 1800.7465590842255\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=5, 5, 58, (3715, 67)\n",
      "Before prediction: train_X.shape=(2222, 10, 67), train_y.shape=(2222, 67), test_X.shape=(741, 10, 67), test_y.shape=(741, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5001 - val_loss: 0.3691\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4918 - val_loss: 0.3651\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4851 - val_loss: 0.3618\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4795 - val_loss: 0.3589\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4744 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4699 - val_loss: 0.3539\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4657 - val_loss: 0.3517\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4618 - val_loss: 0.3497\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4582 - val_loss: 0.3478\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4548 - val_loss: 0.3460\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4516 - val_loss: 0.3443\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4485 - val_loss: 0.3427\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4455 - val_loss: 0.3412\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4426 - val_loss: 0.3398\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4398 - val_loss: 0.3384\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4370 - val_loss: 0.3370\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4342 - val_loss: 0.3357\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4315 - val_loss: 0.3345\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4289 - val_loss: 0.3332\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4263 - val_loss: 0.3321\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4237 - val_loss: 0.3309\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4213 - val_loss: 0.3298\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4189 - val_loss: 0.3287\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4166 - val_loss: 0.3277\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4143 - val_loss: 0.3266\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4120 - val_loss: 0.3256\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4099 - val_loss: 0.3247\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4079 - val_loss: 0.3238\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4059 - val_loss: 0.3230\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4040 - val_loss: 0.3222\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4022 - val_loss: 0.3214\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4005 - val_loss: 0.3206\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3988 - val_loss: 0.3199\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3972 - val_loss: 0.3193\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3956 - val_loss: 0.3186\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3941 - val_loss: 0.3180\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3927 - val_loss: 0.3175\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3912 - val_loss: 0.3169\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3899 - val_loss: 0.3163\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3885 - val_loss: 0.3158\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(741, 67), test_y.shape=(741, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 461.9721639366225, my average MASE = 1222.9207656733142\n",
      "Cluster 0, 461.9721639366225\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1169 - val_loss: 0.0965\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1118 - val_loss: 0.0947\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1077 - val_loss: 0.0935\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1043 - val_loss: 0.0926\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1013 - val_loss: 0.0919\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0987 - val_loss: 0.0913\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0964 - val_loss: 0.0909\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0942 - val_loss: 0.0906\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0923 - val_loss: 0.0904\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0901\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0890 - val_loss: 0.0899\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0875 - val_loss: 0.0897\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0861 - val_loss: 0.0895\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0849 - val_loss: 0.0894\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0837 - val_loss: 0.0892\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0826 - val_loss: 0.0891\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0816 - val_loss: 0.0889\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0807 - val_loss: 0.0888\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0798 - val_loss: 0.0886\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0790 - val_loss: 0.0885\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0782 - val_loss: 0.0884\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0883\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0881\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0761 - val_loss: 0.0880\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0755 - val_loss: 0.0879\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0749 - val_loss: 0.0878\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0743 - val_loss: 0.0877\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0738 - val_loss: 0.0876\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0732 - val_loss: 0.0875\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0727 - val_loss: 0.0875\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0722 - val_loss: 0.0874\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0718 - val_loss: 0.0874\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0713 - val_loss: 0.0874\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0873\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0705 - val_loss: 0.0873\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0873\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0872\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0695 - val_loss: 0.0872\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0689 - val_loss: 0.0871\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 979857680.8759673, my average MASE = 20246393999.460716\n",
      "Cluster 1, 979857680.8759673\n",
      "Before prediction: train_X.shape=(160, 10, 67), train_y.shape=(160, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5150 - val_loss: 0.4228\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5137 - val_loss: 0.4220\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5125 - val_loss: 0.4212\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5113 - val_loss: 0.4205\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5101 - val_loss: 0.4197\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5090 - val_loss: 0.4189\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5079 - val_loss: 0.4182\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5068 - val_loss: 0.4175\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5058 - val_loss: 0.4168\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4161\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5037 - val_loss: 0.4154\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5026 - val_loss: 0.4148\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5016 - val_loss: 0.4141\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5006 - val_loss: 0.4135\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4997 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4987 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4977 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4968 - val_loss: 0.4110\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4958 - val_loss: 0.4104\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4949 - val_loss: 0.4098\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4940 - val_loss: 0.4092\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4931 - val_loss: 0.4086\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4923 - val_loss: 0.4081\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4914 - val_loss: 0.4075\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4905 - val_loss: 0.4069\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4064\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4888 - val_loss: 0.4059\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4880 - val_loss: 0.4053\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4871 - val_loss: 0.4048\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4863 - val_loss: 0.4043\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4855 - val_loss: 0.4038\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4847 - val_loss: 0.4033\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4840 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4832 - val_loss: 0.4023\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4018\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4817 - val_loss: 0.4013\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4809 - val_loss: 0.4008\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4802 - val_loss: 0.4003\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4795 - val_loss: 0.3998\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4787 - val_loss: 0.3994\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.13783551729924, my average MASE = 51951538.633395046\n",
      "Cluster 2, 127.13783551729924\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8383 - val_loss: 0.5938\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8360 - val_loss: 0.5928\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8338 - val_loss: 0.5919\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8316 - val_loss: 0.5910\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8294 - val_loss: 0.5901\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8272 - val_loss: 0.5891\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8251 - val_loss: 0.5882\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 0.5873\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8208 - val_loss: 0.5864\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8187 - val_loss: 0.5855\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8167 - val_loss: 0.5847\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8146 - val_loss: 0.5838\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8126 - val_loss: 0.5830\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8107 - val_loss: 0.5821\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8087 - val_loss: 0.5812\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8068 - val_loss: 0.5803\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8048 - val_loss: 0.5794\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8029 - val_loss: 0.5786\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8009 - val_loss: 0.5777\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7989 - val_loss: 0.5768\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7970 - val_loss: 0.5760\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7951 - val_loss: 0.5751\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7932 - val_loss: 0.5743\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7913 - val_loss: 0.5735\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7894 - val_loss: 0.5727\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7875 - val_loss: 0.5720\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7857 - val_loss: 0.5712\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7839 - val_loss: 0.5704\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7820 - val_loss: 0.5697\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7802 - val_loss: 0.5690\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7784 - val_loss: 0.5682\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7767 - val_loss: 0.5675\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7749 - val_loss: 0.5668\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7732 - val_loss: 0.5661\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7715 - val_loss: 0.5655\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7698 - val_loss: 0.5648\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7681 - val_loss: 0.5641\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7664 - val_loss: 0.5635\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7647 - val_loss: 0.5629\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7630 - val_loss: 0.5623\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1378.9503839591846, my average MASE = 44152799.2879618\n",
      "Cluster 3, 1378.9503839591846\n",
      "Before prediction: train_X.shape=(44, 10, 67), train_y.shape=(44, 67), test_X.shape=(15, 10, 67), test_y.shape=(15, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5170 - val_loss: 0.7315\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5154 - val_loss: 0.7308\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.7300\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5122 - val_loss: 0.7293\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5107 - val_loss: 0.7285\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5092 - val_loss: 0.7278\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5077 - val_loss: 0.7271\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5062 - val_loss: 0.7264\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5047 - val_loss: 0.7257\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5033 - val_loss: 0.7250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5018 - val_loss: 0.7243\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.7236\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4990 - val_loss: 0.7229\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4977 - val_loss: 0.7222\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4963 - val_loss: 0.7215\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4949 - val_loss: 0.7209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4936 - val_loss: 0.7202\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4923 - val_loss: 0.7196\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4910 - val_loss: 0.7189\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4897 - val_loss: 0.7183\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4884 - val_loss: 0.7177\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.7170\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4859 - val_loss: 0.7164\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4847 - val_loss: 0.7158\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4835 - val_loss: 0.7152\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4823 - val_loss: 0.7146\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4811 - val_loss: 0.7140\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4799 - val_loss: 0.7135\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4788 - val_loss: 0.7129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4776 - val_loss: 0.7123\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4765 - val_loss: 0.7118\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4753 - val_loss: 0.7113\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4742 - val_loss: 0.7107\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4731 - val_loss: 0.7102\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4720 - val_loss: 0.7097\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4709 - val_loss: 0.7092\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4698 - val_loss: 0.7087\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4687 - val_loss: 0.7082\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.7077\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.7073\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(15, 67), test_y.shape=(15, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2846600473.0797715, my average MASE = 8256296780.299102\n",
      "Cluster 4, 2846600473.0797715\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=7, 7, 176, (267, 67)\n",
      "Before prediction: train_X.shape=(154, 10, 67), train_y.shape=(154, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3225 - val_loss: 0.2694\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3217 - val_loss: 0.2689\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3209 - val_loss: 0.2684\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3201 - val_loss: 0.2679\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3194 - val_loss: 0.2674\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3187 - val_loss: 0.2669\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3179 - val_loss: 0.2664\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3172 - val_loss: 0.2659\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3165 - val_loss: 0.2655\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3159 - val_loss: 0.2650\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3152 - val_loss: 0.2646\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3145 - val_loss: 0.2641\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3139 - val_loss: 0.2637\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3133 - val_loss: 0.2633\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3127 - val_loss: 0.2629\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3121 - val_loss: 0.2624\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3115 - val_loss: 0.2620\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3109 - val_loss: 0.2616\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3103 - val_loss: 0.2612\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3098 - val_loss: 0.2609\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3092 - val_loss: 0.2605\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3087 - val_loss: 0.2601\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3081 - val_loss: 0.2598\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3076 - val_loss: 0.2594\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3071 - val_loss: 0.2590\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3066 - val_loss: 0.2587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3061 - val_loss: 0.2584\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3056 - val_loss: 0.2580\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3051 - val_loss: 0.2576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3046 - val_loss: 0.2573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3041 - val_loss: 0.2569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3037 - val_loss: 0.2566\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3032 - val_loss: 0.2563\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3027 - val_loss: 0.2559\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3023 - val_loss: 0.2556\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3018 - val_loss: 0.2553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3013 - val_loss: 0.2550\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3009 - val_loss: 0.2546\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3005 - val_loss: 0.2543\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3000 - val_loss: 0.2540\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 173.3029589389659, my average MASE = 89033224.06135572\n",
      "Cluster 0, 173.3029589389659\n",
      "Before prediction: train_X.shape=(5960, 10, 67), train_y.shape=(5960, 67), test_X.shape=(1987, 10, 67), test_y.shape=(1987, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0675 - val_loss: 0.0464\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0617 - val_loss: 0.0432\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0584 - val_loss: 0.0410\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0560 - val_loss: 0.0393\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0541 - val_loss: 0.0377\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0525 - val_loss: 0.0364\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0512 - val_loss: 0.0353\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0501 - val_loss: 0.0343\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0492 - val_loss: 0.0335\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0484 - val_loss: 0.0327\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0477 - val_loss: 0.0321\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0471 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0466 - val_loss: 0.0310\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0461 - val_loss: 0.0306\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0457 - val_loss: 0.0302\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0453 - val_loss: 0.0299\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0449 - val_loss: 0.0296\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0445 - val_loss: 0.0293\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0442 - val_loss: 0.0291\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0288\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0286\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0284\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0432 - val_loss: 0.0282\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0424 - val_loss: 0.0275\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0421 - val_loss: 0.0272\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0420 - val_loss: 0.0271\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0419 - val_loss: 0.0270\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0417 - val_loss: 0.0269\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0268\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0413 - val_loss: 0.0265\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0412 - val_loss: 0.0264\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0409 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1987, 67), test_y.shape=(1987, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 783030752.0753396, my average MASE = 36192993113.38622\n",
      "Cluster 1, 783030752.0753396\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5458 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.3449\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.3440\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5391 - val_loss: 0.3431\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5369 - val_loss: 0.3422\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5348 - val_loss: 0.3413\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.3405\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5304 - val_loss: 0.3396\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5283 - val_loss: 0.3387\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5261 - val_loss: 0.3379\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5240 - val_loss: 0.3371\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5219 - val_loss: 0.3362\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5198 - val_loss: 0.3354\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5177 - val_loss: 0.3346\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5157 - val_loss: 0.3338\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5137 - val_loss: 0.3330\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5117 - val_loss: 0.3322\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5097 - val_loss: 0.3314\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5078 - val_loss: 0.3308\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5059 - val_loss: 0.3301\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5041 - val_loss: 0.3295\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5022 - val_loss: 0.3290\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.3284\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4986 - val_loss: 0.3279\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4968 - val_loss: 0.3274\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4951 - val_loss: 0.3269\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4933 - val_loss: 0.3264\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.3260\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4900 - val_loss: 0.3257\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4884 - val_loss: 0.3254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4868 - val_loss: 0.3251\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4852 - val_loss: 0.3249\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4836 - val_loss: 0.3247\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4821 - val_loss: 0.3245\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4805 - val_loss: 0.3244\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4790 - val_loss: 0.3242\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4775 - val_loss: 0.3241\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4760 - val_loss: 0.3240\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4745 - val_loss: 0.3239\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4730 - val_loss: 0.3238\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 300.2247881778862, my average MASE = 45822553.10580316\n",
      "Cluster 2, 300.2247881778862\n",
      "Before prediction: train_X.shape=(85, 10, 67), train_y.shape=(85, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3796 - val_loss: 0.4594\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3789 - val_loss: 0.4589\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3782 - val_loss: 0.4585\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4581\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3770 - val_loss: 0.4577\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3764 - val_loss: 0.4573\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.4569\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3753 - val_loss: 0.4565\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3748 - val_loss: 0.4561\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3737 - val_loss: 0.4554\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3732 - val_loss: 0.4550\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3727 - val_loss: 0.4547\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4543\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3717 - val_loss: 0.4540\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3713 - val_loss: 0.4537\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3708 - val_loss: 0.4533\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3703 - val_loss: 0.4530\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3699 - val_loss: 0.4527\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3694 - val_loss: 0.4524\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.4521\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3685 - val_loss: 0.4517\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3681 - val_loss: 0.4514\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3677 - val_loss: 0.4512\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3673 - val_loss: 0.4509\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3669 - val_loss: 0.4506\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3664 - val_loss: 0.4503\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4501\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3657 - val_loss: 0.4498\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3653 - val_loss: 0.4495\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3649 - val_loss: 0.4493\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3645 - val_loss: 0.4490\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3641 - val_loss: 0.4487\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.4485\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3634 - val_loss: 0.4482\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3630 - val_loss: 0.4480\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.4478\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3623 - val_loss: 0.4475\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.4473\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3616 - val_loss: 0.4470\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n",
      "average MASE = 329.8443195642471, my average MASE = 91063731.05477783\n",
      "Cluster 3, 329.8443195642471\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6262 - val_loss: 0.5214\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6239 - val_loss: 0.5202\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6216 - val_loss: 0.5190\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6193 - val_loss: 0.5179\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6170 - val_loss: 0.5167\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6148 - val_loss: 0.5156\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6125 - val_loss: 0.5145\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6102 - val_loss: 0.5134\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6080 - val_loss: 0.5123\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6058 - val_loss: 0.5112\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6036 - val_loss: 0.5101\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6015 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5994 - val_loss: 0.5080\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5973 - val_loss: 0.5070\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5953 - val_loss: 0.5060\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5932 - val_loss: 0.5051\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5912 - val_loss: 0.5041\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5892 - val_loss: 0.5032\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5872 - val_loss: 0.5023\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5853 - val_loss: 0.5015\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5834 - val_loss: 0.5006\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5816 - val_loss: 0.4999\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5799 - val_loss: 0.4991\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5782 - val_loss: 0.4984\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5765 - val_loss: 0.4977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5749 - val_loss: 0.4970\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5732 - val_loss: 0.4963\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5716 - val_loss: 0.4957\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5699 - val_loss: 0.4951\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5683 - val_loss: 0.4946\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5667 - val_loss: 0.4941\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5651 - val_loss: 0.4936\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5635 - val_loss: 0.4931\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5619 - val_loss: 0.4927\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5604 - val_loss: 0.4922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5588 - val_loss: 0.4917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5573 - val_loss: 0.4913\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5557 - val_loss: 0.4909\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5542 - val_loss: 0.4906\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5526 - val_loss: 0.4902\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32309710873507563, my average MASE = 0.5656513264705396\n",
      "Cluster 4, 0.32309710873507563\n",
      "Before prediction: train_X.shape=(43, 10, 67), train_y.shape=(43, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5119 - val_loss: 0.6850\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5101 - val_loss: 0.6839\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5083 - val_loss: 0.6829\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5066 - val_loss: 0.6819\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5048 - val_loss: 0.6808\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.6798\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5014 - val_loss: 0.6788\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.6778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4980 - val_loss: 0.6769\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4964 - val_loss: 0.6759\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4948 - val_loss: 0.6749\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4931 - val_loss: 0.6740\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4915 - val_loss: 0.6730\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4900 - val_loss: 0.6721\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4884 - val_loss: 0.6711\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4869 - val_loss: 0.6702\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4853 - val_loss: 0.6693\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4838 - val_loss: 0.6683\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6674\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4808 - val_loss: 0.6665\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.6656\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4779 - val_loss: 0.6647\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4765 - val_loss: 0.6639\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4751 - val_loss: 0.6630\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4737 - val_loss: 0.6622\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4723 - val_loss: 0.6613\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4710 - val_loss: 0.6605\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4697 - val_loss: 0.6596\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4683 - val_loss: 0.6588\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4670 - val_loss: 0.6580\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4657 - val_loss: 0.6572\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4644 - val_loss: 0.6564\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4631 - val_loss: 0.6556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4619 - val_loss: 0.6548\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4606 - val_loss: 0.6540\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4594 - val_loss: 0.6532\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4581 - val_loss: 0.6525\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4569 - val_loss: 0.6517\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4557 - val_loss: 0.6510\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4545 - val_loss: 0.6502\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2340337256.388025, my average MASE = 7806499481.251814\n",
      "Cluster 5, 2340337256.388025\n",
      "Before prediction: train_X.shape=(181, 10, 67), train_y.shape=(181, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6846 - val_loss: 0.5744\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6833 - val_loss: 0.5737\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6820 - val_loss: 0.5730\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6807 - val_loss: 0.5723\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6795 - val_loss: 0.5716\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6783 - val_loss: 0.5709\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6771 - val_loss: 0.5703\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6760 - val_loss: 0.5696\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6749 - val_loss: 0.5690\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6737 - val_loss: 0.5683\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6727 - val_loss: 0.5677\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6716 - val_loss: 0.5671\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6705 - val_loss: 0.5666\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6695 - val_loss: 0.5660\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6685 - val_loss: 0.5654\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6675 - val_loss: 0.5648\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6664 - val_loss: 0.5643\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6654 - val_loss: 0.5637\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6645 - val_loss: 0.5632\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6635 - val_loss: 0.5626\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6626 - val_loss: 0.5621\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.6616 - val_loss: 0.5615\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6607 - val_loss: 0.5610\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6597 - val_loss: 0.5605\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6588 - val_loss: 0.5600\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6579 - val_loss: 0.5594\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6570 - val_loss: 0.5589\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6561 - val_loss: 0.5584\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6553 - val_loss: 0.5579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6544 - val_loss: 0.5574\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6536 - val_loss: 0.5569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6527 - val_loss: 0.5563\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6519 - val_loss: 0.5558\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6510 - val_loss: 0.5553\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6502 - val_loss: 0.5548\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6493 - val_loss: 0.5543\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6485 - val_loss: 0.5538\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6477 - val_loss: 0.5533\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6468 - val_loss: 0.5528\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6460 - val_loss: 0.5523\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 153.88341287865387, my average MASE = 335532064.75560737\n",
      "Cluster 6, 153.88341287865387\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=9, 9, 3, (61, 67)\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5800 - val_loss: 0.4525\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5784 - val_loss: 0.4515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5768 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5753 - val_loss: 0.4496\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5738 - val_loss: 0.4487\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5722 - val_loss: 0.4477\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5707 - val_loss: 0.4468\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5692 - val_loss: 0.4459\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5678 - val_loss: 0.4450\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5663 - val_loss: 0.4441\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5648 - val_loss: 0.4433\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5634 - val_loss: 0.4424\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5619 - val_loss: 0.4415\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5605 - val_loss: 0.4407\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5590 - val_loss: 0.4398\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5576 - val_loss: 0.4390\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5562 - val_loss: 0.4382\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5548 - val_loss: 0.4374\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5534 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5520 - val_loss: 0.4359\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5507 - val_loss: 0.4352\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5493 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5480 - val_loss: 0.4337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5467 - val_loss: 0.4329\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 0.4322\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5441 - val_loss: 0.4315\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5428 - val_loss: 0.4308\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5415 - val_loss: 0.4301\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5403 - val_loss: 0.4294\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5390 - val_loss: 0.4287\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5378 - val_loss: 0.4280\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5366 - val_loss: 0.4273\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5354 - val_loss: 0.4266\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5342 - val_loss: 0.4260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5330 - val_loss: 0.4253\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5318 - val_loss: 0.4246\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5307 - val_loss: 0.4240\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5295 - val_loss: 0.4234\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5284 - val_loss: 0.4227\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5273 - val_loss: 0.4221\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 35650627.66244785, my average MASE = 4899168813.139491\n",
      "Cluster 0, 35650627.66244785\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7142 - val_loss: 0.5624\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7129 - val_loss: 0.5618\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7116 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7104 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7092 - val_loss: 0.5599\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7080 - val_loss: 0.5593\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7069 - val_loss: 0.5588\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7057 - val_loss: 0.5582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7046 - val_loss: 0.5576\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7035 - val_loss: 0.5571\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5565\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7013 - val_loss: 0.5560\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7002 - val_loss: 0.5555\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6993 - val_loss: 0.5550\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6982 - val_loss: 0.5545\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6972 - val_loss: 0.5540\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5535\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6952 - val_loss: 0.5530\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6942 - val_loss: 0.5525\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6932 - val_loss: 0.5520\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5516\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6913 - val_loss: 0.5511\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6903 - val_loss: 0.5506\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6894 - val_loss: 0.5502\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6885 - val_loss: 0.5498\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6875 - val_loss: 0.5493\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6866 - val_loss: 0.5489\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6857 - val_loss: 0.5485\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6848 - val_loss: 0.5481\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6839 - val_loss: 0.5477\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6830 - val_loss: 0.5472\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6821 - val_loss: 0.5468\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6812 - val_loss: 0.5464\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6803 - val_loss: 0.5460\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6794 - val_loss: 0.5456\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.5452\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6777 - val_loss: 0.5449\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6768 - val_loss: 0.5445\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6759 - val_loss: 0.5441\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6751 - val_loss: 0.5437\n",
      "2/2 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n",
      "average MASE = 167.81473432422789, my average MASE = 220460085.3598021\n",
      "Cluster 1, 167.81473432422789\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4267 - val_loss: 0.6677\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4246 - val_loss: 0.6662\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4226 - val_loss: 0.6647\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4205 - val_loss: 0.6632\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.6618\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4166 - val_loss: 0.6605\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4146 - val_loss: 0.6592\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4127 - val_loss: 0.6578\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4107 - val_loss: 0.6565\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4088 - val_loss: 0.6552\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4070 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4051 - val_loss: 0.6527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4033 - val_loss: 0.6514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4014 - val_loss: 0.6502\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3997 - val_loss: 0.6490\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3979 - val_loss: 0.6478\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3961 - val_loss: 0.6466\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3944 - val_loss: 0.6455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3927 - val_loss: 0.6444\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3910 - val_loss: 0.6433\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3893 - val_loss: 0.6423\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3877 - val_loss: 0.6412\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3861 - val_loss: 0.6402\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3845 - val_loss: 0.6392\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3829 - val_loss: 0.6383\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3814 - val_loss: 0.6374\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3799 - val_loss: 0.6364\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3784 - val_loss: 0.6356\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3769 - val_loss: 0.6347\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3754 - val_loss: 0.6338\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3740 - val_loss: 0.6330\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3725 - val_loss: 0.6322\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3711 - val_loss: 0.6314\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3697 - val_loss: 0.6305\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3683 - val_loss: 0.6297\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3669 - val_loss: 0.6289\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.6281\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3642 - val_loss: 0.6273\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3629 - val_loss: 0.6264\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3616 - val_loss: 0.6256\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1967377505.4498963, my average MASE = 5262000054.755049\n",
      "Cluster 2, 1967377505.4498963\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6328 - val_loss: 0.7373\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6300 - val_loss: 0.7359\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6272 - val_loss: 0.7344\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6245 - val_loss: 0.7330\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6218 - val_loss: 0.7316\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6191 - val_loss: 0.7301\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6164 - val_loss: 0.7287\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6137 - val_loss: 0.7273\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6111 - val_loss: 0.7259\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6085 - val_loss: 0.7245\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6058 - val_loss: 0.7230\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6033 - val_loss: 0.7216\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6009 - val_loss: 0.7202\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5985 - val_loss: 0.7188\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5961 - val_loss: 0.7174\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5938 - val_loss: 0.7159\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5915 - val_loss: 0.7146\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5892 - val_loss: 0.7133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5869 - val_loss: 0.7119\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5847 - val_loss: 0.7106\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5825 - val_loss: 0.7092\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5803 - val_loss: 0.7078\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5781 - val_loss: 0.7064\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5759 - val_loss: 0.7050\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5738 - val_loss: 0.7036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5716 - val_loss: 0.7022\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5695 - val_loss: 0.7009\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5674 - val_loss: 0.6996\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5653 - val_loss: 0.6983\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5632 - val_loss: 0.6971\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5611 - val_loss: 0.6959\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5590 - val_loss: 0.6946\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5569 - val_loss: 0.6934\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5549 - val_loss: 0.6922\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5528 - val_loss: 0.6910\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5509 - val_loss: 0.6898\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5490 - val_loss: 0.6886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5472 - val_loss: 0.6874\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5454 - val_loss: 0.6862\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.6850\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.27232041656941225, my average MASE = 0.501167640234202\n",
      "Cluster 3, 0.27232041656941225\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4602 - val_loss: 0.3734\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4580 - val_loss: 0.3723\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4558 - val_loss: 0.3714\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4536 - val_loss: 0.3704\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4515 - val_loss: 0.3694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4494 - val_loss: 0.3685\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4474 - val_loss: 0.3675\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4454 - val_loss: 0.3666\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4435 - val_loss: 0.3657\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4416 - val_loss: 0.3648\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4397 - val_loss: 0.3640\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4379 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4361 - val_loss: 0.3623\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4344 - val_loss: 0.3616\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4328 - val_loss: 0.3608\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4312 - val_loss: 0.3601\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4296 - val_loss: 0.3594\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4279 - val_loss: 0.3587\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4263 - val_loss: 0.3581\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4247 - val_loss: 0.3575\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4231 - val_loss: 0.3569\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.3564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4200 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4184 - val_loss: 0.3553\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4169 - val_loss: 0.3547\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4154 - val_loss: 0.3542\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4138 - val_loss: 0.3537\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4123 - val_loss: 0.3533\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4109 - val_loss: 0.3528\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4094 - val_loss: 0.3524\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4080 - val_loss: 0.3520\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4066 - val_loss: 0.3516\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4053 - val_loss: 0.3512\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4039 - val_loss: 0.3508\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4026 - val_loss: 0.3505\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4000 - val_loss: 0.3498\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3987 - val_loss: 0.3495\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3974 - val_loss: 0.3492\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3490\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 363.8540679781247, my average MASE = 17706113.36217601\n",
      "Cluster 4, 363.8540679781247\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4172 - val_loss: 0.5128\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4165 - val_loss: 0.5124\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4158 - val_loss: 0.5121\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4151 - val_loss: 0.5117\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.5113\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4139 - val_loss: 0.5110\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4132 - val_loss: 0.5107\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4126 - val_loss: 0.5103\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4120 - val_loss: 0.5100\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4114 - val_loss: 0.5096\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4108 - val_loss: 0.5093\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4102 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4097 - val_loss: 0.5086\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4091 - val_loss: 0.5083\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4085 - val_loss: 0.5080\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4080 - val_loss: 0.5077\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.5074\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4069 - val_loss: 0.5071\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4064 - val_loss: 0.5068\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4059 - val_loss: 0.5065\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.5062\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4048 - val_loss: 0.5059\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4043 - val_loss: 0.5056\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4038 - val_loss: 0.5053\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.5051\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4029 - val_loss: 0.5048\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4019 - val_loss: 0.5042\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4014 - val_loss: 0.5039\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4010 - val_loss: 0.5036\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4005 - val_loss: 0.5033\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4000 - val_loss: 0.5030\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3996 - val_loss: 0.5028\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3991 - val_loss: 0.5025\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3987 - val_loss: 0.5022\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3983 - val_loss: 0.5019\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3978 - val_loss: 0.5016\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5013\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3969 - val_loss: 0.5011\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3965 - val_loss: 0.5008\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 210.04101539413423, my average MASE = 60624707.44207928\n",
      "Cluster 5, 210.04101539413423\n",
      "Before prediction: train_X.shape=(104, 10, 67), train_y.shape=(104, 67), test_X.shape=(35, 10, 67), test_y.shape=(35, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3090 - val_loss: 0.2755\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3084 - val_loss: 0.2752\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3078 - val_loss: 0.2749\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3072 - val_loss: 0.2745\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3066 - val_loss: 0.2742\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3061 - val_loss: 0.2739\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3055 - val_loss: 0.2736\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3049 - val_loss: 0.2733\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3044 - val_loss: 0.2730\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3039 - val_loss: 0.2727\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.2724\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3028 - val_loss: 0.2722\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.2719\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3018 - val_loss: 0.2716\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3013 - val_loss: 0.2713\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3008 - val_loss: 0.2711\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3003 - val_loss: 0.2708\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2998 - val_loss: 0.2705\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2994 - val_loss: 0.2703\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2989 - val_loss: 0.2700\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2984 - val_loss: 0.2698\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2980 - val_loss: 0.2695\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2975 - val_loss: 0.2693\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2971 - val_loss: 0.2690\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2966 - val_loss: 0.2688\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2962 - val_loss: 0.2686\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2958 - val_loss: 0.2683\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2953 - val_loss: 0.2681\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2949 - val_loss: 0.2678\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2945 - val_loss: 0.2676\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2941 - val_loss: 0.2674\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2937 - val_loss: 0.2671\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2933 - val_loss: 0.2669\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2929 - val_loss: 0.2667\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2925 - val_loss: 0.2664\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2921 - val_loss: 0.2662\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2917 - val_loss: 0.2660\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2913 - val_loss: 0.2658\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2909 - val_loss: 0.2656\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2906 - val_loss: 0.2654\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(35, 67), test_y.shape=(35, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 554.2347835476104, my average MASE = 43885073.200175166\n",
      "Cluster 6, 554.2347835476104\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6507 - val_loss: 0.5207\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6481 - val_loss: 0.5200\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6456 - val_loss: 0.5192\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6431 - val_loss: 0.5184\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6407 - val_loss: 0.5176\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6383 - val_loss: 0.5169\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6360 - val_loss: 0.5161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6338 - val_loss: 0.5154\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6316 - val_loss: 0.5147\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6293 - val_loss: 0.5140\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6271 - val_loss: 0.5133\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6249 - val_loss: 0.5126\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6227 - val_loss: 0.5119\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6206 - val_loss: 0.5112\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6185 - val_loss: 0.5105\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6164 - val_loss: 0.5099\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6145 - val_loss: 0.5093\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6125 - val_loss: 0.5087\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6107 - val_loss: 0.5082\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6088 - val_loss: 0.5076\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6069 - val_loss: 0.5071\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6051 - val_loss: 0.5067\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6032 - val_loss: 0.5062\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6014 - val_loss: 0.5058\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5996 - val_loss: 0.5053\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5978 - val_loss: 0.5049\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5959 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5941 - val_loss: 0.5040\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5923 - val_loss: 0.5036\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5905 - val_loss: 0.5033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5888 - val_loss: 0.5030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5871 - val_loss: 0.5027\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5853 - val_loss: 0.5024\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5837 - val_loss: 0.5021\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5822 - val_loss: 0.5017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5806 - val_loss: 0.5014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5791 - val_loss: 0.5011\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5775 - val_loss: 0.5009\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5760 - val_loss: 0.5006\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5745 - val_loss: 0.5004\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2390672605525707, my average MASE = 0.4689912396588464\n",
      "Cluster 7, 0.2390672605525707\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1191 - val_loss: 0.0992\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1138 - val_loss: 0.0972\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1096 - val_loss: 0.0959\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1060 - val_loss: 0.0949\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1029 - val_loss: 0.0942\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1002 - val_loss: 0.0935\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0977 - val_loss: 0.0930\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0955 - val_loss: 0.0925\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0916 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0899 - val_loss: 0.0913\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0884 - val_loss: 0.0909\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0870 - val_loss: 0.0906\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0856 - val_loss: 0.0903\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0844 - val_loss: 0.0900\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0833 - val_loss: 0.0898\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0896\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0812 - val_loss: 0.0894\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0803 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0778 - val_loss: 0.0887\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0771 - val_loss: 0.0886\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0764 - val_loss: 0.0885\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0757 - val_loss: 0.0884\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0751 - val_loss: 0.0883\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0745 - val_loss: 0.0882\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0739 - val_loss: 0.0881\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0880\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0879\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0723 - val_loss: 0.0879\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0878\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0877\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0711 - val_loss: 0.0876\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0707 - val_loss: 0.0876\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0703 - val_loss: 0.0875\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0700 - val_loss: 0.0874\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0873\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0694 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 1385618831.00148, my average MASE = 22365614226.60064\n",
      "Cluster 8, 1385618831.00148\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=11, 11, 68, (49, 67)\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5560 - val_loss: 0.4967\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5553 - val_loss: 0.4965\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5546 - val_loss: 0.4963\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5538 - val_loss: 0.4961\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5531 - val_loss: 0.4960\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5524 - val_loss: 0.4958\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5517 - val_loss: 0.4956\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5510 - val_loss: 0.4955\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5503 - val_loss: 0.4953\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5496 - val_loss: 0.4952\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5489 - val_loss: 0.4950\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 0.4949\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5476 - val_loss: 0.4947\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5469 - val_loss: 0.4946\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5463 - val_loss: 0.4945\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5456 - val_loss: 0.4943\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5450 - val_loss: 0.4942\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5443 - val_loss: 0.4940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5437 - val_loss: 0.4939\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5431 - val_loss: 0.4938\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5425 - val_loss: 0.4936\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5419 - val_loss: 0.4935\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.4934\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5407 - val_loss: 0.4933\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5401 - val_loss: 0.4932\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5395 - val_loss: 0.4930\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5389 - val_loss: 0.4929\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5384 - val_loss: 0.4928\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5378 - val_loss: 0.4927\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5372 - val_loss: 0.4926\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5367 - val_loss: 0.4925\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 0.4923\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5356 - val_loss: 0.4922\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5351 - val_loss: 0.4921\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5345 - val_loss: 0.4920\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5340 - val_loss: 0.4919\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5335 - val_loss: 0.4918\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5329 - val_loss: 0.4917\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5324 - val_loss: 0.4915\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5319 - val_loss: 0.4914\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 62.874751666083846, my average MASE = 63681940.89448814\n",
      "Cluster 0, 62.874751666083846\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3794 - val_loss: 0.4534\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3770 - val_loss: 0.4520\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3747 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3724 - val_loss: 0.4494\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3701 - val_loss: 0.4481\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3678 - val_loss: 0.4468\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.4455\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3634 - val_loss: 0.4443\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3612 - val_loss: 0.4430\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3591 - val_loss: 0.4418\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3571 - val_loss: 0.4406\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3551 - val_loss: 0.4394\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3531 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3511 - val_loss: 0.4371\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3492 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3473 - val_loss: 0.4348\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3454 - val_loss: 0.4337\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3436 - val_loss: 0.4326\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3418 - val_loss: 0.4315\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3400 - val_loss: 0.4305\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3382 - val_loss: 0.4294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3365 - val_loss: 0.4284\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3349 - val_loss: 0.4273\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3332 - val_loss: 0.4263\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3316 - val_loss: 0.4253\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3300 - val_loss: 0.4243\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.4233\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3269 - val_loss: 0.4224\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3254 - val_loss: 0.4214\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.4205\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3224 - val_loss: 0.4196\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.4186\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3195 - val_loss: 0.4177\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3181 - val_loss: 0.4168\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3166 - val_loss: 0.4159\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3153 - val_loss: 0.4151\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3139 - val_loss: 0.4142\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3125 - val_loss: 0.4134\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3112 - val_loss: 0.4125\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3098 - val_loss: 0.4117\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1188796320.3185039, my average MASE = 2779981174.701244\n",
      "Cluster 1, 1188796320.3185039\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6283 - val_loss: 0.6105\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6261 - val_loss: 0.6091\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6239 - val_loss: 0.6076\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6218 - val_loss: 0.6062\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6196 - val_loss: 0.6047\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6175 - val_loss: 0.6033\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6153 - val_loss: 0.6018\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6132 - val_loss: 0.6004\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6110 - val_loss: 0.5990\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6089 - val_loss: 0.5976\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6067 - val_loss: 0.5961\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6046 - val_loss: 0.5947\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6026 - val_loss: 0.5933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6005 - val_loss: 0.5919\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5985 - val_loss: 0.5905\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5964 - val_loss: 0.5891\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5944 - val_loss: 0.5877\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5923 - val_loss: 0.5866\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5903 - val_loss: 0.5854\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5882 - val_loss: 0.5842\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5861 - val_loss: 0.5831\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5841 - val_loss: 0.5819\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5820 - val_loss: 0.5808\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5799 - val_loss: 0.5796\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5778 - val_loss: 0.5784\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5758 - val_loss: 0.5773\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5737 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5717 - val_loss: 0.5751\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5697 - val_loss: 0.5740\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5676 - val_loss: 0.5731\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5656 - val_loss: 0.5721\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5636 - val_loss: 0.5712\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5616 - val_loss: 0.5703\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5597 - val_loss: 0.5694\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5577 - val_loss: 0.5686\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5558 - val_loss: 0.5678\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5538 - val_loss: 0.5670\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5519 - val_loss: 0.5663\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5499 - val_loss: 0.5655\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5480 - val_loss: 0.5647\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32481366416229096, my average MASE = 0.6312112420260654\n",
      "Cluster 2, 0.32481366416229096\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4564 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4555 - val_loss: 0.4793\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4547 - val_loss: 0.4791\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4538 - val_loss: 0.4788\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4529 - val_loss: 0.4786\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4521 - val_loss: 0.4783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4512 - val_loss: 0.4781\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4504 - val_loss: 0.4778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4496 - val_loss: 0.4776\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4487 - val_loss: 0.4773\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4479 - val_loss: 0.4771\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4471 - val_loss: 0.4768\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4463 - val_loss: 0.4766\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4455 - val_loss: 0.4763\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4447 - val_loss: 0.4760\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4439 - val_loss: 0.4758\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4431 - val_loss: 0.4755\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4423 - val_loss: 0.4753\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4415 - val_loss: 0.4750\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4407 - val_loss: 0.4747\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4400 - val_loss: 0.4745\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4742\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4385 - val_loss: 0.4739\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4377 - val_loss: 0.4736\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4370 - val_loss: 0.4733\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4362 - val_loss: 0.4730\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4355 - val_loss: 0.4727\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4724\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4341 - val_loss: 0.4721\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4334 - val_loss: 0.4717\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4327 - val_loss: 0.4714\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4320 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4313 - val_loss: 0.4708\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4307 - val_loss: 0.4705\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4300 - val_loss: 0.4701\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4293 - val_loss: 0.4698\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4286 - val_loss: 0.4694\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4280 - val_loss: 0.4691\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4273 - val_loss: 0.4688\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4266 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1418783.6078857174, my average MASE = 35875462.94910899\n",
      "Cluster 3, 1418783.6078857174\n",
      "Before prediction: train_X.shape=(27, 10, 67), train_y.shape=(27, 67), test_X.shape=(9, 10, 67), test_y.shape=(9, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3810 - val_loss: 0.3926\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3805 - val_loss: 0.3924\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3799 - val_loss: 0.3923\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3794 - val_loss: 0.3921\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3789 - val_loss: 0.3920\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3784 - val_loss: 0.3918\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3779 - val_loss: 0.3917\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3774 - val_loss: 0.3916\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3769 - val_loss: 0.3914\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3764 - val_loss: 0.3913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3759 - val_loss: 0.3911\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3754 - val_loss: 0.3910\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3749 - val_loss: 0.3909\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3744 - val_loss: 0.3907\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3739 - val_loss: 0.3906\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3734 - val_loss: 0.3905\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3729 - val_loss: 0.3903\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3725 - val_loss: 0.3902\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3720 - val_loss: 0.3901\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3715 - val_loss: 0.3900\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3711 - val_loss: 0.3899\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3706 - val_loss: 0.3898\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3701 - val_loss: 0.3896\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3697 - val_loss: 0.3895\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3692 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3688 - val_loss: 0.3893\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3683 - val_loss: 0.3892\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3679 - val_loss: 0.3891\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3674 - val_loss: 0.3890\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3670 - val_loss: 0.3889\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3666 - val_loss: 0.3888\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3661 - val_loss: 0.3887\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3657 - val_loss: 0.3886\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3653 - val_loss: 0.3885\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3648 - val_loss: 0.3884\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3644 - val_loss: 0.3883\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3640 - val_loss: 0.3882\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3636 - val_loss: 0.3881\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3632 - val_loss: 0.3880\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3627 - val_loss: 0.3879\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(9, 67), test_y.shape=(9, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 73.99923698083529, my average MASE = 28273926.299095076\n",
      "Cluster 4, 73.99923698083529\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1188 - val_loss: 0.0994\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1133 - val_loss: 0.0973\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1090 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1053 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1021 - val_loss: 0.0936\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0993 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0969 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0946 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0893 - val_loss: 0.0908\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0878 - val_loss: 0.0906\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0864 - val_loss: 0.0903\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0852 - val_loss: 0.0901\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0841 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0830 - val_loss: 0.0897\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0820 - val_loss: 0.0895\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0811 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0802 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0888\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0772 - val_loss: 0.0887\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0886\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0759 - val_loss: 0.0885\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0753 - val_loss: 0.0884\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0747 - val_loss: 0.0884\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0742 - val_loss: 0.0883\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0737 - val_loss: 0.0882\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0881\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0881\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0724 - val_loss: 0.0880\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0720 - val_loss: 0.0880\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0716 - val_loss: 0.0879\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0879\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0879\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0878\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0877\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0699 - val_loss: 0.0877\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0877\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 772933595.2163092, my average MASE = 33112652144.926693\n",
      "Cluster 5, 772933595.2163092\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6742 - val_loss: 0.5426\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6711 - val_loss: 0.5410\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6680 - val_loss: 0.5395\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6649 - val_loss: 0.5381\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6619 - val_loss: 0.5366\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6589 - val_loss: 0.5352\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6560 - val_loss: 0.5338\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6532 - val_loss: 0.5324\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6503 - val_loss: 0.5310\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6475 - val_loss: 0.5296\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6447 - val_loss: 0.5282\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6420 - val_loss: 0.5269\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6393 - val_loss: 0.5255\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6367 - val_loss: 0.5242\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6340 - val_loss: 0.5229\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6314 - val_loss: 0.5216\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6289 - val_loss: 0.5203\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6264 - val_loss: 0.5190\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6240 - val_loss: 0.5178\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6215 - val_loss: 0.5165\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6191 - val_loss: 0.5153\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6168 - val_loss: 0.5141\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6145 - val_loss: 0.5128\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6122 - val_loss: 0.5115\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6098 - val_loss: 0.5102\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6076 - val_loss: 0.5089\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6054 - val_loss: 0.5076\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6033 - val_loss: 0.5062\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6011 - val_loss: 0.5049\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5989 - val_loss: 0.5035\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5968 - val_loss: 0.5022\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5947 - val_loss: 0.5009\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5928 - val_loss: 0.4996\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5908 - val_loss: 0.4982\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5889 - val_loss: 0.4969\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5869 - val_loss: 0.4956\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5850 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5831 - val_loss: 0.4932\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5812 - val_loss: 0.4921\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5794 - val_loss: 0.4911\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.24234404135098125, my average MASE = 0.42071116848846357\n",
      "Cluster 6, 0.24234404135098125\n",
      "Before prediction: train_X.shape=(50, 10, 67), train_y.shape=(50, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4441 - val_loss: 0.4379\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4435 - val_loss: 0.4378\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4430 - val_loss: 0.4376\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4425 - val_loss: 0.4374\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4372\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4414 - val_loss: 0.4371\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4409 - val_loss: 0.4369\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4404 - val_loss: 0.4367\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4398 - val_loss: 0.4366\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4364\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.4362\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4383 - val_loss: 0.4361\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4378 - val_loss: 0.4359\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4373 - val_loss: 0.4357\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4368 - val_loss: 0.4356\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4363 - val_loss: 0.4354\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4358 - val_loss: 0.4352\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4353 - val_loss: 0.4351\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4348 - val_loss: 0.4349\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4343 - val_loss: 0.4348\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4339 - val_loss: 0.4346\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4334 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4329 - val_loss: 0.4343\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4341\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4320 - val_loss: 0.4340\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4315 - val_loss: 0.4338\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4310 - val_loss: 0.4337\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4306 - val_loss: 0.4335\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4301 - val_loss: 0.4334\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4296 - val_loss: 0.4332\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4292 - val_loss: 0.4331\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4287 - val_loss: 0.4329\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4283 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4278 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4274 - val_loss: 0.4325\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4269 - val_loss: 0.4323\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4265 - val_loss: 0.4322\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4261 - val_loss: 0.4320\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4256 - val_loss: 0.4319\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4252 - val_loss: 0.4317\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 191.2474349797922, my average MASE = 74799483.45709221\n",
      "Cluster 7, 191.2474349797922\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2212 - val_loss: 0.1239\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2202 - val_loss: 0.1236\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2192 - val_loss: 0.1233\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2183 - val_loss: 0.1230\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2174 - val_loss: 0.1228\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2165 - val_loss: 0.1225\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2156 - val_loss: 0.1223\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2147 - val_loss: 0.1221\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2138 - val_loss: 0.1219\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2129 - val_loss: 0.1217\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2120 - val_loss: 0.1215\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2111 - val_loss: 0.1213\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2102 - val_loss: 0.1212\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2093 - val_loss: 0.1211\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2085 - val_loss: 0.1210\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2076 - val_loss: 0.1209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2068 - val_loss: 0.1208\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2059 - val_loss: 0.1207\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2051 - val_loss: 0.1207\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2042 - val_loss: 0.1206\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2034 - val_loss: 0.1206\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2026 - val_loss: 0.1205\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2018 - val_loss: 0.1204\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2010 - val_loss: 0.1204\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2002 - val_loss: 0.1203\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1995 - val_loss: 0.1203\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1987 - val_loss: 0.1203\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1980 - val_loss: 0.1203\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1973 - val_loss: 0.1203\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1965 - val_loss: 0.1203\n",
      "Epoch 30: early stopping\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.15391611936993946, my average MASE = 0.29566028544300293\n",
      "Cluster 8, 0.15391611936993946\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5076 - val_loss: 0.4286\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5055 - val_loss: 0.4276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5036 - val_loss: 0.4266\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5017 - val_loss: 0.4256\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4998 - val_loss: 0.4246\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4980 - val_loss: 0.4236\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4962 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4944 - val_loss: 0.4217\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4926 - val_loss: 0.4208\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4908 - val_loss: 0.4199\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4890 - val_loss: 0.4191\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4871 - val_loss: 0.4182\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4853 - val_loss: 0.4173\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4835 - val_loss: 0.4164\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4817 - val_loss: 0.4156\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4148\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4782 - val_loss: 0.4140\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4765 - val_loss: 0.4133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4749 - val_loss: 0.4126\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4732 - val_loss: 0.4118\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4717 - val_loss: 0.4111\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4701 - val_loss: 0.4104\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4686 - val_loss: 0.4097\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4671 - val_loss: 0.4089\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4656 - val_loss: 0.4082\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4641 - val_loss: 0.4075\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4627 - val_loss: 0.4068\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4613 - val_loss: 0.4061\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4600 - val_loss: 0.4054\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4587 - val_loss: 0.4048\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4573 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4560 - val_loss: 0.4036\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4546 - val_loss: 0.4030\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4533 - val_loss: 0.4025\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4520 - val_loss: 0.4019\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4506 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4493 - val_loss: 0.4009\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4480 - val_loss: 0.4004\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.3999\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4454 - val_loss: 0.3994\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2425229695624874, my average MASE = 0.5232189989788755\n",
      "Cluster 9, 0.2425229695624874\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4116 - val_loss: 0.3522\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4095 - val_loss: 0.3515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.3508\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4055 - val_loss: 0.3501\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3494\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4016 - val_loss: 0.3488\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3996 - val_loss: 0.3481\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3977 - val_loss: 0.3475\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3920 - val_loss: 0.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3902 - val_loss: 0.3450\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3884 - val_loss: 0.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3865 - val_loss: 0.3439\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3847 - val_loss: 0.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3829 - val_loss: 0.3430\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3811 - val_loss: 0.3425\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3793 - val_loss: 0.3420\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3776 - val_loss: 0.3416\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3759 - val_loss: 0.3411\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3742 - val_loss: 0.3407\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3725 - val_loss: 0.3402\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3708 - val_loss: 0.3398\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3692 - val_loss: 0.3394\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3675 - val_loss: 0.3390\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3659 - val_loss: 0.3386\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3644 - val_loss: 0.3382\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3628 - val_loss: 0.3379\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3376\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3597 - val_loss: 0.3373\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3583 - val_loss: 0.3370\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3568 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3554 - val_loss: 0.3364\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3540 - val_loss: 0.3361\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3526 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3512 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3498 - val_loss: 0.3352\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3484 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3471 - val_loss: 0.3347\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3457 - val_loss: 0.3344\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 624.4867423423187, my average MASE = 18127046.32229549\n",
      "Cluster 10, 624.4867423423187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maes = defaultdict(lambda: [])\n",
    "mases = defaultdict(lambda: [])\n",
    "mapes = defaultdict(lambda: [])\n",
    "answers = {}\n",
    "bad_values = np.zeros(dataset.shape[1])\n",
    "\n",
    "dif=True\n",
    "\n",
    "for window_size in window_sizes_for_clustering:\n",
    "    for N_clusters in Ns_clusters:\n",
    "        dataset_windows, dataset_y = Forecasting.create_windows(dataset, window_size=window_size)\n",
    "        clusters_labels = Clustering.KMeans_for_windows(dataset_windows, W=window_size, N_clusters=N_clusters, max_iter=50)\n",
    "        print(f\"{clusters_labels.shape=}\")\n",
    "        datasets_clusters = Clustering.flatten_from_interceting_windows(dataset_windows, clusters_labels, W=window_size, \\\n",
    "                N_clusters=N_clusters)\n",
    "        # list of list of ndarrays [N_i, Q], dataset_clusters[cluster_num][i] - i-th part of dataset for cluster_num\n",
    "\n",
    "        print(f\"{N_clusters=}, {len(datasets_clusters)}, {len(datasets_clusters[0])}, {datasets_clusters[0][0].shape}\")\n",
    "        ###window_size for model\n",
    "        errors = [1] * N_clusters\n",
    "        for cluster_num in range(N_clusters):\n",
    "            sc = Forecasting.MyStandardScaler(dif=dif)\n",
    "            #datasets_clusters[cluster_num] - list of [N_i, Q] ndarrays\n",
    "            sc.fit(datasets_clusters[cluster_num])\n",
    "            prepared_data = sc.transform(datasets_clusters[cluster_num])\n",
    "            data_X, data_y = Forecasting.create_windows(prepared_data, window_size=10)\n",
    "            #data_X - list of [N_i-W, W, Q] ndarrays\n",
    "            train_X, train_y, valid_X, valid_y, test_X, test_y, ind = Forecasting.split_to_train_test(data_X, data_y, part_of_test=0.2, part_of_valid=0.2)\n",
    "            #ndarrays [N_i, W, Q] or [N_i, Q]\n",
    "            ind = np.array(ind) + window_size\n",
    "            print(f\"Before prediction: {train_X.shape=}, {train_y.shape=}, {test_X.shape=}, {test_y.shape=}\")\n",
    "            try:\n",
    "                assert(len(test_X.shape) == 3 and test_X.shape[0] > 0)\n",
    "                assert(len(valid_X.shape) == 3 and valid_X.shape[0] > 0)\n",
    "                assert(len(train_X.shape) == 3 and train_X.shape[0] > 0)\n",
    "            except AssertionError:\n",
    "                print(f\"FAIL - {test_X.shape=}, {valid_X.shape=}, {train_X.shape=}\")\n",
    "                errors[cluster_num] = np.Inf\n",
    "                continue\n",
    "            model, history = Forecasting.learn(train_X, train_y, valid_X=valid_X, valid_y=valid_y)\n",
    "            predicted = model.predict(test_X)\n",
    "            predicted_original = sc.inverse_transform(predicted)[0]\n",
    "            #inverse_trasform returns list of ndarrays \n",
    "            # if dif:\n",
    "                #константа при дифференцировании\n",
    "                # predicted_original = sc.add_first_element(predicted_original, ind)[0]\n",
    "            print(f\"{predicted_original.shape=}, {test_y.shape=}\")\n",
    "\n",
    "            #calc all metrics\n",
    "            cur_mae = mae(test_y, predicted_original, multioutput='raw_values')\n",
    "#             error_out = mase(test_y, predicted_original, y_train=test_y)\n",
    "#             error_in = mase(test_y, predicted_original, y_train=train_y)\n",
    "            # cur_mase = mase(test_y, predicted_original, y_train=test_y)\n",
    "            cur_mape = mape(test_y, predicted_original)\n",
    "            cur_mase = Forecasting.my_mase(test_y, predicted_original, multioutput='raw_values')\n",
    "            maes[(window_size, N_clusters)].append(cur_mae)\n",
    "#             mases[(window_size, N_clusters)].append((error_in, error_out))\n",
    "            mapes[(window_size, N_clusters)].append(cur_mape)\n",
    "#             errors[cluster_num] = mase_uni(test_y, predicted_original, y_train=test_y)\n",
    "            tmp_bad = cur_mase > np.percentile(cur_mase, 90)\n",
    "            bad_values += tmp_bad\n",
    "            cur_mase[tmp_bad] = -1\n",
    "#             errors[cluster_num] = Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')\n",
    "            errors[cluster_num] = np.mean(cur_mase[~tmp_bad])\n",
    "            \n",
    "            #show all metrics\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.suptitle(f\"K={N_clusters}, W={window_size}, C={cluster_num}\")\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(cur_mae, color=\"green\", label=\"library\")\n",
    "            plt.plot(Forecasting.my_mae(test_y, predicted_original, multioutput='raw_values'), color=\"red\", label=\"custom\")\n",
    "            plt.title(\"MAE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "#             plt.plot(error_in, label=\"library, in\")\n",
    "#             plt.plot(error_out, label=\"library, out\")\n",
    "            plt.plot(cur_mase, label=\"custom, out\")\n",
    "            plt.title(\"MASE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(cur_mape)\n",
    "            plt.title(\"MAPE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f\"plots/Dataset2/K={N_clusters}  W={window_size} C={cluster_num}.png\")\n",
    "#             plt.show()    \n",
    "            plt.clf()\n",
    "            # print(f\"{cur_mae=}, {cur_mase=}, {cur_mape=}\")\n",
    "            # my_mase = mase()\n",
    "            # print(f\"MASE in_sample = {error_in}, MASE out_sample = {error_out}\")\n",
    "            print(f\"average MASE = {errors[cluster_num]}, my average MASE = {Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')}\")\n",
    "            print(f\"Cluster {cluster_num}, {errors[cluster_num]}\")\n",
    "        answers[(window_size, N_clusters)] = errors\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.suptitle(f\"K={N_clusters}, W={window_size}\")\n",
    "        plt.subplot(2, 2, 1)\n",
    "\n",
    "        plt.bar(np.arange(N_clusters), [np.sum(clusters_labels == i) for i in range(N_clusters)], color='blue')\n",
    "        plt.title(\"Размеры кластеров\")\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.bar(np.arange(N_clusters), [len(datasets_clusters[i]) for i in range(N_clusters)], color=\"green\")\n",
    "        plt.title(\"Количество непрерывных отрезков\")\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.bar(np.arange(N_clusters), errors, color=\"red\")\n",
    "        plt.title(\"MASE на тесте каждого из кластеров\")\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        plt.table(cellText= [[f\"{x:.2f}\"] for x in errors],\n",
    "                      rowLabels=list(range(N_clusters)),\n",
    "                      loc='center')\n",
    "#         plt.show()\n",
    "        plt.savefig(f\"plots/Dataset2/method1: {N_clusters=}  W={window_size}.png\")\n",
    "        #         plt.show()\n",
    "        plt.clf()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.bar(np.arange(bad_values.shape[0]), bad_values)\n",
    "plt.title(\"Количество раз, когда переменная имела максимум MASE\")\n",
    "plt.savefig(f\"plots/Dataset2/bad_values.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([ 2,  4,  7,  8, 11, 14, 18, 21, 23, 25, 28, 30, 33, 37, 39, 43, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 5)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33,\n",
      "       39, 48, 50, 53, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 28, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 33, 37, 39,\n",
      "       41, 43, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 9)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 30, 31, 33, 35, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 12, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 23, 25, 26, 28, 30, 39, 41, 42, 48,\n",
      "       51, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(3, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 13, 14, 15, 18, 21, 23, 25, 26, 28, 30, 33,\n",
      "       37, 39, 41, 42, 44, 48, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 5)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 26, 28, 30, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 7)\n",
      "     (array([ 2, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 35, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 9)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 23, 25, 28, 30, 31, 33, 35, 39,\n",
      "       41, 43, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(3, 11)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 37, 39, 44, 48,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 2)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 12, 14, 18, 21, 23, 25, 30, 31, 33, 37, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 5)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 31, 39, 60, 61,\n",
      "       62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(5, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 16, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 23, 25, 28, 30, 33, 35, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "(5, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 14, 15, 16, 18, 19, 21, 23, 25, 27, 28, 30,\n",
      "       39, 42, 44, 47, 48, 52, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 15, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35,\n",
      "       37, 39, 60, 61, 62, 63, 65]),)\n",
      "(5, 11)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 28, 30, 31, 33, 39,\n",
      "       41, 42, 49, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(10, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 11, 13, 14, 18, 21, 23, 25, 28, 30, 31, 33,\n",
      "       35, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 5)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 22, 23, 25, 28, 30, 31, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 7)\n",
      "     (array([ 2,  4,  8,  9, 14, 16, 18, 19, 30, 58, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "(10, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 23, 24, 25, 26, 28, 30, 31,\n",
      "       33, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(10, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 12, 14, 18, 21, 22, 23, 25, 28, 30, 39, 56, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in maes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in mases.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c[0] < 1)}, {np.where(val_c[1] < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([14, 18, 25, 30, 31, 33, 35, 37, 43]),)\n",
      "     (array([14, 30]),)\n",
      "(1, 5)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(1, 7)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 11, 14]),)\n",
      "     (array([14]),)\n",
      "(1, 9)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 4,  8, 14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14, 60, 61]),)\n",
      "(1, 11)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(3, 2)\n",
      "     (array([ 4, 14, 18, 30, 31, 33, 35, 37, 42, 62]),)\n",
      "     (array([14, 30]),)\n",
      "(3, 5)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(3, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61]),)\n",
      "(3, 9)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 28, 39, 62]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 19, 30]),)\n",
      "(3, 11)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 23, 28, 39, 62, 65]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "(5, 2)\n",
      "     (array([12, 14, 18, 30, 31, 33, 35, 37, 60, 62, 65]),)\n",
      "     (array([14, 30]),)\n",
      "(5, 5)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "(5, 7)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 9, 11, 14, 18, 19, 21, 23, 25, 30, 39, 42, 44, 47, 52, 60, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 11)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 21, 23, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "(10, 2)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "(10, 5)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 14]),)\n",
      "(10, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 11)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in mapes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
