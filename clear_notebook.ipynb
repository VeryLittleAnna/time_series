{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 18:34:16.852722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-20 18:34:16.852752: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSet2.csv\", sep=\";\")#, parse_dates=['Timestamp']) #, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "df = data.groupby(data.index // K).mean() #усреднение\n",
    "df_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError, MeanAbsolutePercentageError\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mase = MeanAbsoluteScaledError(multioutput='raw_values')\n",
    "mase_uni = MeanAbsoluteScaledError(multioutput='uniform_average')\n",
    "mape = MeanAbsolutePercentageError(multioutput='raw_values')\n",
    "# mae = MeanAbsoluteError()\n",
    "\n",
    "\n",
    "#if ‘raw_values’, returns a full set of errors in case of multioutput input. If ‘uniform_average’, errors of all outputs are averaged with uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 67)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_np[:, :]\n",
    "# dataset = np.concatenate((dataset[:, :8], dataset[:, 9:]), axis=1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**__Отбор признаков на минималках__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удаление константных\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(0.001)\n",
    "dataset1 = selector.fit_transform(dataset) \n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 14}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(range(67)) - set(selector.get_feature_names_out(input_features=np.arange(dataset.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset[:, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(dataset[:, 8], color=\"green\")\n",
    "plt.plot(np.concatenate((dataset[:32714, 8], dataset[32717:, 8])))\n",
    "plt.title(\"consumption_09\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00292  0.00733  0.754974 1.658794 1.956544]\n",
      "[32714, 375379, 1, 1, 1]\n",
      "Изменение только в [[32713]\n",
      " [32714]\n",
      " [32715]\n",
      " [32716]]\n"
     ]
    }
   ],
   "source": [
    "values = np.unique(dataset[:, 8])\n",
    "print(values)\n",
    "print([len(np.argwhere(dataset[:, 8] == val)) for val in values])\n",
    "print(f\"Изменение только в {np.argwhere(dataset[1:, 8] - dataset[:-1, 8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Эти датчики пока выкинем из-за константности: ** \n",
    "\n",
    "8: consumption_09\n",
    "\n",
    "14 : consumption_07 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('consumption_07', 'consumption_09')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[15], columns[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa7a0bc6800>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset[7])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import correlate\n",
    "# a = np.array([np.sin(x + 1) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 2) for x in range(10)])\n",
    "# c = correlate(a, b, mode=\"full\") #mode='same'\n",
    "# plt.plot(a, label=\"a\")\n",
    "# plt.plot(b, label=\"b\")\n",
    "# plt.plot(c, label=\"correlation\")\n",
    "# plt.legend()\n",
    "# c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "#еще не поняла до конца\n",
    "from sklearn.feature_selection import f_regression\n",
    "for i in range(1):\n",
    "    X = np.concatenate((dataset[:, :i], dataset[:, i + 1:]), axis=1)\n",
    "    y = dataset[:, i]\n",
    "    res = f_regression(X, y)\n",
    "    print(res[0].shape)\n",
    "    # plt.plot(res[0], label=\"f_statistics\")\n",
    "    # # plt.plot(res[1], label=\"p_values\")\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([np.sin(x) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 1) + 1 for x in range(10)])\n",
    "# c = np.array([np.sin(x + 0.1) for x in range(10)])\n",
    "\n",
    "# f_regression(a[:, None], b), f_regression(a[:, None], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прогнозирование**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "window_sizes_for_clustering = 10\n",
    "# X, y = dataset[:-window_sizes_for_clustering, ...], dataset[window_sizes_for_clustering:, ...]\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "n_split = round(0.2 * dataset.shape[0])\n",
    "dataset_train, dataset_test = dataset[:-n_split, ...], dataset[-n_split:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 65), (2000, 65))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes_for_clustering = [15] #1, 3, 5, 10, 15\n",
    "Ns_clusters = [9] #2, 5, 7, 9, 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns_clusters = [2]\n",
    "# window_sizes_for_clustering = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, Q = 100, 100, 2\n",
    "dataset_train = np.column_stack([[np.sin(x / 40) for x in range(N)], [0.01 + np.sin(x / 20) for x in range(N)]])\n",
    "# dataset_train = np.array([np.sin(x / 10000) for x in range(N)])[:, None]\n",
    "# dataset_train = np.column_stack(([np.sqrt(x / 10) for x in range(N)], [x + ])\n",
    "dataset_test = np.column_stack([[np.sin(x / 30) for x in range(M)], [0.01 + np.sin(x / 30)*1.01 for x in range(M)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28174332, 0.70757836])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(dataset_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_clusters=2\n",
      "dataset_windows.shape=(89, 1, 12, 2), labels.shape=(89,)\n",
      "In split_to_train_test: dataset_X.shape=(31, 11, 2), dataset_y.shape=(31, 2)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 105.4811 - val_loss: 101.3135\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 105.4787 - val_loss: 101.3113\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 105.4764 - val_loss: 101.3091\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 105.4741 - val_loss: 101.3069\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 105.4719 - val_loss: 101.3047\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 105.4696 - val_loss: 101.3025\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 105.4674 - val_loss: 101.3003\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 105.4651 - val_loss: 101.2981\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 105.4628 - val_loss: 101.2958\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 105.4605 - val_loss: 101.2936\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 105.4581 - val_loss: 101.2913\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 105.4556 - val_loss: 101.2891\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 105.4530 - val_loss: 101.2868\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 105.4504 - val_loss: 101.2845\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 105.4478 - val_loss: 101.2822\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 105.4452 - val_loss: 101.2799\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 105.4426 - val_loss: 101.2775\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 105.4401 - val_loss: 101.2752\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 105.4376 - val_loss: 101.2728\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 105.4351 - val_loss: 101.2704\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 105.4327 - val_loss: 101.2681\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 105.4303 - val_loss: 101.2656\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 105.4279 - val_loss: 101.2632\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 105.4254 - val_loss: 101.2608\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 105.4229 - val_loss: 101.2584\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 105.4203 - val_loss: 101.2559\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 105.4176 - val_loss: 101.2534\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 105.4149 - val_loss: 101.2509\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 105.4121 - val_loss: 101.2484\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 105.4093 - val_loss: 101.2459\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "In calc_results: 19, 6, 6, sum = 31\n",
      "In split_to_train_test: dataset_X.shape=(58, 11, 2), dataset_y.shape=(58, 2)\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 51.5271 - val_loss: 68.9189\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 51.5203 - val_loss: 68.9141\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 51.5136 - val_loss: 68.9092\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 51.5070 - val_loss: 68.9044\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 51.5004 - val_loss: 68.8995\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 51.4937 - val_loss: 68.8945\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 51.4872 - val_loss: 68.8896\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 51.4806 - val_loss: 68.8846\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 51.4741 - val_loss: 68.8796\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 51.4676 - val_loss: 68.8746\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 51.4611 - val_loss: 68.8696\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 51.4547 - val_loss: 68.8645\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 51.4482 - val_loss: 68.8594\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 51.4419 - val_loss: 68.8543\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 51.4355 - val_loss: 68.8492\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 51.4291 - val_loss: 68.8441\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 51.4228 - val_loss: 68.8389\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 51.4165 - val_loss: 68.8337\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 51.4102 - val_loss: 68.8285\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 51.4040 - val_loss: 68.8232\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 51.3977 - val_loss: 68.8180\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 51.3915 - val_loss: 68.8127\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 51.3853 - val_loss: 68.8074\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 51.3791 - val_loss: 68.8020\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 51.3730 - val_loss: 68.7966\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 51.3668 - val_loss: 68.7912\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 51.3606 - val_loss: 68.7858\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 51.3545 - val_loss: 68.7803\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 51.3484 - val_loss: 68.7749\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 51.3423 - val_loss: 68.7694\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "In calc_results: 35, 11, 12, sum = 58\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"N_clusters\":Ns_clusters, \"window_size_for_clustering\":window_sizes_for_clustering, \"dif\":True}\n",
    "models, model_mase, results_training = Forecasting.try_parameters(parameters, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [<keras.engine.sequential.Sequential at 0x7fa5a1b9f100>,\n",
       "  <keras.engine.sequential.Sequential at 0x7fa5a0213820>],\n",
       " 'scalers': [<Forecasting.MyStandardScaler at 0x7fa5fccf2cb0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7fa5a02102b0>],\n",
       " 'clusters_model': KMeans(init='random', max_iter=100, n_clusters=2)}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280.75400517183436"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for i, file_name in enumerate(list(os.listdir(\"scalers\"))):\n",
    "    os.unlink(\"scalers/\"+file_name)\n",
    "for i in range(len(models['scalers'])):\n",
    "    with open(\"scalers/\"+str(i)+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(models['scalers'][i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.unlink(\"clusters_model.pkl\")\n",
    "with open(\"clusters_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models['clusters_model'], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_90_layer_call_fn, lstm_cell_90_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/0/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_91_layer_call_fn, lstm_cell_91_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "for i, file_name in enumerate(list(os.listdir(\"models\"))):\n",
    "    shutil.rmtree(\"models/\"+file_name)\n",
    "for i in range(len(models['models'])):\n",
    "    models['models'][i].save(\"models/\"+str(i))\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "N_clusters = len(os.listdir('models'))\n",
    "assert(len(os.listdir('scalers')) == N_clusters)\n",
    "models = {'models':[], 'clusters_model':[], 'scalers':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "for file_name in os.listdir('models'):\n",
    "    models['models'].append(keras.models.load_model('models/'+file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir('scalers'):\n",
    "    with open('scalers/'+file_name, 'rb') as f:\n",
    "        models['scalers'].append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clusters_model.pkl', 'rb') as f:\n",
    "    models['clusters_model'] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_model = models[\"clusters_model\"]\n",
    "forecasting_models = models['models']\n",
    "scalers = models['scalers']\n",
    "assert(len(forecasting_models) == len(scalers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/anna/Desktop/MSU/научка/git/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_sizes_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.shape=(100, 2), dataset_windows.shape=(86, 30), cluster_nums.shape=(86,), 14\n",
      "After pad: dataset.shape=(100, 2), cluster_nums.shape=(100,)\n",
      "cur_windows.shape=(90, 11, 2)\n"
     ]
    }
   ],
   "source": [
    "window_size_for_clustering = clusters_model.cluster_centers_.shape[-1] // dataset_test.shape[-1]\n",
    "y_pred, results_testing = Forecasting.predict_through_clusters(dataset_test, clusters_model, forecasting_models, scalers, window_size_clustering=window_size_for_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 2), 65)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, dataset.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape=(90, 2), dataset_test.shape=(100, 2)\n",
      "(90, 2) (90, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{y_pred.shape=}, {dataset_test.shape=}\")\n",
    "y_true = dataset_test[-y_pred.shape[0]:]\n",
    "print(y_true.shape, results_testing[:, :dataset_train.shape[-1]].shape)\n",
    "results_testing[:, :dataset_train.shape[-1]] = y_true\n",
    "cur_mase = Forecasting.my_mase(y_true, y_pred, multioutput='raw_values')\n",
    "cur_mae = Forecasting.my_mae(y_true, y_pred, multioutput=\"raw_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = dataset_train.shape[-1]\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# full_results = np.concatenate((results_training, results_testing), axis=0)\n",
    "# with open(\"output_table.csv\", \"w\") as fout:\n",
    "#     writer = csv.writer(fout)\n",
    "#     writer.writerow([\"real \"+str(i) for i in range(Q)] + [\"predicted \" + str(i) for i in range(Q)] + [\"cluster_num\", \"mode\"])\n",
    "#     for i in range(full_results.shape[0]):\n",
    "#         writer.writerow(full_results[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.30852157, 1.26862662]), array([0.0134567 , 0.01317689]))"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_mase, cur_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase) #[cur_mase <= np.percentile(cur_mase, 100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mae) #[cur_mase <= np.percentile(cur_mase, 100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.title(\"MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"50% best MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_mape = mape(y_true, y_pred)\n",
    "plt.plot(cur_mape[cur_mape < np.percentile(cur_mape, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"50% best MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mape[cur_mape <= np.percentile(cur_mape,100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 67), dtype=float32, numpy=\n",
       "array([[ 8.25200696e-04, -2.52360152e-03,  1.24429585e-03,\n",
       "         5.61252143e-03,  2.41480279e-03,  6.91283401e-03,\n",
       "        -1.55929942e-04,  5.05245430e-03, -3.45375156e-03,\n",
       "         2.31756223e-03, -5.02947718e-03,  5.21133933e-03,\n",
       "         2.63487943e-03, -1.15680450e-03, -8.61713605e-04,\n",
       "        -4.27721906e-03,  1.65054473e-04,  1.98029215e-03,\n",
       "         1.16372411e-03, -6.18001819e-03,  1.38662616e-03,\n",
       "        -3.87507980e-03, -5.78831602e-03, -4.70064487e-03,\n",
       "        -4.91938740e-03, -9.45061352e-03, -6.37044199e-03,\n",
       "        -1.24200690e-03, -2.50279880e-03,  6.26629405e-03,\n",
       "         7.07075465e-03,  4.37504100e-03,  8.11321661e-06,\n",
       "         6.27311785e-03, -2.45433138e-03,  6.55709300e-04,\n",
       "         1.01655931e-03,  3.92863574e-03, -7.48858880e-03,\n",
       "        -3.09383660e-03, -3.60715576e-03,  3.58439516e-04,\n",
       "         5.01208124e-04,  4.94992966e-03,  4.09077760e-03,\n",
       "        -1.00721011e-03, -6.26226794e-03, -6.27841754e-03,\n",
       "         5.10353828e-03,  4.80458234e-03, -2.42970185e-03,\n",
       "         3.23574082e-03,  4.15166654e-03,  1.97961787e-03,\n",
       "         2.42814887e-03, -2.23055086e-03, -2.55294633e-03,\n",
       "        -3.07056517e-03, -7.46782962e-03,  4.13405150e-03,\n",
       "         4.82963771e-03,  6.89104025e-04, -1.09297456e-04,\n",
       "         3.91600234e-03, -8.97214864e-04, -1.08612701e-03,\n",
       "         4.65779193e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.zeros(67 * 10).reshape(1, 10, 67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=2, 2, 22, (30608, 67)\n",
      "Before prediction: train_X.shape=(18358, 10, 67), train_y.shape=(18358, 67), test_X.shape=(6119, 10, 67), test_y.shape=(6119, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3112 - val_loss: 0.3270\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2915 - val_loss: 0.3111\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2761 - val_loss: 0.2987\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2646 - val_loss: 0.2898\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2564 - val_loss: 0.2830\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2504 - val_loss: 0.2777\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2456 - val_loss: 0.2732\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2415 - val_loss: 0.2694\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2378 - val_loss: 0.2660\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2345 - val_loss: 0.2630\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2314 - val_loss: 0.2603\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2286 - val_loss: 0.2579\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2262 - val_loss: 0.2559\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2241 - val_loss: 0.2541\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2222 - val_loss: 0.2526\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2206 - val_loss: 0.2513\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2191 - val_loss: 0.2500\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2179 - val_loss: 0.2489\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2167 - val_loss: 0.2478\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2156 - val_loss: 0.2470\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2147 - val_loss: 0.2461\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2138 - val_loss: 0.2453\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2129 - val_loss: 0.2444\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2122 - val_loss: 0.2439\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2115 - val_loss: 0.2432\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2109 - val_loss: 0.2427\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2103 - val_loss: 0.2421\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2097 - val_loss: 0.2416\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2092 - val_loss: 0.2410\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2087 - val_loss: 0.2407\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2082 - val_loss: 0.2401\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2397\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2073 - val_loss: 0.2394\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2069 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2065 - val_loss: 0.2386\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2062 - val_loss: 0.2382\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2058 - val_loss: 0.2380\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2055 - val_loss: 0.2376\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2052 - val_loss: 0.2373\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2049 - val_loss: 0.2370\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6119, 67), test_y.shape=(6119, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1578.0531622950014, my average MASE = 2807.2183134542065\n",
      "Cluster 0, 1578.0531622950014\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4317 - val_loss: 1.2280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4299 - val_loss: 1.2276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4282 - val_loss: 1.2273\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4264 - val_loss: 1.2269\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4247 - val_loss: 1.2266\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 1.2263\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 1.2259\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4198 - val_loss: 1.2256\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4182 - val_loss: 1.2253\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4166 - val_loss: 1.2251\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4151 - val_loss: 1.2248\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4135 - val_loss: 1.2245\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4120 - val_loss: 1.2242\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4105 - val_loss: 1.2239\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4089 - val_loss: 1.2236\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4074 - val_loss: 1.2233\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4060 - val_loss: 1.2229\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4045 - val_loss: 1.2226\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 1.2223\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4017 - val_loss: 1.2220\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4004 - val_loss: 1.2216\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3990 - val_loss: 1.2213\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3977 - val_loss: 1.2210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3964 - val_loss: 1.2207\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3951 - val_loss: 1.2204\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3938 - val_loss: 1.2201\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3926 - val_loss: 1.2198\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3914 - val_loss: 1.2195\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3901 - val_loss: 1.2192\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3889 - val_loss: 1.2189\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3877 - val_loss: 1.2186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3866 - val_loss: 1.2184\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 1.2181\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3842 - val_loss: 1.2178\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3831 - val_loss: 1.2175\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 1.2173\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3809 - val_loss: 1.2170\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3798 - val_loss: 1.2167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3787 - val_loss: 1.2165\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3776 - val_loss: 1.2162\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 708619678.5307182, my average MASE = 1911068024.4320867\n",
      "Cluster 1, 708619678.5307182\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=5, 5, 1026, (269, 67)\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5683 - val_loss: 0.4789\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5669 - val_loss: 0.4779\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5656 - val_loss: 0.4770\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5643 - val_loss: 0.4760\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5631 - val_loss: 0.4751\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5619 - val_loss: 0.4743\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5607 - val_loss: 0.4734\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5595 - val_loss: 0.4726\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5584 - val_loss: 0.4718\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5573 - val_loss: 0.4710\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5562 - val_loss: 0.4702\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5552 - val_loss: 0.4694\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5542 - val_loss: 0.4687\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5532 - val_loss: 0.4679\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5522 - val_loss: 0.4672\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5512 - val_loss: 0.4665\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5502 - val_loss: 0.4658\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5493 - val_loss: 0.4651\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5483 - val_loss: 0.4644\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5474 - val_loss: 0.4637\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5465 - val_loss: 0.4630\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5456 - val_loss: 0.4624\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5447 - val_loss: 0.4617\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5438 - val_loss: 0.4611\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5429 - val_loss: 0.4605\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5421 - val_loss: 0.4598\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5412 - val_loss: 0.4592\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5404 - val_loss: 0.4586\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5396 - val_loss: 0.4579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5388 - val_loss: 0.4573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5379 - val_loss: 0.4567\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5371 - val_loss: 0.4561\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5363 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5355 - val_loss: 0.4549\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5348 - val_loss: 0.4543\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5340 - val_loss: 0.4538\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5332 - val_loss: 0.4532\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5324 - val_loss: 0.4526\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5317 - val_loss: 0.4521\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5309 - val_loss: 0.4515\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.40868807431647, my average MASE = 112470179.11258063\n",
      "Cluster 0, 139.40868807431647\n",
      "Before prediction: train_X.shape=(31, 10, 67), train_y.shape=(31, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3364 - val_loss: 0.3469\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3360 - val_loss: 0.3468\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3355 - val_loss: 0.3468\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3350 - val_loss: 0.3467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3346 - val_loss: 0.3466\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3341 - val_loss: 0.3465\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3337 - val_loss: 0.3464\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3332 - val_loss: 0.3463\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3328 - val_loss: 0.3463\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3323 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3319 - val_loss: 0.3461\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3315 - val_loss: 0.3460\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3310 - val_loss: 0.3459\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3306 - val_loss: 0.3458\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3302 - val_loss: 0.3457\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3298 - val_loss: 0.3457\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3294 - val_loss: 0.3456\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3290 - val_loss: 0.3455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3286 - val_loss: 0.3454\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3282 - val_loss: 0.3453\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3278 - val_loss: 0.3453\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3274 - val_loss: 0.3452\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3270 - val_loss: 0.3451\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3267 - val_loss: 0.3450\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3263 - val_loss: 0.3450\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3259 - val_loss: 0.3449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3255 - val_loss: 0.3448\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3252 - val_loss: 0.3448\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3248 - val_loss: 0.3447\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3245 - val_loss: 0.3446\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3242 - val_loss: 0.3445\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3238 - val_loss: 0.3445\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3235 - val_loss: 0.3444\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3231 - val_loss: 0.3443\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3228 - val_loss: 0.3443\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3225 - val_loss: 0.3442\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3222 - val_loss: 0.3441\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3440\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3216 - val_loss: 0.3440\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3213 - val_loss: 0.3439\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3523641.3982873675, my average MASE = 66808534.66599488\n",
      "Cluster 1, 3523641.3982873675\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1130 - val_loss: 0.1021\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1076 - val_loss: 0.1000\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1032 - val_loss: 0.0984\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0995 - val_loss: 0.0974\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0964 - val_loss: 0.0968\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0912 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0889 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0869 - val_loss: 0.0951\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0834 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0804 - val_loss: 0.0940\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0791 - val_loss: 0.0938\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0936\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0934\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0757 - val_loss: 0.0933\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0748 - val_loss: 0.0931\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0739 - val_loss: 0.0930\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0730 - val_loss: 0.0929\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0722 - val_loss: 0.0927\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0926\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0707 - val_loss: 0.0925\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0701 - val_loss: 0.0924\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0694 - val_loss: 0.0923\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0922\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0922\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0677 - val_loss: 0.0922\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0672 - val_loss: 0.0921\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0921\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0663 - val_loss: 0.0920\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0919\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0656 - val_loss: 0.0919\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0918\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0918\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0646 - val_loss: 0.0917\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0638 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0635 - val_loss: 0.0915\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 869790828.2820631, my average MASE = 17262168691.962505\n",
      "Cluster 2, 869790828.2820631\n",
      "Before prediction: train_X.shape=(2219, 10, 67), train_y.shape=(2219, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5462 - val_loss: 0.4045\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5391 - val_loss: 0.4010\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5333 - val_loss: 0.3979\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5281 - val_loss: 0.3951\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5234 - val_loss: 0.3925\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5190 - val_loss: 0.3900\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5147 - val_loss: 0.3877\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5107 - val_loss: 0.3856\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5068 - val_loss: 0.3835\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5031 - val_loss: 0.3816\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4996 - val_loss: 0.3797\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4961 - val_loss: 0.3780\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4928 - val_loss: 0.3763\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4896 - val_loss: 0.3747\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4865 - val_loss: 0.3732\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4835 - val_loss: 0.3717\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4806 - val_loss: 0.3704\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4778 - val_loss: 0.3691\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4750 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4723 - val_loss: 0.3666\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4697 - val_loss: 0.3655\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4672 - val_loss: 0.3644\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4647 - val_loss: 0.3633\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4623 - val_loss: 0.3624\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4600 - val_loss: 0.3614\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4577 - val_loss: 0.3605\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4556 - val_loss: 0.3596\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4535 - val_loss: 0.3588\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4515 - val_loss: 0.3580\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4495 - val_loss: 0.3572\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4476 - val_loss: 0.3564\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4458 - val_loss: 0.3557\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4440 - val_loss: 0.3551\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4423 - val_loss: 0.3544\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4406 - val_loss: 0.3538\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4390 - val_loss: 0.3532\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4374 - val_loss: 0.3525\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4359 - val_loss: 0.3519\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4343 - val_loss: 0.3514\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4329 - val_loss: 0.3508\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 408.78828000932964, my average MASE = 1218.6998180420371\n",
      "Cluster 3, 408.78828000932964\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5668 - val_loss: 0.4468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5648 - val_loss: 0.4459\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5628 - val_loss: 0.4451\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5609 - val_loss: 0.4443\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5589 - val_loss: 0.4435\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5570 - val_loss: 0.4427\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5551 - val_loss: 0.4419\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5533 - val_loss: 0.4412\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5514 - val_loss: 0.4404\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5496 - val_loss: 0.4397\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5478 - val_loss: 0.4389\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5460 - val_loss: 0.4382\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5442 - val_loss: 0.4374\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5425 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5408 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5391 - val_loss: 0.4352\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5374 - val_loss: 0.4344\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5358 - val_loss: 0.4337\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5342 - val_loss: 0.4329\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.4322\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5310 - val_loss: 0.4315\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5295 - val_loss: 0.4308\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5280 - val_loss: 0.4300\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5264 - val_loss: 0.4293\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5250 - val_loss: 0.4286\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5235 - val_loss: 0.4279\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5221 - val_loss: 0.4273\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5207 - val_loss: 0.4266\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5193 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5179 - val_loss: 0.4254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5165 - val_loss: 0.4248\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5151 - val_loss: 0.4241\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5138 - val_loss: 0.4235\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5125 - val_loss: 0.4229\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5112 - val_loss: 0.4223\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5099 - val_loss: 0.4217\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5086 - val_loss: 0.4212\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5073 - val_loss: 0.4206\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5061 - val_loss: 0.4200\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5048 - val_loss: 0.4194\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2631402082.882854, my average MASE = 5288471031.0194235\n",
      "Cluster 4, 2631402082.882854\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=7, 7, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1149 - val_loss: 0.1029\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1092 - val_loss: 0.1008\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1047 - val_loss: 0.0992\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1009 - val_loss: 0.0980\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0972\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0947 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0922 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0899 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0878 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0859 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0842 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0826 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0812 - val_loss: 0.0939\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0799 - val_loss: 0.0936\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0934\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0775 - val_loss: 0.0931\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0929\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0755 - val_loss: 0.0928\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0746 - val_loss: 0.0926\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0737 - val_loss: 0.0924\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0923\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0922\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0921\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0708 - val_loss: 0.0920\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0919\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0696 - val_loss: 0.0918\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0690 - val_loss: 0.0917\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0685 - val_loss: 0.0916\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0680 - val_loss: 0.0916\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0675 - val_loss: 0.0915\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0670 - val_loss: 0.0915\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0666 - val_loss: 0.0915\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0662 - val_loss: 0.0914\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0658 - val_loss: 0.0914\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0654 - val_loss: 0.0913\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0651 - val_loss: 0.0913\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0648 - val_loss: 0.0912\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0645 - val_loss: 0.0912\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0642 - val_loss: 0.0911\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0911\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 1397145651.915293, my average MASE = 8779028319.064796\n",
      "Cluster 0, 1397145651.915293\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4446 - val_loss: 0.4248\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.4440 - val_loss: 0.4245\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4434 - val_loss: 0.4242\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4429 - val_loss: 0.4239\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4423 - val_loss: 0.4236\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4418 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4413 - val_loss: 0.4231\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4408 - val_loss: 0.4228\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4403 - val_loss: 0.4226\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4398 - val_loss: 0.4223\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4393 - val_loss: 0.4221\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4388 - val_loss: 0.4219\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4383 - val_loss: 0.4216\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4378 - val_loss: 0.4214\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4212\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4369 - val_loss: 0.4209\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4364 - val_loss: 0.4207\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4360 - val_loss: 0.4205\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4355 - val_loss: 0.4202\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4351 - val_loss: 0.4200\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4346 - val_loss: 0.4198\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4342 - val_loss: 0.4195\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.4193\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4333 - val_loss: 0.4191\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4329 - val_loss: 0.4189\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4325 - val_loss: 0.4187\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4321 - val_loss: 0.4184\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4317 - val_loss: 0.4182\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4313 - val_loss: 0.4180\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4309 - val_loss: 0.4178\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4305 - val_loss: 0.4176\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4301 - val_loss: 0.4175\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4297 - val_loss: 0.4173\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4293 - val_loss: 0.4171\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4289 - val_loss: 0.4169\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4286 - val_loss: 0.4167\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4282 - val_loss: 0.4165\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4278 - val_loss: 0.4163\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4274 - val_loss: 0.4161\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4271 - val_loss: 0.4159\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 86.00366340249806, my average MASE = 69691247.07168306\n",
      "Cluster 1, 86.00366340249806\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9826 - val_loss: 1.3468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9801 - val_loss: 1.3460\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9776 - val_loss: 1.3453\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9751 - val_loss: 1.3446\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9726 - val_loss: 1.3439\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9701 - val_loss: 1.3432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9677 - val_loss: 1.3425\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9653 - val_loss: 1.3419\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9628 - val_loss: 1.3413\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9604 - val_loss: 1.3408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9580 - val_loss: 1.3402\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9556 - val_loss: 1.3396\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9532 - val_loss: 1.3390\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9508 - val_loss: 1.3384\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9486 - val_loss: 1.3379\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9463 - val_loss: 1.3374\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9440 - val_loss: 1.3368\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9418 - val_loss: 1.3363\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9397 - val_loss: 1.3358\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9375 - val_loss: 1.3352\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9353 - val_loss: 1.3347\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9331 - val_loss: 1.3341\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9309 - val_loss: 1.3337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9287 - val_loss: 1.3332\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9266 - val_loss: 1.3328\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9245 - val_loss: 1.3324\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9224 - val_loss: 1.3321\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9203 - val_loss: 1.3317\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9183 - val_loss: 1.3314\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9162 - val_loss: 1.3311\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9141 - val_loss: 1.3308\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9120 - val_loss: 1.3305\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9100 - val_loss: 1.3303\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9079 - val_loss: 1.3300\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9059 - val_loss: 1.3298\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9039 - val_loss: 1.3295\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9019 - val_loss: 1.3293\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9000 - val_loss: 1.3291\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8981 - val_loss: 1.3288\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8963 - val_loss: 1.3286\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1.6636413128548868, my average MASE = 8.526439257891766\n",
      "Cluster 2, 1.6636413128548868\n",
      "Before prediction: train_X.shape=(177, 10, 67), train_y.shape=(177, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7327 - val_loss: 0.5966\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7311 - val_loss: 0.5956\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7296 - val_loss: 0.5946\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7281 - val_loss: 0.5936\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7266 - val_loss: 0.5927\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7252 - val_loss: 0.5918\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7239 - val_loss: 0.5909\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7225 - val_loss: 0.5901\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7212 - val_loss: 0.5892\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7199 - val_loss: 0.5884\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7186 - val_loss: 0.5875\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7174 - val_loss: 0.5867\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7162 - val_loss: 0.5859\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7150 - val_loss: 0.5852\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7138 - val_loss: 0.5844\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7127 - val_loss: 0.5837\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7116 - val_loss: 0.5829\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7104 - val_loss: 0.5822\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7093 - val_loss: 0.5815\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7082 - val_loss: 0.5808\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7071 - val_loss: 0.5801\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7061 - val_loss: 0.5794\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7050 - val_loss: 0.5788\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7040 - val_loss: 0.5781\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7030 - val_loss: 0.5775\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7020 - val_loss: 0.5768\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7010 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7000 - val_loss: 0.5756\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6990 - val_loss: 0.5750\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6981 - val_loss: 0.5744\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6971 - val_loss: 0.5738\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6962 - val_loss: 0.5732\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6953 - val_loss: 0.5726\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6944 - val_loss: 0.5721\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6935 - val_loss: 0.5715\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6925 - val_loss: 0.5710\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6917 - val_loss: 0.5704\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6908 - val_loss: 0.5699\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6899 - val_loss: 0.5694\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6890 - val_loss: 0.5688\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 148.95203283848892, my average MASE = 195949093.5023566\n",
      "Cluster 3, 148.95203283848892\n",
      "Before prediction: train_X.shape=(59, 10, 67), train_y.shape=(59, 67), test_X.shape=(20, 10, 67), test_y.shape=(20, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4242 - val_loss: 0.4717\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4237 - val_loss: 0.4716\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4715\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4228 - val_loss: 0.4714\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4223 - val_loss: 0.4713\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4219 - val_loss: 0.4712\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4214 - val_loss: 0.4711\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4210 - val_loss: 0.4710\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.4709\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4201 - val_loss: 0.4708\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4197 - val_loss: 0.4707\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4193 - val_loss: 0.4706\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4189 - val_loss: 0.4705\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.4705\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4180 - val_loss: 0.4704\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4176 - val_loss: 0.4703\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4702\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4168 - val_loss: 0.4701\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4164 - val_loss: 0.4700\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4160 - val_loss: 0.4699\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4157 - val_loss: 0.4698\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4153 - val_loss: 0.4698\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4149 - val_loss: 0.4697\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4145 - val_loss: 0.4696\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4141 - val_loss: 0.4695\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4138 - val_loss: 0.4694\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4134 - val_loss: 0.4694\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4130 - val_loss: 0.4693\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4127 - val_loss: 0.4692\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4123 - val_loss: 0.4691\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4119 - val_loss: 0.4690\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4116 - val_loss: 0.4690\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4112 - val_loss: 0.4689\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.4688\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4105 - val_loss: 0.4687\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4101 - val_loss: 0.4687\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4098 - val_loss: 0.4686\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4094 - val_loss: 0.4685\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4091 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4087 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(20, 67), test_y.shape=(20, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 138.4214035546147, my average MASE = 76438634.40084383\n",
      "Cluster 4, 138.4214035546147\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4144 - val_loss: 0.4072\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4116 - val_loss: 0.4056\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4089 - val_loss: 0.4039\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4061 - val_loss: 0.4022\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4034 - val_loss: 0.4005\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4008 - val_loss: 0.3988\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3982 - val_loss: 0.3971\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3957 - val_loss: 0.3954\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3932 - val_loss: 0.3937\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3908 - val_loss: 0.3920\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3885 - val_loss: 0.3903\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3861 - val_loss: 0.3887\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3838 - val_loss: 0.3870\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3816 - val_loss: 0.3854\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3795 - val_loss: 0.3838\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3775 - val_loss: 0.3822\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3755 - val_loss: 0.3807\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3735 - val_loss: 0.3793\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3716 - val_loss: 0.3779\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3697 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3679 - val_loss: 0.3751\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3661 - val_loss: 0.3737\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3644 - val_loss: 0.3723\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3710\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3611 - val_loss: 0.3697\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3594 - val_loss: 0.3684\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3578 - val_loss: 0.3672\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3562 - val_loss: 0.3659\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3547 - val_loss: 0.3646\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3533 - val_loss: 0.3634\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.3621\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3506 - val_loss: 0.3608\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3493 - val_loss: 0.3596\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3481 - val_loss: 0.3583\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3468 - val_loss: 0.3571\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3456 - val_loss: 0.3558\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3443 - val_loss: 0.3546\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3431 - val_loss: 0.3534\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3419 - val_loss: 0.3521\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3407 - val_loss: 0.3509\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 697989181.1057402, my average MASE = 1714132782.1928625\n",
      "Cluster 5, 697989181.1057402\n",
      "Before prediction: train_X.shape=(95, 10, 67), train_y.shape=(95, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3944 - val_loss: 0.3555\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3937 - val_loss: 0.3552\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3930 - val_loss: 0.3549\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3924 - val_loss: 0.3546\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3917 - val_loss: 0.3543\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3910 - val_loss: 0.3540\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3904 - val_loss: 0.3537\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3898 - val_loss: 0.3534\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3892 - val_loss: 0.3532\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3886 - val_loss: 0.3529\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3880 - val_loss: 0.3526\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3874 - val_loss: 0.3523\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3868 - val_loss: 0.3520\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3863 - val_loss: 0.3518\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3857 - val_loss: 0.3515\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3852 - val_loss: 0.3512\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3846 - val_loss: 0.3510\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3841 - val_loss: 0.3507\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3835 - val_loss: 0.3504\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3830 - val_loss: 0.3502\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3825 - val_loss: 0.3499\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3820 - val_loss: 0.3496\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3815 - val_loss: 0.3494\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3810 - val_loss: 0.3491\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3805 - val_loss: 0.3489\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3799 - val_loss: 0.3486\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3795 - val_loss: 0.3484\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3790 - val_loss: 0.3481\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3785 - val_loss: 0.3479\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.3476\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3776 - val_loss: 0.3474\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3771 - val_loss: 0.3471\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3767 - val_loss: 0.3469\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3762 - val_loss: 0.3466\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3758 - val_loss: 0.3464\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3753 - val_loss: 0.3461\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3749 - val_loss: 0.3459\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3745 - val_loss: 0.3456\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3740 - val_loss: 0.3454\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3736 - val_loss: 0.3451\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 265.33452450872096, my average MASE = 56598015.30805221\n",
      "Cluster 6, 265.33452450872096\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=9, 9, 1486, (3, 67)\n",
      "Before prediction: train_X.shape=(97, 10, 67), train_y.shape=(97, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4153 - val_loss: 0.4398\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.4396\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4138 - val_loss: 0.4393\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4131 - val_loss: 0.4391\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4124 - val_loss: 0.4388\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4118 - val_loss: 0.4386\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4111 - val_loss: 0.4383\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4105 - val_loss: 0.4381\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4099 - val_loss: 0.4378\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4093 - val_loss: 0.4376\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4087 - val_loss: 0.4374\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4081 - val_loss: 0.4371\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.4369\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4069 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4064 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4058 - val_loss: 0.4362\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.4360\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4047 - val_loss: 0.4358\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4042 - val_loss: 0.4356\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4037 - val_loss: 0.4353\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4032 - val_loss: 0.4351\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4349\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4022 - val_loss: 0.4347\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4017 - val_loss: 0.4345\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4012 - val_loss: 0.4343\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4007 - val_loss: 0.4341\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4003 - val_loss: 0.4339\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3998 - val_loss: 0.4337\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3993 - val_loss: 0.4335\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3989 - val_loss: 0.4334\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3984 - val_loss: 0.4332\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3980 - val_loss: 0.4330\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3976 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3967 - val_loss: 0.4324\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3963 - val_loss: 0.4322\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4320\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3955 - val_loss: 0.4318\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3950 - val_loss: 0.4316\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.4314\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 106.62824359839709, my average MASE = 181907103.45341906\n",
      "Cluster 0, 106.62824359839709\n",
      "Before prediction: train_X.shape=(1415, 10, 67), train_y.shape=(1415, 67), test_X.shape=(472, 10, 67), test_y.shape=(472, 67)\n",
      "Epoch 1/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.1435 - val_loss: 0.0272\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1388 - val_loss: 0.0264\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1347 - val_loss: 0.0256\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1311 - val_loss: 0.0250\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1278 - val_loss: 0.0244\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1249 - val_loss: 0.0239\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1221 - val_loss: 0.0234\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1196 - val_loss: 0.0231\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.1173 - val_loss: 0.0227\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.1151 - val_loss: 0.0224\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1132 - val_loss: 0.0221\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1113 - val_loss: 0.0220\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1096 - val_loss: 0.0217\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1080 - val_loss: 0.0216\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1065 - val_loss: 0.0214\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1051 - val_loss: 0.0212\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1038 - val_loss: 0.0211\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1026 - val_loss: 0.0209\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1014 - val_loss: 0.0208\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1004 - val_loss: 0.0206\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0993 - val_loss: 0.0206\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0983 - val_loss: 0.0205\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0974 - val_loss: 0.0204\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0965 - val_loss: 0.0202\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0957 - val_loss: 0.0201\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0949 - val_loss: 0.0200\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0941 - val_loss: 0.0200\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0934 - val_loss: 0.0199\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0927 - val_loss: 0.0198\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0920 - val_loss: 0.0197\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0914 - val_loss: 0.0197\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0907 - val_loss: 0.0196\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0902 - val_loss: 0.0195\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0896 - val_loss: 0.0195\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0890 - val_loss: 0.0195\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0885 - val_loss: 0.0194\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0880 - val_loss: 0.0194\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0875 - val_loss: 0.0193\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0871 - val_loss: 0.0194\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0867 - val_loss: 0.0193\n",
      "15/15 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(472, 67), test_y.shape=(472, 67)\n",
      "average MASE = 484561401.3912065, my average MASE = 2109803098.5295365\n",
      "Cluster 1, 484561401.3912065\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4184 - val_loss: 0.4085\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4174 - val_loss: 0.4084\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4165 - val_loss: 0.4083\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4155 - val_loss: 0.4082\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4146 - val_loss: 0.4082\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4136 - val_loss: 0.4081\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4127 - val_loss: 0.4080\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4118 - val_loss: 0.4079\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4109 - val_loss: 0.4078\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4100 - val_loss: 0.4077\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4091 - val_loss: 0.4077\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4083 - val_loss: 0.4076\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4074 - val_loss: 0.4075\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4066 - val_loss: 0.4074\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4057 - val_loss: 0.4074\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4049 - val_loss: 0.4073\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4041 - val_loss: 0.4072\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4033 - val_loss: 0.4071\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4025 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4017 - val_loss: 0.4069\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4009 - val_loss: 0.4069\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4001 - val_loss: 0.4068\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3994 - val_loss: 0.4067\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3986 - val_loss: 0.4066\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3979 - val_loss: 0.4065\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3971 - val_loss: 0.4065\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3964 - val_loss: 0.4064\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3957 - val_loss: 0.4063\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3949 - val_loss: 0.4062\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3942 - val_loss: 0.4062\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3936 - val_loss: 0.4061\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3929 - val_loss: 0.4060\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3922 - val_loss: 0.4059\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4058\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3909 - val_loss: 0.4058\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3902 - val_loss: 0.4057\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3896 - val_loss: 0.4056\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3889 - val_loss: 0.4055\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3883 - val_loss: 0.4055\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3877 - val_loss: 0.4054\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 146.41485105295615, my average MASE = 90287364.09726365\n",
      "Cluster 2, 146.41485105295615\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5429 - val_loss: 0.4489\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5408 - val_loss: 0.4477\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5388 - val_loss: 0.4466\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5367 - val_loss: 0.4454\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5348 - val_loss: 0.4443\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5328 - val_loss: 0.4432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5308 - val_loss: 0.4421\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5289 - val_loss: 0.4410\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5270 - val_loss: 0.4399\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5251 - val_loss: 0.4389\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5232 - val_loss: 0.4378\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5214 - val_loss: 0.4368\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5195 - val_loss: 0.4357\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5177 - val_loss: 0.4347\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5159 - val_loss: 0.4336\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5140 - val_loss: 0.4326\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5123 - val_loss: 0.4316\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5105 - val_loss: 0.4306\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5087 - val_loss: 0.4296\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5069 - val_loss: 0.4287\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5052 - val_loss: 0.4277\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5034 - val_loss: 0.4268\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5017 - val_loss: 0.4258\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5000 - val_loss: 0.4249\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4983 - val_loss: 0.4240\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4967 - val_loss: 0.4230\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4950 - val_loss: 0.4221\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4934 - val_loss: 0.4212\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4918 - val_loss: 0.4204\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4903 - val_loss: 0.4195\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4887 - val_loss: 0.4186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.4177\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4857 - val_loss: 0.4169\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4843 - val_loss: 0.4161\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4828 - val_loss: 0.4152\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4814 - val_loss: 0.4144\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4800 - val_loss: 0.4136\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4786 - val_loss: 0.4127\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4772 - val_loss: 0.4119\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4758 - val_loss: 0.4111\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1177081/3287276626.py:67: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 10))\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3556660081.750684, my average MASE = 7865462670.190711\n",
      "Cluster 3, 3556660081.750684\n",
      "Before prediction: train_X.shape=(173, 10, 67), train_y.shape=(173, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7286 - val_loss: 0.5747\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7270 - val_loss: 0.5740\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7256 - val_loss: 0.5733\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7243 - val_loss: 0.5725\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7229 - val_loss: 0.5718\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7216 - val_loss: 0.5712\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7203 - val_loss: 0.5705\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7190 - val_loss: 0.5698\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7178 - val_loss: 0.5692\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7166 - val_loss: 0.5686\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7154 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7142 - val_loss: 0.5673\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7130 - val_loss: 0.5667\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7119 - val_loss: 0.5662\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7108 - val_loss: 0.5656\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7096 - val_loss: 0.5650\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7086 - val_loss: 0.5645\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7075 - val_loss: 0.5639\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7064 - val_loss: 0.5634\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7054 - val_loss: 0.5629\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7044 - val_loss: 0.5624\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7034 - val_loss: 0.5619\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5614\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7014 - val_loss: 0.5609\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7004 - val_loss: 0.5604\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6995 - val_loss: 0.5599\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6986 - val_loss: 0.5595\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6976 - val_loss: 0.5590\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6967 - val_loss: 0.5585\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6958 - val_loss: 0.5581\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6949 - val_loss: 0.5576\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6940 - val_loss: 0.5571\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6931 - val_loss: 0.5567\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5562\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6914 - val_loss: 0.5558\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6905 - val_loss: 0.5553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6896 - val_loss: 0.5549\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6887 - val_loss: 0.5545\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6879 - val_loss: 0.5540\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5536\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 122.19340890523425, my average MASE = 115345826.80728418\n",
      "Cluster 4, 122.19340890523425\n",
      "Before prediction: train_X.shape=(1562, 10, 67), train_y.shape=(1562, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2392 - val_loss: 0.2772\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2287 - val_loss: 0.2673\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2207 - val_loss: 0.2595\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2144 - val_loss: 0.2534\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2094 - val_loss: 0.2481\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2050 - val_loss: 0.2435\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2013 - val_loss: 0.2394\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1978 - val_loss: 0.2357\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1947 - val_loss: 0.2322\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1919 - val_loss: 0.2289\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1892 - val_loss: 0.2259\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1867 - val_loss: 0.2231\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2204\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1821 - val_loss: 0.2179\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1800 - val_loss: 0.2156\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1761 - val_loss: 0.2114\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1743 - val_loss: 0.2096\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1727 - val_loss: 0.2078\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1712 - val_loss: 0.2062\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1698 - val_loss: 0.2047\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2033\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1672 - val_loss: 0.2020\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1661 - val_loss: 0.2007\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1650 - val_loss: 0.1996\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1640 - val_loss: 0.1985\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1631 - val_loss: 0.1974\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1622 - val_loss: 0.1964\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1614 - val_loss: 0.1954\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1598 - val_loss: 0.1936\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1578 - val_loss: 0.1912\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1572 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1566 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1560 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1554 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1549 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1544 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 151.79409601094594, my average MASE = 3866050940.760538\n",
      "Cluster 5, 151.79409601094594\n",
      "Before prediction: train_X.shape=(83, 10, 67), train_y.shape=(83, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4279 - val_loss: 0.5018\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4270 - val_loss: 0.5012\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4262 - val_loss: 0.5006\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4254 - val_loss: 0.5000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4246 - val_loss: 0.4995\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4239 - val_loss: 0.4989\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4231 - val_loss: 0.4984\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4224 - val_loss: 0.4978\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4217 - val_loss: 0.4973\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4968\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4203 - val_loss: 0.4962\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4197 - val_loss: 0.4958\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4191 - val_loss: 0.4953\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4184 - val_loss: 0.4948\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4178 - val_loss: 0.4943\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4939\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4167 - val_loss: 0.4934\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4161 - val_loss: 0.4930\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4155 - val_loss: 0.4926\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4150 - val_loss: 0.4921\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4144 - val_loss: 0.4917\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4139 - val_loss: 0.4913\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4133 - val_loss: 0.4908\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4128 - val_loss: 0.4904\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4123 - val_loss: 0.4900\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4118 - val_loss: 0.4895\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4113 - val_loss: 0.4891\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4107 - val_loss: 0.4887\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4103 - val_loss: 0.4883\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4098 - val_loss: 0.4879\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4093 - val_loss: 0.4875\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4088 - val_loss: 0.4871\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4083 - val_loss: 0.4867\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4079 - val_loss: 0.4863\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4074 - val_loss: 0.4859\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4069 - val_loss: 0.4855\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4065 - val_loss: 0.4851\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4061 - val_loss: 0.4848\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4056 - val_loss: 0.4844\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4052 - val_loss: 0.4840\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 155.68618683798326, my average MASE = 97738271.39222205\n",
      "Cluster 6, 155.68618683798326\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2911 - val_loss: 0.2917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2907 - val_loss: 0.2915\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2902 - val_loss: 0.2913\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2897 - val_loss: 0.2911\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2892 - val_loss: 0.2909\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2888 - val_loss: 0.2907\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2883 - val_loss: 0.2905\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2878 - val_loss: 0.2903\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2874 - val_loss: 0.2901\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2869 - val_loss: 0.2899\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2865 - val_loss: 0.2898\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2861 - val_loss: 0.2896\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2856 - val_loss: 0.2894\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2852 - val_loss: 0.2892\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2848 - val_loss: 0.2890\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2844 - val_loss: 0.2889\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2840 - val_loss: 0.2887\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2836 - val_loss: 0.2885\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2832 - val_loss: 0.2883\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2828 - val_loss: 0.2882\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2824 - val_loss: 0.2880\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2820 - val_loss: 0.2878\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2816 - val_loss: 0.2877\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2812 - val_loss: 0.2875\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2808 - val_loss: 0.2874\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2804 - val_loss: 0.2872\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2800 - val_loss: 0.2870\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2796 - val_loss: 0.2869\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2793 - val_loss: 0.2867\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2789 - val_loss: 0.2865\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2785 - val_loss: 0.2864\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2781 - val_loss: 0.2862\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2778 - val_loss: 0.2861\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2774 - val_loss: 0.2859\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2770 - val_loss: 0.2858\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2767 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2763 - val_loss: 0.2855\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2759 - val_loss: 0.2853\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2756 - val_loss: 0.2852\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2752 - val_loss: 0.2851\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 112.24086700274312, my average MASE = 119826311.76187374\n",
      "Cluster 8, 112.24086700274312\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=11, 11, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1118 - val_loss: 0.1019\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1064 - val_loss: 0.0996\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1022 - val_loss: 0.0982\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0987 - val_loss: 0.0973\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0956 - val_loss: 0.0966\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0930 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0885 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0866 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0848 - val_loss: 0.0949\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0832 - val_loss: 0.0946\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0818 - val_loss: 0.0944\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0804 - val_loss: 0.0941\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0792 - val_loss: 0.0939\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0780 - val_loss: 0.0937\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0769 - val_loss: 0.0936\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0759 - val_loss: 0.0934\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0749 - val_loss: 0.0933\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0740 - val_loss: 0.0932\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0732 - val_loss: 0.0931\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0724 - val_loss: 0.0929\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0716 - val_loss: 0.0928\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0927\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0926\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0696 - val_loss: 0.0926\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0690 - val_loss: 0.0925\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0924\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0923\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0674 - val_loss: 0.0923\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0922\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0921\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0662 - val_loss: 0.0921\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0658 - val_loss: 0.0920\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0919\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0651 - val_loss: 0.0919\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0648 - val_loss: 0.0918\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0645 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0642 - val_loss: 0.0917\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0637 - val_loss: 0.0916\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 876211806.5152007, my average MASE = 21477700395.128197\n",
      "Cluster 0, 876211806.5152007\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7012 - val_loss: 0.5689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7001 - val_loss: 0.5688\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6990 - val_loss: 0.5687\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6979 - val_loss: 0.5686\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6968 - val_loss: 0.5685\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6958 - val_loss: 0.5684\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6947 - val_loss: 0.5683\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6936 - val_loss: 0.5682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6926 - val_loss: 0.5681\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6916 - val_loss: 0.5680\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6906 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6896 - val_loss: 0.5678\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6887 - val_loss: 0.5677\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6877 - val_loss: 0.5676\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6868 - val_loss: 0.5675\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6859 - val_loss: 0.5674\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6849 - val_loss: 0.5673\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6840 - val_loss: 0.5672\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6831 - val_loss: 0.5671\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6822 - val_loss: 0.5670\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6813 - val_loss: 0.5669\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6805 - val_loss: 0.5668\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6796 - val_loss: 0.5667\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6787 - val_loss: 0.5666\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6779 - val_loss: 0.5665\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6771 - val_loss: 0.5665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6762 - val_loss: 0.5664\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6754 - val_loss: 0.5663\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6746 - val_loss: 0.5662\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6738 - val_loss: 0.5661\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6730 - val_loss: 0.5660\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6722 - val_loss: 0.5659\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6715 - val_loss: 0.5658\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6707 - val_loss: 0.5657\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6699 - val_loss: 0.5656\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6691 - val_loss: 0.5655\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6684 - val_loss: 0.5654\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6676 - val_loss: 0.5653\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6668 - val_loss: 0.5652\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6661 - val_loss: 0.5651\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1104923.1929255812, my average MASE = 35973487.14565515\n",
      "Cluster 1, 1104923.1929255812\n",
      "Before prediction: train_X.shape=(134, 10, 67), train_y.shape=(134, 67), test_X.shape=(45, 10, 67), test_y.shape=(45, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4388 - val_loss: 0.7635\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4381 - val_loss: 0.7630\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4375 - val_loss: 0.7625\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4369 - val_loss: 0.7620\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4363 - val_loss: 0.7616\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4358 - val_loss: 0.7611\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4353 - val_loss: 0.7607\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4348 - val_loss: 0.7603\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4343 - val_loss: 0.7598\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4338 - val_loss: 0.7594\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4333 - val_loss: 0.7590\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4328 - val_loss: 0.7585\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4323 - val_loss: 0.7581\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4318 - val_loss: 0.7576\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4314 - val_loss: 0.7572\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4309 - val_loss: 0.7568\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4305 - val_loss: 0.7564\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4301 - val_loss: 0.7561\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4296 - val_loss: 0.7557\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4292 - val_loss: 0.7554\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4288 - val_loss: 0.7550\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4284 - val_loss: 0.7546\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4280 - val_loss: 0.7543\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4276 - val_loss: 0.7539\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4272 - val_loss: 0.7535\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4268 - val_loss: 0.7532\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4264 - val_loss: 0.7528\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4260 - val_loss: 0.7525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4257 - val_loss: 0.7521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4253 - val_loss: 0.7517\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4249 - val_loss: 0.7514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4245 - val_loss: 0.7511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4242 - val_loss: 0.7508\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4238 - val_loss: 0.7505\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4235 - val_loss: 0.7502\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4231 - val_loss: 0.7499\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4228 - val_loss: 0.7496\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4225 - val_loss: 0.7492\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4221 - val_loss: 0.7489\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4218 - val_loss: 0.7486\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(45, 67), test_y.shape=(45, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 134.01886625392066, my average MASE = 180554408.61752364\n",
      "Cluster 2, 134.01886625392066\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3365 - val_loss: 0.4571\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3346 - val_loss: 0.4566\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3328 - val_loss: 0.4560\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.4555\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3293 - val_loss: 0.4550\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.4544\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3260 - val_loss: 0.4539\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.4534\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3229 - val_loss: 0.4528\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3213 - val_loss: 0.4523\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3197 - val_loss: 0.4518\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3182 - val_loss: 0.4512\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3166 - val_loss: 0.4507\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3152 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3137 - val_loss: 0.4496\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3123 - val_loss: 0.4490\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3109 - val_loss: 0.4485\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3095 - val_loss: 0.4479\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3082 - val_loss: 0.4473\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3070 - val_loss: 0.4468\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3058 - val_loss: 0.4462\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3045 - val_loss: 0.4456\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.4450\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3021 - val_loss: 0.4444\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3009 - val_loss: 0.4438\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2998 - val_loss: 0.4432\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2986 - val_loss: 0.4426\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2974 - val_loss: 0.4420\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2963 - val_loss: 0.4414\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2952 - val_loss: 0.4407\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2940 - val_loss: 0.4401\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2929 - val_loss: 0.4395\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.4389\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2907 - val_loss: 0.4384\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2896 - val_loss: 0.4379\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2885 - val_loss: 0.4373\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2875 - val_loss: 0.4369\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2865 - val_loss: 0.4364\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2854 - val_loss: 0.4359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2844 - val_loss: 0.4355\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.28495017155315366, my average MASE = 0.3992586255016426\n",
      "Cluster 3, 0.28495017155315366\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6320 - val_loss: 1.0222\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6307 - val_loss: 1.0218\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 1.0214\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6284 - val_loss: 1.0211\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6273 - val_loss: 1.0208\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6262 - val_loss: 1.0205\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6252 - val_loss: 1.0201\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6241 - val_loss: 1.0198\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6231 - val_loss: 1.0195\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6221 - val_loss: 1.0192\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6212 - val_loss: 1.0188\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6202 - val_loss: 1.0185\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6193 - val_loss: 1.0182\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6183 - val_loss: 1.0179\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6174 - val_loss: 1.0176\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6166 - val_loss: 1.0172\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6157 - val_loss: 1.0169\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6148 - val_loss: 1.0166\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6139 - val_loss: 1.0162\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6131 - val_loss: 1.0159\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6122 - val_loss: 1.0155\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6114 - val_loss: 1.0152\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6106 - val_loss: 1.0148\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6097 - val_loss: 1.0145\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6089 - val_loss: 1.0141\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6081 - val_loss: 1.0138\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6073 - val_loss: 1.0134\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6066 - val_loss: 1.0131\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6057 - val_loss: 1.0127\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6050 - val_loss: 1.0124\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6042 - val_loss: 1.0121\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6035 - val_loss: 1.0118\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6027 - val_loss: 1.0114\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6020 - val_loss: 1.0111\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6013 - val_loss: 1.0108\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6005 - val_loss: 1.0104\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5998 - val_loss: 1.0101\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5991 - val_loss: 1.0098\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5984 - val_loss: 1.0094\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5977 - val_loss: 1.0091\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 98.33747704062574, my average MASE = 204772160.73570046\n",
      "Cluster 4, 98.33747704062574\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4785 - val_loss: 0.4645\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4760 - val_loss: 0.4629\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4734 - val_loss: 0.4612\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4709 - val_loss: 0.4596\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4684 - val_loss: 0.4580\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4661 - val_loss: 0.4564\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4638 - val_loss: 0.4548\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4615 - val_loss: 0.4532\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4593 - val_loss: 0.4516\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4572 - val_loss: 0.4500\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4551 - val_loss: 0.4484\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4530 - val_loss: 0.4468\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4509 - val_loss: 0.4453\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4489 - val_loss: 0.4438\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4469 - val_loss: 0.4422\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4449 - val_loss: 0.4407\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4429 - val_loss: 0.4393\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4410 - val_loss: 0.4380\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4391 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4371 - val_loss: 0.4354\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4353 - val_loss: 0.4343\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4335 - val_loss: 0.4332\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4317 - val_loss: 0.4322\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4300 - val_loss: 0.4311\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4282 - val_loss: 0.4301\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4265 - val_loss: 0.4291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4248 - val_loss: 0.4281\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 0.4270\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4197 - val_loss: 0.4250\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4181 - val_loss: 0.4240\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4165 - val_loss: 0.4229\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4149 - val_loss: 0.4218\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4134 - val_loss: 0.4208\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4118 - val_loss: 0.4197\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4103 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4088 - val_loss: 0.4176\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.4167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4060 - val_loss: 0.4157\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4046 - val_loss: 0.4148\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 931833756.986838, my average MASE = 2420970654.4710827\n",
      "Cluster 5, 931833756.986838\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4346 - val_loss: 0.4628\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4334 - val_loss: 0.4625\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4323 - val_loss: 0.4621\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4312 - val_loss: 0.4618\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4301 - val_loss: 0.4615\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4290 - val_loss: 0.4612\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4280 - val_loss: 0.4609\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4269 - val_loss: 0.4605\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4259 - val_loss: 0.4602\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4249 - val_loss: 0.4599\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4239 - val_loss: 0.4596\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4228 - val_loss: 0.4593\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4218 - val_loss: 0.4590\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4208 - val_loss: 0.4587\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4198 - val_loss: 0.4584\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4188 - val_loss: 0.4582\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4179 - val_loss: 0.4579\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4169 - val_loss: 0.4576\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4160 - val_loss: 0.4573\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4151 - val_loss: 0.4570\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4141 - val_loss: 0.4567\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4132 - val_loss: 0.4564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4123 - val_loss: 0.4561\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4114 - val_loss: 0.4558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4106 - val_loss: 0.4555\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4097 - val_loss: 0.4552\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4089 - val_loss: 0.4549\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4080 - val_loss: 0.4546\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4072 - val_loss: 0.4544\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4063 - val_loss: 0.4541\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4055 - val_loss: 0.4538\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4047 - val_loss: 0.4536\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4039 - val_loss: 0.4533\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4031 - val_loss: 0.4531\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4023 - val_loss: 0.4529\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4015 - val_loss: 0.4527\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4007 - val_loss: 0.4526\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3999 - val_loss: 0.4524\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3991 - val_loss: 0.4522\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3983 - val_loss: 0.4520\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 806621.4868706047, my average MASE = 27017424.126969155\n",
      "Cluster 6, 806621.4868706047\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8616 - val_loss: 0.8556\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8588 - val_loss: 0.8539\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8561 - val_loss: 0.8522\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8534 - val_loss: 0.8505\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8508 - val_loss: 0.8489\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8484 - val_loss: 0.8472\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8459 - val_loss: 0.8456\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8435 - val_loss: 0.8440\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8412 - val_loss: 0.8424\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8389 - val_loss: 0.8408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8366 - val_loss: 0.8392\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8343 - val_loss: 0.8376\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8320 - val_loss: 0.8361\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8298 - val_loss: 0.8345\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8276 - val_loss: 0.8329\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8254 - val_loss: 0.8314\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8232 - val_loss: 0.8298\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8210 - val_loss: 0.8283\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 0.8267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8168 - val_loss: 0.8253\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8146 - val_loss: 0.8238\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8125 - val_loss: 0.8224\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8104 - val_loss: 0.8210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8084 - val_loss: 0.8197\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8064 - val_loss: 0.8184\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8045 - val_loss: 0.8170\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8025 - val_loss: 0.8157\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8006 - val_loss: 0.8143\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7987 - val_loss: 0.8129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7969 - val_loss: 0.8115\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7950 - val_loss: 0.8102\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7932 - val_loss: 0.8089\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7913 - val_loss: 0.8077\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7894 - val_loss: 0.8065\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7876 - val_loss: 0.8053\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7857 - val_loss: 0.8041\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7839 - val_loss: 0.8030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7821 - val_loss: 0.8019\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7803 - val_loss: 0.8008\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7785 - val_loss: 0.7997\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 964635493.0745914, my average MASE = 2107611139.389815\n",
      "Cluster 7, 964635493.0745914\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3952 - val_loss: 0.3689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3946 - val_loss: 0.3689\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3941 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3935 - val_loss: 0.3687\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3930 - val_loss: 0.3687\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3924 - val_loss: 0.3686\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3919 - val_loss: 0.3685\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3914 - val_loss: 0.3685\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3909 - val_loss: 0.3684\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3903 - val_loss: 0.3684\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3898 - val_loss: 0.3683\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3893 - val_loss: 0.3682\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3888 - val_loss: 0.3682\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3883 - val_loss: 0.3681\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3878 - val_loss: 0.3680\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3873 - val_loss: 0.3680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3869 - val_loss: 0.3679\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3864 - val_loss: 0.3679\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3855 - val_loss: 0.3677\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3850 - val_loss: 0.3677\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3845 - val_loss: 0.3676\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3841 - val_loss: 0.3676\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3836 - val_loss: 0.3675\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3832 - val_loss: 0.3674\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3828 - val_loss: 0.3674\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3823 - val_loss: 0.3673\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3819 - val_loss: 0.3673\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3815 - val_loss: 0.3672\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3811 - val_loss: 0.3672\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3806 - val_loss: 0.3671\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3802 - val_loss: 0.3670\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3798 - val_loss: 0.3670\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.3669\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3790 - val_loss: 0.3669\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3786 - val_loss: 0.3668\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3782 - val_loss: 0.3668\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3778 - val_loss: 0.3667\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3774 - val_loss: 0.3666\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3770 - val_loss: 0.3666\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 51.171495934252626, my average MASE = 30811708.472042836\n",
      "Cluster 8, 51.171495934252626\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4416 - val_loss: 0.4387\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4409 - val_loss: 0.4386\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4402 - val_loss: 0.4384\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4395 - val_loss: 0.4383\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4388 - val_loss: 0.4381\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4382 - val_loss: 0.4380\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4375 - val_loss: 0.4379\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4368 - val_loss: 0.4377\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4362 - val_loss: 0.4376\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4355 - val_loss: 0.4375\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4348 - val_loss: 0.4373\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4342 - val_loss: 0.4372\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4335 - val_loss: 0.4371\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4329 - val_loss: 0.4370\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4323 - val_loss: 0.4368\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4316 - val_loss: 0.4367\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4310 - val_loss: 0.4366\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4304 - val_loss: 0.4365\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4298 - val_loss: 0.4364\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4292 - val_loss: 0.4363\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4286 - val_loss: 0.4362\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4280 - val_loss: 0.4361\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4274 - val_loss: 0.4359\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4268 - val_loss: 0.4358\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4262 - val_loss: 0.4357\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4256 - val_loss: 0.4356\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4250 - val_loss: 0.4355\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4245 - val_loss: 0.4354\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4239 - val_loss: 0.4353\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4352\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4227 - val_loss: 0.4351\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4221 - val_loss: 0.4350\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.4349\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4348\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4204 - val_loss: 0.4347\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4199 - val_loss: 0.4346\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4193 - val_loss: 0.4345\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4187 - val_loss: 0.4345\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4182 - val_loss: 0.4344\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4176 - val_loss: 0.4343\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 67.68630348587587, my average MASE = 34346224.36796317\n",
      "Cluster 9, 67.68630348587587\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=2, 2, 18, (30610, 67)\n",
      "Before prediction: train_X.shape=(18359, 10, 67), train_y.shape=(18359, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3046 - val_loss: 0.3213\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2853 - val_loss: 0.3058\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2698 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2588 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2516 - val_loss: 0.2788\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2460 - val_loss: 0.2736\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2412 - val_loss: 0.2691\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2371 - val_loss: 0.2652\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2335 - val_loss: 0.2618\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2301 - val_loss: 0.2588\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2271 - val_loss: 0.2562\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2243 - val_loss: 0.2538\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2219 - val_loss: 0.2516\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2199 - val_loss: 0.2498\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2181 - val_loss: 0.2483\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2166 - val_loss: 0.2469\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2153 - val_loss: 0.2458\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2142 - val_loss: 0.2448\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2122 - val_loss: 0.2430\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2114 - val_loss: 0.2422\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2106 - val_loss: 0.2414\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2099 - val_loss: 0.2407\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2092 - val_loss: 0.2401\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2086 - val_loss: 0.2395\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2080 - val_loss: 0.2389\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2074 - val_loss: 0.2385\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2069 - val_loss: 0.2380\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2064 - val_loss: 0.2376\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2059 - val_loss: 0.2370\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2054 - val_loss: 0.2367\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2050 - val_loss: 0.2362\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2046 - val_loss: 0.2359\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2042 - val_loss: 0.2356\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2038 - val_loss: 0.2351\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2034 - val_loss: 0.2349\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2031 - val_loss: 0.2345\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2021 - val_loss: 0.2337\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1675.644817755528, my average MASE = 2652.7812514268226\n",
      "Cluster 0, 1675.644817755528\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4228 - val_loss: 1.1321\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4209 - val_loss: 1.1320\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4191 - val_loss: 1.1319\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4173 - val_loss: 1.1318\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 1.1317\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4139 - val_loss: 1.1315\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4122 - val_loss: 1.1314\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4106 - val_loss: 1.1313\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4090 - val_loss: 1.1311\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4075 - val_loss: 1.1310\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4059 - val_loss: 1.1308\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4044 - val_loss: 1.1306\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4030 - val_loss: 1.1304\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4015 - val_loss: 1.1302\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4001 - val_loss: 1.1300\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 1.1298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3973 - val_loss: 1.1296\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3960 - val_loss: 1.1294\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3946 - val_loss: 1.1292\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3933 - val_loss: 1.1290\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 1.1288\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3907 - val_loss: 1.1286\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3895 - val_loss: 1.1283\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3883 - val_loss: 1.1281\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3871 - val_loss: 1.1279\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 1.1277\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3847 - val_loss: 1.1275\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3836 - val_loss: 1.1272\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3825 - val_loss: 1.1270\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3814 - val_loss: 1.1268\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3803 - val_loss: 1.1266\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3792 - val_loss: 1.1264\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3781 - val_loss: 1.1262\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3771 - val_loss: 1.1259\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3761 - val_loss: 1.1257\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3750 - val_loss: 1.1255\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3740 - val_loss: 1.1253\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 1.1251\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3721 - val_loss: 1.1249\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3711 - val_loss: 1.1247\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 993839931.13901, my average MASE = 2723871222.022616\n",
      "Cluster 1, 993839931.13901\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=5, 5, 75, (319, 67)\n",
      "Before prediction: train_X.shape=(185, 10, 67), train_y.shape=(185, 67), test_X.shape=(62, 10, 67), test_y.shape=(62, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6944 - val_loss: 0.6444\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6929 - val_loss: 0.6434\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6914 - val_loss: 0.6425\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6901 - val_loss: 0.6415\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6887 - val_loss: 0.6406\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6874 - val_loss: 0.6397\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6860 - val_loss: 0.6388\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6847 - val_loss: 0.6380\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6834 - val_loss: 0.6372\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6822 - val_loss: 0.6363\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6810 - val_loss: 0.6355\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6798 - val_loss: 0.6347\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.6340\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6775 - val_loss: 0.6332\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.6325\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6753 - val_loss: 0.6318\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6742 - val_loss: 0.6310\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6732 - val_loss: 0.6303\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6721 - val_loss: 0.6296\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6711 - val_loss: 0.6289\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6701 - val_loss: 0.6283\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6692 - val_loss: 0.6276\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6682 - val_loss: 0.6270\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6672 - val_loss: 0.6263\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6663 - val_loss: 0.6257\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6654 - val_loss: 0.6251\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.6244\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6636 - val_loss: 0.6238\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6627 - val_loss: 0.6232\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6618 - val_loss: 0.6226\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6610 - val_loss: 0.6220\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6601 - val_loss: 0.6214\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6593 - val_loss: 0.6208\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6584 - val_loss: 0.6202\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6576 - val_loss: 0.6196\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6568 - val_loss: 0.6191\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6559 - val_loss: 0.6185\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6551 - val_loss: 0.6179\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6543 - val_loss: 0.6173\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6535 - val_loss: 0.6167\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(62, 67), test_y.shape=(62, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 141.38884780958514, my average MASE = 173942620.82410374\n",
      "Cluster 0, 141.38884780958514\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0665 - val_loss: 0.0455\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0607 - val_loss: 0.0424\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0575 - val_loss: 0.0402\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0551 - val_loss: 0.0384\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0531 - val_loss: 0.0370\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0515 - val_loss: 0.0358\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0502 - val_loss: 0.0347\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0491 - val_loss: 0.0338\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0481 - val_loss: 0.0331\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0473 - val_loss: 0.0324\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0466 - val_loss: 0.0319\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0460 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0454 - val_loss: 0.0311\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0449 - val_loss: 0.0307\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0304\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0301\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0437 - val_loss: 0.0299\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0433 - val_loss: 0.0297\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0294\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0292\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0424 - val_loss: 0.0290\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0422 - val_loss: 0.0288\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0420 - val_loss: 0.0287\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0418 - val_loss: 0.0285\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0416 - val_loss: 0.0284\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0414 - val_loss: 0.0283\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0412 - val_loss: 0.0281\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0411 - val_loss: 0.0280\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0279\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0278\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0278\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0277\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0276\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0403 - val_loss: 0.0276\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0275\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0401 - val_loss: 0.0274\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0274\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0273\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0273\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0272\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1157555182.6490364, my average MASE = 73085160895.13536\n",
      "Cluster 1, 1157555182.6490364\n",
      "Before prediction: train_X.shape=(37, 10, 67), train_y.shape=(37, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5516 - val_loss: 0.5380\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5498 - val_loss: 0.5365\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5480 - val_loss: 0.5350\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5462 - val_loss: 0.5335\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5444 - val_loss: 0.5321\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5427 - val_loss: 0.5306\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5410 - val_loss: 0.5292\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5393 - val_loss: 0.5278\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5376 - val_loss: 0.5264\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5360 - val_loss: 0.5250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5343 - val_loss: 0.5237\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5328 - val_loss: 0.5223\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5312 - val_loss: 0.5210\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5297 - val_loss: 0.5197\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5281 - val_loss: 0.5184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5266 - val_loss: 0.5171\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5252 - val_loss: 0.5158\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5237 - val_loss: 0.5146\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5223 - val_loss: 0.5133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5208 - val_loss: 0.5121\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5194 - val_loss: 0.5109\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5181 - val_loss: 0.5098\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5167 - val_loss: 0.5086\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5154 - val_loss: 0.5075\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5141 - val_loss: 0.5063\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5128 - val_loss: 0.5052\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5115 - val_loss: 0.5041\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5103 - val_loss: 0.5031\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5091 - val_loss: 0.5020\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5078 - val_loss: 0.5010\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.5000\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5055 - val_loss: 0.4990\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5043 - val_loss: 0.4980\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5031 - val_loss: 0.4970\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5020 - val_loss: 0.4961\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5008 - val_loss: 0.4952\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.4943\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4986 - val_loss: 0.4934\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4975 - val_loss: 0.4926\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4964 - val_loss: 0.4917\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4324881186.205308, my average MASE = 10393885205.318085\n",
      "Cluster 2, 4324881186.205308\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4066 - val_loss: 0.3845\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4060 - val_loss: 0.3840\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.3836\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4048 - val_loss: 0.3831\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4042 - val_loss: 0.3826\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4036 - val_loss: 0.3822\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 0.3817\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4025 - val_loss: 0.3812\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4019 - val_loss: 0.3808\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4014 - val_loss: 0.3803\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3799\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4003 - val_loss: 0.3795\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3791\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3992 - val_loss: 0.3787\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 0.3783\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3982 - val_loss: 0.3779\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3977 - val_loss: 0.3775\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.3772\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3966 - val_loss: 0.3768\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3764\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3956 - val_loss: 0.3761\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3757\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3946 - val_loss: 0.3754\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3942 - val_loss: 0.3751\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3937 - val_loss: 0.3747\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3932 - val_loss: 0.3744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3927 - val_loss: 0.3741\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3922 - val_loss: 0.3738\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3918 - val_loss: 0.3735\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3913 - val_loss: 0.3732\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3908 - val_loss: 0.3729\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3903 - val_loss: 0.3726\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.3723\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3894 - val_loss: 0.3720\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3890 - val_loss: 0.3718\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3885 - val_loss: 0.3715\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3881 - val_loss: 0.3712\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3877 - val_loss: 0.3709\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3872 - val_loss: 0.3706\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3868 - val_loss: 0.3704\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n",
      "average MASE = 1110146.2653270473, my average MASE = 43278995.990564056\n",
      "Cluster 3, 1110146.2653270473\n",
      "Before prediction: train_X.shape=(25, 10, 67), train_y.shape=(25, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5208 - val_loss: 0.4711\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5196 - val_loss: 0.4707\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5184 - val_loss: 0.4702\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5173 - val_loss: 0.4698\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5161 - val_loss: 0.4694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5150 - val_loss: 0.4690\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4686\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5127 - val_loss: 0.4682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5116 - val_loss: 0.4678\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5105 - val_loss: 0.4675\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5094 - val_loss: 0.4671\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5084 - val_loss: 0.4667\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5073 - val_loss: 0.4664\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5063 - val_loss: 0.4660\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5052 - val_loss: 0.4657\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5042 - val_loss: 0.4654\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5031 - val_loss: 0.4651\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4648\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5011 - val_loss: 0.4645\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5001 - val_loss: 0.4643\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4991 - val_loss: 0.4641\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.4638\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4971 - val_loss: 0.4636\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4962 - val_loss: 0.4634\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.4632\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4942 - val_loss: 0.4629\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4933 - val_loss: 0.4627\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4923 - val_loss: 0.4625\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4914 - val_loss: 0.4623\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4904 - val_loss: 0.4621\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4895 - val_loss: 0.4619\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4886 - val_loss: 0.4617\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4876 - val_loss: 0.4616\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4867 - val_loss: 0.4614\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4858 - val_loss: 0.4613\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4849 - val_loss: 0.4611\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4841 - val_loss: 0.4610\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4608\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4823 - val_loss: 0.4607\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4815 - val_loss: 0.4605\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 111.6892159594304, my average MASE = 112347014.53903662\n",
      "Cluster 4, 111.6892159594304\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=7, 7, 884, (12, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0672 - val_loss: 0.0440\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0611 - val_loss: 0.0410\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0576 - val_loss: 0.0390\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0552 - val_loss: 0.0374\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0533 - val_loss: 0.0361\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0517 - val_loss: 0.0350\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0504 - val_loss: 0.0340\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0493 - val_loss: 0.0332\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0484 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0476 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0469 - val_loss: 0.0313\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0462 - val_loss: 0.0308\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0457 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0447 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0442 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0435 - val_loss: 0.0287\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0285\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0283\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0281\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0280\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0278\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0277\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0275\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0274\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0273\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0411 - val_loss: 0.0271\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0270\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0408 - val_loss: 0.0269\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0268\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0267\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0405 - val_loss: 0.0266\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0403 - val_loss: 0.0265\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0401 - val_loss: 0.0264\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0263\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0399 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1103404601.9868512, my average MASE = 55700347192.937294\n",
      "Cluster 1, 1103404601.9868512\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5205 - val_loss: 0.4218\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5186 - val_loss: 0.4208\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5167 - val_loss: 0.4198\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5148 - val_loss: 0.4189\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5129 - val_loss: 0.4179\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5111 - val_loss: 0.4170\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5093 - val_loss: 0.4161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5074 - val_loss: 0.4152\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5057 - val_loss: 0.4143\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5039 - val_loss: 0.4134\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5022 - val_loss: 0.4125\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5004 - val_loss: 0.4117\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4987 - val_loss: 0.4108\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4971 - val_loss: 0.4100\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4954 - val_loss: 0.4092\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4938 - val_loss: 0.4083\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4922 - val_loss: 0.4075\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4906 - val_loss: 0.4067\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4890 - val_loss: 0.4060\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4875 - val_loss: 0.4052\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4860 - val_loss: 0.4044\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4845 - val_loss: 0.4036\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4830 - val_loss: 0.4028\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4815 - val_loss: 0.4021\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4800 - val_loss: 0.4013\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4771 - val_loss: 0.3999\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4757 - val_loss: 0.3992\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4743 - val_loss: 0.3985\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4730 - val_loss: 0.3978\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4716 - val_loss: 0.3971\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4703 - val_loss: 0.3964\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4689 - val_loss: 0.3958\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.3951\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.3945\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4650 - val_loss: 0.3939\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4637 - val_loss: 0.3932\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4625 - val_loss: 0.3926\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4612 - val_loss: 0.3920\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4600 - val_loss: 0.3913\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3560489905.356454, my average MASE = 9030960108.787361\n",
      "Cluster 2, 3560489905.356454\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3774 - val_loss: 0.3465\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3767 - val_loss: 0.3460\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3759 - val_loss: 0.3456\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3752 - val_loss: 0.3452\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3744 - val_loss: 0.3448\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3737 - val_loss: 0.3444\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 0.3440\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3723 - val_loss: 0.3436\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3716 - val_loss: 0.3432\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3710 - val_loss: 0.3429\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3703 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3696 - val_loss: 0.3421\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.3418\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3683 - val_loss: 0.3415\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3411\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3671 - val_loss: 0.3408\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3665 - val_loss: 0.3405\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3659 - val_loss: 0.3401\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3653 - val_loss: 0.3398\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3647 - val_loss: 0.3395\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3641 - val_loss: 0.3392\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3635 - val_loss: 0.3389\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3630 - val_loss: 0.3386\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.3383\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.3380\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3613 - val_loss: 0.3377\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3608 - val_loss: 0.3374\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3602 - val_loss: 0.3371\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3597 - val_loss: 0.3368\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3592 - val_loss: 0.3365\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3362\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3581 - val_loss: 0.3359\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3576 - val_loss: 0.3356\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3571 - val_loss: 0.3353\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3566 - val_loss: 0.3350\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3561 - val_loss: 0.3347\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3556 - val_loss: 0.3344\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3551 - val_loss: 0.3342\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3546 - val_loss: 0.3339\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3541 - val_loss: 0.3336\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 332.8608286989534, my average MASE = 85442913.95523748\n",
      "Cluster 3, 332.8608286989534\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7187 - val_loss: 0.5712\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7172 - val_loss: 0.5706\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7158 - val_loss: 0.5700\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7145 - val_loss: 0.5694\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7132 - val_loss: 0.5688\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7119 - val_loss: 0.5682\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7107 - val_loss: 0.5677\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7095 - val_loss: 0.5671\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7083 - val_loss: 0.5666\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7071 - val_loss: 0.5660\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7060 - val_loss: 0.5655\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7049 - val_loss: 0.5650\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7038 - val_loss: 0.5646\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7028 - val_loss: 0.5641\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7018 - val_loss: 0.5636\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7008 - val_loss: 0.5631\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6999 - val_loss: 0.5627\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6989 - val_loss: 0.5622\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6980 - val_loss: 0.5618\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6971 - val_loss: 0.5613\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5609\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6953 - val_loss: 0.5604\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6944 - val_loss: 0.5600\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6935 - val_loss: 0.5596\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6927 - val_loss: 0.5592\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6918 - val_loss: 0.5587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6910 - val_loss: 0.5583\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6902 - val_loss: 0.5579\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6894 - val_loss: 0.5576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6886 - val_loss: 0.5572\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6878 - val_loss: 0.5568\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5564\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6862 - val_loss: 0.5560\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6854 - val_loss: 0.5557\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6846 - val_loss: 0.5553\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6839 - val_loss: 0.5549\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6831 - val_loss: 0.5546\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6824 - val_loss: 0.5542\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6816 - val_loss: 0.5538\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6809 - val_loss: 0.5535\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.45484282658396, my average MASE = 350849744.5231373\n",
      "Cluster 4, 139.45484282658396\n",
      "Before prediction: train_X.shape=(133, 10, 67), train_y.shape=(133, 67), test_X.shape=(44, 10, 67), test_y.shape=(44, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4266 - val_loss: 0.6651\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4259 - val_loss: 0.6645\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4253 - val_loss: 0.6639\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4247 - val_loss: 0.6633\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4242 - val_loss: 0.6628\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4236 - val_loss: 0.6623\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4231 - val_loss: 0.6618\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4226 - val_loss: 0.6613\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4221 - val_loss: 0.6608\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4216 - val_loss: 0.6603\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4211 - val_loss: 0.6599\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4206 - val_loss: 0.6594\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4201 - val_loss: 0.6590\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4197 - val_loss: 0.6585\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4192 - val_loss: 0.6581\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4188 - val_loss: 0.6576\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4184 - val_loss: 0.6572\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4180 - val_loss: 0.6568\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4175 - val_loss: 0.6564\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4171 - val_loss: 0.6559\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4167 - val_loss: 0.6554\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4163 - val_loss: 0.6550\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4159 - val_loss: 0.6545\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4155 - val_loss: 0.6541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4151 - val_loss: 0.6537\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4147 - val_loss: 0.6533\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4143 - val_loss: 0.6529\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4139 - val_loss: 0.6525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4135 - val_loss: 0.6521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4131 - val_loss: 0.6518\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4128 - val_loss: 0.6514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4124 - val_loss: 0.6511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4120 - val_loss: 0.6507\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4117 - val_loss: 0.6504\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4114 - val_loss: 0.6501\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4110 - val_loss: 0.6498\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4107 - val_loss: 0.6494\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4103 - val_loss: 0.6491\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4100 - val_loss: 0.6487\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4096 - val_loss: 0.6484\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(44, 67), test_y.shape=(44, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 116.65244791791511, my average MASE = 142786035.78420427\n",
      "Cluster 5, 116.65244791791511\n",
      "Before prediction: train_X.shape=(78, 10, 67), train_y.shape=(78, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4078 - val_loss: 0.4868\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4070 - val_loss: 0.4862\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4062 - val_loss: 0.4856\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4055 - val_loss: 0.4850\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4048 - val_loss: 0.4845\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4041 - val_loss: 0.4839\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.4833\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4828\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4021 - val_loss: 0.4823\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4015 - val_loss: 0.4818\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4008 - val_loss: 0.4813\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4002 - val_loss: 0.4808\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3997 - val_loss: 0.4803\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3991 - val_loss: 0.4798\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3985 - val_loss: 0.4794\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3980 - val_loss: 0.4789\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3974 - val_loss: 0.4785\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3969 - val_loss: 0.4780\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3964 - val_loss: 0.4776\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4772\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3954 - val_loss: 0.4768\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3949 - val_loss: 0.4764\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3944 - val_loss: 0.4760\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.4757\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3934 - val_loss: 0.4753\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3930 - val_loss: 0.4750\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3925 - val_loss: 0.4747\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3921 - val_loss: 0.4743\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3916 - val_loss: 0.4740\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3912 - val_loss: 0.4737\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3907 - val_loss: 0.4733\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3903 - val_loss: 0.4730\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.4727\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3895 - val_loss: 0.4724\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3890 - val_loss: 0.4721\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3886 - val_loss: 0.4718\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4715\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3878 - val_loss: 0.4712\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.4709\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3870 - val_loss: 0.4706\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 221.65144919995234, my average MASE = 102271349.10812314\n",
      "Cluster 6, 221.65144919995234\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=9, 9, 14, (3245, 67)\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1141 - val_loss: 0.1031\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1086 - val_loss: 0.1010\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1042 - val_loss: 0.0995\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1005 - val_loss: 0.0982\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0973 - val_loss: 0.0973\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0945 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0920 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0897 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0877 - val_loss: 0.0950\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0858 - val_loss: 0.0947\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0841 - val_loss: 0.0943\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0826 - val_loss: 0.0941\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0812 - val_loss: 0.0938\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0798 - val_loss: 0.0935\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0786 - val_loss: 0.0933\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0930\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0765 - val_loss: 0.0928\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0755 - val_loss: 0.0926\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0746 - val_loss: 0.0925\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0737 - val_loss: 0.0923\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0729 - val_loss: 0.0921\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0722 - val_loss: 0.0920\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0715 - val_loss: 0.0919\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0708 - val_loss: 0.0917\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0916\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0915\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0691 - val_loss: 0.0914\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0686 - val_loss: 0.0913\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0681 - val_loss: 0.0912\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0676 - val_loss: 0.0911\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0910\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0668 - val_loss: 0.0910\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0664 - val_loss: 0.0909\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0660 - val_loss: 0.0909\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0656 - val_loss: 0.0908\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0653 - val_loss: 0.0908\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0650 - val_loss: 0.0907\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0647 - val_loss: 0.0907\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0644 - val_loss: 0.0907\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0906\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1289233887.8234715, my average MASE = 15636865244.557127\n",
      "Cluster 0, 1289233887.8234715\n",
      "Before prediction: train_X.shape=(29, 10, 67), train_y.shape=(29, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4693 - val_loss: 0.6570\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4687 - val_loss: 0.6567\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4680 - val_loss: 0.6563\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4674 - val_loss: 0.6560\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4668 - val_loss: 0.6557\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4662 - val_loss: 0.6554\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4656 - val_loss: 0.6551\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4650 - val_loss: 0.6548\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4644 - val_loss: 0.6545\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4638 - val_loss: 0.6542\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4633 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4627 - val_loss: 0.6536\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4621 - val_loss: 0.6533\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.6530\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4610 - val_loss: 0.6527\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4605 - val_loss: 0.6524\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4599 - val_loss: 0.6521\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4594 - val_loss: 0.6519\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4588 - val_loss: 0.6516\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4583 - val_loss: 0.6513\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4578 - val_loss: 0.6510\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4573 - val_loss: 0.6508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4568 - val_loss: 0.6505\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4563 - val_loss: 0.6502\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4558 - val_loss: 0.6499\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4553 - val_loss: 0.6496\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4548 - val_loss: 0.6493\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4543 - val_loss: 0.6491\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4538 - val_loss: 0.6488\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4533 - val_loss: 0.6485\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4528 - val_loss: 0.6483\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4524 - val_loss: 0.6480\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4519 - val_loss: 0.6478\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4514 - val_loss: 0.6475\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4510 - val_loss: 0.6473\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4505 - val_loss: 0.6470\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4500 - val_loss: 0.6468\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4496 - val_loss: 0.6465\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4492 - val_loss: 0.6463\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.6460\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 10049120.449906044, my average MASE = 246733533.9412494\n",
      "Cluster 1, 10049120.449906044\n",
      "Before prediction: train_X.shape=(1564, 10, 67), train_y.shape=(1564, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2359 - val_loss: 0.2748\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2264 - val_loss: 0.2656\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2192 - val_loss: 0.2584\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2135 - val_loss: 0.2523\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2087 - val_loss: 0.2471\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2045 - val_loss: 0.2424\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2007 - val_loss: 0.2382\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1973 - val_loss: 0.2342\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1941 - val_loss: 0.2307\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1912 - val_loss: 0.2273\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1884 - val_loss: 0.2242\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1858 - val_loss: 0.2214\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1833 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1810 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1789 - val_loss: 0.2140\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1769 - val_loss: 0.2119\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1750 - val_loss: 0.2100\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1733 - val_loss: 0.2082\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1717 - val_loss: 0.2066\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1702 - val_loss: 0.2051\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1689 - val_loss: 0.2038\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1677 - val_loss: 0.2024\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2012\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2001\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1645 - val_loss: 0.1989\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1979\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1627 - val_loss: 0.1969\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1619 - val_loss: 0.1959\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1611 - val_loss: 0.1950\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1603 - val_loss: 0.1941\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1596 - val_loss: 0.1933\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1589 - val_loss: 0.1925\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1582 - val_loss: 0.1917\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1576 - val_loss: 0.1910\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1570 - val_loss: 0.1903\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1564 - val_loss: 0.1895\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1558 - val_loss: 0.1889\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1553 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1548 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1543 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 187.65491616156584, my average MASE = 1727876346.7517292\n",
      "Cluster 2, 187.65491616156584\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5179 - val_loss: 0.4772\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5158 - val_loss: 0.4757\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4743\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5118 - val_loss: 0.4729\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5098 - val_loss: 0.4715\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5079 - val_loss: 0.4701\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5059 - val_loss: 0.4687\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5040 - val_loss: 0.4673\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4660\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5002 - val_loss: 0.4646\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4984 - val_loss: 0.4633\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4966 - val_loss: 0.4620\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4948 - val_loss: 0.4607\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4931 - val_loss: 0.4594\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4913 - val_loss: 0.4581\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4896 - val_loss: 0.4568\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4879 - val_loss: 0.4555\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4862 - val_loss: 0.4543\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4845 - val_loss: 0.4531\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4828 - val_loss: 0.4518\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4812 - val_loss: 0.4506\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4795 - val_loss: 0.4495\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4779 - val_loss: 0.4483\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4763 - val_loss: 0.4471\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4747 - val_loss: 0.4460\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4731 - val_loss: 0.4449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4716 - val_loss: 0.4438\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4700 - val_loss: 0.4427\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4685 - val_loss: 0.4416\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4670 - val_loss: 0.4405\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4655 - val_loss: 0.4395\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4640 - val_loss: 0.4385\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4626 - val_loss: 0.4374\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4611 - val_loss: 0.4364\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4597 - val_loss: 0.4354\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4582 - val_loss: 0.4344\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4568 - val_loss: 0.4334\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4555 - val_loss: 0.4324\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4541 - val_loss: 0.4314\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4527 - val_loss: 0.4304\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3258333520.23763, my average MASE = 7487984704.271554\n",
      "Cluster 3, 3258333520.23763\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3367 - val_loss: 0.3564\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3362 - val_loss: 0.3564\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3356 - val_loss: 0.3564\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3351 - val_loss: 0.3563\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3346 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3340 - val_loss: 0.3563\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3335 - val_loss: 0.3563\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3330 - val_loss: 0.3562\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3325 - val_loss: 0.3562\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3319 - val_loss: 0.3562\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3314 - val_loss: 0.3561\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3309 - val_loss: 0.3561\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3304 - val_loss: 0.3561\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3560\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3294 - val_loss: 0.3560\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3289 - val_loss: 0.3560\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.3559\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3280 - val_loss: 0.3559\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3275 - val_loss: 0.3559\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3270 - val_loss: 0.3559\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3266 - val_loss: 0.3558\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3261 - val_loss: 0.3558\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3256 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3252 - val_loss: 0.3558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3248 - val_loss: 0.3558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3243 - val_loss: 0.3557\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3239 - val_loss: 0.3557\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.3557\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3230 - val_loss: 0.3557\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3226 - val_loss: 0.3557\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3222 - val_loss: 0.3556\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3218 - val_loss: 0.3556\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3214 - val_loss: 0.3556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3556\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3205 - val_loss: 0.3556\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3201 - val_loss: 0.3556\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.3556\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3193 - val_loss: 0.3555\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3189 - val_loss: 0.3555\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3185 - val_loss: 0.3555\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 544.8910068645505, my average MASE = 25915172.7591836\n",
      "Cluster 4, 544.8910068645505\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5189 - val_loss: 0.8510\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5183 - val_loss: 0.8507\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5176 - val_loss: 0.8503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5170 - val_loss: 0.8500\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5163 - val_loss: 0.8496\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5157 - val_loss: 0.8493\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5151 - val_loss: 0.8490\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5145 - val_loss: 0.8487\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5138 - val_loss: 0.8484\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5132 - val_loss: 0.8481\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5126 - val_loss: 0.8478\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5120 - val_loss: 0.8476\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5114 - val_loss: 0.8473\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5108 - val_loss: 0.8471\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5102 - val_loss: 0.8468\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5096 - val_loss: 0.8466\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5090 - val_loss: 0.8463\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5084 - val_loss: 0.8461\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5078 - val_loss: 0.8458\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5072 - val_loss: 0.8456\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.8454\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5060 - val_loss: 0.8451\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5055 - val_loss: 0.8449\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5049 - val_loss: 0.8447\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5043 - val_loss: 0.8445\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5038 - val_loss: 0.8443\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5032 - val_loss: 0.8441\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5027 - val_loss: 0.8439\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5021 - val_loss: 0.8437\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5016 - val_loss: 0.8435\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5010 - val_loss: 0.8433\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5005 - val_loss: 0.8431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4999 - val_loss: 0.8429\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4994 - val_loss: 0.8428\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4989 - val_loss: 0.8426\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4983 - val_loss: 0.8424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4978 - val_loss: 0.8422\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4973 - val_loss: 0.8420\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4967 - val_loss: 0.8419\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4962 - val_loss: 0.8417\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1963484.3822421303, my average MASE = 64800710.430740915\n",
      "Cluster 5, 1963484.3822421303\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8495 - val_loss: 4.3516\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8473 - val_loss: 4.3510\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8451 - val_loss: 4.3503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8429 - val_loss: 4.3497\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8408 - val_loss: 4.3491\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8386 - val_loss: 4.3485\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8365 - val_loss: 4.3479\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8344 - val_loss: 4.3473\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8323 - val_loss: 4.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8301 - val_loss: 4.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8280 - val_loss: 4.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8259 - val_loss: 4.3451\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8238 - val_loss: 4.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8217 - val_loss: 4.3440\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8197 - val_loss: 4.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8176 - val_loss: 4.3428\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8156 - val_loss: 4.3423\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8136 - val_loss: 4.3417\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8117 - val_loss: 4.3412\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8098 - val_loss: 4.3407\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 4.3403\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8061 - val_loss: 4.3399\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8042 - val_loss: 4.3395\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8023 - val_loss: 4.3390\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8004 - val_loss: 4.3386\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7986 - val_loss: 4.3382\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7967 - val_loss: 4.3378\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7949 - val_loss: 4.3374\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7930 - val_loss: 4.3370\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7912 - val_loss: 4.3365\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7893 - val_loss: 4.3361\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7874 - val_loss: 4.3357\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7856 - val_loss: 4.3353\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7839 - val_loss: 4.3349\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7822 - val_loss: 4.3345\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7805 - val_loss: 4.3341\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7787 - val_loss: 4.3338\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7771 - val_loss: 4.3334\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7754 - val_loss: 4.3330\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7738 - val_loss: 4.3327\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4.116072897890656, my average MASE = 12.21206426084865\n",
      "Cluster 6, 4.116072897890656\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3660 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3652 - val_loss: 0.3455\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3645 - val_loss: 0.3451\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3638 - val_loss: 0.3448\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3632 - val_loss: 0.3445\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3625 - val_loss: 0.3441\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3619 - val_loss: 0.3438\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3435\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3606 - val_loss: 0.3431\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3599 - val_loss: 0.3428\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3593 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3422\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3581 - val_loss: 0.3419\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3576 - val_loss: 0.3416\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3570 - val_loss: 0.3413\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3564 - val_loss: 0.3410\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3558 - val_loss: 0.3407\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3553 - val_loss: 0.3404\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3547 - val_loss: 0.3401\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3542 - val_loss: 0.3398\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3536 - val_loss: 0.3395\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3531 - val_loss: 0.3393\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3526 - val_loss: 0.3390\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3521 - val_loss: 0.3387\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3516 - val_loss: 0.3384\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3511 - val_loss: 0.3382\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3506 - val_loss: 0.3379\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3501 - val_loss: 0.3376\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3496 - val_loss: 0.3373\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3491 - val_loss: 0.3371\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3487 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3482 - val_loss: 0.3366\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3477 - val_loss: 0.3363\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3473 - val_loss: 0.3360\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3464 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3459 - val_loss: 0.3353\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3455 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3451 - val_loss: 0.3348\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3446 - val_loss: 0.3345\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 266.09609302896547, my average MASE = 71685898.00003502\n",
      "Cluster 8, 266.09609302896547\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=11, 11, 663, (11, 67)\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3610 - val_loss: 0.4969\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3601 - val_loss: 0.4969\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3592 - val_loss: 0.4970\n",
      "Epoch 3: early stopping\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.35712691602972574, my average MASE = 0.5241910168311086\n",
      "Cluster 0, 0.35712691602972574\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2752 - val_loss: 0.2714\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2747 - val_loss: 0.2712\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2742 - val_loss: 0.2710\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2737 - val_loss: 0.2707\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2733 - val_loss: 0.2705\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2728 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2723 - val_loss: 0.2701\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2718 - val_loss: 0.2699\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2714 - val_loss: 0.2697\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2709 - val_loss: 0.2695\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2704 - val_loss: 0.2693\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2700 - val_loss: 0.2691\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2695 - val_loss: 0.2690\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2691 - val_loss: 0.2688\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2687 - val_loss: 0.2686\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2682 - val_loss: 0.2684\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2678 - val_loss: 0.2682\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2673 - val_loss: 0.2680\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2669 - val_loss: 0.2678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2665 - val_loss: 0.2676\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2661 - val_loss: 0.2674\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.2672\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2653 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2649 - val_loss: 0.2669\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2645 - val_loss: 0.2667\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2641 - val_loss: 0.2665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2637 - val_loss: 0.2663\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2633 - val_loss: 0.2662\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2629 - val_loss: 0.2660\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2625 - val_loss: 0.2658\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2621 - val_loss: 0.2656\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2618 - val_loss: 0.2655\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2614 - val_loss: 0.2653\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2610 - val_loss: 0.2652\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2606 - val_loss: 0.2650\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2602 - val_loss: 0.2649\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2599 - val_loss: 0.2647\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2595 - val_loss: 0.2646\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2591 - val_loss: 0.2644\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2588 - val_loss: 0.2643\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 114.92828938190037, my average MASE = 64775351.69732988\n",
      "Cluster 1, 114.92828938190037\n",
      "Before prediction: train_X.shape=(21, 10, 67), train_y.shape=(21, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6587 - val_loss: 0.2666\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6569 - val_loss: 0.2655\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6551 - val_loss: 0.2645\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6533 - val_loss: 0.2635\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6515 - val_loss: 0.2624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6497 - val_loss: 0.2614\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6480 - val_loss: 0.2604\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6463 - val_loss: 0.2594\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6446 - val_loss: 0.2584\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6429 - val_loss: 0.2574\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6412 - val_loss: 0.2565\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6395 - val_loss: 0.2555\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6379 - val_loss: 0.2546\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6363 - val_loss: 0.2538\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6346 - val_loss: 0.2529\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6331 - val_loss: 0.2520\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6315 - val_loss: 0.2512\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6300 - val_loss: 0.2504\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6285 - val_loss: 0.2496\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6270 - val_loss: 0.2488\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6255 - val_loss: 0.2480\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6240 - val_loss: 0.2473\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6225 - val_loss: 0.2466\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6211 - val_loss: 0.2458\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6197 - val_loss: 0.2451\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6182 - val_loss: 0.2444\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6168 - val_loss: 0.2437\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6155 - val_loss: 0.2430\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6141 - val_loss: 0.2423\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6127 - val_loss: 0.2416\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6114 - val_loss: 0.2410\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6101 - val_loss: 0.2403\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6088 - val_loss: 0.2397\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6075 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6063 - val_loss: 0.2384\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6050 - val_loss: 0.2378\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6038 - val_loss: 0.2372\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6026 - val_loss: 0.2365\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6014 - val_loss: 0.2359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6002 - val_loss: 0.2353\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 26456338.054780327, my average MASE = 1170397376.6808207\n",
      "Cluster 2, 26456338.054780327\n",
      "Before prediction: train_X.shape=(62, 10, 67), train_y.shape=(62, 67), test_X.shape=(21, 10, 67), test_y.shape=(21, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3828 - val_loss: 0.5067\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3824 - val_loss: 0.5064\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3820 - val_loss: 0.5062\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3816 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3812 - val_loss: 0.5056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3808 - val_loss: 0.5053\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3804 - val_loss: 0.5051\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3801 - val_loss: 0.5048\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3797 - val_loss: 0.5045\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3793 - val_loss: 0.5043\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3790 - val_loss: 0.5040\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3786 - val_loss: 0.5038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3783 - val_loss: 0.5035\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3779 - val_loss: 0.5032\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3776 - val_loss: 0.5030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3772 - val_loss: 0.5027\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3769 - val_loss: 0.5025\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3765 - val_loss: 0.5022\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3762 - val_loss: 0.5020\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3758 - val_loss: 0.5017\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3755 - val_loss: 0.5015\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3752 - val_loss: 0.5012\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3748 - val_loss: 0.5010\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3745 - val_loss: 0.5008\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3742 - val_loss: 0.5005\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3738 - val_loss: 0.5003\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3735 - val_loss: 0.5000\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3732 - val_loss: 0.4998\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3729 - val_loss: 0.4995\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3726 - val_loss: 0.4993\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3722 - val_loss: 0.4991\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3719 - val_loss: 0.4988\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3716 - val_loss: 0.4986\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3713 - val_loss: 0.4984\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3710 - val_loss: 0.4982\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3707 - val_loss: 0.4979\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3704 - val_loss: 0.4977\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3701 - val_loss: 0.4975\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3698 - val_loss: 0.4973\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3695 - val_loss: 0.4971\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(21, 67), test_y.shape=(21, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 88.873907317969, my average MASE = 105114880.66517946\n",
      "Cluster 3, 88.873907317969\n",
      "Before prediction: train_X.shape=(58, 10, 67), train_y.shape=(58, 67), test_X.shape=(19, 10, 67), test_y.shape=(19, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6113 - val_loss: 0.3397\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6107 - val_loss: 0.3395\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6100 - val_loss: 0.3394\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6094 - val_loss: 0.3393\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6087 - val_loss: 0.3392\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6081 - val_loss: 0.3391\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6075 - val_loss: 0.3390\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6069 - val_loss: 0.3389\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6062 - val_loss: 0.3388\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6056 - val_loss: 0.3387\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6050 - val_loss: 0.3386\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6044 - val_loss: 0.3385\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6038 - val_loss: 0.3384\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6032 - val_loss: 0.3383\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6026 - val_loss: 0.3382\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6020 - val_loss: 0.3381\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6014 - val_loss: 0.3380\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6009 - val_loss: 0.3379\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6003 - val_loss: 0.3378\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5997 - val_loss: 0.3377\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5992 - val_loss: 0.3376\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5986 - val_loss: 0.3375\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5981 - val_loss: 0.3374\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5976 - val_loss: 0.3373\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5970 - val_loss: 0.3372\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5965 - val_loss: 0.3372\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5960 - val_loss: 0.3371\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5955 - val_loss: 0.3370\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5949 - val_loss: 0.3369\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5944 - val_loss: 0.3369\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5939 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5934 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5929 - val_loss: 0.3366\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5924 - val_loss: 0.3366\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5919 - val_loss: 0.3365\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5915 - val_loss: 0.3364\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5910 - val_loss: 0.3364\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5905 - val_loss: 0.3363\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5900 - val_loss: 0.3362\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5895 - val_loss: 0.3362\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(19, 67), test_y.shape=(19, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2288977.9462372796, my average MASE = 275894539.3328722\n",
      "Cluster 4, 2288977.9462372796\n",
      "Before prediction: train_X.shape=(22, 10, 67), train_y.shape=(22, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6507 - val_loss: 0.5866\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6499 - val_loss: 0.5864\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6491 - val_loss: 0.5862\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6483 - val_loss: 0.5861\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6475 - val_loss: 0.5859\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6467 - val_loss: 0.5857\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6459 - val_loss: 0.5855\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6451 - val_loss: 0.5854\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6443 - val_loss: 0.5852\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6435 - val_loss: 0.5851\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6427 - val_loss: 0.5849\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6420 - val_loss: 0.5848\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6412 - val_loss: 0.5846\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6405 - val_loss: 0.5844\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6397 - val_loss: 0.5843\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6389 - val_loss: 0.5841\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6382 - val_loss: 0.5840\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6374 - val_loss: 0.5838\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6367 - val_loss: 0.5837\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6359 - val_loss: 0.5836\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6352 - val_loss: 0.5834\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6345 - val_loss: 0.5833\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6337 - val_loss: 0.5832\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6330 - val_loss: 0.5830\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6323 - val_loss: 0.5829\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6316 - val_loss: 0.5827\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6309 - val_loss: 0.5826\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6302 - val_loss: 0.5825\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 0.5824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6288 - val_loss: 0.5822\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6281 - val_loss: 0.5821\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6275 - val_loss: 0.5820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6268 - val_loss: 0.5819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6261 - val_loss: 0.5818\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6254 - val_loss: 0.5816\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6248 - val_loss: 0.5815\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6241 - val_loss: 0.5814\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6235 - val_loss: 0.5813\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6228 - val_loss: 0.5811\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6222 - val_loss: 0.5810\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 56.939779008571485, my average MASE = 37107546.21609385\n",
      "Cluster 5, 56.939779008571485\n",
      "Before prediction: train_X.shape=(4681, 10, 67), train_y.shape=(4681, 67), test_X.shape=(1560, 10, 67), test_y.shape=(1560, 67)\n",
      "Epoch 1/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0785 - val_loss: 0.0245\n",
      "Epoch 2/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0726 - val_loss: 0.0222\n",
      "Epoch 3/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0688 - val_loss: 0.0210\n",
      "Epoch 4/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0661 - val_loss: 0.0201\n",
      "Epoch 5/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0638 - val_loss: 0.0195\n",
      "Epoch 6/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0620 - val_loss: 0.0189\n",
      "Epoch 7/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0604 - val_loss: 0.0185\n",
      "Epoch 8/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0590 - val_loss: 0.0182\n",
      "Epoch 9/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0579 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0569 - val_loss: 0.0176\n",
      "Epoch 11/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0560 - val_loss: 0.0174\n",
      "Epoch 12/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0552 - val_loss: 0.0172\n",
      "Epoch 13/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0545 - val_loss: 0.0171\n",
      "Epoch 14/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0539 - val_loss: 0.0169\n",
      "Epoch 15/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0533 - val_loss: 0.0168\n",
      "Epoch 16/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0528 - val_loss: 0.0167\n",
      "Epoch 17/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0524 - val_loss: 0.0166\n",
      "Epoch 18/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0519 - val_loss: 0.0165\n",
      "Epoch 19/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0516 - val_loss: 0.0165\n",
      "Epoch 20/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0512 - val_loss: 0.0164\n",
      "Epoch 21/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0509 - val_loss: 0.0163\n",
      "Epoch 22/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0505 - val_loss: 0.0163\n",
      "Epoch 23/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0502 - val_loss: 0.0162\n",
      "Epoch 24/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0500 - val_loss: 0.0162\n",
      "Epoch 25/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0497 - val_loss: 0.0161\n",
      "Epoch 26/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0495 - val_loss: 0.0161\n",
      "Epoch 27/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0492 - val_loss: 0.0161\n",
      "Epoch 28/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0490 - val_loss: 0.0160\n",
      "Epoch 29/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0488 - val_loss: 0.0160\n",
      "Epoch 30/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0486 - val_loss: 0.0159\n",
      "Epoch 31/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0485 - val_loss: 0.0159\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0483 - val_loss: 0.0158\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0481 - val_loss: 0.0158\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0480 - val_loss: 0.0158\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0479 - val_loss: 0.0157\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0477 - val_loss: 0.0157\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0476 - val_loss: 0.0157\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0475 - val_loss: 0.0156\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0474 - val_loss: 0.0156\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0473 - val_loss: 0.0156\n",
      "49/49 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1560, 67), test_y.shape=(1560, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 149408746.52177918, my average MASE = 566572768.961764\n",
      "Cluster 6, 149408746.52177918\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5377 - val_loss: 0.4682\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5358 - val_loss: 0.4667\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5339 - val_loss: 0.4653\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5320 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5302 - val_loss: 0.4624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5283 - val_loss: 0.4609\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5265 - val_loss: 0.4595\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5247 - val_loss: 0.4581\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5229 - val_loss: 0.4567\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5211 - val_loss: 0.4554\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5194 - val_loss: 0.4540\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5177 - val_loss: 0.4527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5160 - val_loss: 0.4514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5143 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5126 - val_loss: 0.4488\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5110 - val_loss: 0.4475\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5093 - val_loss: 0.4462\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5077 - val_loss: 0.4450\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5062 - val_loss: 0.4438\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5046 - val_loss: 0.4425\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5030 - val_loss: 0.4413\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5015 - val_loss: 0.4401\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5000 - val_loss: 0.4390\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4985 - val_loss: 0.4378\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4970 - val_loss: 0.4367\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4955 - val_loss: 0.4355\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4940 - val_loss: 0.4344\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4925 - val_loss: 0.4334\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4911 - val_loss: 0.4323\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4897 - val_loss: 0.4312\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4882 - val_loss: 0.4302\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4868 - val_loss: 0.4292\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4854 - val_loss: 0.4281\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4840 - val_loss: 0.4271\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4826 - val_loss: 0.4261\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4813 - val_loss: 0.4251\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4242\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4232\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4772 - val_loss: 0.4223\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4759 - val_loss: 0.4214\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3453236106.5511885, my average MASE = 6985920382.132476\n",
      "Cluster 7, 3453236106.5511885\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3084 - val_loss: 0.3104\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3075 - val_loss: 0.3100\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3066 - val_loss: 0.3095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3058 - val_loss: 0.3091\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3050 - val_loss: 0.3086\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3042 - val_loss: 0.3082\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3034 - val_loss: 0.3077\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3026 - val_loss: 0.3073\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3018 - val_loss: 0.3068\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3010 - val_loss: 0.3064\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3002 - val_loss: 0.3059\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2995 - val_loss: 0.3055\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2987 - val_loss: 0.3051\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2980 - val_loss: 0.3047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2973 - val_loss: 0.3043\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2965 - val_loss: 0.3039\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2958 - val_loss: 0.3035\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2951 - val_loss: 0.3031\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2944 - val_loss: 0.3027\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2937 - val_loss: 0.3024\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2930 - val_loss: 0.3020\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2924 - val_loss: 0.3017\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2917 - val_loss: 0.3014\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2911 - val_loss: 0.3011\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2904 - val_loss: 0.3008\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2898 - val_loss: 0.3006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2891 - val_loss: 0.3003\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2885 - val_loss: 0.3001\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2878 - val_loss: 0.2998\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2872 - val_loss: 0.2996\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2866 - val_loss: 0.2994\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2859 - val_loss: 0.2992\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2853 - val_loss: 0.2990\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2846 - val_loss: 0.2988\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2840 - val_loss: 0.2985\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2834 - val_loss: 0.2983\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2827 - val_loss: 0.2981\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2822 - val_loss: 0.2979\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2816 - val_loss: 0.2977\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2810 - val_loss: 0.2975\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2112740905793214, my average MASE = 0.3813496945040607\n",
      "Cluster 8, 0.2112740905793214\n",
      "Before prediction: train_X.shape=(33, 10, 67), train_y.shape=(33, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5052 - val_loss: 0.6961\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5045 - val_loss: 0.6956\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5038 - val_loss: 0.6950\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5030 - val_loss: 0.6945\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5023 - val_loss: 0.6939\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5016 - val_loss: 0.6934\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5009 - val_loss: 0.6928\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5002 - val_loss: 0.6923\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4995 - val_loss: 0.6918\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4988 - val_loss: 0.6913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.6908\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4975 - val_loss: 0.6903\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4968 - val_loss: 0.6898\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4961 - val_loss: 0.6893\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4955 - val_loss: 0.6888\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4948 - val_loss: 0.6883\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4942 - val_loss: 0.6879\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4935 - val_loss: 0.6874\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4929 - val_loss: 0.6869\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4923 - val_loss: 0.6865\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.6860\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4910 - val_loss: 0.6855\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4904 - val_loss: 0.6851\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4898 - val_loss: 0.6846\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4892 - val_loss: 0.6842\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4886 - val_loss: 0.6837\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4880 - val_loss: 0.6833\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4874 - val_loss: 0.6829\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4868 - val_loss: 0.6824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4863 - val_loss: 0.6820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4857 - val_loss: 0.6816\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4851 - val_loss: 0.6811\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4845 - val_loss: 0.6807\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4840 - val_loss: 0.6803\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4834 - val_loss: 0.6799\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4828 - val_loss: 0.6794\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6790\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4817 - val_loss: 0.6786\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4811 - val_loss: 0.6782\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4806 - val_loss: 0.6778\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 74.79960857799604, my average MASE = 23518054.91533832\n",
      "Cluster 9, 74.79960857799604\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3521 - val_loss: 0.2993\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3508 - val_loss: 0.2987\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3496 - val_loss: 0.2982\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3483 - val_loss: 0.2976\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3470 - val_loss: 0.2971\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3458 - val_loss: 0.2966\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3446 - val_loss: 0.2961\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3435 - val_loss: 0.2957\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3423 - val_loss: 0.2954\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3412 - val_loss: 0.2950\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3400 - val_loss: 0.2946\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3389 - val_loss: 0.2943\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3378 - val_loss: 0.2939\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3368 - val_loss: 0.2935\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3357 - val_loss: 0.2932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3347 - val_loss: 0.2928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3337 - val_loss: 0.2925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3326 - val_loss: 0.2921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3317 - val_loss: 0.2918\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3307 - val_loss: 0.2915\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3298 - val_loss: 0.2912\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3289 - val_loss: 0.2910\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3279 - val_loss: 0.2908\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.2905\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3261 - val_loss: 0.2903\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3252 - val_loss: 0.2901\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3244 - val_loss: 0.2899\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.2897\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3227 - val_loss: 0.2895\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3219 - val_loss: 0.2894\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3211 - val_loss: 0.2892\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3203 - val_loss: 0.2891\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3195 - val_loss: 0.2890\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3187 - val_loss: 0.2889\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3179 - val_loss: 0.2888\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3171 - val_loss: 0.2887\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3163 - val_loss: 0.2886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3155 - val_loss: 0.2886\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.2885\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3139 - val_loss: 0.2885\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.1864435054204945, my average MASE = 0.27675363785512175\n",
      "Cluster 10, 0.1864435054204945\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=2, 2, 18, (30612, 67)\n",
      "Before prediction: train_X.shape=(18361, 10, 67), train_y.shape=(18361, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.3015 - val_loss: 0.3194\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2836 - val_loss: 0.3051\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2695 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2585 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2510 - val_loss: 0.2789\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2456 - val_loss: 0.2737\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2410 - val_loss: 0.2693\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2369 - val_loss: 0.2653\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2332 - val_loss: 0.2616\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2298 - val_loss: 0.2584\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2267 - val_loss: 0.2555\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2238 - val_loss: 0.2531\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2212 - val_loss: 0.2509\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2190 - val_loss: 0.2490\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2172 - val_loss: 0.2474\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2156 - val_loss: 0.2461\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2143 - val_loss: 0.2448\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2120 - val_loss: 0.2428\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2110 - val_loss: 0.2420\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2101 - val_loss: 0.2412\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2092 - val_loss: 0.2404\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2084 - val_loss: 0.2395\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2077 - val_loss: 0.2390\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2070 - val_loss: 0.2383\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2064 - val_loss: 0.2377\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2058 - val_loss: 0.2371\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2052 - val_loss: 0.2365\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2047 - val_loss: 0.2361\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2041 - val_loss: 0.2356\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2352\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2032 - val_loss: 0.2348\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2020 - val_loss: 0.2336\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2016 - val_loss: 0.2332\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2013 - val_loss: 0.2329\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2009 - val_loss: 0.2327\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2006 - val_loss: 0.2324\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2321\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2046.5122369835897, my average MASE = 2805.5341357338157\n",
      "Cluster 0, 2046.5122369835897\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5756 - val_loss: 1.2952\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5738 - val_loss: 1.2950\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5721 - val_loss: 1.2949\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5703 - val_loss: 1.2948\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5686 - val_loss: 1.2947\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5670 - val_loss: 1.2946\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5653 - val_loss: 1.2945\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5637 - val_loss: 1.2944\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5621 - val_loss: 1.2943\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5605 - val_loss: 1.2941\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5589 - val_loss: 1.2940\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5573 - val_loss: 1.2939\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5558 - val_loss: 1.2937\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5542 - val_loss: 1.2936\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5527 - val_loss: 1.2934\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5512 - val_loss: 1.2932\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5497 - val_loss: 1.2930\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 1.2929\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5468 - val_loss: 1.2927\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 1.2925\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5440 - val_loss: 1.2924\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5426 - val_loss: 1.2922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5413 - val_loss: 1.2921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5400 - val_loss: 1.2920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5386 - val_loss: 1.2919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5374 - val_loss: 1.2918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 1.2918\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5349 - val_loss: 1.2917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5337 - val_loss: 1.2916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5325 - val_loss: 1.2915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5314 - val_loss: 1.2914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5302 - val_loss: 1.2912\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5290 - val_loss: 1.2911\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5279 - val_loss: 1.2909\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5268 - val_loss: 1.2907\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5256 - val_loss: 1.2905\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5246 - val_loss: 1.2903\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5235 - val_loss: 1.2902\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5224 - val_loss: 1.2901\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5213 - val_loss: 1.2900\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 950350834.5172157, my average MASE = 2745439088.6097794\n",
      "Cluster 1, 950350834.5172157\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=5, 5, 599, (8, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3119 - val_loss: 0.2829\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3116 - val_loss: 0.2829\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3112 - val_loss: 0.2828\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3109 - val_loss: 0.2828\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3106 - val_loss: 0.2828\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3102 - val_loss: 0.2827\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3099 - val_loss: 0.2827\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3096 - val_loss: 0.2827\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3092 - val_loss: 0.2827\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3089 - val_loss: 0.2826\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3086 - val_loss: 0.2826\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3083 - val_loss: 0.2826\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3080 - val_loss: 0.2826\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3077 - val_loss: 0.2825\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3074 - val_loss: 0.2825\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3070 - val_loss: 0.2825\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3067 - val_loss: 0.2825\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3064 - val_loss: 0.2824\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3061 - val_loss: 0.2824\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3058 - val_loss: 0.2824\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3055 - val_loss: 0.2823\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3052 - val_loss: 0.2823\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3049 - val_loss: 0.2823\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3047 - val_loss: 0.2822\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3044 - val_loss: 0.2822\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3041 - val_loss: 0.2822\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3038 - val_loss: 0.2821\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3035 - val_loss: 0.2821\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3032 - val_loss: 0.2821\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3029 - val_loss: 0.2820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3027 - val_loss: 0.2820\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3024 - val_loss: 0.2820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3021 - val_loss: 0.2819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.2819\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3016 - val_loss: 0.2818\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3013 - val_loss: 0.2818\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3010 - val_loss: 0.2818\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3008 - val_loss: 0.2817\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3005 - val_loss: 0.2817\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3002 - val_loss: 0.2816\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 104.97029321074898, my average MASE = 15924142.879668588\n",
      "Cluster 0, 104.97029321074898\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5420 - val_loss: 0.4071\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5399 - val_loss: 0.4062\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5378 - val_loss: 0.4054\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5357 - val_loss: 0.4045\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5337 - val_loss: 0.4037\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5316 - val_loss: 0.4029\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5296 - val_loss: 0.4021\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5276 - val_loss: 0.4013\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5257 - val_loss: 0.4005\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5237 - val_loss: 0.3998\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5218 - val_loss: 0.3990\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5199 - val_loss: 0.3983\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5179 - val_loss: 0.3975\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5161 - val_loss: 0.3968\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5142 - val_loss: 0.3961\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5124 - val_loss: 0.3954\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5106 - val_loss: 0.3947\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5088 - val_loss: 0.3940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5070 - val_loss: 0.3933\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5052 - val_loss: 0.3926\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5035 - val_loss: 0.3919\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5018 - val_loss: 0.3913\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5001 - val_loss: 0.3906\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4985 - val_loss: 0.3899\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4968 - val_loss: 0.3892\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.3886\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4936 - val_loss: 0.3879\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4920 - val_loss: 0.3873\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4905 - val_loss: 0.3866\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4889 - val_loss: 0.3860\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4874 - val_loss: 0.3853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4858 - val_loss: 0.3847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4843 - val_loss: 0.3840\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4828 - val_loss: 0.3834\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4813 - val_loss: 0.3828\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4798 - val_loss: 0.3821\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4783 - val_loss: 0.3815\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4769 - val_loss: 0.3809\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4754 - val_loss: 0.3803\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4740 - val_loss: 0.3797\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3145368812.0062547, my average MASE = 5974295545.526059\n",
      "Cluster 1, 3145368812.0062547\n",
      "Before prediction: train_X.shape=(2220, 10, 67), train_y.shape=(2220, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.5043 - val_loss: 0.3721\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4967 - val_loss: 0.3684\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4907 - val_loss: 0.3653\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4855 - val_loss: 0.3625\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4810 - val_loss: 0.3601\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4769 - val_loss: 0.3579\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4731 - val_loss: 0.3558\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4695 - val_loss: 0.3540\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4661 - val_loss: 0.3522\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4629 - val_loss: 0.3506\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4598 - val_loss: 0.3490\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4568 - val_loss: 0.3476\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4539 - val_loss: 0.3462\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4510 - val_loss: 0.3448\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4483 - val_loss: 0.3435\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4455 - val_loss: 0.3422\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4429 - val_loss: 0.3410\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4402 - val_loss: 0.3398\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4376 - val_loss: 0.3386\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4351 - val_loss: 0.3375\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4326 - val_loss: 0.3363\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4302 - val_loss: 0.3352\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4278 - val_loss: 0.3342\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4255 - val_loss: 0.3331\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4232 - val_loss: 0.3321\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4211 - val_loss: 0.3311\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4189 - val_loss: 0.3302\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4169 - val_loss: 0.3292\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4149 - val_loss: 0.3284\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4129 - val_loss: 0.3276\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4111 - val_loss: 0.3268\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4093 - val_loss: 0.3260\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4076 - val_loss: 0.3253\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4060 - val_loss: 0.3246\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4044 - val_loss: 0.3240\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4029 - val_loss: 0.3234\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4014 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4000 - val_loss: 0.3222\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3986 - val_loss: 0.3217\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3972 - val_loss: 0.3211\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 487.922050733615, my average MASE = 1880.6635092100216\n",
      "Cluster 2, 487.922050733615\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1089 - val_loss: 0.0991\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1039 - val_loss: 0.0970\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0998 - val_loss: 0.0956\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0965 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0938\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0911 - val_loss: 0.0932\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0889 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0869 - val_loss: 0.0924\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0852 - val_loss: 0.0922\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0836 - val_loss: 0.0920\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0821 - val_loss: 0.0918\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0808 - val_loss: 0.0917\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0795 - val_loss: 0.0915\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0783 - val_loss: 0.0913\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0773 - val_loss: 0.0912\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0763 - val_loss: 0.0910\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0908\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0744 - val_loss: 0.0907\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0736 - val_loss: 0.0905\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0903\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0901\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0900\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0708 - val_loss: 0.0899\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0897\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0696 - val_loss: 0.0896\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0690 - val_loss: 0.0895\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0894\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0680 - val_loss: 0.0893\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0675 - val_loss: 0.0892\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0892\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0666 - val_loss: 0.0891\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0661 - val_loss: 0.0890\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0658 - val_loss: 0.0890\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0654 - val_loss: 0.0889\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0650 - val_loss: 0.0889\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0647 - val_loss: 0.0888\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0644 - val_loss: 0.0888\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0888\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0887\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0636 - val_loss: 0.0887\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1152398695.5185678, my average MASE = 7118534712.468365\n",
      "Cluster 3, 1152398695.5185678\n",
      "Before prediction: train_X.shape=(156, 10, 67), train_y.shape=(156, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5146 - val_loss: 0.4378\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5133 - val_loss: 0.4370\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5122 - val_loss: 0.4361\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5111 - val_loss: 0.4352\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5100 - val_loss: 0.4344\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5089 - val_loss: 0.4335\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5078 - val_loss: 0.4327\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5068 - val_loss: 0.4319\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5057 - val_loss: 0.4311\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4303\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5037 - val_loss: 0.4296\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5028 - val_loss: 0.4288\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5018 - val_loss: 0.4281\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5008 - val_loss: 0.4273\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4999 - val_loss: 0.4266\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4990 - val_loss: 0.4259\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4981 - val_loss: 0.4252\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4972 - val_loss: 0.4245\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4963 - val_loss: 0.4238\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4954 - val_loss: 0.4232\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4945 - val_loss: 0.4225\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4937 - val_loss: 0.4219\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4929 - val_loss: 0.4213\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4920 - val_loss: 0.4207\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4912 - val_loss: 0.4201\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4905 - val_loss: 0.4195\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4897 - val_loss: 0.4189\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4889 - val_loss: 0.4183\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4881 - val_loss: 0.4177\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4874 - val_loss: 0.4172\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4867 - val_loss: 0.4166\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4859 - val_loss: 0.4161\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4852 - val_loss: 0.4155\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4845 - val_loss: 0.4150\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4838 - val_loss: 0.4145\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4831 - val_loss: 0.4139\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4824 - val_loss: 0.4134\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4817 - val_loss: 0.4129\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4811 - val_loss: 0.4124\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4804 - val_loss: 0.4119\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 117.29272898284657, my average MASE = 138077149.3198319\n",
      "Cluster 4, 117.29272898284657\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=7, 7, 49, (317, 67)\n",
      "Before prediction: train_X.shape=(184, 10, 67), train_y.shape=(184, 67), test_X.shape=(61, 10, 67), test_y.shape=(61, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6997 - val_loss: 0.6374\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6982 - val_loss: 0.6363\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6968 - val_loss: 0.6352\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6954 - val_loss: 0.6341\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.6331\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6927 - val_loss: 0.6320\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.6310\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6901 - val_loss: 0.6300\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6889 - val_loss: 0.6290\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6876 - val_loss: 0.6281\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6864 - val_loss: 0.6272\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6852 - val_loss: 0.6262\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6840 - val_loss: 0.6253\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6829 - val_loss: 0.6244\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6818 - val_loss: 0.6235\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6807 - val_loss: 0.6227\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6796 - val_loss: 0.6218\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6785 - val_loss: 0.6210\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6774 - val_loss: 0.6202\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6763 - val_loss: 0.6194\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.6186\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6743 - val_loss: 0.6178\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6733 - val_loss: 0.6171\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6723 - val_loss: 0.6163\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6713 - val_loss: 0.6156\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6704 - val_loss: 0.6149\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6694 - val_loss: 0.6142\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6685 - val_loss: 0.6135\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6676 - val_loss: 0.6127\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6666 - val_loss: 0.6121\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6658 - val_loss: 0.6114\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6649 - val_loss: 0.6107\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6640 - val_loss: 0.6100\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6631 - val_loss: 0.6093\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6622 - val_loss: 0.6086\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6614 - val_loss: 0.6079\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6605 - val_loss: 0.6073\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6597 - val_loss: 0.6066\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6588 - val_loss: 0.6060\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6580 - val_loss: 0.6053\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(61, 67), test_y.shape=(61, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 140.79883300988942, my average MASE = 132025753.41047312\n",
      "Cluster 0, 140.79883300988942\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5180 - val_loss: 0.4305\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5161 - val_loss: 0.4294\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5142 - val_loss: 0.4283\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5123 - val_loss: 0.4272\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5104 - val_loss: 0.4261\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5085 - val_loss: 0.4251\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5067 - val_loss: 0.4241\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5049 - val_loss: 0.4230\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.4221\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5013 - val_loss: 0.4211\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4996 - val_loss: 0.4202\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4978 - val_loss: 0.4193\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4961 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4944 - val_loss: 0.4175\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4927 - val_loss: 0.4166\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4911 - val_loss: 0.4158\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4895 - val_loss: 0.4149\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4879 - val_loss: 0.4141\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4863 - val_loss: 0.4133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4847 - val_loss: 0.4126\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4118\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4816 - val_loss: 0.4110\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4801 - val_loss: 0.4103\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4787 - val_loss: 0.4095\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4772 - val_loss: 0.4088\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4758 - val_loss: 0.4080\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4743 - val_loss: 0.4073\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4729 - val_loss: 0.4066\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4715 - val_loss: 0.4058\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4701 - val_loss: 0.4051\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4687 - val_loss: 0.4044\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4673 - val_loss: 0.4038\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4660 - val_loss: 0.4031\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4646 - val_loss: 0.4024\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4633 - val_loss: 0.4017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4620 - val_loss: 0.4010\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4607 - val_loss: 0.4004\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4594 - val_loss: 0.3997\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4582 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4569 - val_loss: 0.3985\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3225148693.3924103, my average MASE = 6345532768.562708\n",
      "Cluster 1, 3225148693.3924103\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1129 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1075 - val_loss: 0.0981\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1032 - val_loss: 0.0968\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0996 - val_loss: 0.0960\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0965 - val_loss: 0.0953\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0938 - val_loss: 0.0949\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0913 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0892 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0872 - val_loss: 0.0938\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0854 - val_loss: 0.0935\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0838 - val_loss: 0.0933\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0823 - val_loss: 0.0931\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0809 - val_loss: 0.0928\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0796 - val_loss: 0.0926\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0784 - val_loss: 0.0924\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0773 - val_loss: 0.0921\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0762 - val_loss: 0.0919\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0752 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0743 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0734 - val_loss: 0.0913\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0726 - val_loss: 0.0912\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0719 - val_loss: 0.0910\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0907\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0699 - val_loss: 0.0906\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0693 - val_loss: 0.0904\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0687 - val_loss: 0.0903\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0682 - val_loss: 0.0903\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0677 - val_loss: 0.0902\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0901\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0668 - val_loss: 0.0901\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0663 - val_loss: 0.0900\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0899\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0655 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0898\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0648 - val_loss: 0.0897\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0645 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0636 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1209643109.1461504, my average MASE = 20216236756.2103\n",
      "Cluster 2, 1209643109.1461504\n",
      "Before prediction: train_X.shape=(47, 10, 67), train_y.shape=(47, 67), test_X.shape=(16, 10, 67), test_y.shape=(16, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4112 - val_loss: 0.3544\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.3542\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4104 - val_loss: 0.3540\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4100 - val_loss: 0.3538\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4095 - val_loss: 0.3536\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4091 - val_loss: 0.3534\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4087 - val_loss: 0.3533\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4083 - val_loss: 0.3531\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4079 - val_loss: 0.3529\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4075 - val_loss: 0.3527\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4071 - val_loss: 0.3525\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4067 - val_loss: 0.3524\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4063 - val_loss: 0.3522\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4059 - val_loss: 0.3520\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4055 - val_loss: 0.3519\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4051 - val_loss: 0.3517\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4047 - val_loss: 0.3515\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4043 - val_loss: 0.3514\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4039 - val_loss: 0.3512\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3511\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4032 - val_loss: 0.3509\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4028 - val_loss: 0.3508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4024 - val_loss: 0.3506\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4020 - val_loss: 0.3505\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4017 - val_loss: 0.3503\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4009 - val_loss: 0.3501\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4006 - val_loss: 0.3499\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4002 - val_loss: 0.3498\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3999 - val_loss: 0.3497\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.3495\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3992 - val_loss: 0.3494\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.3493\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3985 - val_loss: 0.3492\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3982 - val_loss: 0.3491\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3978 - val_loss: 0.3489\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3975 - val_loss: 0.3488\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3972 - val_loss: 0.3487\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3968 - val_loss: 0.3486\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3965 - val_loss: 0.3485\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(16, 67), test_y.shape=(16, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 66.79284837728264, my average MASE = 54990938.33317367\n",
      "Cluster 3, 66.79284837728264\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5009 - val_loss: 0.4222\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4998 - val_loss: 0.4214\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4988 - val_loss: 0.4207\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4978 - val_loss: 0.4200\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4968 - val_loss: 0.4193\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4958 - val_loss: 0.4186\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4949 - val_loss: 0.4179\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4939 - val_loss: 0.4172\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4930 - val_loss: 0.4165\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4921 - val_loss: 0.4159\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4912 - val_loss: 0.4153\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4903 - val_loss: 0.4146\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4894 - val_loss: 0.4140\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4886 - val_loss: 0.4134\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4877 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4869 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4861 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4853 - val_loss: 0.4111\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4845 - val_loss: 0.4105\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4837 - val_loss: 0.4100\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4829 - val_loss: 0.4094\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4822 - val_loss: 0.4089\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4814 - val_loss: 0.4084\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4807 - val_loss: 0.4078\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4799 - val_loss: 0.4073\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4792 - val_loss: 0.4068\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4785 - val_loss: 0.4063\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4777 - val_loss: 0.4058\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4770 - val_loss: 0.4052\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4763 - val_loss: 0.4047\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4756 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4749 - val_loss: 0.4037\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4742 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4735 - val_loss: 0.4027\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4728 - val_loss: 0.4023\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4721 - val_loss: 0.4018\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4715 - val_loss: 0.4013\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4708 - val_loss: 0.4008\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4701 - val_loss: 0.4003\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4695 - val_loss: 0.3999\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.45341483860946, my average MASE = 95916870.45268953\n",
      "Cluster 4, 127.45341483860946\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2476 - val_loss: 0.2883\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2353 - val_loss: 0.2762\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2258 - val_loss: 0.2666\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2185 - val_loss: 0.2589\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2127 - val_loss: 0.2526\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2078 - val_loss: 0.2473\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2036 - val_loss: 0.2426\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1999 - val_loss: 0.2383\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1966 - val_loss: 0.2346\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1935 - val_loss: 0.2311\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1907 - val_loss: 0.2280\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1881 - val_loss: 0.2251\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1857 - val_loss: 0.2225\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1834 - val_loss: 0.2200\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1813 - val_loss: 0.2178\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1794 - val_loss: 0.2157\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1777 - val_loss: 0.2137\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1760 - val_loss: 0.2120\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1746 - val_loss: 0.2103\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1732 - val_loss: 0.2087\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1719 - val_loss: 0.2072\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1707 - val_loss: 0.2058\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1695 - val_loss: 0.2045\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2032\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1674 - val_loss: 0.2020\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1664 - val_loss: 0.2009\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1655 - val_loss: 0.1998\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1646 - val_loss: 0.1988\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1638 - val_loss: 0.1978\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1630 - val_loss: 0.1968\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1622 - val_loss: 0.1960\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1614 - val_loss: 0.1951\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1607 - val_loss: 0.1943\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1600 - val_loss: 0.1935\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1594 - val_loss: 0.1927\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1587 - val_loss: 0.1920\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1913\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1575 - val_loss: 0.1906\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1570 - val_loss: 0.1899\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1893\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 224.71735313764052, my average MASE = 374017026.3746446\n",
      "Cluster 5, 224.71735313764052\n",
      "Before prediction: train_X.shape=(51, 10, 67), train_y.shape=(51, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4065 - val_loss: 0.3790\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4060 - val_loss: 0.3788\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4055 - val_loss: 0.3787\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4049 - val_loss: 0.3786\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4044 - val_loss: 0.3784\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4038 - val_loss: 0.3783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4033 - val_loss: 0.3782\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4028 - val_loss: 0.3780\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4023 - val_loss: 0.3779\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4018 - val_loss: 0.3778\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4013 - val_loss: 0.3776\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3775\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4003 - val_loss: 0.3774\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3773\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3993 - val_loss: 0.3771\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3988 - val_loss: 0.3770\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3984 - val_loss: 0.3769\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3768\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3975 - val_loss: 0.3767\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3970 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3966 - val_loss: 0.3764\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3763\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3762\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3953 - val_loss: 0.3761\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3949 - val_loss: 0.3760\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3945 - val_loss: 0.3759\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3941 - val_loss: 0.3757\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3937 - val_loss: 0.3756\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3933 - val_loss: 0.3755\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3929 - val_loss: 0.3754\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3925 - val_loss: 0.3753\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3921 - val_loss: 0.3752\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3917 - val_loss: 0.3751\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3913 - val_loss: 0.3750\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3749\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3905 - val_loss: 0.3748\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3902 - val_loss: 0.3747\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3898 - val_loss: 0.3745\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3894 - val_loss: 0.3744\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3891 - val_loss: 0.3743\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 82.26261385879712, my average MASE = 20260153.97451399\n",
      "Cluster 6, 82.26261385879712\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=9, 9, 48, (301, 67)\n",
      "Before prediction: train_X.shape=(174, 10, 67), train_y.shape=(174, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7089 - val_loss: 0.5627\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7074 - val_loss: 0.5619\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7059 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7045 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7031 - val_loss: 0.5598\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7017 - val_loss: 0.5591\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7004 - val_loss: 0.5585\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6991 - val_loss: 0.5578\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6979 - val_loss: 0.5572\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6966 - val_loss: 0.5566\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6954 - val_loss: 0.5559\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.5553\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6930 - val_loss: 0.5548\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6918 - val_loss: 0.5542\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6907 - val_loss: 0.5536\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6895 - val_loss: 0.5531\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6884 - val_loss: 0.5525\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6873 - val_loss: 0.5520\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6863 - val_loss: 0.5515\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6852 - val_loss: 0.5509\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6842 - val_loss: 0.5504\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6831 - val_loss: 0.5499\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6821 - val_loss: 0.5494\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6811 - val_loss: 0.5489\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6801 - val_loss: 0.5484\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6792 - val_loss: 0.5479\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6782 - val_loss: 0.5475\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6772 - val_loss: 0.5470\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.5465\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.5461\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6744 - val_loss: 0.5456\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6735 - val_loss: 0.5452\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6726 - val_loss: 0.5447\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5443\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6707 - val_loss: 0.5439\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6698 - val_loss: 0.5434\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6689 - val_loss: 0.5430\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6680 - val_loss: 0.5426\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6671 - val_loss: 0.5422\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6663 - val_loss: 0.5417\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 144.45290178213432, my average MASE = 192607450.5447097\n",
      "Cluster 0, 144.45290178213432\n",
      "Before prediction: train_X.shape=(86, 10, 67), train_y.shape=(86, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3954 - val_loss: 0.4825\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3947 - val_loss: 0.4820\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3940 - val_loss: 0.4815\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3933 - val_loss: 0.4810\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3927 - val_loss: 0.4806\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3921 - val_loss: 0.4801\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4797\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3909 - val_loss: 0.4793\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3903 - val_loss: 0.4789\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3898 - val_loss: 0.4785\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3892 - val_loss: 0.4781\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3887 - val_loss: 0.4777\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4774\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3877 - val_loss: 0.4770\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3872 - val_loss: 0.4767\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4763\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3862 - val_loss: 0.4760\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.4757\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3853 - val_loss: 0.4753\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3848 - val_loss: 0.4750\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3844 - val_loss: 0.4747\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3840 - val_loss: 0.4744\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3835 - val_loss: 0.4741\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3831 - val_loss: 0.4738\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3827 - val_loss: 0.4735\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3822 - val_loss: 0.4732\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3818 - val_loss: 0.4729\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3814 - val_loss: 0.4726\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3810 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3806 - val_loss: 0.4720\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3802 - val_loss: 0.4717\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3798 - val_loss: 0.4714\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.4711\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3790 - val_loss: 0.4708\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3786 - val_loss: 0.4705\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3783 - val_loss: 0.4703\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3779 - val_loss: 0.4700\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3775 - val_loss: 0.4697\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3771 - val_loss: 0.4695\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3768 - val_loss: 0.4692\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 261.83661307224526, my average MASE = 165152999.01271424\n",
      "Cluster 1, 261.83661307224526\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3860 - val_loss: 0.4764\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3839 - val_loss: 0.4752\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3818 - val_loss: 0.4741\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3798 - val_loss: 0.4730\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3778 - val_loss: 0.4719\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3758 - val_loss: 0.4709\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3738 - val_loss: 0.4699\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3718 - val_loss: 0.4689\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3699 - val_loss: 0.4680\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3680 - val_loss: 0.4670\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4660\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3643 - val_loss: 0.4650\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.4640\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3606 - val_loss: 0.4630\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3588 - val_loss: 0.4620\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3570 - val_loss: 0.4610\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3553 - val_loss: 0.4599\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3535 - val_loss: 0.4588\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3518 - val_loss: 0.4578\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3501 - val_loss: 0.4567\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3484 - val_loss: 0.4557\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.4547\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3452 - val_loss: 0.4537\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3437 - val_loss: 0.4528\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3422 - val_loss: 0.4521\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3407 - val_loss: 0.4513\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.4506\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3378 - val_loss: 0.4498\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3363 - val_loss: 0.4493\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3349 - val_loss: 0.4487\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3336 - val_loss: 0.4481\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3323 - val_loss: 0.4475\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3311 - val_loss: 0.4470\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3299 - val_loss: 0.4464\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3287 - val_loss: 0.4459\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3276 - val_loss: 0.4453\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3264 - val_loss: 0.4447\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3253 - val_loss: 0.4441\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3241 - val_loss: 0.4436\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3231 - val_loss: 0.4430\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.29600762869721386, my average MASE = 0.4272698543687938\n",
      "Cluster 2, 0.29600762869721386\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4866 - val_loss: 0.4310\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4848 - val_loss: 0.4300\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4830 - val_loss: 0.4290\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4812 - val_loss: 0.4280\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.4271\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4777 - val_loss: 0.4261\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4760 - val_loss: 0.4252\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4744 - val_loss: 0.4243\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4727 - val_loss: 0.4235\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4711 - val_loss: 0.4226\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4695 - val_loss: 0.4217\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4679 - val_loss: 0.4209\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4663 - val_loss: 0.4200\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4648 - val_loss: 0.4192\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4633 - val_loss: 0.4184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4618 - val_loss: 0.4175\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4603 - val_loss: 0.4167\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4589 - val_loss: 0.4159\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4574 - val_loss: 0.4150\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4560 - val_loss: 0.4142\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4546 - val_loss: 0.4134\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4532 - val_loss: 0.4126\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4518 - val_loss: 0.4118\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4504 - val_loss: 0.4109\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4491 - val_loss: 0.4101\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4477 - val_loss: 0.4093\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4464 - val_loss: 0.4085\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4451 - val_loss: 0.4077\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4438 - val_loss: 0.4069\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4425 - val_loss: 0.4061\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4412 - val_loss: 0.4053\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4399 - val_loss: 0.4045\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4387 - val_loss: 0.4037\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4029\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4362 - val_loss: 0.4021\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4350 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4337 - val_loss: 0.4006\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4325 - val_loss: 0.3998\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4313 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4301 - val_loss: 0.3983\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3346396028.9972167, my average MASE = 7814754000.575592\n",
      "Cluster 3, 3346396028.9972167\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3142 - val_loss: 0.7771\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3138 - val_loss: 0.7770\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3135 - val_loss: 0.7769\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3131 - val_loss: 0.7768\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3127 - val_loss: 0.7767\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3123 - val_loss: 0.7765\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3119 - val_loss: 0.7764\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3116 - val_loss: 0.7763\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3112 - val_loss: 0.7762\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3108 - val_loss: 0.7761\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3105 - val_loss: 0.7759\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3101 - val_loss: 0.7758\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3097 - val_loss: 0.7757\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3094 - val_loss: 0.7756\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3090 - val_loss: 0.7755\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3087 - val_loss: 0.7754\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3083 - val_loss: 0.7753\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3080 - val_loss: 0.7752\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3076 - val_loss: 0.7751\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3073 - val_loss: 0.7749\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3069 - val_loss: 0.7748\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3066 - val_loss: 0.7747\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3063 - val_loss: 0.7746\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3059 - val_loss: 0.7746\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3056 - val_loss: 0.7745\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3053 - val_loss: 0.7744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3049 - val_loss: 0.7743\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3046 - val_loss: 0.7742\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3043 - val_loss: 0.7741\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3040 - val_loss: 0.7740\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3037 - val_loss: 0.7739\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3033 - val_loss: 0.7739\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3030 - val_loss: 0.7738\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3027 - val_loss: 0.7737\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3024 - val_loss: 0.7736\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3021 - val_loss: 0.7735\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.7734\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3015 - val_loss: 0.7733\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3012 - val_loss: 0.7732\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3009 - val_loss: 0.7731\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 93.69104182165661, my average MASE = 20945629.206220664\n",
      "Cluster 4, 93.69104182165661\n",
      "Before prediction: train_X.shape=(89, 10, 67), train_y.shape=(89, 67), test_X.shape=(30, 10, 67), test_y.shape=(30, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3424 - val_loss: 0.3360\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3416 - val_loss: 0.3355\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3408 - val_loss: 0.3350\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3400 - val_loss: 0.3346\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.3341\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3386 - val_loss: 0.3337\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3379 - val_loss: 0.3333\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3372 - val_loss: 0.3329\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3365 - val_loss: 0.3324\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3358 - val_loss: 0.3320\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3351 - val_loss: 0.3316\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3344 - val_loss: 0.3312\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3338 - val_loss: 0.3309\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3331 - val_loss: 0.3305\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3325 - val_loss: 0.3301\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3319 - val_loss: 0.3297\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3312 - val_loss: 0.3293\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3306 - val_loss: 0.3290\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3300 - val_loss: 0.3286\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3294 - val_loss: 0.3282\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3288 - val_loss: 0.3279\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3282 - val_loss: 0.3275\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3276 - val_loss: 0.3272\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3271 - val_loss: 0.3268\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3265 - val_loss: 0.3265\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3260 - val_loss: 0.3262\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3254 - val_loss: 0.3258\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3249 - val_loss: 0.3255\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3244 - val_loss: 0.3252\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.3249\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3234 - val_loss: 0.3246\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3228 - val_loss: 0.3243\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3223 - val_loss: 0.3240\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3237\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3214 - val_loss: 0.3234\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3231\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3204 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3199 - val_loss: 0.3225\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3195 - val_loss: 0.3222\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3190 - val_loss: 0.3219\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(30, 67), test_y.shape=(30, 67)\n",
      "average MASE = 188.45046029060867, my average MASE = 121680879.21353056\n",
      "Cluster 5, 188.45046029060867\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1120 - val_loss: 0.1007\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0987\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1025 - val_loss: 0.0974\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0990 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0960 - val_loss: 0.0954\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0933 - val_loss: 0.0947\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0942\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0888 - val_loss: 0.0938\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0868 - val_loss: 0.0934\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0931\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0834 - val_loss: 0.0928\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0819 - val_loss: 0.0926\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0806 - val_loss: 0.0923\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0793 - val_loss: 0.0921\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0781 - val_loss: 0.0919\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0770 - val_loss: 0.0917\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0759 - val_loss: 0.0916\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0749 - val_loss: 0.0914\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0740 - val_loss: 0.0912\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0732 - val_loss: 0.0911\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0724 - val_loss: 0.0910\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0716 - val_loss: 0.0909\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0709 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0908\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0695 - val_loss: 0.0907\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0689 - val_loss: 0.0906\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0683 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0678 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0673 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0660 - val_loss: 0.0902\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0901\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0900\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0645 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0637 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0634 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1073797047.1669116, my average MASE = 13075073766.705614\n",
      "Cluster 6, 1073797047.1669116\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2348 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2252 - val_loss: 0.2653\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2178 - val_loss: 0.2575\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2120 - val_loss: 0.2511\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2071 - val_loss: 0.2457\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2029 - val_loss: 0.2409\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1991 - val_loss: 0.2366\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1956 - val_loss: 0.2328\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1924 - val_loss: 0.2293\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1895 - val_loss: 0.2261\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1868 - val_loss: 0.2231\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2203\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1820 - val_loss: 0.2178\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1799 - val_loss: 0.2155\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1762 - val_loss: 0.2114\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1745 - val_loss: 0.2096\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1730 - val_loss: 0.2079\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1715 - val_loss: 0.2063\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1702 - val_loss: 0.2048\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1689 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1678 - val_loss: 0.2020\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1666 - val_loss: 0.2007\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1656 - val_loss: 0.1995\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1646 - val_loss: 0.1984\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1636 - val_loss: 0.1973\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1627 - val_loss: 0.1962\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1619 - val_loss: 0.1952\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1610 - val_loss: 0.1943\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1934\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1595 - val_loss: 0.1925\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1588 - val_loss: 0.1917\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1909\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1574 - val_loss: 0.1901\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1568 - val_loss: 0.1894\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1886\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1556 - val_loss: 0.1880\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1550 - val_loss: 0.1873\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1867\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1539 - val_loss: 0.1860\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 180.26488918007823, my average MASE = 179278352.44392422\n",
      "Cluster 7, 180.26488918007823\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=11, 11, 904, (6, 67)\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3401 - val_loss: 0.3875\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3395 - val_loss: 0.3872\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3390 - val_loss: 0.3870\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3385 - val_loss: 0.3868\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3380 - val_loss: 0.3866\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3375 - val_loss: 0.3863\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3370 - val_loss: 0.3861\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3366 - val_loss: 0.3859\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3361 - val_loss: 0.3856\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3357 - val_loss: 0.3854\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3352 - val_loss: 0.3852\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3348 - val_loss: 0.3850\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3343 - val_loss: 0.3848\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3339 - val_loss: 0.3846\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3335 - val_loss: 0.3844\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3331 - val_loss: 0.3842\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3327 - val_loss: 0.3840\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3323 - val_loss: 0.3837\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3318 - val_loss: 0.3835\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3314 - val_loss: 0.3833\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.3831\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3307 - val_loss: 0.3829\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3303 - val_loss: 0.3827\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3825\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3295 - val_loss: 0.3823\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3292 - val_loss: 0.3821\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3288 - val_loss: 0.3820\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3284 - val_loss: 0.3818\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3281 - val_loss: 0.3816\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.3814\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3274 - val_loss: 0.3812\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.3810\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3267 - val_loss: 0.3808\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3263 - val_loss: 0.3806\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3260 - val_loss: 0.3805\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3257 - val_loss: 0.3803\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3254 - val_loss: 0.3801\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3250 - val_loss: 0.3799\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3247 - val_loss: 0.3798\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.3796\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 122.2598699731945, my average MASE = 164200403.28208458\n",
      "Cluster 0, 122.2598699731945\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5011 - val_loss: 0.7038\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5005 - val_loss: 0.7036\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4998 - val_loss: 0.7034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4991 - val_loss: 0.7032\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4984 - val_loss: 0.7030\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4978 - val_loss: 0.7028\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4971 - val_loss: 0.7026\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4964 - val_loss: 0.7024\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4958 - val_loss: 0.7022\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4951 - val_loss: 0.7020\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4945 - val_loss: 0.7017\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4938 - val_loss: 0.7015\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4932 - val_loss: 0.7014\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4926 - val_loss: 0.7012\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4919 - val_loss: 0.7010\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4913 - val_loss: 0.7008\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4907 - val_loss: 0.7006\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4901 - val_loss: 0.7004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4894 - val_loss: 0.7002\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4888 - val_loss: 0.7000\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4882 - val_loss: 0.6998\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4877 - val_loss: 0.6997\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4871 - val_loss: 0.6995\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4865 - val_loss: 0.6993\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4859 - val_loss: 0.6991\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4853 - val_loss: 0.6989\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4847 - val_loss: 0.6988\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4842 - val_loss: 0.6986\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4836 - val_loss: 0.6984\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4831 - val_loss: 0.6983\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4825 - val_loss: 0.6981\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4820 - val_loss: 0.6979\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4815 - val_loss: 0.6978\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4809 - val_loss: 0.6976\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4804 - val_loss: 0.6974\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4799 - val_loss: 0.6973\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4794 - val_loss: 0.6971\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4789 - val_loss: 0.6970\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4783 - val_loss: 0.6968\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4778 - val_loss: 0.6966\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2966824.6919978233, my average MASE = 79205816.45072892\n",
      "Cluster 1, 2966824.6919978233\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1998 - val_loss: 0.3035\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1993 - val_loss: 0.3034\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1988 - val_loss: 0.3034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1982 - val_loss: 0.3033\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1977 - val_loss: 0.3033\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1972 - val_loss: 0.3032\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1967 - val_loss: 0.3032\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1962 - val_loss: 0.3032\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1957 - val_loss: 0.3031\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1952 - val_loss: 0.3031\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1947 - val_loss: 0.3031\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1942 - val_loss: 0.3031\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1938 - val_loss: 0.3030\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1933 - val_loss: 0.3030\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1928 - val_loss: 0.3030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1924 - val_loss: 0.3030\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1919 - val_loss: 0.3030\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1915 - val_loss: 0.3030\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1911 - val_loss: 0.3030\n",
      "Epoch 19: early stopping\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 130.97936905502368, my average MASE = 132554988.34305501\n",
      "Cluster 2, 130.97936905502368\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4496 - val_loss: 0.4061\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4490 - val_loss: 0.4060\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4484 - val_loss: 0.4058\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4478 - val_loss: 0.4057\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4472 - val_loss: 0.4056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4466 - val_loss: 0.4055\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4461 - val_loss: 0.4054\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4455 - val_loss: 0.4053\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4450 - val_loss: 0.4052\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4444 - val_loss: 0.4051\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4439 - val_loss: 0.4050\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4433 - val_loss: 0.4049\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4428 - val_loss: 0.4048\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4423 - val_loss: 0.4047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4417 - val_loss: 0.4046\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4412 - val_loss: 0.4045\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4407 - val_loss: 0.4044\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4402 - val_loss: 0.4043\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4397 - val_loss: 0.4042\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4041\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4387 - val_loss: 0.4040\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4382 - val_loss: 0.4039\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4377 - val_loss: 0.4038\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4372 - val_loss: 0.4037\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4367 - val_loss: 0.4036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4362 - val_loss: 0.4035\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4357 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4352 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4032\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4343 - val_loss: 0.4031\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4338 - val_loss: 0.4030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4333 - val_loss: 0.4029\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4329 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4028\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4027\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4315 - val_loss: 0.4026\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4311 - val_loss: 0.4025\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4306 - val_loss: 0.4024\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4302 - val_loss: 0.4023\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4297 - val_loss: 0.4022\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1437.7621485075726, my average MASE = 33408169.939470924\n",
      "Cluster 3, 1437.7621485075726\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3791 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3768 - val_loss: 0.4780\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3745 - val_loss: 0.4765\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4750\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3700 - val_loss: 0.4735\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3678 - val_loss: 0.4721\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3657 - val_loss: 0.4707\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3636 - val_loss: 0.4693\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3616 - val_loss: 0.4679\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3595 - val_loss: 0.4665\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3576 - val_loss: 0.4652\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3556 - val_loss: 0.4639\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3537 - val_loss: 0.4626\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.4614\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3500 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3482 - val_loss: 0.4590\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3464 - val_loss: 0.4578\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3447 - val_loss: 0.4567\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3430 - val_loss: 0.4556\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3414 - val_loss: 0.4545\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3398 - val_loss: 0.4534\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3382 - val_loss: 0.4524\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3366 - val_loss: 0.4513\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3351 - val_loss: 0.4504\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3335 - val_loss: 0.4494\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3320 - val_loss: 0.4484\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3305 - val_loss: 0.4475\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3291 - val_loss: 0.4466\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3277 - val_loss: 0.4457\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3263 - val_loss: 0.4448\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3249 - val_loss: 0.4439\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3236 - val_loss: 0.4431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3222 - val_loss: 0.4422\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3209 - val_loss: 0.4413\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.4404\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3184 - val_loss: 0.4395\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3171 - val_loss: 0.4386\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3159 - val_loss: 0.4378\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.4369\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3135 - val_loss: 0.4360\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1399316882.5162897, my average MASE = 3857319737.5045514\n",
      "Cluster 4, 1399316882.5162897\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2312 - val_loss: 0.2708\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2231 - val_loss: 0.2627\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2165 - val_loss: 0.2559\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2110 - val_loss: 0.2500\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2061 - val_loss: 0.2449\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2018 - val_loss: 0.2403\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1979 - val_loss: 0.2361\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1944 - val_loss: 0.2322\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1912 - val_loss: 0.2287\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1882 - val_loss: 0.2255\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1854 - val_loss: 0.2224\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1829 - val_loss: 0.2197\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1806 - val_loss: 0.2172\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1785 - val_loss: 0.2150\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1767 - val_loss: 0.2129\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1750 - val_loss: 0.2110\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1734 - val_loss: 0.2093\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1720 - val_loss: 0.2077\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1707 - val_loss: 0.2061\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1695 - val_loss: 0.2047\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1683 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1672 - val_loss: 0.2021\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1661 - val_loss: 0.2009\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1651 - val_loss: 0.1997\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1641 - val_loss: 0.1986\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1632 - val_loss: 0.1975\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1623 - val_loss: 0.1965\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1615 - val_loss: 0.1955\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1599 - val_loss: 0.1937\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1577 - val_loss: 0.1912\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1570 - val_loss: 0.1904\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1897\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1558 - val_loss: 0.1890\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1552 - val_loss: 0.1883\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1547 - val_loss: 0.1877\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1542 - val_loss: 0.1871\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1537 - val_loss: 0.1864\n",
      "17/17 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n",
      "average MASE = 146.93947390831542, my average MASE = 534465305.08164215\n",
      "Cluster 5, 146.93947390831542\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3864 - val_loss: 0.3280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.3279\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3849 - val_loss: 0.3278\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3842 - val_loss: 0.3277\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3834 - val_loss: 0.3276\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3827 - val_loss: 0.3275\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3820 - val_loss: 0.3274\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3813 - val_loss: 0.3274\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.3273\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3799 - val_loss: 0.3272\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.3272\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3785 - val_loss: 0.3271\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3778 - val_loss: 0.3270\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3772 - val_loss: 0.3270\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3765 - val_loss: 0.3269\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.3269\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3753 - val_loss: 0.3268\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3746 - val_loss: 0.3268\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3740 - val_loss: 0.3267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3734 - val_loss: 0.3266\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3728 - val_loss: 0.3266\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3722 - val_loss: 0.3265\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3717 - val_loss: 0.3265\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3711 - val_loss: 0.3264\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3705 - val_loss: 0.3264\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3699 - val_loss: 0.3263\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3694 - val_loss: 0.3263\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3688 - val_loss: 0.3262\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3682 - val_loss: 0.3262\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3262\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3671 - val_loss: 0.3261\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3666 - val_loss: 0.3261\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3660 - val_loss: 0.3260\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3655 - val_loss: 0.3260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3649 - val_loss: 0.3260\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3643 - val_loss: 0.3259\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3632 - val_loss: 0.3259\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3259\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3621 - val_loss: 0.3259\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 304.5484747914777, my average MASE = 15252291.46578898\n",
      "Cluster 6, 304.5484747914777\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8703 - val_loss: 8.9197\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8672 - val_loss: 8.9197\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8642 - val_loss: 8.9196\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8613 - val_loss: 8.9196\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8586 - val_loss: 8.9196\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8558 - val_loss: 8.9195\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8532 - val_loss: 8.9194\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8506 - val_loss: 8.9194\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8480 - val_loss: 8.9193\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8455 - val_loss: 8.9192\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8431 - val_loss: 8.9192\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8407 - val_loss: 8.9191\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8383 - val_loss: 8.9190\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8360 - val_loss: 8.9189\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8337 - val_loss: 8.9188\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8315 - val_loss: 8.9187\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8293 - val_loss: 8.9187\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8271 - val_loss: 8.9186\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8250 - val_loss: 8.9185\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 8.9184\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8209 - val_loss: 8.9184\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 8.9183\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8170 - val_loss: 8.9182\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8150 - val_loss: 8.9181\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8131 - val_loss: 8.9180\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8113 - val_loss: 8.9179\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8095 - val_loss: 8.9179\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 8.9178\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8062 - val_loss: 8.9177\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8046 - val_loss: 8.9176\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8031 - val_loss: 8.9175\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8016 - val_loss: 8.9175\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8000 - val_loss: 8.9174\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7985 - val_loss: 8.9173\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7970 - val_loss: 8.9172\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7955 - val_loss: 8.9171\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7941 - val_loss: 8.9171\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7927 - val_loss: 8.9170\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7913 - val_loss: 8.9170\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7899 - val_loss: 8.9170\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 192382848.4747458, my average MASE = 882590618.8453726\n",
      "Cluster 7, 192382848.4747458\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1119 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0986\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1024 - val_loss: 0.0973\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0988 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0957 - val_loss: 0.0956\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0930 - val_loss: 0.0950\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0905 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0883 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0863 - val_loss: 0.0937\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0933\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0828 - val_loss: 0.0930\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0813 - val_loss: 0.0928\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0799 - val_loss: 0.0925\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0787 - val_loss: 0.0924\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0775 - val_loss: 0.0922\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0764 - val_loss: 0.0920\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0754 - val_loss: 0.0918\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0744 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0735 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0727 - val_loss: 0.0914\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0719 - val_loss: 0.0913\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0711 - val_loss: 0.0912\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0705 - val_loss: 0.0910\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0909\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0692 - val_loss: 0.0908\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0687 - val_loss: 0.0907\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0677 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0660 - val_loss: 0.0901\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0900\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0653 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0646 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0898\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0897\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0896\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0635 - val_loss: 0.0896\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1222984943.0994627, my average MASE = 34180380931.05725\n",
      "Cluster 8, 1222984943.0994627\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3097 - val_loss: 0.3956\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3089 - val_loss: 0.3954\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3081 - val_loss: 0.3952\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3074 - val_loss: 0.3950\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3066 - val_loss: 0.3948\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3059 - val_loss: 0.3945\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3051 - val_loss: 0.3943\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3044 - val_loss: 0.3941\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3037 - val_loss: 0.3939\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3030 - val_loss: 0.3937\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.3935\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3017 - val_loss: 0.3934\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3010 - val_loss: 0.3933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3003 - val_loss: 0.3931\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2997 - val_loss: 0.3930\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2990 - val_loss: 0.3929\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2984 - val_loss: 0.3927\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2977 - val_loss: 0.3926\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2971 - val_loss: 0.3925\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2965 - val_loss: 0.3924\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2959 - val_loss: 0.3923\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2953 - val_loss: 0.3922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2947 - val_loss: 0.3921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2941 - val_loss: 0.3920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2935 - val_loss: 0.3919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2930 - val_loss: 0.3918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2924 - val_loss: 0.3917\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.3917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2913 - val_loss: 0.3916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2907 - val_loss: 0.3915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2902 - val_loss: 0.3914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2896 - val_loss: 0.3914\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2891 - val_loss: 0.3913\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2885 - val_loss: 0.3912\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2880 - val_loss: 0.3911\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2875 - val_loss: 0.3910\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2870 - val_loss: 0.3909\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2865 - val_loss: 0.3908\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2859 - val_loss: 0.3907\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2854 - val_loss: 0.3907\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 561.7864488366092, my average MASE = 24722978.57949824\n",
      "Cluster 10, 561.7864488366092\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=2, 2, 13, (10045, 67)\n",
      "Before prediction: train_X.shape=(6020, 10, 67), train_y.shape=(6020, 67), test_X.shape=(2007, 10, 67), test_y.shape=(2007, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0647 - val_loss: 0.0484\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0596 - val_loss: 0.0453\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0565 - val_loss: 0.0429\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0542 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0523 - val_loss: 0.0394\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0508 - val_loss: 0.0381\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0495 - val_loss: 0.0370\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0484 - val_loss: 0.0360\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0475 - val_loss: 0.0351\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0467 - val_loss: 0.0344\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0461 - val_loss: 0.0338\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0454 - val_loss: 0.0333\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0328\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0444 - val_loss: 0.0323\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0440 - val_loss: 0.0320\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0435 - val_loss: 0.0316\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0313\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0428 - val_loss: 0.0311\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0308\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0306\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0304\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0415 - val_loss: 0.0303\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0412 - val_loss: 0.0301\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0410 - val_loss: 0.0300\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0298\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0297\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0296\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0294\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0293\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0292\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0397 - val_loss: 0.0291\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0396 - val_loss: 0.0291\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0395 - val_loss: 0.0290\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0394 - val_loss: 0.0289\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0393 - val_loss: 0.0289\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0288\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0287\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0390 - val_loss: 0.0287\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0389 - val_loss: 0.0286\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0388 - val_loss: 0.0286\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2007, 67), test_y.shape=(2007, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 124611449.52884135, my average MASE = 52097635280.213745\n",
      "Cluster 0, 124611449.52884135\n",
      "Before prediction: train_X.shape=(18364, 10, 67), train_y.shape=(18364, 67), test_X.shape=(6121, 10, 67), test_y.shape=(6121, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3019 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2812 - val_loss: 0.3011\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2652 - val_loss: 0.2888\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2545 - val_loss: 0.2808\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2479 - val_loss: 0.2750\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2428 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2385 - val_loss: 0.2663\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2348 - val_loss: 0.2629\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2315 - val_loss: 0.2599\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2283 - val_loss: 0.2570\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2254 - val_loss: 0.2544\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2226 - val_loss: 0.2520\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2201 - val_loss: 0.2499\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2179 - val_loss: 0.2480\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2161 - val_loss: 0.2464\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2145 - val_loss: 0.2449\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2436\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2118 - val_loss: 0.2425\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2107 - val_loss: 0.2414\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2096 - val_loss: 0.2403\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2087 - val_loss: 0.2395\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2387\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2070 - val_loss: 0.2379\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2063 - val_loss: 0.2371\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2056 - val_loss: 0.2364\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2049 - val_loss: 0.2358\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2352\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2038 - val_loss: 0.2346\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2032 - val_loss: 0.2342\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2027 - val_loss: 0.2337\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2023 - val_loss: 0.2332\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2018 - val_loss: 0.2329\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2014 - val_loss: 0.2325\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2321\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2006 - val_loss: 0.2318\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2314\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1999 - val_loss: 0.2311\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1996 - val_loss: 0.2308\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.1993 - val_loss: 0.2305\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1990 - val_loss: 0.2302\n",
      "192/192 [==============================] - 2s 11ms/step\n",
      "predicted_original.shape=(6121, 67), test_y.shape=(6121, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1515.0877642124253, my average MASE = 2752.3099444505265\n",
      "Cluster 1, 1515.0877642124253\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=5, 5, 12, (3253, 67)\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1101 - val_loss: 0.0983\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1050 - val_loss: 0.0966\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1009 - val_loss: 0.0954\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0975 - val_loss: 0.0944\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0945 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0919 - val_loss: 0.0931\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0895 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0923\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0855 - val_loss: 0.0921\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0838 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0915\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0807 - val_loss: 0.0912\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0794 - val_loss: 0.0910\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0782 - val_loss: 0.0908\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0771 - val_loss: 0.0906\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0760 - val_loss: 0.0904\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0750 - val_loss: 0.0902\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0741 - val_loss: 0.0901\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0733 - val_loss: 0.0899\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0725 - val_loss: 0.0898\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0717 - val_loss: 0.0897\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0710 - val_loss: 0.0895\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0704 - val_loss: 0.0895\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0894\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0691 - val_loss: 0.0893\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0686 - val_loss: 0.0892\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0681 - val_loss: 0.0892\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0891\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0671 - val_loss: 0.0891\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0890\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0662 - val_loss: 0.0889\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0658 - val_loss: 0.0889\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0888\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0651 - val_loss: 0.0887\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0647 - val_loss: 0.0887\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0644 - val_loss: 0.0886\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0641 - val_loss: 0.0885\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0638 - val_loss: 0.0885\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0636 - val_loss: 0.0884\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0633 - val_loss: 0.0883\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n",
      "average MASE = 1286975259.8033035, my average MASE = 26869301348.284866\n",
      "Cluster 0, 1286975259.8033035\n",
      "Before prediction: train_X.shape=(2221, 10, 67), train_y.shape=(2221, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5056 - val_loss: 0.3755\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4985 - val_loss: 0.3720\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4926 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4874 - val_loss: 0.3660\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4828 - val_loss: 0.3635\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4785 - val_loss: 0.3611\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4745 - val_loss: 0.3590\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4707 - val_loss: 0.3570\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4671 - val_loss: 0.3552\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4637 - val_loss: 0.3535\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4604 - val_loss: 0.3519\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4572 - val_loss: 0.3504\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4542 - val_loss: 0.3489\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4512 - val_loss: 0.3475\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4483 - val_loss: 0.3462\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4455 - val_loss: 0.3449\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4428 - val_loss: 0.3436\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4401 - val_loss: 0.3424\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4375 - val_loss: 0.3412\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4350 - val_loss: 0.3401\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4325 - val_loss: 0.3390\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4301 - val_loss: 0.3380\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4278 - val_loss: 0.3370\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4255 - val_loss: 0.3360\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4233 - val_loss: 0.3350\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4211 - val_loss: 0.3341\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4190 - val_loss: 0.3332\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4170 - val_loss: 0.3324\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4150 - val_loss: 0.3315\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4131 - val_loss: 0.3307\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4113 - val_loss: 0.3299\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4095 - val_loss: 0.3292\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4078 - val_loss: 0.3285\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4061 - val_loss: 0.3278\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4045 - val_loss: 0.3271\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4030 - val_loss: 0.3265\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4014 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3999 - val_loss: 0.3253\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3985 - val_loss: 0.3247\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3971 - val_loss: 0.3242\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 455.57479189703486, my average MASE = 880.739926655778\n",
      "Cluster 1, 455.57479189703486\n",
      "Before prediction: train_X.shape=(41, 10, 67), train_y.shape=(41, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4961 - val_loss: 0.6170\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4945 - val_loss: 0.6160\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4928 - val_loss: 0.6151\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4912 - val_loss: 0.6141\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4896 - val_loss: 0.6132\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4880 - val_loss: 0.6123\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4864 - val_loss: 0.6114\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4849 - val_loss: 0.6105\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4834 - val_loss: 0.6096\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4818 - val_loss: 0.6088\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4803 - val_loss: 0.6080\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4788 - val_loss: 0.6071\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4774 - val_loss: 0.6063\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4759 - val_loss: 0.6055\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4745 - val_loss: 0.6047\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4731 - val_loss: 0.6040\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4717 - val_loss: 0.6033\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4703 - val_loss: 0.6025\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4689 - val_loss: 0.6018\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4676 - val_loss: 0.6012\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4663 - val_loss: 0.6005\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4649 - val_loss: 0.5998\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4636 - val_loss: 0.5992\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4624 - val_loss: 0.5985\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4611 - val_loss: 0.5979\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4598 - val_loss: 0.5973\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4586 - val_loss: 0.5967\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4574 - val_loss: 0.5961\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4561 - val_loss: 0.5955\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4549 - val_loss: 0.5950\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4537 - val_loss: 0.5944\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4525 - val_loss: 0.5939\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4513 - val_loss: 0.5933\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4501 - val_loss: 0.5928\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4489 - val_loss: 0.5922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4478 - val_loss: 0.5917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4466 - val_loss: 0.5912\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4455 - val_loss: 0.5907\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4443 - val_loss: 0.5902\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4432 - val_loss: 0.5897\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3633974576.8812943, my average MASE = 9316750037.661146\n",
      "Cluster 2, 3633974576.8812943\n",
      "Before prediction: train_X.shape=(158, 10, 67), train_y.shape=(158, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5152 - val_loss: 0.4273\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5139 - val_loss: 0.4265\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5128 - val_loss: 0.4257\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5117 - val_loss: 0.4249\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5105 - val_loss: 0.4241\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5095 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5084 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5074 - val_loss: 0.4219\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5064 - val_loss: 0.4212\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5054 - val_loss: 0.4204\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5044 - val_loss: 0.4197\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5034 - val_loss: 0.4191\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5025 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5015 - val_loss: 0.4178\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5006 - val_loss: 0.4171\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4997 - val_loss: 0.4165\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4988 - val_loss: 0.4159\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4979 - val_loss: 0.4153\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4970 - val_loss: 0.4147\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4961 - val_loss: 0.4141\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4953 - val_loss: 0.4135\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4944 - val_loss: 0.4129\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4936 - val_loss: 0.4123\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4928 - val_loss: 0.4118\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4920 - val_loss: 0.4112\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4912 - val_loss: 0.4107\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4904 - val_loss: 0.4101\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4096\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4889 - val_loss: 0.4091\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4882 - val_loss: 0.4086\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4874 - val_loss: 0.4080\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4867 - val_loss: 0.4075\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4860 - val_loss: 0.4070\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4852 - val_loss: 0.4065\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4845 - val_loss: 0.4060\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4838 - val_loss: 0.4055\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4831 - val_loss: 0.4050\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4045\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4818 - val_loss: 0.4040\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4811 - val_loss: 0.4036\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 113.07393682707622, my average MASE = 188079219.47717956\n",
      "Cluster 3, 113.07393682707622\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7117 - val_loss: 0.7129\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7087 - val_loss: 0.7117\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7057 - val_loss: 0.7104\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7028 - val_loss: 0.7094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7000 - val_loss: 0.7084\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6972 - val_loss: 0.7075\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6945 - val_loss: 0.7066\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6918 - val_loss: 0.7056\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6891 - val_loss: 0.7047\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6865 - val_loss: 0.7037\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6838 - val_loss: 0.7028\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6811 - val_loss: 0.7018\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6785 - val_loss: 0.7009\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6758 - val_loss: 0.6999\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6732 - val_loss: 0.6990\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6706 - val_loss: 0.6981\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6680 - val_loss: 0.6971\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6654 - val_loss: 0.6961\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6628 - val_loss: 0.6951\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6604 - val_loss: 0.6942\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6580 - val_loss: 0.6934\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6556 - val_loss: 0.6926\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6534 - val_loss: 0.6918\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6512 - val_loss: 0.6910\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6491 - val_loss: 0.6902\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6470 - val_loss: 0.6894\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6449 - val_loss: 0.6886\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6429 - val_loss: 0.6877\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6409 - val_loss: 0.6869\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6389 - val_loss: 0.6861\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6369 - val_loss: 0.6853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6350 - val_loss: 0.6847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6332 - val_loss: 0.6841\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6314 - val_loss: 0.6836\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6297 - val_loss: 0.6831\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6280 - val_loss: 0.6827\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6263 - val_loss: 0.6825\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6246 - val_loss: 0.6824\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6229 - val_loss: 0.6823\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6212 - val_loss: 0.6822\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2798887382418345, my average MASE = 0.5334982550486497\n",
      "Cluster 4, 0.2798887382418345\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=7, 7, 431, (13, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(180, 10, 67), train_y.shape=(180, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6852 - val_loss: 0.5575\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6838 - val_loss: 0.5569\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6824 - val_loss: 0.5563\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6811 - val_loss: 0.5557\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6799 - val_loss: 0.5551\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6786 - val_loss: 0.5545\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6774 - val_loss: 0.5540\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6762 - val_loss: 0.5534\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6750 - val_loss: 0.5528\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6739 - val_loss: 0.5523\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6727 - val_loss: 0.5518\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5512\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6705 - val_loss: 0.5507\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6694 - val_loss: 0.5501\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6684 - val_loss: 0.5496\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6673 - val_loss: 0.5491\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6663 - val_loss: 0.5486\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6653 - val_loss: 0.5481\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6643 - val_loss: 0.5475\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6632 - val_loss: 0.5470\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6623 - val_loss: 0.5465\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6613 - val_loss: 0.5461\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6603 - val_loss: 0.5456\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6594 - val_loss: 0.5451\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6584 - val_loss: 0.5446\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6575 - val_loss: 0.5441\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6566 - val_loss: 0.5437\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6557 - val_loss: 0.5432\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6548 - val_loss: 0.5427\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6539 - val_loss: 0.5423\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6531 - val_loss: 0.5418\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6522 - val_loss: 0.5414\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6513 - val_loss: 0.5409\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6505 - val_loss: 0.5405\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6497 - val_loss: 0.5400\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6489 - val_loss: 0.5396\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6480 - val_loss: 0.5392\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6472 - val_loss: 0.5387\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6464 - val_loss: 0.5383\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6456 - val_loss: 0.5379\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 161.0036674860674, my average MASE = 412096886.9283237\n",
      "Cluster 1, 161.0036674860674\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6031 - val_loss: 0.4390\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6002 - val_loss: 0.4369\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5975 - val_loss: 0.4349\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5947 - val_loss: 0.4328\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5919 - val_loss: 0.4307\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5892 - val_loss: 0.4287\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5864 - val_loss: 0.4267\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5838 - val_loss: 0.4248\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5812 - val_loss: 0.4230\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5786 - val_loss: 0.4213\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5761 - val_loss: 0.4196\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5736 - val_loss: 0.4180\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5712 - val_loss: 0.4164\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5687 - val_loss: 0.4148\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5663 - val_loss: 0.4132\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5638 - val_loss: 0.4116\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5614 - val_loss: 0.4101\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5590 - val_loss: 0.4085\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5566 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5542 - val_loss: 0.4054\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5518 - val_loss: 0.4039\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5494 - val_loss: 0.4024\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5471 - val_loss: 0.4008\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5448 - val_loss: 0.3992\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5424 - val_loss: 0.3977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5401 - val_loss: 0.3961\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5378 - val_loss: 0.3945\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5355 - val_loss: 0.3930\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5333 - val_loss: 0.3914\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5310 - val_loss: 0.3898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5288 - val_loss: 0.3883\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5266 - val_loss: 0.3868\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5243 - val_loss: 0.3855\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5221 - val_loss: 0.3842\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5199 - val_loss: 0.3830\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5176 - val_loss: 0.3817\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5154 - val_loss: 0.3804\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5133 - val_loss: 0.3792\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5111 - val_loss: 0.3780\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5089 - val_loss: 0.3770\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.22679251401977166, my average MASE = 0.3179573135228401\n",
      "Cluster 2, 0.22679251401977166\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4783 - val_loss: 0.4457\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4766 - val_loss: 0.4444\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4750 - val_loss: 0.4432\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4734 - val_loss: 0.4420\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4719 - val_loss: 0.4408\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4703 - val_loss: 0.4397\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4687 - val_loss: 0.4385\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4672 - val_loss: 0.4374\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4657 - val_loss: 0.4362\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4642 - val_loss: 0.4351\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4627 - val_loss: 0.4340\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4613 - val_loss: 0.4329\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4598 - val_loss: 0.4318\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4584 - val_loss: 0.4307\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4296\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4555 - val_loss: 0.4286\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4541 - val_loss: 0.4275\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4527 - val_loss: 0.4265\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4513 - val_loss: 0.4255\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4499 - val_loss: 0.4245\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4486 - val_loss: 0.4235\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4472 - val_loss: 0.4225\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4459 - val_loss: 0.4215\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4445 - val_loss: 0.4205\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4432 - val_loss: 0.4195\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4186\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4406 - val_loss: 0.4176\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4167\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4380 - val_loss: 0.4158\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4368 - val_loss: 0.4149\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4355 - val_loss: 0.4139\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4343 - val_loss: 0.4130\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4330 - val_loss: 0.4121\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4318 - val_loss: 0.4112\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4306 - val_loss: 0.4103\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4294 - val_loss: 0.4094\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4282 - val_loss: 0.4085\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4270 - val_loss: 0.4077\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4258 - val_loss: 0.4068\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4246 - val_loss: 0.4059\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3532936323.38913, my average MASE = 7800622104.848636\n",
      "Cluster 3, 3532936323.38913\n",
      "Before prediction: train_X.shape=(152, 10, 67), train_y.shape=(152, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3354 - val_loss: 0.2774\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3344 - val_loss: 0.2769\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3336 - val_loss: 0.2763\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3328 - val_loss: 0.2758\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3320 - val_loss: 0.2753\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3312 - val_loss: 0.2747\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3304 - val_loss: 0.2742\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3297 - val_loss: 0.2737\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3290 - val_loss: 0.2733\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3282 - val_loss: 0.2728\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3275 - val_loss: 0.2723\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3268 - val_loss: 0.2718\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3262 - val_loss: 0.2714\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3255 - val_loss: 0.2709\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3248 - val_loss: 0.2705\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3242 - val_loss: 0.2700\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3235 - val_loss: 0.2696\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3229 - val_loss: 0.2692\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3223 - val_loss: 0.2687\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3217 - val_loss: 0.2683\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3210 - val_loss: 0.2678\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3204 - val_loss: 0.2674\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3198 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3192 - val_loss: 0.2666\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3187 - val_loss: 0.2662\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3181 - val_loss: 0.2658\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3175 - val_loss: 0.2654\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3170 - val_loss: 0.2650\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3164 - val_loss: 0.2647\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3158 - val_loss: 0.2643\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3153 - val_loss: 0.2639\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3148 - val_loss: 0.2635\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3142 - val_loss: 0.2632\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3137 - val_loss: 0.2628\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3132 - val_loss: 0.2624\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3127 - val_loss: 0.2621\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3122 - val_loss: 0.2617\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3117 - val_loss: 0.2614\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3112 - val_loss: 0.2610\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3107 - val_loss: 0.2607\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 185.09520141259705, my average MASE = 132066880.5161765\n",
      "Cluster 4, 185.09520141259705\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0679 - val_loss: 0.0461\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0619 - val_loss: 0.0426\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0586 - val_loss: 0.0401\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0561 - val_loss: 0.0381\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0542 - val_loss: 0.0366\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0527 - val_loss: 0.0352\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0514 - val_loss: 0.0341\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0503 - val_loss: 0.0333\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0312\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0473 - val_loss: 0.0307\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0468 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0463 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0459 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0455 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0452 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0448 - val_loss: 0.0288\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0286\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0443 - val_loss: 0.0284\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0283\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0281\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0436 - val_loss: 0.0279\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0434 - val_loss: 0.0278\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0277\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0276\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0274\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0273\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0426 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0425 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0423 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0422 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0421 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0420 - val_loss: 0.0269\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0419 - val_loss: 0.0268\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0267\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 1042799882.6542007, my average MASE = 20591462481.802387\n",
      "Cluster 5, 1042799882.6542007\n",
      "Before prediction: train_X.shape=(82, 10, 67), train_y.shape=(82, 67), test_X.shape=(27, 10, 67), test_y.shape=(27, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3924 - val_loss: 0.4859\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3915 - val_loss: 0.4852\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3907 - val_loss: 0.4846\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3899 - val_loss: 0.4840\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3891 - val_loss: 0.4835\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3883 - val_loss: 0.4829\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3876 - val_loss: 0.4824\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3868 - val_loss: 0.4818\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3861 - val_loss: 0.4813\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 0.4808\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3847 - val_loss: 0.4802\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3841 - val_loss: 0.4797\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3834 - val_loss: 0.4792\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3828 - val_loss: 0.4787\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3821 - val_loss: 0.4783\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3815 - val_loss: 0.4778\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3809 - val_loss: 0.4773\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3804 - val_loss: 0.4769\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3798 - val_loss: 0.4764\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.4760\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3787 - val_loss: 0.4755\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3781 - val_loss: 0.4751\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4747\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3771 - val_loss: 0.4743\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3766 - val_loss: 0.4738\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3761 - val_loss: 0.4734\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3756 - val_loss: 0.4731\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3751 - val_loss: 0.4727\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3746 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3741 - val_loss: 0.4719\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3737 - val_loss: 0.4715\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3732 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3728 - val_loss: 0.4707\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3723 - val_loss: 0.4703\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3719 - val_loss: 0.4699\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3715 - val_loss: 0.4696\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3710 - val_loss: 0.4692\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3706 - val_loss: 0.4688\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3702 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3698 - val_loss: 0.4681\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(27, 67), test_y.shape=(27, 67)\n",
      "average MASE = 307.7375965485456, my average MASE = 158440912.42565766\n",
      "Cluster 6, 307.7375965485456\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=9, 9, 32, (76, 67)\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4763 - val_loss: 0.4497\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4746 - val_loss: 0.4487\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4729 - val_loss: 0.4477\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4713 - val_loss: 0.4467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4696 - val_loss: 0.4458\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4680 - val_loss: 0.4448\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.4439\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4647 - val_loss: 0.4429\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4631 - val_loss: 0.4420\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.4410\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4600 - val_loss: 0.4401\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4585 - val_loss: 0.4392\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4554 - val_loss: 0.4373\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4539 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4524 - val_loss: 0.4355\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4510 - val_loss: 0.4345\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4495 - val_loss: 0.4336\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4481 - val_loss: 0.4327\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.4319\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4453 - val_loss: 0.4310\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4439 - val_loss: 0.4301\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4425 - val_loss: 0.4293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4412 - val_loss: 0.4284\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4398 - val_loss: 0.4276\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4385 - val_loss: 0.4267\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4371 - val_loss: 0.4259\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4358 - val_loss: 0.4251\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.4243\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4332 - val_loss: 0.4234\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4226\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4307 - val_loss: 0.4218\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4294 - val_loss: 0.4210\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4282 - val_loss: 0.4202\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4270 - val_loss: 0.4195\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4258 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4246 - val_loss: 0.4179\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4234 - val_loss: 0.4172\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4222 - val_loss: 0.4164\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4211 - val_loss: 0.4157\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3502979890.5184355, my average MASE = 5633924620.870799\n",
      "Cluster 0, 3502979890.5184355\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1163 - val_loss: 0.0998\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1111 - val_loss: 0.0974\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1069 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1034 - val_loss: 0.0946\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1003 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0952 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0929 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0909 - val_loss: 0.0914\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0891 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0907\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0859 - val_loss: 0.0904\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0902\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0831 - val_loss: 0.0900\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0808 - val_loss: 0.0896\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0797 - val_loss: 0.0894\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0787 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0778 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0769 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0761 - val_loss: 0.0890\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0889\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0745 - val_loss: 0.0888\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0738 - val_loss: 0.0887\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0731 - val_loss: 0.0886\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0725 - val_loss: 0.0886\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0885\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0713 - val_loss: 0.0885\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0707 - val_loss: 0.0884\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0702 - val_loss: 0.0884\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0697 - val_loss: 0.0883\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0692 - val_loss: 0.0883\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0882\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0683 - val_loss: 0.0882\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0881\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0881\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0880\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0880\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0665 - val_loss: 0.0879\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0662 - val_loss: 0.0879\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1199834821.8603294, my average MASE = 15362171394.25593\n",
      "Cluster 1, 1199834821.8603294\n",
      "Before prediction: train_X.shape=(1567, 10, 67), train_y.shape=(1567, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2378 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2280 - val_loss: 0.2658\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2204 - val_loss: 0.2582\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2142 - val_loss: 0.2520\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2091 - val_loss: 0.2467\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2046 - val_loss: 0.2420\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2006 - val_loss: 0.2378\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1971 - val_loss: 0.2340\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1938 - val_loss: 0.2304\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1908 - val_loss: 0.2272\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1880 - val_loss: 0.2241\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1853 - val_loss: 0.2213\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1829 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1806 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1784 - val_loss: 0.2141\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1765 - val_loss: 0.2121\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1747 - val_loss: 0.2103\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1730 - val_loss: 0.2086\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1715 - val_loss: 0.2071\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1702 - val_loss: 0.2056\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1689 - val_loss: 0.2042\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1677 - val_loss: 0.2029\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2016\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2005\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1645 - val_loss: 0.1993\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1983\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1626 - val_loss: 0.1973\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1618 - val_loss: 0.1962\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1610 - val_loss: 0.1953\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1944\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1594 - val_loss: 0.1935\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1587 - val_loss: 0.1927\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1580 - val_loss: 0.1919\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1573 - val_loss: 0.1911\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1567 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1555 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1550 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1539 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 164.5516081334958, my average MASE = 793528060.8539205\n",
      "Cluster 2, 164.5516081334958\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3929 - val_loss: 0.4650\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 0.4646\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3912 - val_loss: 0.4642\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3904 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3896 - val_loss: 0.4635\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3889 - val_loss: 0.4631\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3881 - val_loss: 0.4627\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3874 - val_loss: 0.4624\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4621\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.4617\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3854 - val_loss: 0.4614\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3847 - val_loss: 0.4611\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3841 - val_loss: 0.4608\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3835 - val_loss: 0.4605\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3829 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3823 - val_loss: 0.4600\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3817 - val_loss: 0.4597\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3812 - val_loss: 0.4594\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.4591\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3800 - val_loss: 0.4588\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3795 - val_loss: 0.4585\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3790 - val_loss: 0.4583\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3785 - val_loss: 0.4580\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.4578\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3775 - val_loss: 0.4575\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3770 - val_loss: 0.4572\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3765 - val_loss: 0.4570\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3761 - val_loss: 0.4567\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3756 - val_loss: 0.4565\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3752 - val_loss: 0.4563\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3747 - val_loss: 0.4560\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3738 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3734 - val_loss: 0.4553\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3730 - val_loss: 0.4551\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3725 - val_loss: 0.4549\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3721 - val_loss: 0.4547\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3717 - val_loss: 0.4545\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3713 - val_loss: 0.4542\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3709 - val_loss: 0.4540\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 177.05816941536048, my average MASE = 104373067.45181417\n",
      "Cluster 3, 177.05816941536048\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4712 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4689 - val_loss: 0.3159\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.3148\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4644 - val_loss: 0.3137\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4621 - val_loss: 0.3125\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4598 - val_loss: 0.3114\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4576 - val_loss: 0.3103\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4553 - val_loss: 0.3092\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4531 - val_loss: 0.3081\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4509 - val_loss: 0.3071\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.3062\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4465 - val_loss: 0.3053\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4444 - val_loss: 0.3044\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4422 - val_loss: 0.3036\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4401 - val_loss: 0.3028\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4379 - val_loss: 0.3020\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4358 - val_loss: 0.3012\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.3004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4317 - val_loss: 0.2996\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4297 - val_loss: 0.2988\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4278 - val_loss: 0.2979\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4259 - val_loss: 0.2970\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4240 - val_loss: 0.2961\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4222 - val_loss: 0.2952\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4204 - val_loss: 0.2943\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4186 - val_loss: 0.2934\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4168 - val_loss: 0.2924\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4151 - val_loss: 0.2915\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4134 - val_loss: 0.2906\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4118 - val_loss: 0.2898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4102 - val_loss: 0.2890\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4086 - val_loss: 0.2883\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4070 - val_loss: 0.2876\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.2869\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4039 - val_loss: 0.2863\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4009 - val_loss: 0.2850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.2845\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3980 - val_loss: 0.2840\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3966 - val_loss: 0.2835\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 254.89087963107983, my average MASE = 19795911.088192035\n",
      "Cluster 5, 254.89087963107983\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(176, 10, 67), train_y.shape=(176, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7010 - val_loss: 0.5674\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6997 - val_loss: 0.5667\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6984 - val_loss: 0.5660\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6972 - val_loss: 0.5654\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6960 - val_loss: 0.5647\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6948 - val_loss: 0.5641\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6937 - val_loss: 0.5635\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6925 - val_loss: 0.5629\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.5623\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6903 - val_loss: 0.5617\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6893 - val_loss: 0.5611\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6882 - val_loss: 0.5605\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6871 - val_loss: 0.5599\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6861 - val_loss: 0.5594\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6851 - val_loss: 0.5588\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6841 - val_loss: 0.5583\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6831 - val_loss: 0.5577\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6821 - val_loss: 0.5572\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6811 - val_loss: 0.5567\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6802 - val_loss: 0.5562\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6792 - val_loss: 0.5556\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6783 - val_loss: 0.5551\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6774 - val_loss: 0.5546\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6765 - val_loss: 0.5541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6756 - val_loss: 0.5536\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6747 - val_loss: 0.5531\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6738 - val_loss: 0.5526\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6729 - val_loss: 0.5521\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6720 - val_loss: 0.5516\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6712 - val_loss: 0.5512\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6703 - val_loss: 0.5507\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6695 - val_loss: 0.5502\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6686 - val_loss: 0.5497\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6678 - val_loss: 0.5493\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6670 - val_loss: 0.5488\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6661 - val_loss: 0.5483\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6653 - val_loss: 0.5479\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.5474\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6637 - val_loss: 0.5469\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6629 - val_loss: 0.5464\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 154.34881195949765, my average MASE = 318959730.30915844\n",
      "Cluster 7, 154.34881195949765\n",
      "Before prediction: train_X.shape=(150, 10, 67), train_y.shape=(150, 67), test_X.shape=(50, 10, 67), test_y.shape=(50, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3127 - val_loss: 0.2620\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3118 - val_loss: 0.2614\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3110 - val_loss: 0.2608\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3103 - val_loss: 0.2603\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3096 - val_loss: 0.2597\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3088 - val_loss: 0.2592\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3081 - val_loss: 0.2587\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3074 - val_loss: 0.2582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3067 - val_loss: 0.2577\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3060 - val_loss: 0.2572\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3054 - val_loss: 0.2567\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3047 - val_loss: 0.2563\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3041 - val_loss: 0.2558\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3035 - val_loss: 0.2554\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3029 - val_loss: 0.2549\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3023 - val_loss: 0.2545\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3017 - val_loss: 0.2541\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3011 - val_loss: 0.2537\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3005 - val_loss: 0.2533\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3000 - val_loss: 0.2529\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2994 - val_loss: 0.2525\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2988 - val_loss: 0.2521\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2983 - val_loss: 0.2517\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2978 - val_loss: 0.2513\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2973 - val_loss: 0.2509\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2967 - val_loss: 0.2505\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2962 - val_loss: 0.2502\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2957 - val_loss: 0.2498\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2952 - val_loss: 0.2494\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2948 - val_loss: 0.2491\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2943 - val_loss: 0.2487\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2938 - val_loss: 0.2484\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2933 - val_loss: 0.2480\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2929 - val_loss: 0.2477\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2924 - val_loss: 0.2473\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2920 - val_loss: 0.2470\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2915 - val_loss: 0.2467\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2911 - val_loss: 0.2463\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2907 - val_loss: 0.2460\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2902 - val_loss: 0.2457\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(50, 67), test_y.shape=(50, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 222.6692241509544, my average MASE = 77008768.33506098\n",
      "Cluster 8, 222.6692241509544\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=11, 11, 435, (11, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4436 - val_loss: 0.3307\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4426 - val_loss: 0.3306\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4417 - val_loss: 0.3306\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4408 - val_loss: 0.3305\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4398 - val_loss: 0.3305\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4389 - val_loss: 0.3304\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4380 - val_loss: 0.3303\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4371 - val_loss: 0.3303\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4362 - val_loss: 0.3302\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4354 - val_loss: 0.3301\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.3301\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4337 - val_loss: 0.3300\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4329 - val_loss: 0.3299\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4320 - val_loss: 0.3299\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4312 - val_loss: 0.3298\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4304 - val_loss: 0.3298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4296 - val_loss: 0.3297\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4288 - val_loss: 0.3296\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4280 - val_loss: 0.3295\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4273 - val_loss: 0.3295\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4265 - val_loss: 0.3294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4258 - val_loss: 0.3293\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4250 - val_loss: 0.3293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4243 - val_loss: 0.3292\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4235 - val_loss: 0.3291\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4228 - val_loss: 0.3291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4221 - val_loss: 0.3290\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4213 - val_loss: 0.3290\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.3289\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4199 - val_loss: 0.3288\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4191 - val_loss: 0.3288\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4184 - val_loss: 0.3287\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4177 - val_loss: 0.3287\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4170 - val_loss: 0.3286\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4163 - val_loss: 0.3286\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 0.3285\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4149 - val_loss: 0.3285\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4143 - val_loss: 0.3285\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4136 - val_loss: 0.3284\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4129 - val_loss: 0.3284\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 623.4242587364998, my average MASE = 13116998.58946489\n",
      "Cluster 0, 623.4242587364998\n",
      "Before prediction: train_X.shape=(18, 10, 67), train_y.shape=(18, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4512 - val_loss: 0.5917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4491 - val_loss: 0.5900\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4470 - val_loss: 0.5884\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4449 - val_loss: 0.5867\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4429 - val_loss: 0.5851\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4408 - val_loss: 0.5835\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.5818\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4369 - val_loss: 0.5802\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4349 - val_loss: 0.5786\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4330 - val_loss: 0.5770\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4311 - val_loss: 0.5755\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4293 - val_loss: 0.5739\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4275 - val_loss: 0.5724\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4257 - val_loss: 0.5709\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4239 - val_loss: 0.5694\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4222 - val_loss: 0.5680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4205 - val_loss: 0.5666\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4188 - val_loss: 0.5652\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4171 - val_loss: 0.5638\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4155 - val_loss: 0.5625\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4139 - val_loss: 0.5611\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4123 - val_loss: 0.5598\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4107 - val_loss: 0.5584\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4092 - val_loss: 0.5571\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4077 - val_loss: 0.5558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4062 - val_loss: 0.5545\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4047 - val_loss: 0.5532\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4032 - val_loss: 0.5519\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4017 - val_loss: 0.5506\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4003 - val_loss: 0.5494\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.5482\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5470\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3960 - val_loss: 0.5458\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.5446\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3933 - val_loss: 0.5435\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3920 - val_loss: 0.5424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3906 - val_loss: 0.5414\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3893 - val_loss: 0.5403\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3881 - val_loss: 0.5393\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3868 - val_loss: 0.5382\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1669347283.8471758, my average MASE = 4344504132.76493\n",
      "Cluster 1, 1669347283.8471758\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0678 - val_loss: 0.0460\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0618 - val_loss: 0.0427\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0585 - val_loss: 0.0404\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0561 - val_loss: 0.0385\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0542 - val_loss: 0.0369\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0527 - val_loss: 0.0355\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0514 - val_loss: 0.0344\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0503 - val_loss: 0.0335\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0327\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0321\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0315\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0473 - val_loss: 0.0310\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0468 - val_loss: 0.0306\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0463 - val_loss: 0.0302\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0458 - val_loss: 0.0299\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0454 - val_loss: 0.0296\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0293\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0447 - val_loss: 0.0291\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0444 - val_loss: 0.0289\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0442 - val_loss: 0.0287\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0439 - val_loss: 0.0285\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0283\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0434 - val_loss: 0.0281\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0430 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0427 - val_loss: 0.0276\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0423 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0419 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0266\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0415 - val_loss: 0.0265\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0264\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0263\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 811440996.3412759, my average MASE = 40052487777.48425\n",
      "Cluster 2, 811440996.3412759\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1986 - val_loss: 0.8095\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1967 - val_loss: 0.8095\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1948 - val_loss: 0.8095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1930 - val_loss: 0.8094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1912 - val_loss: 0.8094\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1894 - val_loss: 0.8094\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1876 - val_loss: 0.8094\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1858 - val_loss: 0.8094\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1840 - val_loss: 0.8094\n",
      "Epoch 9: early stopping\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 72.88641883174732, my average MASE = 50002377.286928184\n",
      "Cluster 3, 72.88641883174732\n",
      "Before prediction: train_X.shape=(87, 10, 67), train_y.shape=(87, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5691 - val_loss: 0.5072\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5682 - val_loss: 0.5068\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5674 - val_loss: 0.5063\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5666 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5659 - val_loss: 0.5055\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5651 - val_loss: 0.5051\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5643 - val_loss: 0.5047\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5636 - val_loss: 0.5042\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5628 - val_loss: 0.5038\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5621 - val_loss: 0.5034\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5614 - val_loss: 0.5030\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5606 - val_loss: 0.5026\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5600 - val_loss: 0.5022\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5592 - val_loss: 0.5018\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5586 - val_loss: 0.5014\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5579 - val_loss: 0.5011\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5572 - val_loss: 0.5007\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5565 - val_loss: 0.5003\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5558 - val_loss: 0.4999\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5552 - val_loss: 0.4996\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5545 - val_loss: 0.4993\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5539 - val_loss: 0.4989\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5532 - val_loss: 0.4986\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5526 - val_loss: 0.4983\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5520 - val_loss: 0.4979\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5513 - val_loss: 0.4976\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5507 - val_loss: 0.4973\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5501 - val_loss: 0.4970\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5495 - val_loss: 0.4967\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5489 - val_loss: 0.4964\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5483 - val_loss: 0.4961\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5477 - val_loss: 0.4958\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5471 - val_loss: 0.4956\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5465 - val_loss: 0.4953\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5459 - val_loss: 0.4950\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5453 - val_loss: 0.4947\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5447 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5442 - val_loss: 0.4942\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.4939\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5430 - val_loss: 0.4936\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 98.29689269118158, my average MASE = 78492579.83265808\n",
      "Cluster 4, 98.29689269118158\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4003 - val_loss: 0.3997\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3997 - val_loss: 0.3991\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3991 - val_loss: 0.3986\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3985 - val_loss: 0.3981\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3976\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3973 - val_loss: 0.3971\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3968 - val_loss: 0.3967\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3962\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3957 - val_loss: 0.3958\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3953\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3946 - val_loss: 0.3949\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3940 - val_loss: 0.3945\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3935 - val_loss: 0.3941\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3930 - val_loss: 0.3937\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3924 - val_loss: 0.3932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3919 - val_loss: 0.3928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3914 - val_loss: 0.3925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3904 - val_loss: 0.3917\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3899 - val_loss: 0.3913\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3894 - val_loss: 0.3909\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3889 - val_loss: 0.3906\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3884 - val_loss: 0.3902\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3879 - val_loss: 0.3898\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3870 - val_loss: 0.3891\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3865 - val_loss: 0.3887\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.3883\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3856 - val_loss: 0.3880\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3851 - val_loss: 0.3876\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3847 - val_loss: 0.3872\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3842 - val_loss: 0.3869\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3838 - val_loss: 0.3865\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3833 - val_loss: 0.3861\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3829 - val_loss: 0.3857\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3824 - val_loss: 0.3853\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 0.3850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3815 - val_loss: 0.3846\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3811 - val_loss: 0.3842\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3807 - val_loss: 0.3838\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 517837.8778283109, my average MASE = 16943290.739345513\n",
      "Cluster 6, 517837.8778283109\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2151 - val_loss: 0.4042\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2146 - val_loss: 0.4041\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2142 - val_loss: 0.4041\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2137 - val_loss: 0.4040\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2133 - val_loss: 0.4040\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2128 - val_loss: 0.4040\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2124 - val_loss: 0.4039\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2119 - val_loss: 0.4039\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2115 - val_loss: 0.4038\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2111 - val_loss: 0.4038\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2107 - val_loss: 0.4038\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2103 - val_loss: 0.4038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2099 - val_loss: 0.4037\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2096 - val_loss: 0.4037\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2092 - val_loss: 0.4037\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2088 - val_loss: 0.4036\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2084 - val_loss: 0.4036\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2081 - val_loss: 0.4036\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2077 - val_loss: 0.4035\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2074 - val_loss: 0.4035\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2070 - val_loss: 0.4035\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2067 - val_loss: 0.4035\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2063 - val_loss: 0.4035\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2060 - val_loss: 0.4034\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2057 - val_loss: 0.4034\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2054 - val_loss: 0.4034\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2050 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2047 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2044 - val_loss: 0.4033\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2041 - val_loss: 0.4033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2038 - val_loss: 0.4032\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2035 - val_loss: 0.4032\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2032 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2029 - val_loss: 0.4031\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2026 - val_loss: 0.4031\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2023 - val_loss: 0.4031\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2020 - val_loss: 0.4030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2017 - val_loss: 0.4030\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2014 - val_loss: 0.4029\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2011 - val_loss: 0.4029\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 181.01448499364625, my average MASE = 73613295.18701741\n",
      "Cluster 7, 181.01448499364625\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2941 - val_loss: 0.3652\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2932 - val_loss: 0.3650\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2923 - val_loss: 0.3648\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2914 - val_loss: 0.3646\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2905 - val_loss: 0.3644\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2897 - val_loss: 0.3641\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2888 - val_loss: 0.3639\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2880 - val_loss: 0.3638\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2872 - val_loss: 0.3636\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2864 - val_loss: 0.3634\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2856 - val_loss: 0.3632\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2848 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2840 - val_loss: 0.3629\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2832 - val_loss: 0.3628\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2824 - val_loss: 0.3626\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2817 - val_loss: 0.3625\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2809 - val_loss: 0.3624\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2802 - val_loss: 0.3622\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2794 - val_loss: 0.3621\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2787 - val_loss: 0.3620\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2780 - val_loss: 0.3619\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2772 - val_loss: 0.3618\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2765 - val_loss: 0.3617\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2758 - val_loss: 0.3616\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2751 - val_loss: 0.3615\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2744 - val_loss: 0.3615\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2738 - val_loss: 0.3614\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2731 - val_loss: 0.3613\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2725 - val_loss: 0.3613\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2718 - val_loss: 0.3612\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2712 - val_loss: 0.3612\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2705 - val_loss: 0.3611\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2699 - val_loss: 0.3611\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2693 - val_loss: 0.3610\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2687 - val_loss: 0.3610\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2681 - val_loss: 0.3610\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2675 - val_loss: 0.3609\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2669 - val_loss: 0.3609\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2663 - val_loss: 0.3608\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.3608\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 679.6913673037432, my average MASE = 68962615.13093176\n",
      "Cluster 9, 679.6913673037432\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=2, 2, 11, (10056, 67)\n",
      "Before prediction: train_X.shape=(6027, 10, 67), train_y.shape=(6027, 67), test_X.shape=(2009, 10, 67), test_y.shape=(2009, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0641 - val_loss: 0.0494\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0590 - val_loss: 0.0459\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0558 - val_loss: 0.0432\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0535 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0516 - val_loss: 0.0393\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0501 - val_loss: 0.0378\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0489 - val_loss: 0.0366\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0478 - val_loss: 0.0357\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0470 - val_loss: 0.0348\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0462 - val_loss: 0.0341\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0455 - val_loss: 0.0335\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0330\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0443 - val_loss: 0.0325\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0321\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0317\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0314\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0311\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0423 - val_loss: 0.0308\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0419 - val_loss: 0.0305\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0303\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0414 - val_loss: 0.0300\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0298\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0296\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0406 - val_loss: 0.0294\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0404 - val_loss: 0.0293\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0403 - val_loss: 0.0291\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0401 - val_loss: 0.0290\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0399 - val_loss: 0.0289\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0397 - val_loss: 0.0287\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0396 - val_loss: 0.0286\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0394 - val_loss: 0.0286\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0393 - val_loss: 0.0285\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0392 - val_loss: 0.0284\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0391 - val_loss: 0.0283\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0389 - val_loss: 0.0282\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0388 - val_loss: 0.0282\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0387 - val_loss: 0.0281\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0386 - val_loss: 0.0281\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0385 - val_loss: 0.0280\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0384 - val_loss: 0.0280\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2009, 67), test_y.shape=(2009, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 137177179.8661396, my average MASE = 15662264218.215044\n",
      "Cluster 0, 137177179.8661396\n",
      "Before prediction: train_X.shape=(18366, 10, 67), train_y.shape=(18366, 67), test_X.shape=(6122, 10, 67), test_y.shape=(6122, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3004 - val_loss: 0.3159\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2809 - val_loss: 0.3004\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2655 - val_loss: 0.2878\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2540 - val_loss: 0.2790\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2465 - val_loss: 0.2727\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2409 - val_loss: 0.2676\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2364 - val_loss: 0.2633\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2324 - val_loss: 0.2598\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2290 - val_loss: 0.2567\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2259 - val_loss: 0.2539\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2230 - val_loss: 0.2514\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2204 - val_loss: 0.2493\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2181 - val_loss: 0.2474\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2161 - val_loss: 0.2457\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2144 - val_loss: 0.2442\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2129 - val_loss: 0.2429\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2115 - val_loss: 0.2418\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2103 - val_loss: 0.2406\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2092 - val_loss: 0.2396\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2083 - val_loss: 0.2386\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2073 - val_loss: 0.2378\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2065 - val_loss: 0.2370\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2057 - val_loss: 0.2363\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2050 - val_loss: 0.2356\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2350\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2344\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2031 - val_loss: 0.2338\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2025 - val_loss: 0.2333\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2020 - val_loss: 0.2328\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2015 - val_loss: 0.2324\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2319\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2006 - val_loss: 0.2314\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2002 - val_loss: 0.2311\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1998 - val_loss: 0.2307\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.1994 - val_loss: 0.2304\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1991 - val_loss: 0.2301\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.1987 - val_loss: 0.2298\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1984 - val_loss: 0.2294\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1981 - val_loss: 0.2291\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1978 - val_loss: 0.2290\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6122, 67), test_y.shape=(6122, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1800.7465590842255, my average MASE = 3633.615501921918\n",
      "Cluster 1, 1800.7465590842255\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=5, 5, 58, (3715, 67)\n",
      "Before prediction: train_X.shape=(2222, 10, 67), train_y.shape=(2222, 67), test_X.shape=(741, 10, 67), test_y.shape=(741, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5001 - val_loss: 0.3691\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4918 - val_loss: 0.3651\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4851 - val_loss: 0.3618\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4795 - val_loss: 0.3589\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4744 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4699 - val_loss: 0.3539\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4657 - val_loss: 0.3517\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4618 - val_loss: 0.3497\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4582 - val_loss: 0.3478\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4548 - val_loss: 0.3460\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4516 - val_loss: 0.3443\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4485 - val_loss: 0.3427\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4455 - val_loss: 0.3412\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4426 - val_loss: 0.3398\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4398 - val_loss: 0.3384\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4370 - val_loss: 0.3370\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4342 - val_loss: 0.3357\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4315 - val_loss: 0.3345\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4289 - val_loss: 0.3332\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4263 - val_loss: 0.3321\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4237 - val_loss: 0.3309\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4213 - val_loss: 0.3298\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4189 - val_loss: 0.3287\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4166 - val_loss: 0.3277\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4143 - val_loss: 0.3266\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4120 - val_loss: 0.3256\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4099 - val_loss: 0.3247\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4079 - val_loss: 0.3238\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4059 - val_loss: 0.3230\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4040 - val_loss: 0.3222\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4022 - val_loss: 0.3214\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4005 - val_loss: 0.3206\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3988 - val_loss: 0.3199\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3972 - val_loss: 0.3193\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3956 - val_loss: 0.3186\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3941 - val_loss: 0.3180\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3927 - val_loss: 0.3175\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3912 - val_loss: 0.3169\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3899 - val_loss: 0.3163\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3885 - val_loss: 0.3158\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(741, 67), test_y.shape=(741, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 461.9721639366225, my average MASE = 1222.9207656733142\n",
      "Cluster 0, 461.9721639366225\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1169 - val_loss: 0.0965\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1118 - val_loss: 0.0947\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1077 - val_loss: 0.0935\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1043 - val_loss: 0.0926\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1013 - val_loss: 0.0919\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0987 - val_loss: 0.0913\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0964 - val_loss: 0.0909\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0942 - val_loss: 0.0906\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0923 - val_loss: 0.0904\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0901\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0890 - val_loss: 0.0899\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0875 - val_loss: 0.0897\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0861 - val_loss: 0.0895\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0849 - val_loss: 0.0894\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0837 - val_loss: 0.0892\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0826 - val_loss: 0.0891\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0816 - val_loss: 0.0889\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0807 - val_loss: 0.0888\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0798 - val_loss: 0.0886\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0790 - val_loss: 0.0885\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0782 - val_loss: 0.0884\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0883\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0881\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0761 - val_loss: 0.0880\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0755 - val_loss: 0.0879\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0749 - val_loss: 0.0878\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0743 - val_loss: 0.0877\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0738 - val_loss: 0.0876\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0732 - val_loss: 0.0875\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0727 - val_loss: 0.0875\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0722 - val_loss: 0.0874\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0718 - val_loss: 0.0874\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0713 - val_loss: 0.0874\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0873\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0705 - val_loss: 0.0873\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0873\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0872\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0695 - val_loss: 0.0872\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0689 - val_loss: 0.0871\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 979857680.8759673, my average MASE = 20246393999.460716\n",
      "Cluster 1, 979857680.8759673\n",
      "Before prediction: train_X.shape=(160, 10, 67), train_y.shape=(160, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5150 - val_loss: 0.4228\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5137 - val_loss: 0.4220\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5125 - val_loss: 0.4212\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5113 - val_loss: 0.4205\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5101 - val_loss: 0.4197\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5090 - val_loss: 0.4189\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5079 - val_loss: 0.4182\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5068 - val_loss: 0.4175\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5058 - val_loss: 0.4168\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4161\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5037 - val_loss: 0.4154\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5026 - val_loss: 0.4148\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5016 - val_loss: 0.4141\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5006 - val_loss: 0.4135\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4997 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4987 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4977 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4968 - val_loss: 0.4110\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4958 - val_loss: 0.4104\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4949 - val_loss: 0.4098\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4940 - val_loss: 0.4092\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4931 - val_loss: 0.4086\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4923 - val_loss: 0.4081\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4914 - val_loss: 0.4075\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4905 - val_loss: 0.4069\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4064\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4888 - val_loss: 0.4059\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4880 - val_loss: 0.4053\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4871 - val_loss: 0.4048\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4863 - val_loss: 0.4043\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4855 - val_loss: 0.4038\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4847 - val_loss: 0.4033\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4840 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4832 - val_loss: 0.4023\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4018\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4817 - val_loss: 0.4013\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4809 - val_loss: 0.4008\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4802 - val_loss: 0.4003\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4795 - val_loss: 0.3998\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4787 - val_loss: 0.3994\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.13783551729924, my average MASE = 51951538.633395046\n",
      "Cluster 2, 127.13783551729924\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8383 - val_loss: 0.5938\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8360 - val_loss: 0.5928\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8338 - val_loss: 0.5919\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8316 - val_loss: 0.5910\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8294 - val_loss: 0.5901\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8272 - val_loss: 0.5891\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8251 - val_loss: 0.5882\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 0.5873\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8208 - val_loss: 0.5864\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8187 - val_loss: 0.5855\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8167 - val_loss: 0.5847\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8146 - val_loss: 0.5838\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8126 - val_loss: 0.5830\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8107 - val_loss: 0.5821\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8087 - val_loss: 0.5812\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8068 - val_loss: 0.5803\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8048 - val_loss: 0.5794\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8029 - val_loss: 0.5786\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8009 - val_loss: 0.5777\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7989 - val_loss: 0.5768\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7970 - val_loss: 0.5760\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7951 - val_loss: 0.5751\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7932 - val_loss: 0.5743\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7913 - val_loss: 0.5735\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7894 - val_loss: 0.5727\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7875 - val_loss: 0.5720\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7857 - val_loss: 0.5712\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7839 - val_loss: 0.5704\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7820 - val_loss: 0.5697\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7802 - val_loss: 0.5690\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7784 - val_loss: 0.5682\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7767 - val_loss: 0.5675\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7749 - val_loss: 0.5668\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7732 - val_loss: 0.5661\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7715 - val_loss: 0.5655\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7698 - val_loss: 0.5648\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7681 - val_loss: 0.5641\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7664 - val_loss: 0.5635\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7647 - val_loss: 0.5629\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7630 - val_loss: 0.5623\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1378.9503839591846, my average MASE = 44152799.2879618\n",
      "Cluster 3, 1378.9503839591846\n",
      "Before prediction: train_X.shape=(44, 10, 67), train_y.shape=(44, 67), test_X.shape=(15, 10, 67), test_y.shape=(15, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5170 - val_loss: 0.7315\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5154 - val_loss: 0.7308\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.7300\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5122 - val_loss: 0.7293\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5107 - val_loss: 0.7285\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5092 - val_loss: 0.7278\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5077 - val_loss: 0.7271\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5062 - val_loss: 0.7264\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5047 - val_loss: 0.7257\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5033 - val_loss: 0.7250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5018 - val_loss: 0.7243\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.7236\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4990 - val_loss: 0.7229\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4977 - val_loss: 0.7222\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4963 - val_loss: 0.7215\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4949 - val_loss: 0.7209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4936 - val_loss: 0.7202\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4923 - val_loss: 0.7196\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4910 - val_loss: 0.7189\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4897 - val_loss: 0.7183\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4884 - val_loss: 0.7177\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.7170\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4859 - val_loss: 0.7164\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4847 - val_loss: 0.7158\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4835 - val_loss: 0.7152\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4823 - val_loss: 0.7146\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4811 - val_loss: 0.7140\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4799 - val_loss: 0.7135\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4788 - val_loss: 0.7129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4776 - val_loss: 0.7123\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4765 - val_loss: 0.7118\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4753 - val_loss: 0.7113\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4742 - val_loss: 0.7107\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4731 - val_loss: 0.7102\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4720 - val_loss: 0.7097\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4709 - val_loss: 0.7092\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4698 - val_loss: 0.7087\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4687 - val_loss: 0.7082\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.7077\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.7073\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(15, 67), test_y.shape=(15, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2846600473.0797715, my average MASE = 8256296780.299102\n",
      "Cluster 4, 2846600473.0797715\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=7, 7, 176, (267, 67)\n",
      "Before prediction: train_X.shape=(154, 10, 67), train_y.shape=(154, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3225 - val_loss: 0.2694\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3217 - val_loss: 0.2689\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3209 - val_loss: 0.2684\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3201 - val_loss: 0.2679\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3194 - val_loss: 0.2674\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3187 - val_loss: 0.2669\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3179 - val_loss: 0.2664\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3172 - val_loss: 0.2659\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3165 - val_loss: 0.2655\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3159 - val_loss: 0.2650\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3152 - val_loss: 0.2646\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3145 - val_loss: 0.2641\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3139 - val_loss: 0.2637\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3133 - val_loss: 0.2633\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3127 - val_loss: 0.2629\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3121 - val_loss: 0.2624\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3115 - val_loss: 0.2620\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3109 - val_loss: 0.2616\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3103 - val_loss: 0.2612\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3098 - val_loss: 0.2609\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3092 - val_loss: 0.2605\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3087 - val_loss: 0.2601\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3081 - val_loss: 0.2598\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3076 - val_loss: 0.2594\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3071 - val_loss: 0.2590\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3066 - val_loss: 0.2587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3061 - val_loss: 0.2584\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3056 - val_loss: 0.2580\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3051 - val_loss: 0.2576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3046 - val_loss: 0.2573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3041 - val_loss: 0.2569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3037 - val_loss: 0.2566\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3032 - val_loss: 0.2563\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3027 - val_loss: 0.2559\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3023 - val_loss: 0.2556\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3018 - val_loss: 0.2553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3013 - val_loss: 0.2550\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3009 - val_loss: 0.2546\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3005 - val_loss: 0.2543\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3000 - val_loss: 0.2540\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 173.3029589389659, my average MASE = 89033224.06135572\n",
      "Cluster 0, 173.3029589389659\n",
      "Before prediction: train_X.shape=(5960, 10, 67), train_y.shape=(5960, 67), test_X.shape=(1987, 10, 67), test_y.shape=(1987, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0675 - val_loss: 0.0464\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0617 - val_loss: 0.0432\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0584 - val_loss: 0.0410\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0560 - val_loss: 0.0393\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0541 - val_loss: 0.0377\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0525 - val_loss: 0.0364\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0512 - val_loss: 0.0353\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0501 - val_loss: 0.0343\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0492 - val_loss: 0.0335\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0484 - val_loss: 0.0327\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0477 - val_loss: 0.0321\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0471 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0466 - val_loss: 0.0310\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0461 - val_loss: 0.0306\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0457 - val_loss: 0.0302\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0453 - val_loss: 0.0299\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0449 - val_loss: 0.0296\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0445 - val_loss: 0.0293\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0442 - val_loss: 0.0291\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0288\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0286\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0284\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0432 - val_loss: 0.0282\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0424 - val_loss: 0.0275\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0421 - val_loss: 0.0272\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0420 - val_loss: 0.0271\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0419 - val_loss: 0.0270\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0417 - val_loss: 0.0269\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0268\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0413 - val_loss: 0.0265\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0412 - val_loss: 0.0264\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0409 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1987, 67), test_y.shape=(1987, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 783030752.0753396, my average MASE = 36192993113.38622\n",
      "Cluster 1, 783030752.0753396\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5458 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.3449\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.3440\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5391 - val_loss: 0.3431\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5369 - val_loss: 0.3422\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5348 - val_loss: 0.3413\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.3405\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5304 - val_loss: 0.3396\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5283 - val_loss: 0.3387\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5261 - val_loss: 0.3379\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5240 - val_loss: 0.3371\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5219 - val_loss: 0.3362\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5198 - val_loss: 0.3354\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5177 - val_loss: 0.3346\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5157 - val_loss: 0.3338\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5137 - val_loss: 0.3330\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5117 - val_loss: 0.3322\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5097 - val_loss: 0.3314\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5078 - val_loss: 0.3308\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5059 - val_loss: 0.3301\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5041 - val_loss: 0.3295\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5022 - val_loss: 0.3290\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.3284\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4986 - val_loss: 0.3279\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4968 - val_loss: 0.3274\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4951 - val_loss: 0.3269\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4933 - val_loss: 0.3264\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.3260\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4900 - val_loss: 0.3257\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4884 - val_loss: 0.3254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4868 - val_loss: 0.3251\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4852 - val_loss: 0.3249\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4836 - val_loss: 0.3247\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4821 - val_loss: 0.3245\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4805 - val_loss: 0.3244\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4790 - val_loss: 0.3242\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4775 - val_loss: 0.3241\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4760 - val_loss: 0.3240\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4745 - val_loss: 0.3239\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4730 - val_loss: 0.3238\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 300.2247881778862, my average MASE = 45822553.10580316\n",
      "Cluster 2, 300.2247881778862\n",
      "Before prediction: train_X.shape=(85, 10, 67), train_y.shape=(85, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3796 - val_loss: 0.4594\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3789 - val_loss: 0.4589\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3782 - val_loss: 0.4585\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4581\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3770 - val_loss: 0.4577\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3764 - val_loss: 0.4573\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.4569\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3753 - val_loss: 0.4565\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3748 - val_loss: 0.4561\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3737 - val_loss: 0.4554\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3732 - val_loss: 0.4550\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3727 - val_loss: 0.4547\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4543\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3717 - val_loss: 0.4540\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3713 - val_loss: 0.4537\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3708 - val_loss: 0.4533\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3703 - val_loss: 0.4530\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3699 - val_loss: 0.4527\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3694 - val_loss: 0.4524\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.4521\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3685 - val_loss: 0.4517\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3681 - val_loss: 0.4514\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3677 - val_loss: 0.4512\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3673 - val_loss: 0.4509\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3669 - val_loss: 0.4506\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3664 - val_loss: 0.4503\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4501\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3657 - val_loss: 0.4498\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3653 - val_loss: 0.4495\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3649 - val_loss: 0.4493\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3645 - val_loss: 0.4490\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3641 - val_loss: 0.4487\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.4485\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3634 - val_loss: 0.4482\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3630 - val_loss: 0.4480\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.4478\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3623 - val_loss: 0.4475\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.4473\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3616 - val_loss: 0.4470\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n",
      "average MASE = 329.8443195642471, my average MASE = 91063731.05477783\n",
      "Cluster 3, 329.8443195642471\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6262 - val_loss: 0.5214\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6239 - val_loss: 0.5202\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6216 - val_loss: 0.5190\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6193 - val_loss: 0.5179\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6170 - val_loss: 0.5167\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6148 - val_loss: 0.5156\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6125 - val_loss: 0.5145\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6102 - val_loss: 0.5134\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6080 - val_loss: 0.5123\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6058 - val_loss: 0.5112\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6036 - val_loss: 0.5101\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6015 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5994 - val_loss: 0.5080\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5973 - val_loss: 0.5070\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5953 - val_loss: 0.5060\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5932 - val_loss: 0.5051\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5912 - val_loss: 0.5041\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5892 - val_loss: 0.5032\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5872 - val_loss: 0.5023\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5853 - val_loss: 0.5015\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5834 - val_loss: 0.5006\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5816 - val_loss: 0.4999\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5799 - val_loss: 0.4991\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5782 - val_loss: 0.4984\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5765 - val_loss: 0.4977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5749 - val_loss: 0.4970\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5732 - val_loss: 0.4963\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5716 - val_loss: 0.4957\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5699 - val_loss: 0.4951\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5683 - val_loss: 0.4946\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5667 - val_loss: 0.4941\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5651 - val_loss: 0.4936\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5635 - val_loss: 0.4931\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5619 - val_loss: 0.4927\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5604 - val_loss: 0.4922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5588 - val_loss: 0.4917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5573 - val_loss: 0.4913\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5557 - val_loss: 0.4909\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5542 - val_loss: 0.4906\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5526 - val_loss: 0.4902\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32309710873507563, my average MASE = 0.5656513264705396\n",
      "Cluster 4, 0.32309710873507563\n",
      "Before prediction: train_X.shape=(43, 10, 67), train_y.shape=(43, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5119 - val_loss: 0.6850\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5101 - val_loss: 0.6839\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5083 - val_loss: 0.6829\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5066 - val_loss: 0.6819\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5048 - val_loss: 0.6808\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.6798\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5014 - val_loss: 0.6788\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.6778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4980 - val_loss: 0.6769\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4964 - val_loss: 0.6759\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4948 - val_loss: 0.6749\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4931 - val_loss: 0.6740\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4915 - val_loss: 0.6730\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4900 - val_loss: 0.6721\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4884 - val_loss: 0.6711\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4869 - val_loss: 0.6702\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4853 - val_loss: 0.6693\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4838 - val_loss: 0.6683\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6674\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4808 - val_loss: 0.6665\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.6656\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4779 - val_loss: 0.6647\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4765 - val_loss: 0.6639\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4751 - val_loss: 0.6630\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4737 - val_loss: 0.6622\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4723 - val_loss: 0.6613\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4710 - val_loss: 0.6605\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4697 - val_loss: 0.6596\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4683 - val_loss: 0.6588\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4670 - val_loss: 0.6580\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4657 - val_loss: 0.6572\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4644 - val_loss: 0.6564\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4631 - val_loss: 0.6556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4619 - val_loss: 0.6548\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4606 - val_loss: 0.6540\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4594 - val_loss: 0.6532\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4581 - val_loss: 0.6525\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4569 - val_loss: 0.6517\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4557 - val_loss: 0.6510\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4545 - val_loss: 0.6502\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2340337256.388025, my average MASE = 7806499481.251814\n",
      "Cluster 5, 2340337256.388025\n",
      "Before prediction: train_X.shape=(181, 10, 67), train_y.shape=(181, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6846 - val_loss: 0.5744\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6833 - val_loss: 0.5737\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6820 - val_loss: 0.5730\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6807 - val_loss: 0.5723\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6795 - val_loss: 0.5716\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6783 - val_loss: 0.5709\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6771 - val_loss: 0.5703\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6760 - val_loss: 0.5696\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6749 - val_loss: 0.5690\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6737 - val_loss: 0.5683\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6727 - val_loss: 0.5677\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6716 - val_loss: 0.5671\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6705 - val_loss: 0.5666\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6695 - val_loss: 0.5660\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6685 - val_loss: 0.5654\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6675 - val_loss: 0.5648\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6664 - val_loss: 0.5643\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6654 - val_loss: 0.5637\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6645 - val_loss: 0.5632\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6635 - val_loss: 0.5626\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6626 - val_loss: 0.5621\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.6616 - val_loss: 0.5615\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6607 - val_loss: 0.5610\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6597 - val_loss: 0.5605\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6588 - val_loss: 0.5600\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6579 - val_loss: 0.5594\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6570 - val_loss: 0.5589\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6561 - val_loss: 0.5584\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6553 - val_loss: 0.5579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6544 - val_loss: 0.5574\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6536 - val_loss: 0.5569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6527 - val_loss: 0.5563\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6519 - val_loss: 0.5558\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6510 - val_loss: 0.5553\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6502 - val_loss: 0.5548\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6493 - val_loss: 0.5543\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6485 - val_loss: 0.5538\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6477 - val_loss: 0.5533\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6468 - val_loss: 0.5528\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6460 - val_loss: 0.5523\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 153.88341287865387, my average MASE = 335532064.75560737\n",
      "Cluster 6, 153.88341287865387\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=9, 9, 3, (61, 67)\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5800 - val_loss: 0.4525\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5784 - val_loss: 0.4515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5768 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5753 - val_loss: 0.4496\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5738 - val_loss: 0.4487\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5722 - val_loss: 0.4477\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5707 - val_loss: 0.4468\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5692 - val_loss: 0.4459\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5678 - val_loss: 0.4450\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5663 - val_loss: 0.4441\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5648 - val_loss: 0.4433\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5634 - val_loss: 0.4424\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5619 - val_loss: 0.4415\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5605 - val_loss: 0.4407\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5590 - val_loss: 0.4398\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5576 - val_loss: 0.4390\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5562 - val_loss: 0.4382\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5548 - val_loss: 0.4374\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5534 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5520 - val_loss: 0.4359\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5507 - val_loss: 0.4352\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5493 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5480 - val_loss: 0.4337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5467 - val_loss: 0.4329\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 0.4322\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5441 - val_loss: 0.4315\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5428 - val_loss: 0.4308\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5415 - val_loss: 0.4301\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5403 - val_loss: 0.4294\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5390 - val_loss: 0.4287\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5378 - val_loss: 0.4280\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5366 - val_loss: 0.4273\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5354 - val_loss: 0.4266\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5342 - val_loss: 0.4260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5330 - val_loss: 0.4253\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5318 - val_loss: 0.4246\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5307 - val_loss: 0.4240\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5295 - val_loss: 0.4234\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5284 - val_loss: 0.4227\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5273 - val_loss: 0.4221\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 35650627.66244785, my average MASE = 4899168813.139491\n",
      "Cluster 0, 35650627.66244785\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7142 - val_loss: 0.5624\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7129 - val_loss: 0.5618\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7116 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7104 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7092 - val_loss: 0.5599\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7080 - val_loss: 0.5593\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7069 - val_loss: 0.5588\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7057 - val_loss: 0.5582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7046 - val_loss: 0.5576\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7035 - val_loss: 0.5571\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5565\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7013 - val_loss: 0.5560\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7002 - val_loss: 0.5555\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6993 - val_loss: 0.5550\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6982 - val_loss: 0.5545\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6972 - val_loss: 0.5540\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5535\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6952 - val_loss: 0.5530\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6942 - val_loss: 0.5525\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6932 - val_loss: 0.5520\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5516\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6913 - val_loss: 0.5511\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6903 - val_loss: 0.5506\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6894 - val_loss: 0.5502\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6885 - val_loss: 0.5498\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6875 - val_loss: 0.5493\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6866 - val_loss: 0.5489\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6857 - val_loss: 0.5485\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6848 - val_loss: 0.5481\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6839 - val_loss: 0.5477\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6830 - val_loss: 0.5472\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6821 - val_loss: 0.5468\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6812 - val_loss: 0.5464\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6803 - val_loss: 0.5460\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6794 - val_loss: 0.5456\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.5452\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6777 - val_loss: 0.5449\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6768 - val_loss: 0.5445\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6759 - val_loss: 0.5441\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6751 - val_loss: 0.5437\n",
      "2/2 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n",
      "average MASE = 167.81473432422789, my average MASE = 220460085.3598021\n",
      "Cluster 1, 167.81473432422789\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4267 - val_loss: 0.6677\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4246 - val_loss: 0.6662\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4226 - val_loss: 0.6647\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4205 - val_loss: 0.6632\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.6618\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4166 - val_loss: 0.6605\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4146 - val_loss: 0.6592\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4127 - val_loss: 0.6578\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4107 - val_loss: 0.6565\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4088 - val_loss: 0.6552\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4070 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4051 - val_loss: 0.6527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4033 - val_loss: 0.6514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4014 - val_loss: 0.6502\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3997 - val_loss: 0.6490\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3979 - val_loss: 0.6478\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3961 - val_loss: 0.6466\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3944 - val_loss: 0.6455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3927 - val_loss: 0.6444\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3910 - val_loss: 0.6433\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3893 - val_loss: 0.6423\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3877 - val_loss: 0.6412\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3861 - val_loss: 0.6402\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3845 - val_loss: 0.6392\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3829 - val_loss: 0.6383\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3814 - val_loss: 0.6374\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3799 - val_loss: 0.6364\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3784 - val_loss: 0.6356\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3769 - val_loss: 0.6347\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3754 - val_loss: 0.6338\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3740 - val_loss: 0.6330\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3725 - val_loss: 0.6322\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3711 - val_loss: 0.6314\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3697 - val_loss: 0.6305\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3683 - val_loss: 0.6297\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3669 - val_loss: 0.6289\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.6281\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3642 - val_loss: 0.6273\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3629 - val_loss: 0.6264\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3616 - val_loss: 0.6256\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1967377505.4498963, my average MASE = 5262000054.755049\n",
      "Cluster 2, 1967377505.4498963\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6328 - val_loss: 0.7373\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6300 - val_loss: 0.7359\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6272 - val_loss: 0.7344\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6245 - val_loss: 0.7330\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6218 - val_loss: 0.7316\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6191 - val_loss: 0.7301\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6164 - val_loss: 0.7287\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6137 - val_loss: 0.7273\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6111 - val_loss: 0.7259\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6085 - val_loss: 0.7245\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6058 - val_loss: 0.7230\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6033 - val_loss: 0.7216\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6009 - val_loss: 0.7202\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5985 - val_loss: 0.7188\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5961 - val_loss: 0.7174\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5938 - val_loss: 0.7159\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5915 - val_loss: 0.7146\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5892 - val_loss: 0.7133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5869 - val_loss: 0.7119\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5847 - val_loss: 0.7106\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5825 - val_loss: 0.7092\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5803 - val_loss: 0.7078\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5781 - val_loss: 0.7064\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5759 - val_loss: 0.7050\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5738 - val_loss: 0.7036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5716 - val_loss: 0.7022\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5695 - val_loss: 0.7009\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5674 - val_loss: 0.6996\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5653 - val_loss: 0.6983\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5632 - val_loss: 0.6971\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5611 - val_loss: 0.6959\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5590 - val_loss: 0.6946\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5569 - val_loss: 0.6934\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5549 - val_loss: 0.6922\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5528 - val_loss: 0.6910\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5509 - val_loss: 0.6898\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5490 - val_loss: 0.6886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5472 - val_loss: 0.6874\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5454 - val_loss: 0.6862\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.6850\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.27232041656941225, my average MASE = 0.501167640234202\n",
      "Cluster 3, 0.27232041656941225\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4602 - val_loss: 0.3734\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4580 - val_loss: 0.3723\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4558 - val_loss: 0.3714\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4536 - val_loss: 0.3704\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4515 - val_loss: 0.3694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4494 - val_loss: 0.3685\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4474 - val_loss: 0.3675\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4454 - val_loss: 0.3666\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4435 - val_loss: 0.3657\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4416 - val_loss: 0.3648\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4397 - val_loss: 0.3640\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4379 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4361 - val_loss: 0.3623\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4344 - val_loss: 0.3616\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4328 - val_loss: 0.3608\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4312 - val_loss: 0.3601\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4296 - val_loss: 0.3594\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4279 - val_loss: 0.3587\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4263 - val_loss: 0.3581\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4247 - val_loss: 0.3575\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4231 - val_loss: 0.3569\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.3564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4200 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4184 - val_loss: 0.3553\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4169 - val_loss: 0.3547\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4154 - val_loss: 0.3542\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4138 - val_loss: 0.3537\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4123 - val_loss: 0.3533\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4109 - val_loss: 0.3528\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4094 - val_loss: 0.3524\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4080 - val_loss: 0.3520\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4066 - val_loss: 0.3516\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4053 - val_loss: 0.3512\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4039 - val_loss: 0.3508\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4026 - val_loss: 0.3505\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4000 - val_loss: 0.3498\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3987 - val_loss: 0.3495\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3974 - val_loss: 0.3492\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3490\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 363.8540679781247, my average MASE = 17706113.36217601\n",
      "Cluster 4, 363.8540679781247\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4172 - val_loss: 0.5128\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4165 - val_loss: 0.5124\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4158 - val_loss: 0.5121\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4151 - val_loss: 0.5117\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.5113\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4139 - val_loss: 0.5110\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4132 - val_loss: 0.5107\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4126 - val_loss: 0.5103\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4120 - val_loss: 0.5100\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4114 - val_loss: 0.5096\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4108 - val_loss: 0.5093\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4102 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4097 - val_loss: 0.5086\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4091 - val_loss: 0.5083\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4085 - val_loss: 0.5080\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4080 - val_loss: 0.5077\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.5074\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4069 - val_loss: 0.5071\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4064 - val_loss: 0.5068\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4059 - val_loss: 0.5065\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.5062\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4048 - val_loss: 0.5059\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4043 - val_loss: 0.5056\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4038 - val_loss: 0.5053\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.5051\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4029 - val_loss: 0.5048\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4019 - val_loss: 0.5042\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4014 - val_loss: 0.5039\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4010 - val_loss: 0.5036\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4005 - val_loss: 0.5033\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4000 - val_loss: 0.5030\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3996 - val_loss: 0.5028\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3991 - val_loss: 0.5025\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3987 - val_loss: 0.5022\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3983 - val_loss: 0.5019\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3978 - val_loss: 0.5016\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5013\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3969 - val_loss: 0.5011\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3965 - val_loss: 0.5008\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 210.04101539413423, my average MASE = 60624707.44207928\n",
      "Cluster 5, 210.04101539413423\n",
      "Before prediction: train_X.shape=(104, 10, 67), train_y.shape=(104, 67), test_X.shape=(35, 10, 67), test_y.shape=(35, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3090 - val_loss: 0.2755\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3084 - val_loss: 0.2752\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3078 - val_loss: 0.2749\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3072 - val_loss: 0.2745\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3066 - val_loss: 0.2742\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3061 - val_loss: 0.2739\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3055 - val_loss: 0.2736\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3049 - val_loss: 0.2733\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3044 - val_loss: 0.2730\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3039 - val_loss: 0.2727\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.2724\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3028 - val_loss: 0.2722\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.2719\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3018 - val_loss: 0.2716\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3013 - val_loss: 0.2713\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3008 - val_loss: 0.2711\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3003 - val_loss: 0.2708\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2998 - val_loss: 0.2705\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2994 - val_loss: 0.2703\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2989 - val_loss: 0.2700\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2984 - val_loss: 0.2698\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2980 - val_loss: 0.2695\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2975 - val_loss: 0.2693\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2971 - val_loss: 0.2690\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2966 - val_loss: 0.2688\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2962 - val_loss: 0.2686\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2958 - val_loss: 0.2683\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2953 - val_loss: 0.2681\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2949 - val_loss: 0.2678\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2945 - val_loss: 0.2676\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2941 - val_loss: 0.2674\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2937 - val_loss: 0.2671\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2933 - val_loss: 0.2669\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2929 - val_loss: 0.2667\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2925 - val_loss: 0.2664\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2921 - val_loss: 0.2662\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2917 - val_loss: 0.2660\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2913 - val_loss: 0.2658\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2909 - val_loss: 0.2656\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2906 - val_loss: 0.2654\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(35, 67), test_y.shape=(35, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 554.2347835476104, my average MASE = 43885073.200175166\n",
      "Cluster 6, 554.2347835476104\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6507 - val_loss: 0.5207\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6481 - val_loss: 0.5200\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6456 - val_loss: 0.5192\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6431 - val_loss: 0.5184\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6407 - val_loss: 0.5176\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6383 - val_loss: 0.5169\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6360 - val_loss: 0.5161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6338 - val_loss: 0.5154\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6316 - val_loss: 0.5147\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6293 - val_loss: 0.5140\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6271 - val_loss: 0.5133\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6249 - val_loss: 0.5126\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6227 - val_loss: 0.5119\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6206 - val_loss: 0.5112\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6185 - val_loss: 0.5105\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6164 - val_loss: 0.5099\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6145 - val_loss: 0.5093\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6125 - val_loss: 0.5087\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6107 - val_loss: 0.5082\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6088 - val_loss: 0.5076\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6069 - val_loss: 0.5071\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6051 - val_loss: 0.5067\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6032 - val_loss: 0.5062\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6014 - val_loss: 0.5058\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5996 - val_loss: 0.5053\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5978 - val_loss: 0.5049\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5959 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5941 - val_loss: 0.5040\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5923 - val_loss: 0.5036\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5905 - val_loss: 0.5033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5888 - val_loss: 0.5030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5871 - val_loss: 0.5027\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5853 - val_loss: 0.5024\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5837 - val_loss: 0.5021\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5822 - val_loss: 0.5017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5806 - val_loss: 0.5014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5791 - val_loss: 0.5011\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5775 - val_loss: 0.5009\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5760 - val_loss: 0.5006\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5745 - val_loss: 0.5004\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2390672605525707, my average MASE = 0.4689912396588464\n",
      "Cluster 7, 0.2390672605525707\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1191 - val_loss: 0.0992\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1138 - val_loss: 0.0972\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1096 - val_loss: 0.0959\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1060 - val_loss: 0.0949\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1029 - val_loss: 0.0942\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1002 - val_loss: 0.0935\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0977 - val_loss: 0.0930\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0955 - val_loss: 0.0925\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0916 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0899 - val_loss: 0.0913\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0884 - val_loss: 0.0909\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0870 - val_loss: 0.0906\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0856 - val_loss: 0.0903\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0844 - val_loss: 0.0900\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0833 - val_loss: 0.0898\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0896\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0812 - val_loss: 0.0894\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0803 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0778 - val_loss: 0.0887\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0771 - val_loss: 0.0886\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0764 - val_loss: 0.0885\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0757 - val_loss: 0.0884\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0751 - val_loss: 0.0883\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0745 - val_loss: 0.0882\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0739 - val_loss: 0.0881\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0880\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0879\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0723 - val_loss: 0.0879\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0878\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0877\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0711 - val_loss: 0.0876\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0707 - val_loss: 0.0876\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0703 - val_loss: 0.0875\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0700 - val_loss: 0.0874\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0873\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0694 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 1385618831.00148, my average MASE = 22365614226.60064\n",
      "Cluster 8, 1385618831.00148\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=11, 11, 68, (49, 67)\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5560 - val_loss: 0.4967\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5553 - val_loss: 0.4965\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5546 - val_loss: 0.4963\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5538 - val_loss: 0.4961\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5531 - val_loss: 0.4960\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5524 - val_loss: 0.4958\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5517 - val_loss: 0.4956\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5510 - val_loss: 0.4955\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5503 - val_loss: 0.4953\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5496 - val_loss: 0.4952\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5489 - val_loss: 0.4950\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 0.4949\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5476 - val_loss: 0.4947\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5469 - val_loss: 0.4946\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5463 - val_loss: 0.4945\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5456 - val_loss: 0.4943\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5450 - val_loss: 0.4942\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5443 - val_loss: 0.4940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5437 - val_loss: 0.4939\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5431 - val_loss: 0.4938\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5425 - val_loss: 0.4936\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5419 - val_loss: 0.4935\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.4934\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5407 - val_loss: 0.4933\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5401 - val_loss: 0.4932\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5395 - val_loss: 0.4930\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5389 - val_loss: 0.4929\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5384 - val_loss: 0.4928\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5378 - val_loss: 0.4927\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5372 - val_loss: 0.4926\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5367 - val_loss: 0.4925\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 0.4923\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5356 - val_loss: 0.4922\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5351 - val_loss: 0.4921\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5345 - val_loss: 0.4920\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5340 - val_loss: 0.4919\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5335 - val_loss: 0.4918\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5329 - val_loss: 0.4917\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5324 - val_loss: 0.4915\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5319 - val_loss: 0.4914\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 62.874751666083846, my average MASE = 63681940.89448814\n",
      "Cluster 0, 62.874751666083846\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3794 - val_loss: 0.4534\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3770 - val_loss: 0.4520\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3747 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3724 - val_loss: 0.4494\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3701 - val_loss: 0.4481\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3678 - val_loss: 0.4468\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.4455\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3634 - val_loss: 0.4443\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3612 - val_loss: 0.4430\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3591 - val_loss: 0.4418\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3571 - val_loss: 0.4406\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3551 - val_loss: 0.4394\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3531 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3511 - val_loss: 0.4371\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3492 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3473 - val_loss: 0.4348\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3454 - val_loss: 0.4337\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3436 - val_loss: 0.4326\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3418 - val_loss: 0.4315\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3400 - val_loss: 0.4305\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3382 - val_loss: 0.4294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3365 - val_loss: 0.4284\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3349 - val_loss: 0.4273\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3332 - val_loss: 0.4263\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3316 - val_loss: 0.4253\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3300 - val_loss: 0.4243\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.4233\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3269 - val_loss: 0.4224\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3254 - val_loss: 0.4214\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.4205\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3224 - val_loss: 0.4196\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.4186\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3195 - val_loss: 0.4177\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3181 - val_loss: 0.4168\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3166 - val_loss: 0.4159\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3153 - val_loss: 0.4151\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3139 - val_loss: 0.4142\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3125 - val_loss: 0.4134\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3112 - val_loss: 0.4125\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3098 - val_loss: 0.4117\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1188796320.3185039, my average MASE = 2779981174.701244\n",
      "Cluster 1, 1188796320.3185039\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6283 - val_loss: 0.6105\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6261 - val_loss: 0.6091\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6239 - val_loss: 0.6076\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6218 - val_loss: 0.6062\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6196 - val_loss: 0.6047\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6175 - val_loss: 0.6033\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6153 - val_loss: 0.6018\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6132 - val_loss: 0.6004\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6110 - val_loss: 0.5990\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6089 - val_loss: 0.5976\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6067 - val_loss: 0.5961\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6046 - val_loss: 0.5947\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6026 - val_loss: 0.5933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6005 - val_loss: 0.5919\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5985 - val_loss: 0.5905\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5964 - val_loss: 0.5891\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5944 - val_loss: 0.5877\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5923 - val_loss: 0.5866\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5903 - val_loss: 0.5854\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5882 - val_loss: 0.5842\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5861 - val_loss: 0.5831\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5841 - val_loss: 0.5819\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5820 - val_loss: 0.5808\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5799 - val_loss: 0.5796\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5778 - val_loss: 0.5784\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5758 - val_loss: 0.5773\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5737 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5717 - val_loss: 0.5751\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5697 - val_loss: 0.5740\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5676 - val_loss: 0.5731\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5656 - val_loss: 0.5721\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5636 - val_loss: 0.5712\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5616 - val_loss: 0.5703\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5597 - val_loss: 0.5694\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5577 - val_loss: 0.5686\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5558 - val_loss: 0.5678\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5538 - val_loss: 0.5670\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5519 - val_loss: 0.5663\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5499 - val_loss: 0.5655\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5480 - val_loss: 0.5647\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32481366416229096, my average MASE = 0.6312112420260654\n",
      "Cluster 2, 0.32481366416229096\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4564 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4555 - val_loss: 0.4793\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4547 - val_loss: 0.4791\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4538 - val_loss: 0.4788\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4529 - val_loss: 0.4786\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4521 - val_loss: 0.4783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4512 - val_loss: 0.4781\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4504 - val_loss: 0.4778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4496 - val_loss: 0.4776\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4487 - val_loss: 0.4773\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4479 - val_loss: 0.4771\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4471 - val_loss: 0.4768\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4463 - val_loss: 0.4766\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4455 - val_loss: 0.4763\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4447 - val_loss: 0.4760\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4439 - val_loss: 0.4758\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4431 - val_loss: 0.4755\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4423 - val_loss: 0.4753\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4415 - val_loss: 0.4750\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4407 - val_loss: 0.4747\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4400 - val_loss: 0.4745\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4742\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4385 - val_loss: 0.4739\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4377 - val_loss: 0.4736\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4370 - val_loss: 0.4733\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4362 - val_loss: 0.4730\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4355 - val_loss: 0.4727\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4724\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4341 - val_loss: 0.4721\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4334 - val_loss: 0.4717\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4327 - val_loss: 0.4714\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4320 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4313 - val_loss: 0.4708\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4307 - val_loss: 0.4705\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4300 - val_loss: 0.4701\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4293 - val_loss: 0.4698\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4286 - val_loss: 0.4694\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4280 - val_loss: 0.4691\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4273 - val_loss: 0.4688\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4266 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1418783.6078857174, my average MASE = 35875462.94910899\n",
      "Cluster 3, 1418783.6078857174\n",
      "Before prediction: train_X.shape=(27, 10, 67), train_y.shape=(27, 67), test_X.shape=(9, 10, 67), test_y.shape=(9, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3810 - val_loss: 0.3926\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3805 - val_loss: 0.3924\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3799 - val_loss: 0.3923\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3794 - val_loss: 0.3921\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3789 - val_loss: 0.3920\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3784 - val_loss: 0.3918\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3779 - val_loss: 0.3917\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3774 - val_loss: 0.3916\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3769 - val_loss: 0.3914\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3764 - val_loss: 0.3913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3759 - val_loss: 0.3911\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3754 - val_loss: 0.3910\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3749 - val_loss: 0.3909\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3744 - val_loss: 0.3907\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3739 - val_loss: 0.3906\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3734 - val_loss: 0.3905\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3729 - val_loss: 0.3903\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3725 - val_loss: 0.3902\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3720 - val_loss: 0.3901\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3715 - val_loss: 0.3900\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3711 - val_loss: 0.3899\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3706 - val_loss: 0.3898\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3701 - val_loss: 0.3896\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3697 - val_loss: 0.3895\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3692 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3688 - val_loss: 0.3893\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3683 - val_loss: 0.3892\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3679 - val_loss: 0.3891\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3674 - val_loss: 0.3890\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3670 - val_loss: 0.3889\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3666 - val_loss: 0.3888\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3661 - val_loss: 0.3887\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3657 - val_loss: 0.3886\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3653 - val_loss: 0.3885\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3648 - val_loss: 0.3884\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3644 - val_loss: 0.3883\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3640 - val_loss: 0.3882\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3636 - val_loss: 0.3881\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3632 - val_loss: 0.3880\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3627 - val_loss: 0.3879\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(9, 67), test_y.shape=(9, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 73.99923698083529, my average MASE = 28273926.299095076\n",
      "Cluster 4, 73.99923698083529\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1188 - val_loss: 0.0994\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1133 - val_loss: 0.0973\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1090 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1053 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1021 - val_loss: 0.0936\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0993 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0969 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0946 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0893 - val_loss: 0.0908\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0878 - val_loss: 0.0906\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0864 - val_loss: 0.0903\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0852 - val_loss: 0.0901\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0841 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0830 - val_loss: 0.0897\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0820 - val_loss: 0.0895\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0811 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0802 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0888\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0772 - val_loss: 0.0887\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0886\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0759 - val_loss: 0.0885\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0753 - val_loss: 0.0884\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0747 - val_loss: 0.0884\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0742 - val_loss: 0.0883\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0737 - val_loss: 0.0882\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0881\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0881\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0724 - val_loss: 0.0880\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0720 - val_loss: 0.0880\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0716 - val_loss: 0.0879\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0879\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0879\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0878\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0877\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0699 - val_loss: 0.0877\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0877\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 772933595.2163092, my average MASE = 33112652144.926693\n",
      "Cluster 5, 772933595.2163092\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6742 - val_loss: 0.5426\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6711 - val_loss: 0.5410\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6680 - val_loss: 0.5395\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6649 - val_loss: 0.5381\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6619 - val_loss: 0.5366\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6589 - val_loss: 0.5352\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6560 - val_loss: 0.5338\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6532 - val_loss: 0.5324\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6503 - val_loss: 0.5310\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6475 - val_loss: 0.5296\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6447 - val_loss: 0.5282\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6420 - val_loss: 0.5269\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6393 - val_loss: 0.5255\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6367 - val_loss: 0.5242\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6340 - val_loss: 0.5229\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6314 - val_loss: 0.5216\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6289 - val_loss: 0.5203\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6264 - val_loss: 0.5190\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6240 - val_loss: 0.5178\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6215 - val_loss: 0.5165\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6191 - val_loss: 0.5153\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6168 - val_loss: 0.5141\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6145 - val_loss: 0.5128\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6122 - val_loss: 0.5115\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6098 - val_loss: 0.5102\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6076 - val_loss: 0.5089\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6054 - val_loss: 0.5076\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6033 - val_loss: 0.5062\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6011 - val_loss: 0.5049\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5989 - val_loss: 0.5035\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5968 - val_loss: 0.5022\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5947 - val_loss: 0.5009\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5928 - val_loss: 0.4996\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5908 - val_loss: 0.4982\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5889 - val_loss: 0.4969\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5869 - val_loss: 0.4956\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5850 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5831 - val_loss: 0.4932\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5812 - val_loss: 0.4921\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5794 - val_loss: 0.4911\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.24234404135098125, my average MASE = 0.42071116848846357\n",
      "Cluster 6, 0.24234404135098125\n",
      "Before prediction: train_X.shape=(50, 10, 67), train_y.shape=(50, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4441 - val_loss: 0.4379\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4435 - val_loss: 0.4378\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4430 - val_loss: 0.4376\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4425 - val_loss: 0.4374\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4372\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4414 - val_loss: 0.4371\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4409 - val_loss: 0.4369\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4404 - val_loss: 0.4367\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4398 - val_loss: 0.4366\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4364\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.4362\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4383 - val_loss: 0.4361\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4378 - val_loss: 0.4359\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4373 - val_loss: 0.4357\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4368 - val_loss: 0.4356\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4363 - val_loss: 0.4354\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4358 - val_loss: 0.4352\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4353 - val_loss: 0.4351\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4348 - val_loss: 0.4349\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4343 - val_loss: 0.4348\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4339 - val_loss: 0.4346\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4334 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4329 - val_loss: 0.4343\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4341\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4320 - val_loss: 0.4340\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4315 - val_loss: 0.4338\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4310 - val_loss: 0.4337\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4306 - val_loss: 0.4335\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4301 - val_loss: 0.4334\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4296 - val_loss: 0.4332\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4292 - val_loss: 0.4331\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4287 - val_loss: 0.4329\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4283 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4278 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4274 - val_loss: 0.4325\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4269 - val_loss: 0.4323\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4265 - val_loss: 0.4322\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4261 - val_loss: 0.4320\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4256 - val_loss: 0.4319\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4252 - val_loss: 0.4317\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 191.2474349797922, my average MASE = 74799483.45709221\n",
      "Cluster 7, 191.2474349797922\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2212 - val_loss: 0.1239\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2202 - val_loss: 0.1236\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2192 - val_loss: 0.1233\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2183 - val_loss: 0.1230\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2174 - val_loss: 0.1228\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2165 - val_loss: 0.1225\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2156 - val_loss: 0.1223\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2147 - val_loss: 0.1221\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2138 - val_loss: 0.1219\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2129 - val_loss: 0.1217\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2120 - val_loss: 0.1215\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2111 - val_loss: 0.1213\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2102 - val_loss: 0.1212\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2093 - val_loss: 0.1211\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2085 - val_loss: 0.1210\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2076 - val_loss: 0.1209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2068 - val_loss: 0.1208\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2059 - val_loss: 0.1207\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2051 - val_loss: 0.1207\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2042 - val_loss: 0.1206\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2034 - val_loss: 0.1206\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2026 - val_loss: 0.1205\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2018 - val_loss: 0.1204\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2010 - val_loss: 0.1204\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2002 - val_loss: 0.1203\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1995 - val_loss: 0.1203\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1987 - val_loss: 0.1203\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1980 - val_loss: 0.1203\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1973 - val_loss: 0.1203\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1965 - val_loss: 0.1203\n",
      "Epoch 30: early stopping\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.15391611936993946, my average MASE = 0.29566028544300293\n",
      "Cluster 8, 0.15391611936993946\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5076 - val_loss: 0.4286\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5055 - val_loss: 0.4276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5036 - val_loss: 0.4266\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5017 - val_loss: 0.4256\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4998 - val_loss: 0.4246\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4980 - val_loss: 0.4236\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4962 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4944 - val_loss: 0.4217\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4926 - val_loss: 0.4208\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4908 - val_loss: 0.4199\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4890 - val_loss: 0.4191\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4871 - val_loss: 0.4182\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4853 - val_loss: 0.4173\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4835 - val_loss: 0.4164\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4817 - val_loss: 0.4156\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4148\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4782 - val_loss: 0.4140\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4765 - val_loss: 0.4133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4749 - val_loss: 0.4126\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4732 - val_loss: 0.4118\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4717 - val_loss: 0.4111\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4701 - val_loss: 0.4104\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4686 - val_loss: 0.4097\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4671 - val_loss: 0.4089\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4656 - val_loss: 0.4082\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4641 - val_loss: 0.4075\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4627 - val_loss: 0.4068\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4613 - val_loss: 0.4061\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4600 - val_loss: 0.4054\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4587 - val_loss: 0.4048\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4573 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4560 - val_loss: 0.4036\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4546 - val_loss: 0.4030\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4533 - val_loss: 0.4025\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4520 - val_loss: 0.4019\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4506 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4493 - val_loss: 0.4009\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4480 - val_loss: 0.4004\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.3999\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4454 - val_loss: 0.3994\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2425229695624874, my average MASE = 0.5232189989788755\n",
      "Cluster 9, 0.2425229695624874\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4116 - val_loss: 0.3522\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4095 - val_loss: 0.3515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.3508\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4055 - val_loss: 0.3501\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3494\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4016 - val_loss: 0.3488\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3996 - val_loss: 0.3481\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3977 - val_loss: 0.3475\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3920 - val_loss: 0.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3902 - val_loss: 0.3450\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3884 - val_loss: 0.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3865 - val_loss: 0.3439\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3847 - val_loss: 0.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3829 - val_loss: 0.3430\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3811 - val_loss: 0.3425\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3793 - val_loss: 0.3420\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3776 - val_loss: 0.3416\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3759 - val_loss: 0.3411\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3742 - val_loss: 0.3407\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3725 - val_loss: 0.3402\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3708 - val_loss: 0.3398\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3692 - val_loss: 0.3394\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3675 - val_loss: 0.3390\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3659 - val_loss: 0.3386\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3644 - val_loss: 0.3382\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3628 - val_loss: 0.3379\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3376\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3597 - val_loss: 0.3373\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3583 - val_loss: 0.3370\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3568 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3554 - val_loss: 0.3364\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3540 - val_loss: 0.3361\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3526 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3512 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3498 - val_loss: 0.3352\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3484 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3471 - val_loss: 0.3347\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3457 - val_loss: 0.3344\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 624.4867423423187, my average MASE = 18127046.32229549\n",
      "Cluster 10, 624.4867423423187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maes = defaultdict(lambda: [])\n",
    "mases = defaultdict(lambda: [])\n",
    "mapes = defaultdict(lambda: [])\n",
    "answers = {}\n",
    "bad_values = np.zeros(dataset.shape[1])\n",
    "\n",
    "dif=True\n",
    "\n",
    "for window_size in window_sizes_for_clustering:\n",
    "    for N_clusters in Ns_clusters:\n",
    "        dataset_windows, dataset_y = Forecasting.create_windows(dataset, window_size=window_size)\n",
    "        clusters_labels = Clustering.KMeans_for_windows(dataset_windows, W=window_size, N_clusters=N_clusters, max_iter=50)\n",
    "        print(f\"{clusters_labels.shape=}\")\n",
    "        datasets_clusters = Clustering.flatten_from_interceting_windows(dataset_windows, clusters_labels, W=window_size, \\\n",
    "                N_clusters=N_clusters)\n",
    "        # list of list of ndarrays [N_i, Q], dataset_clusters[cluster_num][i] - i-th part of dataset for cluster_num\n",
    "\n",
    "        print(f\"{N_clusters=}, {len(datasets_clusters)}, {len(datasets_clusters[0])}, {datasets_clusters[0][0].shape}\")\n",
    "        ###window_size for model\n",
    "        errors = [1] * N_clusters\n",
    "        for cluster_num in range(N_clusters):\n",
    "            sc = Forecasting.MyStandardScaler(dif=dif)\n",
    "            #datasets_clusters[cluster_num] - list of [N_i, Q] ndarrays\n",
    "            sc.fit(datasets_clusters[cluster_num])\n",
    "            prepared_data = sc.transform(datasets_clusters[cluster_num])\n",
    "            data_X, data_y = Forecasting.create_windows(prepared_data, window_size=10)\n",
    "            #data_X - list of [N_i-W, W, Q] ndarrays\n",
    "            train_X, train_y, valid_X, valid_y, test_X, test_y, ind = Forecasting.split_to_train_test(data_X, data_y, part_of_test=0.2, part_of_valid=0.2)\n",
    "            #ndarrays [N_i, W, Q] or [N_i, Q]\n",
    "            ind = np.array(ind) + window_size\n",
    "            print(f\"Before prediction: {train_X.shape=}, {train_y.shape=}, {test_X.shape=}, {test_y.shape=}\")\n",
    "            try:\n",
    "                assert(len(test_X.shape) == 3 and test_X.shape[0] > 0)\n",
    "                assert(len(valid_X.shape) == 3 and valid_X.shape[0] > 0)\n",
    "                assert(len(train_X.shape) == 3 and train_X.shape[0] > 0)\n",
    "            except AssertionError:\n",
    "                print(f\"FAIL - {test_X.shape=}, {valid_X.shape=}, {train_X.shape=}\")\n",
    "                errors[cluster_num] = np.Inf\n",
    "                continue\n",
    "            model, history = Forecasting.learn(train_X, train_y, valid_X=valid_X, valid_y=valid_y)\n",
    "            predicted = model.predict(test_X)\n",
    "            predicted_original = sc.inverse_transform(predicted)[0]\n",
    "            #inverse_trasform returns list of ndarrays \n",
    "            # if dif:\n",
    "                #константа при дифференцировании\n",
    "                # predicted_original = sc.add_first_element(predicted_original, ind)[0]\n",
    "            print(f\"{predicted_original.shape=}, {test_y.shape=}\")\n",
    "\n",
    "            #calc all metrics\n",
    "            cur_mae = mae(test_y, predicted_original, multioutput='raw_values')\n",
    "#             error_out = mase(test_y, predicted_original, y_train=test_y)\n",
    "#             error_in = mase(test_y, predicted_original, y_train=train_y)\n",
    "            # cur_mase = mase(test_y, predicted_original, y_train=test_y)\n",
    "            cur_mape = mape(test_y, predicted_original)\n",
    "            cur_mase = Forecasting.my_mase(test_y, predicted_original, multioutput='raw_values')\n",
    "            maes[(window_size, N_clusters)].append(cur_mae)\n",
    "#             mases[(window_size, N_clusters)].append((error_in, error_out))\n",
    "            mapes[(window_size, N_clusters)].append(cur_mape)\n",
    "#             errors[cluster_num] = mase_uni(test_y, predicted_original, y_train=test_y)\n",
    "            tmp_bad = cur_mase > np.percentile(cur_mase, 90)\n",
    "            bad_values += tmp_bad\n",
    "            cur_mase[tmp_bad] = -1\n",
    "#             errors[cluster_num] = Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')\n",
    "            errors[cluster_num] = np.mean(cur_mase[~tmp_bad])\n",
    "            \n",
    "            #show all metrics\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.suptitle(f\"K={N_clusters}, W={window_size}, C={cluster_num}\")\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(cur_mae, color=\"green\", label=\"library\")\n",
    "            plt.plot(Forecasting.my_mae(test_y, predicted_original, multioutput='raw_values'), color=\"red\", label=\"custom\")\n",
    "            plt.title(\"MAE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "#             plt.plot(error_in, label=\"library, in\")\n",
    "#             plt.plot(error_out, label=\"library, out\")\n",
    "            plt.plot(cur_mase, label=\"custom, out\")\n",
    "            plt.title(\"MASE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(cur_mape)\n",
    "            plt.title(\"MAPE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f\"plots/Dataset2/K={N_clusters}  W={window_size} C={cluster_num}.png\")\n",
    "#             plt.show()    \n",
    "            plt.clf()\n",
    "            # print(f\"{cur_mae=}, {cur_mase=}, {cur_mape=}\")\n",
    "            # my_mase = mase()\n",
    "            # print(f\"MASE in_sample = {error_in}, MASE out_sample = {error_out}\")\n",
    "            print(f\"average MASE = {errors[cluster_num]}, my average MASE = {Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')}\")\n",
    "            print(f\"Cluster {cluster_num}, {errors[cluster_num]}\")\n",
    "        answers[(window_size, N_clusters)] = errors\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.suptitle(f\"K={N_clusters}, W={window_size}\")\n",
    "        plt.subplot(2, 2, 1)\n",
    "\n",
    "        plt.bar(np.arange(N_clusters), [np.sum(clusters_labels == i) for i in range(N_clusters)], color='blue')\n",
    "        plt.title(\"Размеры кластеров\")\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.bar(np.arange(N_clusters), [len(datasets_clusters[i]) for i in range(N_clusters)], color=\"green\")\n",
    "        plt.title(\"Количество непрерывных отрезков\")\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.bar(np.arange(N_clusters), errors, color=\"red\")\n",
    "        plt.title(\"MASE на тесте каждого из кластеров\")\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        plt.table(cellText= [[f\"{x:.2f}\"] for x in errors],\n",
    "                      rowLabels=list(range(N_clusters)),\n",
    "                      loc='center')\n",
    "#         plt.show()\n",
    "        plt.savefig(f\"plots/Dataset2/method1: {N_clusters=}  W={window_size}.png\")\n",
    "        #         plt.show()\n",
    "        plt.clf()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.bar(np.arange(bad_values.shape[0]), bad_values)\n",
    "plt.title(\"Количество раз, когда переменная имела максимум MASE\")\n",
    "plt.savefig(f\"plots/Dataset2/bad_values.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([ 2,  4,  7,  8, 11, 14, 18, 21, 23, 25, 28, 30, 33, 37, 39, 43, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 5)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33,\n",
      "       39, 48, 50, 53, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 28, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 33, 37, 39,\n",
      "       41, 43, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 9)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 30, 31, 33, 35, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 12, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 23, 25, 26, 28, 30, 39, 41, 42, 48,\n",
      "       51, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(3, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 13, 14, 15, 18, 21, 23, 25, 26, 28, 30, 33,\n",
      "       37, 39, 41, 42, 44, 48, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 5)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 26, 28, 30, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 7)\n",
      "     (array([ 2, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 35, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 9)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 23, 25, 28, 30, 31, 33, 35, 39,\n",
      "       41, 43, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(3, 11)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 37, 39, 44, 48,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 2)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 12, 14, 18, 21, 23, 25, 30, 31, 33, 37, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 5)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 31, 39, 60, 61,\n",
      "       62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(5, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 16, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 23, 25, 28, 30, 33, 35, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "(5, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 14, 15, 16, 18, 19, 21, 23, 25, 27, 28, 30,\n",
      "       39, 42, 44, 47, 48, 52, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 15, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35,\n",
      "       37, 39, 60, 61, 62, 63, 65]),)\n",
      "(5, 11)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 28, 30, 31, 33, 39,\n",
      "       41, 42, 49, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(10, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 11, 13, 14, 18, 21, 23, 25, 28, 30, 31, 33,\n",
      "       35, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 5)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 22, 23, 25, 28, 30, 31, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 7)\n",
      "     (array([ 2,  4,  8,  9, 14, 16, 18, 19, 30, 58, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "(10, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 23, 24, 25, 26, 28, 30, 31,\n",
      "       33, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(10, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 12, 14, 18, 21, 22, 23, 25, 28, 30, 39, 56, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in maes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in mases.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c[0] < 1)}, {np.where(val_c[1] < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([14, 18, 25, 30, 31, 33, 35, 37, 43]),)\n",
      "     (array([14, 30]),)\n",
      "(1, 5)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(1, 7)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 11, 14]),)\n",
      "     (array([14]),)\n",
      "(1, 9)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 4,  8, 14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14, 60, 61]),)\n",
      "(1, 11)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(3, 2)\n",
      "     (array([ 4, 14, 18, 30, 31, 33, 35, 37, 42, 62]),)\n",
      "     (array([14, 30]),)\n",
      "(3, 5)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(3, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61]),)\n",
      "(3, 9)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 28, 39, 62]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 19, 30]),)\n",
      "(3, 11)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 23, 28, 39, 62, 65]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "(5, 2)\n",
      "     (array([12, 14, 18, 30, 31, 33, 35, 37, 60, 62, 65]),)\n",
      "     (array([14, 30]),)\n",
      "(5, 5)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "(5, 7)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 9, 11, 14, 18, 19, 21, 23, 25, 30, 39, 42, 44, 47, 52, 60, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 11)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 21, 23, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "(10, 2)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "(10, 5)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 14]),)\n",
      "(10, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 11)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in mapes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
