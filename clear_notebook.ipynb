{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 18:41:25.988541: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSet2.csv\", sep=\";\")#, parse_dates=['Timestamp']) #, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "df = data.groupby(data.index // K).mean() #усреднение\n",
    "df_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError, MeanAbsolutePercentageError\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mase = MeanAbsoluteScaledError(multioutput='raw_values')\n",
    "mase_uni = MeanAbsoluteScaledError(multioutput='uniform_average')\n",
    "mape = MeanAbsolutePercentageError(multioutput='raw_values')\n",
    "# mae = MeanAbsoluteError()\n",
    "\n",
    "\n",
    "#if ‘raw_values’, returns a full set of errors in case of multioutput input. If ‘uniform_average’, errors of all outputs are averaged with uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 67)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_np[:, :]\n",
    "# dataset = np.concatenate((dataset[:, :8], dataset[:, 9:]), axis=1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**__Отбор признаков на минималках__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удаление константных\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(0.001)\n",
    "dataset1 = selector.fit_transform(dataset) \n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 14}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(range(67)) - set(selector.get_feature_names_out(input_features=np.arange(dataset.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset[:, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(dataset[:, 8], color=\"green\")\n",
    "plt.plot(np.concatenate((dataset[:32714, 8], dataset[32717:, 8])))\n",
    "plt.title(\"consumption_09\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00292  0.00733  0.754974 1.658794 1.956544]\n",
      "[32714, 375379, 1, 1, 1]\n",
      "Изменение только в [[32713]\n",
      " [32714]\n",
      " [32715]\n",
      " [32716]]\n"
     ]
    }
   ],
   "source": [
    "values = np.unique(dataset[:, 8])\n",
    "print(values)\n",
    "print([len(np.argwhere(dataset[:, 8] == val)) for val in values])\n",
    "print(f\"Изменение только в {np.argwhere(dataset[1:, 8] - dataset[:-1, 8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Эти датчики пока выкинем из-за константности: ** \n",
    "\n",
    "8: consumption_09\n",
    "\n",
    "14 : consumption_07 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('consumption_07', 'consumption_09')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[15], columns[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f10d264ea90>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset[7])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import correlate\n",
    "# a = np.array([np.sin(x + 1) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 2) for x in range(10)])\n",
    "# c = correlate(a, b, mode=\"full\") #mode='same'\n",
    "# plt.plot(a, label=\"a\")\n",
    "# plt.plot(b, label=\"b\")\n",
    "# plt.plot(c, label=\"correlation\")\n",
    "# plt.legend()\n",
    "# c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "#еще не поняла до конца\n",
    "from sklearn.feature_selection import f_regression\n",
    "for i in range(1):\n",
    "    X = np.concatenate((dataset[:, :i], dataset[:, i + 1:]), axis=1)\n",
    "    y = dataset[:, i]\n",
    "    res = f_regression(X, y)\n",
    "    print(res[0].shape)\n",
    "    # plt.plot(res[0], label=\"f_statistics\")\n",
    "    # # plt.plot(res[1], label=\"p_values\")\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([np.sin(x) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 1) + 1 for x in range(10)])\n",
    "# c = np.array([np.sin(x + 0.1) for x in range(10)])\n",
    "\n",
    "# f_regression(a[:, None], b), f_regression(a[:, None], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прогнозирование**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "window_sizes_for_clustering = 10\n",
    "# X, y = dataset[:-window_sizes_for_clustering, ...], dataset[window_sizes_for_clustering:, ...]\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "n_split = round(0.2 * dataset.shape[0])\n",
    "dataset_train, dataset_test = dataset[:-n_split, ...], dataset[-n_split:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((326477, 65), (81619, 65))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes_for_clustering = [15] #1, 3, 5, 10, 15\n",
    "Ns_clusters = [9] #2, 5, 7, 9, 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns_clusters = [2]\n",
    "# window_sizes_for_clustering = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, M, Q = 100, 100, 2\n",
    "# dataset_train = np.column_stack([[np.sin(x / 25) for x in range(N)], [0.01 + np.sin(x / 25)*1.01 for x in range(N)]])\n",
    "# dataset_test = np.column_stack([[np.sin(x / 25) for x in range(M)], [0.01 + np.sin(x / 25)*1.01 for x in range(M)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326477, 65)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_windows.shape=(326462, 15, 65)\n",
      "N_clusters=9\n",
      "dataset_windows.shape=(326466, 1, 12, 65), labels.shape=(326466,)\n",
      "meow:  [(72767, 12, 65), (7329, 12, 65), (11549, 12, 65), (22124, 12, 65), (19450, 12, 65), (7194, 12, 65), (17214, 12, 65), (103622, 12, 65), (65217, 12, 65)]\n",
      "All: 72767\n",
      "In split_to_train_test: dataset_X.shape=(72767, 11, 65), dataset_y.shape=(72767, 65)\n",
      "Before prediction: train_X.shape=(43660, 11, 65), train_y.shape=(43660, 65), test_X.shape=(14553, 11, 65), test_y.shape=(14553, 65)\n",
      "Epoch 1/30\n",
      "683/683 [==============================] - 21s 30ms/step - loss: 772.3183 - val_loss: 770.0585\n",
      "Epoch 2/30\n",
      "683/683 [==============================] - 22s 33ms/step - loss: 771.1393 - val_loss: 768.8803\n",
      "Epoch 3/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 769.9655 - val_loss: 767.7038\n",
      "Epoch 4/30\n",
      "683/683 [==============================] - 22s 32ms/step - loss: 768.7938 - val_loss: 766.5289\n",
      "Epoch 5/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 767.6096 - val_loss: 765.2053\n",
      "Epoch 6/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 766.2392 - val_loss: 763.9142\n",
      "Epoch 7/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 764.9893 - val_loss: 762.6807\n",
      "Epoch 8/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 763.7751 - val_loss: 761.4673\n",
      "Epoch 9/30\n",
      "683/683 [==============================] - 23s 33ms/step - loss: 762.5801 - val_loss: 760.2719\n",
      "Epoch 10/30\n",
      "683/683 [==============================] - 22s 33ms/step - loss: 761.3951 - val_loss: 759.0826\n",
      "Epoch 11/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 760.1573 - val_loss: 757.7220\n",
      "Epoch 12/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 758.8502 - val_loss: 756.5204\n",
      "Epoch 13/30\n",
      "683/683 [==============================] - 22s 32ms/step - loss: 757.6418 - val_loss: 755.2328\n",
      "Epoch 14/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 756.3157 - val_loss: 753.9444\n",
      "Epoch 15/30\n",
      "683/683 [==============================] - 22s 32ms/step - loss: 755.0576 - val_loss: 752.7094\n",
      "Epoch 16/30\n",
      "683/683 [==============================] - 22s 32ms/step - loss: 753.8259 - val_loss: 751.4902\n",
      "Epoch 17/30\n",
      "683/683 [==============================] - 23s 33ms/step - loss: 752.6031 - val_loss: 750.2761\n",
      "Epoch 18/30\n",
      "683/683 [==============================] - 23s 33ms/step - loss: 751.3876 - val_loss: 749.0659\n",
      "Epoch 19/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 750.1788 - val_loss: 747.8576\n",
      "Epoch 20/30\n",
      "683/683 [==============================] - 21s 31ms/step - loss: 748.9752 - val_loss: 746.6499\n",
      "Epoch 21/30\n",
      "683/683 [==============================] - 22s 32ms/step - loss: 747.7755 - val_loss: 745.4439\n",
      "Epoch 22/30\n",
      "683/683 [==============================] - 24s 36ms/step - loss: 746.5802 - val_loss: 744.2389\n",
      "Epoch 23/30\n",
      "683/683 [==============================] - 23s 33ms/step - loss: 745.3890 - val_loss: 743.0356\n",
      "Epoch 24/30\n",
      "683/683 [==============================] - 22s 33ms/step - loss: 744.2010 - val_loss: 741.8371\n",
      "Epoch 25/30\n",
      "683/683 [==============================] - 23s 34ms/step - loss: 743.0190 - val_loss: 740.6439\n",
      "Epoch 26/30\n",
      "683/683 [==============================] - 23s 33ms/step - loss: 741.8445 - val_loss: 739.4591\n",
      "Epoch 27/30\n",
      "683/683 [==============================] - 23s 33ms/step - loss: 740.6796 - val_loss: 738.2820\n",
      "Epoch 28/30\n",
      "683/683 [==============================] - 22s 32ms/step - loss: 739.5251 - val_loss: 737.1121\n",
      "Epoch 29/30\n",
      "683/683 [==============================] - 22s 33ms/step - loss: 738.3818 - val_loss: 735.9540\n",
      "Epoch 30/30\n",
      "683/683 [==============================] - 23s 34ms/step - loss: 737.2501 - val_loss: 734.8047\n",
      "455/455 [==============================] - 5s 11ms/step\n",
      "In calc_results: 43660, 14554, 14553, sum = 72767\n",
      "All: 7329\n",
      "In split_to_train_test: dataset_X.shape=(7329, 11, 65), dataset_y.shape=(7329, 65)\n",
      "Before prediction: train_X.shape=(4397, 11, 65), train_y.shape=(4397, 65), test_X.shape=(1466, 11, 65), test_y.shape=(1466, 65)\n",
      "Epoch 1/30\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 1153.5854 - val_loss: 1160.3033\n",
      "Epoch 2/30\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 1153.4845 - val_loss: 1160.2026\n",
      "Epoch 3/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1153.3840 - val_loss: 1160.1019\n",
      "Epoch 4/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1153.2834 - val_loss: 1160.0010\n",
      "Epoch 5/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1153.1825 - val_loss: 1159.9001\n",
      "Epoch 6/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1153.0822 - val_loss: 1159.7992\n",
      "Epoch 7/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1152.9813 - val_loss: 1159.6986\n",
      "Epoch 8/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1152.8811 - val_loss: 1159.5977\n",
      "Epoch 9/30\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 1152.7802 - val_loss: 1159.4967\n",
      "Epoch 10/30\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 1152.6793 - val_loss: 1159.3959\n",
      "Epoch 11/30\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 1152.5789 - val_loss: 1159.2950\n",
      "Epoch 12/30\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 1152.4781 - val_loss: 1159.1943\n",
      "Epoch 13/30\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 1152.3776 - val_loss: 1159.0934\n",
      "Epoch 14/30\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 1152.2766 - val_loss: 1158.9926\n",
      "Epoch 15/30\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 1152.1761 - val_loss: 1158.8916\n",
      "Epoch 16/30\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 1152.0756 - val_loss: 1158.7909\n",
      "Epoch 17/30\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 1151.9751 - val_loss: 1158.6899\n",
      "Epoch 18/30\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 1151.8741 - val_loss: 1158.5892\n",
      "Epoch 19/30\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 1151.7737 - val_loss: 1158.4884\n",
      "Epoch 20/30\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 1151.6730 - val_loss: 1158.3875\n",
      "Epoch 21/30\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 1151.5723 - val_loss: 1158.2866\n",
      "Epoch 22/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1151.4719 - val_loss: 1158.1859\n",
      "Epoch 23/30\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 1151.3712 - val_loss: 1158.0850\n",
      "Epoch 24/30\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 1151.2705 - val_loss: 1157.9843\n",
      "Epoch 25/30\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 1151.1700 - val_loss: 1157.8833\n",
      "Epoch 26/30\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 1151.0690 - val_loss: 1157.7826\n",
      "Epoch 27/30\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 1150.9689 - val_loss: 1157.6818\n",
      "Epoch 28/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1150.8680 - val_loss: 1157.5807\n",
      "Epoch 29/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1150.7672 - val_loss: 1157.4800\n",
      "Epoch 30/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1150.6666 - val_loss: 1157.3792\n",
      "46/46 [==============================] - 1s 12ms/step\n",
      "In calc_results: 4397, 1466, 1466, sum = 7329\n",
      "All: 11549\n",
      "In split_to_train_test: dataset_X.shape=(11549, 11, 65), dataset_y.shape=(11549, 65)\n",
      "Before prediction: train_X.shape=(6929, 11, 65), train_y.shape=(6929, 65), test_X.shape=(2310, 11, 65), test_y.shape=(2310, 65)\n",
      "Epoch 1/30\n",
      "109/109 [==============================] - 4s 35ms/step - loss: 1070.3495 - val_loss: 1090.0300\n",
      "Epoch 2/30\n",
      "109/109 [==============================] - 4s 35ms/step - loss: 1070.2455 - val_loss: 1089.9264\n",
      "Epoch 3/30\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 1070.1415 - val_loss: 1089.8224\n",
      "Epoch 4/30\n",
      "109/109 [==============================] - 4s 35ms/step - loss: 1070.0378 - val_loss: 1089.7185\n",
      "Epoch 5/30\n",
      "109/109 [==============================] - 4s 35ms/step - loss: 1069.9342 - val_loss: 1089.6146\n",
      "Epoch 6/30\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1069.8306 - val_loss: 1089.5107\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 4s 34ms/step - loss: 1069.7269 - val_loss: 1089.4073\n",
      "Epoch 8/30\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1069.6230 - val_loss: 1089.3033\n",
      "Epoch 9/30\n",
      "109/109 [==============================] - 4s 35ms/step - loss: 1069.5192 - val_loss: 1089.1998\n",
      "Epoch 10/30\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1069.4155 - val_loss: 1089.0959\n",
      "Epoch 11/30\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 1069.3119 - val_loss: 1088.9919\n",
      "Epoch 12/30\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1069.2081 - val_loss: 1088.8882\n",
      "Epoch 13/30\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1069.1044 - val_loss: 1088.7842\n",
      "Epoch 14/30\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1069.0007 - val_loss: 1088.6809\n",
      "Epoch 15/30\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1068.8965 - val_loss: 1088.5769\n",
      "Epoch 16/30\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1068.7930 - val_loss: 1088.4733\n",
      "Epoch 17/30\n",
      "109/109 [==============================] - 4s 35ms/step - loss: 1068.6890 - val_loss: 1088.3694\n",
      "Epoch 18/30\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1068.5858 - val_loss: 1088.2654\n",
      "Epoch 19/30\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 1068.4819 - val_loss: 1088.1617\n",
      "Epoch 20/30\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1068.3781 - val_loss: 1088.0579\n",
      "Epoch 21/30\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 1068.2742 - val_loss: 1087.9545\n",
      "Epoch 22/30\n",
      "109/109 [==============================] - 3s 32ms/step - loss: 1068.1708 - val_loss: 1087.8506\n",
      "Epoch 23/30\n",
      "109/109 [==============================] - 3s 32ms/step - loss: 1068.0667 - val_loss: 1087.7468\n",
      "Epoch 24/30\n",
      "109/109 [==============================] - 3s 32ms/step - loss: 1067.9633 - val_loss: 1087.6429\n",
      "Epoch 25/30\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 1067.8593 - val_loss: 1087.5392\n",
      "Epoch 26/30\n",
      "109/109 [==============================] - 4s 35ms/step - loss: 1067.7559 - val_loss: 1087.4355\n",
      "Epoch 27/30\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1067.6517 - val_loss: 1087.3315\n",
      "Epoch 28/30\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1067.5483 - val_loss: 1087.2283\n",
      "Epoch 29/30\n",
      "109/109 [==============================] - 4s 35ms/step - loss: 1067.4442 - val_loss: 1087.1241\n",
      "Epoch 30/30\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1067.3408 - val_loss: 1087.0205\n",
      "73/73 [==============================] - 1s 12ms/step\n",
      "In calc_results: 6929, 2310, 2310, sum = 11549\n",
      "All: 22124\n",
      "In split_to_train_test: dataset_X.shape=(22124, 11, 65), dataset_y.shape=(22124, 65)\n",
      "Before prediction: train_X.shape=(13274, 11, 65), train_y.shape=(13274, 65), test_X.shape=(4425, 11, 65), test_y.shape=(4425, 65)\n",
      "Epoch 1/30\n",
      "208/208 [==============================] - 7s 35ms/step - loss: 1000.3745 - val_loss: 1022.3040\n",
      "Epoch 2/30\n",
      "208/208 [==============================] - 7s 34ms/step - loss: 1000.1377 - val_loss: 1022.0689\n",
      "Epoch 3/30\n",
      "208/208 [==============================] - 7s 32ms/step - loss: 999.9022 - val_loss: 1021.8344\n",
      "Epoch 4/30\n",
      "208/208 [==============================] - 6s 31ms/step - loss: 999.6667 - val_loss: 1021.6000\n",
      "Epoch 5/30\n",
      "208/208 [==============================] - 6s 31ms/step - loss: 999.4308 - val_loss: 1021.3652\n",
      "Epoch 6/30\n",
      "208/208 [==============================] - 7s 33ms/step - loss: 999.1954 - val_loss: 1021.1304\n",
      "Epoch 7/30\n",
      "208/208 [==============================] - 7s 33ms/step - loss: 998.9602 - val_loss: 1020.8963\n",
      "Epoch 8/30\n",
      "208/208 [==============================] - 7s 34ms/step - loss: 998.7247 - val_loss: 1020.6616\n",
      "Epoch 9/30\n",
      "208/208 [==============================] - 6s 30ms/step - loss: 998.4891 - val_loss: 1020.4274\n",
      "Epoch 10/30\n",
      "208/208 [==============================] - 6s 30ms/step - loss: 998.2537 - val_loss: 1020.1932\n",
      "Epoch 11/30\n",
      "208/208 [==============================] - 7s 34ms/step - loss: 998.0180 - val_loss: 1019.9589\n",
      "Epoch 12/30\n",
      "208/208 [==============================] - 7s 32ms/step - loss: 997.7827 - val_loss: 1019.7246\n",
      "Epoch 13/30\n",
      "208/208 [==============================] - 7s 33ms/step - loss: 997.5469 - val_loss: 1019.4908\n",
      "Epoch 14/30\n",
      "208/208 [==============================] - 8s 38ms/step - loss: 997.3123 - val_loss: 1019.2565\n",
      "Epoch 15/30\n",
      "208/208 [==============================] - 8s 37ms/step - loss: 997.0761 - val_loss: 1019.0223\n",
      "Epoch 16/30\n",
      "208/208 [==============================] - 7s 36ms/step - loss: 996.8411 - val_loss: 1018.7885\n",
      "Epoch 17/30\n",
      "208/208 [==============================] - 7s 32ms/step - loss: 996.6056 - val_loss: 1018.5541\n",
      "Epoch 18/30\n",
      "208/208 [==============================] - 7s 33ms/step - loss: 996.3705 - val_loss: 1018.3200\n",
      "Epoch 19/30\n",
      "208/208 [==============================] - 6s 31ms/step - loss: 996.1347 - val_loss: 1018.0860\n",
      "Epoch 20/30\n",
      "208/208 [==============================] - 6s 30ms/step - loss: 995.8992 - val_loss: 1017.8517\n",
      "Epoch 21/30\n",
      "208/208 [==============================] - 7s 33ms/step - loss: 995.6642 - val_loss: 1017.6177\n",
      "Epoch 22/30\n",
      "208/208 [==============================] - 7s 34ms/step - loss: 995.4289 - val_loss: 1017.3840\n",
      "Epoch 23/30\n",
      "208/208 [==============================] - 7s 34ms/step - loss: 995.1932 - val_loss: 1017.1496\n",
      "Epoch 24/30\n",
      "208/208 [==============================] - 7s 31ms/step - loss: 994.9579 - val_loss: 1016.9153\n",
      "Epoch 25/30\n",
      "208/208 [==============================] - 7s 32ms/step - loss: 994.7226 - val_loss: 1016.6817\n",
      "Epoch 26/30\n",
      "208/208 [==============================] - 7s 34ms/step - loss: 994.4875 - val_loss: 1016.4476\n",
      "Epoch 27/30\n",
      "208/208 [==============================] - 7s 34ms/step - loss: 994.2521 - val_loss: 1016.2133\n",
      "Epoch 28/30\n",
      "208/208 [==============================] - 7s 34ms/step - loss: 994.0168 - val_loss: 1015.9796\n",
      "Epoch 29/30\n",
      "208/208 [==============================] - 6s 31ms/step - loss: 993.7808 - val_loss: 1015.7454\n",
      "Epoch 30/30\n",
      "208/208 [==============================] - 7s 32ms/step - loss: 993.5464 - val_loss: 1015.5115\n",
      "139/139 [==============================] - 1s 10ms/step\n",
      "In calc_results: 13274, 4425, 4425, sum = 22124\n",
      "All: 19450\n",
      "In split_to_train_test: dataset_X.shape=(19450, 11, 65), dataset_y.shape=(19450, 65)\n",
      "Before prediction: train_X.shape=(11670, 11, 65), train_y.shape=(11670, 65), test_X.shape=(3890, 11, 65), test_y.shape=(3890, 65)\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 378.5475 - val_loss: 375.3475\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 378.1904 - val_loss: 375.0010\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 377.8383 - val_loss: 374.6561\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 6s 30ms/step - loss: 377.4887 - val_loss: 374.3138\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 377.1389 - val_loss: 373.9722\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 376.7904 - val_loss: 373.6313\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 376.4422 - val_loss: 373.2906\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 376.0945 - val_loss: 372.9503\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 375.7470 - val_loss: 372.6100\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 375.3993 - val_loss: 372.2700\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 375.0524 - val_loss: 371.9311\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 374.7074 - val_loss: 371.5930\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 374.3622 - val_loss: 371.2557\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 374.0179 - val_loss: 370.9186\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 373.6733 - val_loss: 370.5815\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 373.3286 - val_loss: 370.2445\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 6s 31ms/step - loss: 372.9839 - val_loss: 369.9075\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 6s 30ms/step - loss: 372.6392 - val_loss: 369.5708\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 372.2948 - val_loss: 369.2338\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 371.9503 - val_loss: 368.8973\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 371.6060 - val_loss: 368.5615\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 371.1887 - val_loss: 368.1339\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 370.8201 - val_loss: 367.7903\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 5s 30ms/step - loss: 370.4686 - val_loss: 367.4477\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 370.1181 - val_loss: 367.1058\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 369.7682 - val_loss: 366.7649\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 369.4190 - val_loss: 366.4246\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 369.0703 - val_loss: 366.0844\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 368.7219 - val_loss: 365.7447\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 368.3740 - val_loss: 365.4053\n",
      "122/122 [==============================] - 1s 11ms/step\n",
      "In calc_results: 11670, 3890, 3890, sum = 19450\n",
      "All: 7194\n",
      "In split_to_train_test: dataset_X.shape=(7194, 11, 65), dataset_y.shape=(7194, 65)\n",
      "Before prediction: train_X.shape=(4316, 11, 65), train_y.shape=(4316, 65), test_X.shape=(1439, 11, 65), test_y.shape=(1439, 65)\n",
      "Epoch 1/30\n",
      "68/68 [==============================] - 2s 34ms/step - loss: 162.6384 - val_loss: 163.5737\n",
      "Epoch 2/30\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 162.5380 - val_loss: 163.4784\n",
      "Epoch 3/30\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 162.4453 - val_loss: 163.3993\n",
      "Epoch 4/30\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 162.3641 - val_loss: 163.3244\n",
      "Epoch 5/30\n",
      "68/68 [==============================] - 2s 34ms/step - loss: 162.2857 - val_loss: 163.2522\n",
      "Epoch 6/30\n",
      "68/68 [==============================] - 2s 34ms/step - loss: 162.2089 - val_loss: 163.1806\n",
      "Epoch 7/30\n",
      "68/68 [==============================] - 2s 33ms/step - loss: 162.1332 - val_loss: 163.1099\n",
      "Epoch 8/30\n",
      "68/68 [==============================] - 2s 34ms/step - loss: 162.0583 - val_loss: 163.0394\n",
      "Epoch 9/30\n",
      "68/68 [==============================] - 2s 35ms/step - loss: 161.9836 - val_loss: 162.9693\n",
      "Epoch 10/30\n",
      "68/68 [==============================] - 2s 34ms/step - loss: 161.9089 - val_loss: 162.8992\n",
      "Epoch 11/30\n",
      "68/68 [==============================] - 2s 34ms/step - loss: 161.8345 - val_loss: 162.8292\n",
      "Epoch 12/30\n",
      "68/68 [==============================] - 2s 34ms/step - loss: 161.7601 - val_loss: 162.7594\n",
      "Epoch 13/30\n",
      "68/68 [==============================] - 2s 34ms/step - loss: 161.6859 - val_loss: 162.6903\n",
      "Epoch 14/30\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 161.6118 - val_loss: 162.6217\n",
      "Epoch 15/30\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 161.5380 - val_loss: 162.5532\n",
      "Epoch 16/30\n",
      "68/68 [==============================] - 2s 30ms/step - loss: 161.4643 - val_loss: 162.4848\n",
      "Epoch 17/30\n",
      "68/68 [==============================] - 2s 30ms/step - loss: 161.3905 - val_loss: 162.4167\n",
      "Epoch 18/30\n",
      "68/68 [==============================] - 2s 33ms/step - loss: 161.3168 - val_loss: 162.3486\n",
      "Epoch 19/30\n",
      "68/68 [==============================] - 2s 33ms/step - loss: 161.2430 - val_loss: 162.2805\n",
      "Epoch 20/30\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 161.1694 - val_loss: 162.2128\n",
      "Epoch 21/30\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 161.0966 - val_loss: 162.1456\n",
      "Epoch 22/30\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 161.0241 - val_loss: 162.0785\n",
      "Epoch 23/30\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 160.9520 - val_loss: 162.0118\n",
      "Epoch 24/30\n",
      "68/68 [==============================] - 2s 35ms/step - loss: 160.8799 - val_loss: 161.9454\n",
      "Epoch 25/30\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 160.8081 - val_loss: 161.8791\n",
      "Epoch 26/30\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 160.7366 - val_loss: 161.8128\n",
      "Epoch 27/30\n",
      "68/68 [==============================] - 2s 32ms/step - loss: 160.6651 - val_loss: 161.7466\n",
      "Epoch 28/30\n",
      "68/68 [==============================] - 2s 35ms/step - loss: 160.5936 - val_loss: 161.6805\n",
      "Epoch 29/30\n",
      "68/68 [==============================] - 2s 33ms/step - loss: 160.5222 - val_loss: 161.6144\n",
      "Epoch 30/30\n",
      "68/68 [==============================] - 2s 34ms/step - loss: 160.4508 - val_loss: 161.5482\n",
      "45/45 [==============================] - 0s 10ms/step\n",
      "In calc_results: 4316, 1439, 1439, sum = 7194\n",
      "All: 17214\n",
      "In split_to_train_test: dataset_X.shape=(17214, 11, 65), dataset_y.shape=(17214, 65)\n",
      "Before prediction: train_X.shape=(10328, 11, 65), train_y.shape=(10328, 65), test_X.shape=(3443, 11, 65), test_y.shape=(3443, 65)\n",
      "Epoch 1/30\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 12446755094265856.0000 - val_loss: 12689328404692992.0000\n",
      "Epoch 2/30\n",
      "162/162 [==============================] - 5s 31ms/step - loss: 12446756168007680.0000 - val_loss: 12689328404692992.0000\n",
      "Epoch 3/30\n",
      "161/162 [============================>.] - ETA: 0s - loss: 12446749725556736.0000Restoring model weights from the end of the best epoch: 1.\n",
      "162/162 [==============================] - 5s 30ms/step - loss: 12446756168007680.0000 - val_loss: 12689328404692992.0000\n",
      "Epoch 3: early stopping\n",
      "108/108 [==============================] - 1s 11ms/step\n",
      "In calc_results: 10328, 3443, 3443, sum = 17214\n",
      "All: 103622\n",
      "In split_to_train_test: dataset_X.shape=(103622, 11, 65), dataset_y.shape=(103622, 65)\n",
      "Before prediction: train_X.shape=(62173, 11, 65), train_y.shape=(62173, 65), test_X.shape=(20724, 11, 65), test_y.shape=(20724, 65)\n",
      "Epoch 1/30\n",
      "972/972 [==============================] - 31s 32ms/step - loss: 853.5562 - val_loss: 853.1600\n",
      "Epoch 2/30\n",
      "972/972 [==============================] - 32s 33ms/step - loss: 852.3335 - val_loss: 851.9221\n",
      "Epoch 3/30\n",
      "972/972 [==============================] - 30s 31ms/step - loss: 851.1159 - val_loss: 850.6865\n",
      "Epoch 4/30\n",
      "972/972 [==============================] - 33s 34ms/step - loss: 849.9006 - val_loss: 849.4529\n",
      "Epoch 5/30\n",
      "972/972 [==============================] - 32s 32ms/step - loss: 848.6855 - val_loss: 848.2203\n",
      "Epoch 6/30\n",
      "972/972 [==============================] - 30s 31ms/step - loss: 847.4730 - val_loss: 846.9900\n",
      "Epoch 7/30\n",
      "972/972 [==============================] - 31s 32ms/step - loss: 846.2623 - val_loss: 845.7624\n",
      "Epoch 8/30\n",
      "972/972 [==============================] - 32s 33ms/step - loss: 845.0538 - val_loss: 844.5412\n",
      "Epoch 9/30\n",
      "972/972 [==============================] - 31s 31ms/step - loss: 843.8530 - val_loss: 843.3348\n",
      "Epoch 10/30\n",
      "972/972 [==============================] - 32s 33ms/step - loss: 842.6642 - val_loss: 842.1370\n",
      "Epoch 11/30\n",
      "972/972 [==============================] - 32s 32ms/step - loss: 841.4783 - val_loss: 840.9434\n",
      "Epoch 12/30\n",
      "972/972 [==============================] - 31s 32ms/step - loss: 840.2952 - val_loss: 839.7544\n",
      "Epoch 13/30\n",
      "972/972 [==============================] - 32s 33ms/step - loss: 839.0264 - val_loss: 838.4081\n",
      "Epoch 14/30\n",
      "972/972 [==============================] - 29s 30ms/step - loss: 837.7231 - val_loss: 837.1321\n",
      "Epoch 15/30\n",
      "972/972 [==============================] - 30s 31ms/step - loss: 836.4587 - val_loss: 835.8718\n",
      "Epoch 16/30\n",
      "972/972 [==============================] - 30s 31ms/step - loss: 835.2051 - val_loss: 834.6221\n",
      "Epoch 17/30\n",
      "972/972 [==============================] - 31s 32ms/step - loss: 833.9568 - val_loss: 833.3795\n",
      "Epoch 18/30\n",
      "972/972 [==============================] - 31s 32ms/step - loss: 832.7135 - val_loss: 832.1434\n",
      "Epoch 19/30\n",
      "972/972 [==============================] - 33s 34ms/step - loss: 831.4738 - val_loss: 830.9141\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972/972 [==============================] - 33s 34ms/step - loss: 830.2398 - val_loss: 829.6909\n",
      "Epoch 21/30\n",
      "972/972 [==============================] - 29s 30ms/step - loss: 829.0093 - val_loss: 828.4736\n",
      "Epoch 22/30\n",
      "972/972 [==============================] - 30s 31ms/step - loss: 827.7836 - val_loss: 827.2625\n",
      "Epoch 23/30\n",
      "972/972 [==============================] - 31s 32ms/step - loss: 826.5605 - val_loss: 826.0586\n",
      "Epoch 24/30\n",
      "972/972 [==============================] - 33s 34ms/step - loss: 825.3489 - val_loss: 824.8693\n",
      "Epoch 25/30\n",
      "972/972 [==============================] - 32s 33ms/step - loss: 824.1497 - val_loss: 823.6856\n",
      "Epoch 26/30\n",
      "972/972 [==============================] - 31s 32ms/step - loss: 822.9553 - val_loss: 822.5035\n",
      "Epoch 27/30\n",
      "972/972 [==============================] - 32s 33ms/step - loss: 821.7637 - val_loss: 821.3246\n",
      "Epoch 28/30\n",
      "972/972 [==============================] - 29s 30ms/step - loss: 820.5753 - val_loss: 820.1479\n",
      "Epoch 29/30\n",
      "972/972 [==============================] - 32s 33ms/step - loss: 819.3908 - val_loss: 818.9768\n",
      "Epoch 30/30\n",
      "972/972 [==============================] - 31s 31ms/step - loss: 818.2093 - val_loss: 817.8119\n",
      "648/648 [==============================] - 7s 11ms/step\n",
      "In calc_results: 62173, 20725, 20724, sum = 103622\n",
      "All: 65217\n",
      "In split_to_train_test: dataset_X.shape=(65217, 11, 65), dataset_y.shape=(65217, 65)\n",
      "Before prediction: train_X.shape=(39130, 11, 65), train_y.shape=(39130, 65), test_X.shape=(13043, 11, 65), test_y.shape=(13043, 65)\n",
      "Epoch 1/30\n",
      "612/612 [==============================] - 20s 32ms/step - loss: 671.8853 - val_loss: 662.0859\n",
      "Epoch 2/30\n",
      "612/612 [==============================] - 21s 34ms/step - loss: 670.9957 - val_loss: 661.2106\n",
      "Epoch 3/30\n",
      "612/612 [==============================] - 21s 34ms/step - loss: 670.1291 - val_loss: 660.3465\n",
      "Epoch 4/30\n",
      "612/612 [==============================] - 20s 33ms/step - loss: 669.2681 - val_loss: 659.4844\n",
      "Epoch 5/30\n",
      "612/612 [==============================] - 18s 30ms/step - loss: 668.3935 - val_loss: 658.5479\n",
      "Epoch 6/30\n",
      "612/612 [==============================] - 19s 31ms/step - loss: 667.4624 - val_loss: 657.6631\n",
      "Epoch 7/30\n",
      "612/612 [==============================] - 22s 37ms/step - loss: 666.5844 - val_loss: 656.7845\n",
      "Epoch 8/30\n",
      "612/612 [==============================] - 20s 33ms/step - loss: 665.7108 - val_loss: 655.9094\n",
      "Epoch 9/30\n",
      "612/612 [==============================] - 19s 31ms/step - loss: 664.8401 - val_loss: 655.0401\n",
      "Epoch 10/30\n",
      "612/612 [==============================] - 20s 33ms/step - loss: 663.9747 - val_loss: 654.1796\n",
      "Epoch 11/30\n",
      "612/612 [==============================] - 20s 33ms/step - loss: 663.1125 - val_loss: 653.3243\n",
      "Epoch 12/30\n",
      "612/612 [==============================] - 19s 31ms/step - loss: 662.2551 - val_loss: 652.4760\n",
      "Epoch 13/30\n",
      "612/612 [==============================] - 19s 31ms/step - loss: 661.4006 - val_loss: 651.6303\n",
      "Epoch 14/30\n",
      "612/612 [==============================] - 19s 31ms/step - loss: 660.5475 - val_loss: 650.7880\n",
      "Epoch 15/30\n",
      "612/612 [==============================] - 19s 31ms/step - loss: 659.6957 - val_loss: 649.9498\n",
      "Epoch 16/30\n",
      "612/612 [==============================] - 20s 33ms/step - loss: 658.8454 - val_loss: 649.1161\n",
      "Epoch 17/30\n",
      "612/612 [==============================] - 20s 33ms/step - loss: 658.0003 - val_loss: 648.2904\n",
      "Epoch 18/30\n",
      "612/612 [==============================] - 18s 30ms/step - loss: 657.1577 - val_loss: 647.4667\n",
      "Epoch 19/30\n",
      "612/612 [==============================] - 19s 32ms/step - loss: 656.3167 - val_loss: 646.6457\n",
      "Epoch 20/30\n",
      "612/612 [==============================] - 20s 33ms/step - loss: 655.4772 - val_loss: 645.8265\n",
      "Epoch 21/30\n",
      "612/612 [==============================] - 19s 32ms/step - loss: 654.6409 - val_loss: 645.0093\n",
      "Epoch 22/30\n",
      "612/612 [==============================] - 19s 30ms/step - loss: 653.8077 - val_loss: 644.1947\n",
      "Epoch 23/30\n",
      "612/612 [==============================] - 19s 31ms/step - loss: 652.9777 - val_loss: 643.3823\n",
      "Epoch 24/30\n",
      "612/612 [==============================] - 20s 32ms/step - loss: 652.1489 - val_loss: 642.5710\n",
      "Epoch 25/30\n",
      "612/612 [==============================] - 20s 32ms/step - loss: 651.3223 - val_loss: 641.7619\n",
      "Epoch 26/30\n",
      "612/612 [==============================] - 19s 31ms/step - loss: 650.4978 - val_loss: 640.9537\n",
      "Epoch 27/30\n",
      "612/612 [==============================] - 20s 32ms/step - loss: 649.6753 - val_loss: 640.1468\n",
      "Epoch 28/30\n",
      "612/612 [==============================] - 20s 33ms/step - loss: 648.8550 - val_loss: 639.3416\n",
      "Epoch 29/30\n",
      "612/612 [==============================] - 20s 33ms/step - loss: 648.0376 - val_loss: 638.5391\n",
      "Epoch 30/30\n",
      "612/612 [==============================] - 19s 32ms/step - loss: 647.2224 - val_loss: 637.7404\n",
      "408/408 [==============================] - 4s 10ms/step\n",
      "In calc_results: 39130, 13044, 13043, sum = 65217\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"N_clusters\":Ns_clusters, \"window_size_for_clustering\":window_sizes_for_clustering, \"dif\":True}\n",
    "models, model_mase, results_training = Forecasting.try_parameters(parameters, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [<keras.engine.sequential.Sequential at 0x7f10d1c94b20>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f0fb7628f10>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f0fb7b09220>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f0fb944bfd0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f0fb945e130>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f0fbac185e0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f0fb96da580>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f0fb9464d00>,\n",
       "  <keras.engine.sequential.Sequential at 0x7f0fb954c820>],\n",
       " 'scalers': [<Forecasting.MyStandardScaler at 0x7f11341796a0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f0f72fcf730>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f0fb93f80d0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f0fb945e0d0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f0fb9310a60>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f0fb760cb20>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f0fb96da850>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f0fb9571c70>,\n",
       "  <Forecasting.MyStandardScaler at 0x7f0fb95f4f40>],\n",
       " 'clusters_model': KMeans(init='random', max_iter=100, n_clusters=9)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/0/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/3/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/4/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/5/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/6/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/7/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models['models'])):\n",
    "    models['models'][i].save(\"models/\"+str(i))\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "tmp_model = keras.models.load_model('models/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models['clusters_model'].save(\"clusters_model_15\")\n",
    "with open(\"clusters_model_15.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models['clusters_model'], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1192642076112797.8"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_model = models[\"clusters_model\"]\n",
    "forecasting_models = models['models']\n",
    "scalers = models['scalers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_sizes_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.shape=(81619, 65), dataset_windows.shape=(81604, 975), cluster_nums.shape=(81604,), 15\n",
      "After pad: dataset.shape=(81619, 65), cluster_nums.shape=(81619,)\n",
      "cur_windows.shape=(30424, 11, 65)\n",
      "cur_windows.shape=(278, 11, 65)\n",
      "cur_windows.shape=(878, 11, 65)\n",
      "cur_windows.shape=(684, 11, 65)\n",
      "cur_windows.shape=(2152, 11, 65)\n",
      "cur_windows.shape=(29977, 11, 65)\n",
      "cur_windows.shape=(17216, 11, 65)\n"
     ]
    }
   ],
   "source": [
    "window_size_for_clustering = clusters_model.cluster_centers_.shape[-1] // dataset_test.shape[-1]\n",
    "y_pred, results_testing = Forecasting.predict_through_clusters(dataset_test, clusters_model, forecasting_models, scalers, window_size_clustering=window_size_for_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81609, 65), 65)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, dataset.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape=(81609, 65), dataset_test.shape=(81619, 65)\n",
      "(81609, 65) (81609, 65)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{y_pred.shape=}, {dataset_test.shape=}\")\n",
    "y_true = dataset_test[-y_pred.shape[0]:]\n",
    "print(y_true.shape, results_testing[:, :dataset_train.shape[-1]].shape)\n",
    "results_testing[:, :dataset_train.shape[-1]] = y_true\n",
    "cur_mase = Forecasting.my_mase(y_true, y_pred, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = dataset_train.shape[-1]\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "full_results = np.concatenate((results_training, results_testing), axis=0)\n",
    "with open(\"output_table.csv\", \"w\") as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    writer.writerow([\"real \"+str(i) for i in range(Q)] + [\"predicted \" + str(i) for i in range(Q)] + [\"cluster_num\", \"mode\"])\n",
    "    for i in range(full_results.shape[0]):\n",
    "        writer.writerow(full_results[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408075, 132)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAHFCAYAAAA5VBcVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABv7klEQVR4nO3dd3xb9b0//tfR9JK87djxiLOdHbJIIIQQyKKBNqxCKWE3JdCy28L3XmhLb2jvD1oKBe5lpXApCS2jjAQSCBkkBJKQvacdJ473tmVZ0vn9IZ0jD9nWOEfz9Xw8eDwaW5ZOVEV+6/1+f95vQRRFEURERETkM02oL4CIiIgoUjGQIiIiIvITAykiIiIiPzGQIiIiIvITAykiIiIiPzGQIiIiIvITAykiIiIiPzGQIiIiIvITAykiIiIiPzGQIqKot2LFCgiCAEEQsGHDhh7fF0URQ4cOhSAIuPTSS3t8v7q6GkajEYIgYMeOHR4fQxRFrFy5EjNnzkRWVhbi4uKQl5eHefPm4dVXX+1yW+laPP136623KvA3JqJg0YX6AoiIgsVkMuG1117rESxt3LgRJ06cgMlk8vhzb731FqxWKwDgtddew+TJk3vc5je/+Q3++Mc/4q677sIjjzwCk8mEkpISrF+/Hv/+979x5513drn9tddei4ceeqjH/WRmZvr5tyOiUBC4a4+Iot2KFStw22234c4778Tbb7+N8+fPw2w2y9//6U9/ihMnTqCxsREZGRk9slZjx45FZWUlCgsLcfToUZSXlyM+Pl7+fltbG1JTU3HDDTfg73//e4/Hdzgc0GjcBQBBELBs2TK88MILyv9liSioWNojophx4403AgDeeecd+WsNDQ147733cPvtt3v8mW+//Rb79+/HT3/6U9x1113y7TtraWlBe3s7cnJyPN5H5yCKiKIL/3UTUcwwm8249tpr8frrr8tfe+edd6DRaHDDDTd4/JnXXnsNAHD77bfjxz/+MRISEuSvSTIyMjB06FC8+OKLePbZZ3H48GH0l+wXRRE2m63HfywSEEUWBlJEFFNuv/12fPfddzhw4AAA4PXXX8d1113nsT+qtbUVq1atwoUXXohRo0bBZDLhuuuuk3uqOvvHP/6B1NRUPPTQQyguLkZycjIWLVqEt956y2Nw9OKLL0Kv1/f47+2331bnL05EqmAgRUQxZdasWRgyZAhef/117Nu3D9u3b++1rPfuu++isbGxy/dvv/12iKKIN954o8ttp0yZguPHj+Ozzz7DY489hunTp+PLL7/ELbfcgquuuqpHMHX99ddj+/btPf5buHCh8n9pIlINT+0RUUwRBAG33XYb/vrXv8JisWD48OGYOXOmx9u+9tpriIuLw/z581FfXw8AGDduHAYNGoQVK1bgt7/9LbRarXx7vV6PefPmYd68eQCAmpoaXHvttfjkk0+wZs2aLkFSZmamx9N/RBRZmJEiophz6623orq6Gi+//DJuu+02j7c5evQovv76a1gsFhQUFCA1NVX+7/Tp0zh79iw+//zzPh8nPT0d999/PwBg//79Sv81iCgMMCNFRDFn4MCBeOSRR3D48GEsWbLE422khvJXXnkFQ4cO7fK9trY2XH311Xj99dexcOFCdHR0oLGxEenp6T3u59ChQwCA3Nxchf8WRBQOGEgRUUx6+umne/2ezWbDm2++ieLi4h6DNCWLFi3CRx99hKqqKgiCgEGDBuG6667D5Zdfjvz8fDQ3N2PDhg147rnnUFxcjMWLF3f5+YqKCmzbtq3H/ZrNZowaNSqwvxwRBQ0DKSKibj799FOcP38ev/71r3u9zd133433338fb731Fu6991789re/xZdffonHHnsMFRUVEAQBRUVFuP/++/GrX/0KCQkJXX7+X//6F/71r3/1uN+LLroIX3/9teJ/JyJSByebExEREfmJzeZEREREfmIgRUREROQnBlJEREREfmIgRUREROQnBlJEREREfmIgRUREROQnzpFSkcPhwLlz52AymSAIQqgvh4iIiLwgiiKampqQm5sLjabvnBMDKRWdO3cO+fn5ob4MIiIi8sOZM2eQl5fX520YSKnIZDIBcP4fYTabQ3w1RERE5I3Gxkbk5+fLv8f7wkBKRVI5z2w2M5AiIiKKMN605bDZnIiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAiihE2qz2UF8CEREFiIEUUQi8sukkxjz5ObYcrw71pRDFpFarDQuf24z//Pf+UF8KRTgGUkQh8M3JGtgdInaW1IX6Uohi0q7Sehwsb8S7O85AFMVQXw5FMAZSRCFQ1dQOAKhrtYb4Sohi0+maFgCApcOBqub2EF8NRTIGUkQhUO16425o7QjxlRDFptPVLfL/PlPbFsIroUjHQIooyBwOUQ6kmJEiCo3TNa3y/y6ra+3jlkR9YyBFFGQNbR3osDt7MuqYkSIKia4ZKQZS5D8GUkRB1rkfo6GNgRRRsDkcIko6BU8s7VEgGEgRBZnUaA6wtEcUCucbLbDaHPKfz7C0RwFgIEUUZJ0DqYa2DjgcPHpNFEydy3oAAykKDAMpoiCr7lTaE0Wg0cLyHlEwSY3mxTlmAMC5egtsdkdfP0LUKwZSREHWOSMFsOGcKNikGVLTitJg0Gpgd4gob7CE+KooUjGQIgqy7oFUPfukiIJKKu0VZSRiYGo8AJ7cI/8xkCIKsu5TlOuZkSIKKikjNSgjEXlSIMU+KfITAymiIJMyUlqNAIAn94iCyeEQUeLqkRqUnoD8tAQAHIFA/mMgRRRkUiA1KN35Bs6MlDI+3HUWaw+cD/VlUJg732hBu80BnUbAwJR4FEiBFDNS5CcGUhRValusKK0J3zdEm92BWlcGani2CQB7pJRwrKIJ96/ajaX/txPHK5tDfTkUxqSyXn5aAnRaDfJTpYxU+L5vUHhjIEVRo91mx+IXt+CKP2/E2frwTNPXtlghioBGcDa6Ajy1p4RP9pYDABwi8Jcvjob4aiicna52l/UAID9N6pEKz/cMCn8MpChqvLfzLE7XtKLd5sCmo1WhvhyPKl1lvfQkI9ISDQCAeq6JCdjqfeXy//5kbzkOlTeG8GoonJW4MlKF6c4PMlJGqqqpHZYOe8iuiyIXAymKCh12B17ccFz+89YTNSG8mt5JJ/Yyk4xITXAFUiztBeRYRROOVTZDrxUwa3gmAODP65iVIs9OdRp9AAApCXokGXUAgDL2SZEfGEhRVPhg11mU1bVBr3WehPvmRDVEMfxWr0iN5pkmI1IT9QB4ai9Qq/c5G8wvHpqB//hBMTQCsPZgBfaW1Yf2wigsSSf2Cl2lPUEQ5BEIpeyTIj8wkKKIZ7M78LevnNmo+y8fjji9BtXNVhwLw6bjzoFUcryUkVK/tLertA5T//AF/m9bieqPFWxSWW/h2BwMzTLhhxMGAgCeWcusFHXlcIgoqXXNkHKV9gBwBAIFhIEURbyP9pxDSU0r0hINuHXGIEwZlAYA2Hq8OsRX1lOXjFSCMyMVjEDqqyNVqGxqx5MfHcD+sw2qP16wHK9sxpGKJui1AuaOGgAA+OXlw6DVCNh4tAo7TteG+AopnFQ0WWDpcI4+kLJQAHhyjwLCQIoimt0h4gVXNurOmUVINOowY0gGgPDsk6r20CPV3G5Dh8oLU2tbnI9rc4h4YNXuqGmqlbJRFw3NQLIrMC1MT8R1k/IAMCtFXUkn9vJS46HTun/9FaRxujn5j4EURbRP95XjZFULkuP1uGX6IADAjCHpAIBtJ2tgd4RXn5SUkcowGWGO10NwtnSpnpWqbXH3YR2rbMafPjui6uMFS+eyXmf3zRkGg1aDb07WhGVmkkKj82qYzljao0AwkKKI5XCIeGH9MQDAHRcXySdvRueaYYrTodFiw4Fz4VXG6nxqT6sRYI6TynvqNpzXNDvvf/FEZ//Q61tOYUuEBxgnqppx+HwTdBoBc0dld/newJR43Dg1HwDwzLqjYXnwgIJPDqTSewmkmJEiPzCQooj1+YHzOFrRDJNRhyUzBslf12k1mFbkzEqFW3mvc48UAHeflMqzpKSTgYsvyMPNFxYAAB7+5x40RPAw0DWubNSMoRlIcZVJO1s2eyiMOg12ltRhQ5jOFaPgOl0tBVIJXb4u9Us1WWwR/W+CQoOBFEUkURTx1/XO3qjbLhqE5Hh9l+9L5b1wCqQsHXY0WWwA3IFUsisAqGtRNyMllfbSEg14bGExijISUd5gwX/8e7+qj6umT11jD64cO8Dj97PMcbhleiEA4Nm1zEpRp9EH3Up7CQYdMpKc/xaZlSJfMZCiiPTFoUocKm9EokGL2y8u6vH9GUOdgdT2U7Ww2tRt5PaWlI0y6DQwxznLkME4uedwiPIamvQkAxIMOvz5hgnQagR8tOcc/r37rGqPrZZT1S04VN4IrcZ9Ws+TpbOGIMGgxb6zDVh7sCKIV0jhxuEQ5dJeUbfSHgDk8eQe+YmBFEUcURTx1y+dvVG3zBjksawzPMuE9EQD2jrs2BMmgxk7n9gTXF3mKfFSaU+9jFRDW4fcdJ/iCtwm5KfgvsuGAgD+48P9KG+IrCZbqcl8xpB0pCb2/P9fkp5kxO0XOQPtZ9cehSPMDh9Q8FQ2tcPS4YBWI2Bgp9EHEqlPikM5yVcMpCjibDhahX1nGxCv1+JOD9koANBoBFwolfeOh0d5r/OJPYkUBKq5uLjGVdYzGXUw6rTy15fNHorx+SlotNjw8D/3RFSQIQVSV3Y7refJXTMHwxSnw5GKJnzSaScfxRZpNUx+ajz02p6/+vJTOQKB/MNAiiJK52zUzRcWID3J2Ott3X1S4XE6rfOJPUkw9u1JjeZpSV0zN3qtBn++fjzi9BpsOV6Dv39zWrVrUFJJTQsOnHOV9Ub3XtaTJCfocdfMwQCAv3xxFDaVZ3ZReOq+rLi7Ao5AID8xkKKIsuV4DXaV1sOo0+CuSwb3eVtpMOeu0nq0WUM/gLL7iT3AXWpTs0dKGn2Q5qEENjgzCY9fOQoA8PSawzhW0aTadSjlU1dWafrgdI9/J09uu2gQUhP0OFnVgg93n1Pz8ihMnarxfGJPwhEI5C8GUhQxRFHEc186J1XfOLUAWaa4Pm8/KD0BOclxsNod2FlSF4xL7FNfgZSai4ulE3vpvQQdN08rwKzhmWi3OXD/qt1h05zfm96GcPbFFKfHz2YNAQA89+VR1SfJU/gpcU017z6MUyKtiSmra4uoMjeFHgMpihjbTtZi++k6GLQaLHX9UuyLIAiYHkblPU+BlLu0p15GSloPk+qhKR9wPk//fe04pCToceBcoxyshqPSmlbsP+ss680bnd3/D3Ryy/RCZCQZcaa2Df/cUabSFVK46m0YpyQnJQ4aAbDaHHIZnsgbDKQoYjzvmmJ+/ZQ8DEjuOxslCae9e556pIJS2mvx3CPVWZY5Dst/NBYA8NKGE2G77Fcq6104OK3P/jhPEgw6LJvtDMCfX38savYNUv9EUZRnSPWWkdJrNchJdjWc8+Qe+YCBFEWEHadrsfVEDfRaAT+/dKjXPydlpPaW1aPREtqJxfL4A5M7oEmVT+2p2GzeT2lPsmBsDhZfMBAOEXjw3T1obrepdk3+WrPf97JeZzdOLUBOchzKGyx457tSJS+NwlhlUzvaOuzQagR5irkn+VxeTH5gIEURQZpifs0FeRiY0vsbYXcDU+IxKD0BDtE5nDNURFF0l/aS3Nk0KSPVbnOoliGRM1KJ/WdwnrxqNAamxKO0thVPfXJQlevx15naVuwta4BGAOZ5cVrPkzi9Fve65mf97asTYXEIgdQnjT7I62X0gSQ/lSf3yHcMpCjs7Sqtw6ajVdBqBNzjQzZKMj0MynvN7TZYOpwNzhmdMlJJRh10GudwTrWyUv01m3dmjtPjmevHQxCAldvPYF0YTQOXmsynFaUjw8eyXmfXTcpHflo8qpvb8WaEjHygwPQ3+kDCoZzkDwZSFPaed2WjfjhhIAp6Obrcl3DYuydlo5KMOiQYdPLXBUFwn9xrUaf0KAVSfU0A7+zCwem42zV36dfv7ZVLkqEmn9Yb519ZT2LQafDLOcMBAC9vPIGmEJd8SX2nXCf2ivp5/3DPkmIgRd5jIEVhbf/ZBqw/XAmNALlR2FdSn9Sh8kY5qAg2Tyf2JMkqrokRRVEu7XmTkZI8OHc4Rg4woabFil+/tzfkC3/P1LZij6usN9/Psl5nP5yQi8EZiahr7cAbW04HfoEU1rzPSDnbBsrqWNoj7zGQorAmTTG/anwuBmcm+XUfGUlGjBxgAgBsOxmarJSnE3sSNUcgtFrt8lwob4dXAoBRp8Wfb5gAg1aDLw5VhnxcwGf7zwMAphaleQxGfaXTanD/Fc6s1CubT6JBxVOTFHpSj1RRLyf2JFKPVHlDG2eNkdcYSFHYOlTeiLUHKyAIkBuE/SVlpbYcD808qeo+MlIpKp7ckzJwRp0GCQZtP7fuqjjHjF9ePgwA8Na2EsWvzRef+rBbz1s/GJuDEdkmNFlseGXzScXul8JL59EHhf2U9jJNRhh1GjhE4Fw9s1LkHQZSFLZecPVGLRybg6FZpoDuS5on9U2I+qSkjFSGh1lOas6S6lzWEwTB55//0cSBAIAD5xpCNg7hbH0bdp+phyAA88YEXtaTaDQCHnBlpV7fcirk4zFIHdLoA40A5KX2HUgJgns8Ak/ukbcYSFFYOlbRhNWumUH3BZiNApwlIY0AnKxuQXlD8N8g++qRSpUDKTUyUq6p5j6U9TrLTYlHXmo8HCLwfYjW7KxxZaOmDErrdy2Qr+aNzsawrCS0Wu34iDv4otJpefRBAgy6/n/lcede5Gi12lDRaAn1ZTCQiiXHK5swffmX+N3H4TUfyJMXvjoOUXT+ohs5wBzw/SXH6zF2YDKA0GSl+gqk3KU9FTJSfSws9tbUQWkAgO0hmnauRllPIggCbpiSDwBYtf2M4vdPoXdabjT37sSve5YUA6lwt+5gBab915f45cpdIb0OBlIxwuEQ8Zv396G8wYL/21YS1mWMM7Wt+HiPMztw32XDFLvfUM6TkpvNPQZS6pX2pL4rX07sdTelyBlIfReCgabn6tuwq9RZ1lugYFmvs8UX5EGvFbDvbAMOnGtQ5TEodE67+qP6azSXuKebs7QX7r44VAnAmTkPJQZSMeKfO89g+2lnacZqd+DLQ+EzaLG7t7aVwCECFw1NxxhXFkkJ0jypb07UBP04v6ep5hL3qT3lS3u+TDXvzRRXRmrXmXq024I7CXyN67TelMI0ZJmVLetJ0hINmOsaqfAus1JRRyrt9Tf6QFLAoZwRocPuwIYjzkDq8uKskF4LA6kYUNPcjuVrDgMABrnS25/uLQ/lJfWq1WrDStcOtNtmFCl635MHpUKvFXC2vi2ob5IOhyiX2PrMSLUpn5GqdT1ueh8Li/szJDMR6YkGWG0O7CsLbsZGHsI5Vp1slOSGyc7y3ge7znKZcZRxZ6S8K+1JDellDKTC2vZTtWiy2JCeaMCE/NSQXgsDqRjwh9WHUN/ageIcM/72kwsAAJuOVodlee/978+i0WJDYXoCLhup7KeMBIMOE13/4IJZ3qtv64DN4cyAeQpoUuLVy0jJU80T/A+kBEGQs1LfBbFPqryhDTtdDe7zxyjfH9XZxUMzMDAlHo0WGz4/cF7Vx6LgcY4+8C0jJTWb17RY0RKGi7vJSSrrzR6ZBa3G9xPJSmIgFeW2nqjG+9+fhSAA//WjMRiVY8bQrCRY7Q58EUZ71ADnm96KracBALdMHwSNCv84podgXYxU1ktN0HtcmJqa6O6RUrrk6C7t+R9IAe4+qWAufl6zzxnQTC5MxYBkdcp6Eo1GwHWT8wAAK79Tt7x3vsGCb0M0GDbWVDW1o9XqHH2Q38/oA0lyvB7mOOcaJ044D0+iKOILV3tKqMt6AAOpqNZus+P/fbAfAPCTaQWYWJAKQRCw0HX6SSqbhIvNx6pxvLIZiQat/EtNae4+qeqg9Un1dWIPcGeLbA5R8VlNcrN5AKU9wH1yb8fpOtgdwXne3GU9dbNRkusm50MQgG9O1shZDKXZ7A7c9Oo23PC/27A1RMNhY4lU1huYGu/V6ANJPnfuhbXjlc0orW2FQavBzGGZob4cBlLR7OUNJ3GyugUZSUY8Mm+k/PUfuJa+hlt5T8pGXTc5H+Y4vSqPMaEgBXF6DaqbrThW2azKY3RX1eycc9JbIBWn18LoepNX+uRerQLjDwCgOMeEJKMOTe02HD7fqMSl9el8gwU7XGW9BSr3R0kGpsTLb8rv7lAnK/Xv3edwssoZpP3D1QtI6pEazQd5WdaTyCMQOEsqLEllvelD0pFo1PVza/UxkIpSp6pb8LcNzsng//GDYnkxLgAMzzaFXXnvVHUL1h+uhCAAS2YMUu1xjDqt3O8TrIyA+8Re7yfnUlVYE9Nus6PJleEKZPwB4NxNd0Ghs78sGOW9z1zDWCcVpiInOXhHm3/smin1zx1lsCm8a81md+CFr47Lf157oEKVvjhyk2ZI+RxIpXG6eTgLp7IewEAqKomiiP/4cD+sNgdmDsvAVeNze9xGGm4YLqf3/u7KRs0ekeX1vBd/BbtPqr/SHqDOLKm6Fud9aTWCIhm+qYNcgdRp9Secr3b1RwWrrCe5vDgbaYkGVDa1Y+PRKkXv++O953CqugUpCXoMc32Q+TenqavK12GcEk43D181ze34vtT5HjSnODvEV+PEQCoKfbTnHL4+Xg2DToPfXz3G4461K13lvc3HqtGgwrF7XzRaOvBPVynlVhWzURJp7962kzVB6fep7mP0gUQKpJTMSNW0uJvclWjclzJ5356qVbW/rLLRgu0lzqyXWkM4e2PQabDYtV9wpYIzpewOEc+7dkfeNXMwfjKtAIB6JURyOl3t2zBOCXukwtdXR6ogisCoHHPIB3FKGEhFmYbWDvz+E+cKmPtmD8WgXt5Ahmeb5E/FoS7v/WtHGVqsdgzNSsLMYRmqP96YXDNMRh0aLTYcPKd+v4+UkcrworSnRkYq0P4oyfj8FBi0GlQ3t8tNvGpYs/88RBGYWJASkjdKaWXM+sOVqGxSZo/XJ3udvVHJ8XrcMr0QP5w4EAatBgfONWL/WU5TV4Moip0yUn72SNW2Bn14L/VNGiZ9+ajwyEYBDKSizh8/P4zqZiuGZCbi7lmD+7ytVDb5NISn9+wOEX//5jQAZzbKU/ZMaTqtBtMGu/qkTqjfJxWq0p6UkVIqkIrTazE+3zlpXs0+KTV363ljWLYJFxSkwO4Q8d7OswHfn90h4q9fHgMA3HlxEUxxeqQkGDB3tPMXwb92lgX8GNRTVXOn0QdpvgXkeanO27dY7arswCT/tNvs2OQquYdLfxTAQCqq7Cypwz++dZ4E+sOPxsKo0/Z5e3d5rypk5b2vDleipKYV5jgdFl8wMGiPG8y9e33t2ZOkqNBsLg3jTA9gPUx3ag/mrGyyyMuRF4QokAKAH09xl94CzUh8uq8cJ6paYI7TYclFg+SvX89p6qqSynq5KfH9vhd2F6fXIsv175XlvfCx7WQtWqx2ZJmMGJOr3PqwQDGQihIddgce/2AfAOCaC/Jw4eD0fn9meLYJw7OT0GEXsS5E5T1p5MGPpxYgwRC8Y6zSPKnvTtXCalP2dFZnHXaHHND0fWpPykgpH0hJAz+VoPYC489cZb0J+SkYGML+hyvH5SDRoMWp6paA/q4Oh4jnXdmoOy4e3KXp/6KhGchNjkNDW4d8ComUI5X1/D28wobz8COV9eYUZ6sysNlfDKSixBtbTuHw+SakJOjx+JXFXv9cKIdzHq1owtfHq6ERgFumFwb1sUdkm5CWaEBbhx17yupVexxpx55WI/S5pkVeE6NgZlCJhcXdTSpMhUZwLnStaFSmf6gz6RRpqMp6kkSjDotcp11XBdB0vnp/OY5VNsMUp8OtnbJRgPM1ce2kvIAfgzxzLyv27cSeJD+VIxDCiSiKcj9vOJX1AAZSUaGsrhV/Xuf81PvYgmKfemKkX1ihKO+9seU0AGDuqAHyotBg0WgE9xiE4+qV96qbpUZzQ5+foNyn9pRsNpdKe8r0SAGAOU6P4hwzAOWzUpWNFrlkGKwhnH2Rms5X7y/369+Go1Nv1O0XFXWZ5Sa5dpLzMb4+Xo2z9fyF3dJuU6y5u8R1IMLXGVKScMpI/fq9vVj0/NcxvfvvUHkTzjVYEKfX4KKh6h9K8gUDqQgniiKe/OgA2jrsmDoozefVKsNCVN6rb7Xig13OJtvbun1SD5YZ8jwp9RrOvTmxBwCprmCnQdHxB8pMNe9O6pParnCf1GcH3GW9YAfWnkzIT8Hw7CRYOhz4aI/v854+O3AeRyuaYTLqcPtFRR5vU5CegOmD0yGKwHsx3nS+9sB5TPjdWvz+k0OK3J+/wzglnU/uhVKb1Y53d5zBvrMN2BLDa4Wkst7FQzMRp/et501tDKQi3OcHKvDFoUrotQL+8CPPM6P6c+VYZwnj073BGw64cvsZWDocGJVjxlRX302wSfOkdpXWo82qTrOvNyf2ACAlXvmMVK0KGSkA8v9fSmekPnGV9aQVRqEmCAJucDWdr9ru2zqXztmo2y4ahOSE3vvUrp/i/PDzz51n4AjSHsNwU1bXiof/uQcddhHvfFca8M5JURTd62Ey/CztuTJSoV5cfKSiCdLLQukPL5Ek3KaZd8ZAKoI1t9vw5EcHAAB3XzIYw7JNft3PleOcZZSvj1ejIQhHfW12B950NZnfelFwRh54Mig9ATnJcbDaHdhZos60bvnEXj8ZKenUXqOlQ7Ehoe5mc3UyUkcqmhR7vVQ2hsdpve5+NHEg9FoB+8/6Nu9p7cHzOHy+CUlGHW6/2HM2SjJ/dA5MRh3O1LZh26ngTNsPJza7A79cuRuNFmfw1NZhx2f7zwd0n9XNVrRY7RAEd0DkK2lkwtm6tqAt6vbkwDn36+67IGwVCEeVjRbsKXM+D5eNZCBFCnp27VGcb7QgPy0e984e5vf9DM0yYUS2CR12EWsPBvYG5o21BytwrsGC9ESDx/U1wSIInfqkVCrveZ2RcmUsRBFoVKBXze4Q5ROASmekMk1GDM5IhCgCO0qU+YTceQhnKE/rdZeWaMDc0c4PGt5OIXc4RDz3pXOK+a0zBslBcm/iDVosmuD8d/DPHbFX3vvLF8ews6QOJqNO3nUYaJlTKuvlJvs++kCSkxwPnUaA1e5Q5WCFtzoPDT5wtgGt1tjrk1p/2LmkeHx+CrLMcSG+mp4YSEWo/WcbsGLrKQDA768eg3hDYDXjYJ7ee2OL87pvmlYQ8lr3DJXnSXkbSOm1GiS5tpgrMUuqoa1DLgconZEClJ8nFeohnH2Rfrl/6OW8p3WHKnCovBGJBi3u6CcbJZFmSq3eV45GS+wMgNxyvFperv70NeNw72VDAQDfnKxBWQBN3lJZL5C9nVqNIE/WD2Wf1MFydyBlc4jYVVofsmsJFbmsF4bZKICBVESyO0Q8/sE+OETnvJtLRwT+4pLKe5uPqVve23+2AdtP10GnEXDzhcEdeeCJlJHaW1avyi8wbwMpQNmTe7WuqebmOB30WuX/mSs5Typcy3qSi4ZkYGBKPBottn5LTqLo7o1aMmOQ10Hs+LxkDM9OQrvNgY/9aGyPRNXN7bh/1W6IInDj1AJcOS4HeakJuNC1deDDXf5Plfd3WXF3UnnvTIj6pOwOEYfLmwAAYwe6tgrEWJ+UpcOOr11N9uGypLg7BlIR6O1vS7CnrAEmow5P/GCUIvcplfdsDhGfq1jek0YeLBybg+wwSNEOTInHoPQEOER11p64xx94H0g1tAWekZLmV6V78bj+mOYKpPaVNQTcqB+uZT2JRiPIGaOV/TSdf3GoEgfONSLBoMWdM/te0dSZILgf490YKO85HCIeencPqpraMTw7Cf/Z6X3smguczffvfX/W71EI0i7IQDJSQOhP7p2qbkFbhx3xei2ud53IjrVAasvxalg6HBiYEo/iHP/6gNXGQCoCjc5NxohsEx6ZP0LRerG0Mkat8l5VU7v8aTtUIw88UXNdjC8ZKWlgp7RsOBByo3kfp8UCkZcajwHmOGep4UxgDbDhMoSzL9dOzoMgOFdUSGWj7kRRxHNfHgUA3DJ9kM9jJ344cSB0GgF7ztTjyPmmgK85nL369UlsPFqFOL0GL9x0QZfWhAVjcxCvd06V/97PMpZ7GGeAgVSIZ0lJjeYjc0yY5tpW8X1JPTrs6m1jCDdfyNPMs0J2MKk/DKQi0KTCVHzyi4vxk2nKlsakPqmvj1UruqpE8s53pbDaHZiQn4KJBamK37+/3POklA2k2qx2NLmOcXtX2lNu315tq/JTzTsTBEEu720/5X8gVdFowXZXw/rCMA6kBqbE45JhmQB6bzpff7gS+882Il6vxV0zveuN6iwjyYg5rqPd//SysT0S7T5Tjz99dgQA8MSi0Rje7bRxklGH+WOcrQbvf+97dk4URXkYZ5Gfow8k0vLishBNN5f6o0bnmjE0MwkpCXq0ddhxoFMDejRzOER8ecjZaB6uZT2AgVTE0ms10Cq8a2hoVhJGDnCW99YqPJzTanPgrW0lAMIrGwVA3kt4qLxRzuQoQSrrGXUamIz97xGUZkkpMWG+tlmdE3udTR3kDIa/O+1/ALpmXzlEEbigIEVu7A1XUtP5v3aWwdYtI+DMRjl7o346vdDvkqo0Tf2DXWdV3QEZKo2WDtz3zvewOURcOS5Hfk67k8p7H+855/NC5+pmK5rbbRAEBDzYtSDEGSnpxN6onGRoNAImF0ofXmKjvLf/XAMqm9qRaNDKvXPhiIEUdSGVV6Ryi1JW7ytHVVM7ss3GsMs8ZJqMGJaVBAD4XsF5UpWdynrepKRT5WZzBXqkpKnmSSoGUkWBlxpW73P244Xba8KTOcXZSE80oLKpHRuOVHX53oYjVdhb1oA4vQZ3+dAb1d0lwzKRZTKipsUqH/mOFqIo4jfv78OZ2jbkpcZj+eKxvf67mD4kHTnJcWi02OSMhLdKOo0+CPRUsFTaO99oQbtNnaG9vRFF0R1I5TrXMk2RP7zERiAl7da7ZHim32MsgoGBFHWx0NUnteW4cuU9URTlkQc3TytU5RRZoKQ3qiMVyvWm+NIfBXQu7SnXI6VmRmpYVhKS4/0vNURKWU9i0Gmw+IKBAJyT+SWiKOIvrmzUzdMKvf7/2xOdVoNrXIuMo628t2r7GXy6txw6jYDnb5wIc1zv/XtajYAfTXQ+176W904FONG8s/REA+L1WoiiczBnMFU2taOmxQqNAIwc4Cx/SuX0HadrY2IK/hcRUNYDGEhRN0MyO5X3DihT3tt1ph57yhpg0Glw07QCRe5TaSNcb1RKNvlWeznVXCKf2lMwkErtZxhkIDQaQf6E7E+pIZLKehKp9PbVkUpUuoY0bjxahT1n6mHUaXD3LP+zUZLrXIHUV0cqQzoIUklHK5rw5MfOLQwPzxvhVY/kYld5b8PRKvlDiTek/qhAG80BZy9gqEYgSI3mQzKT5MzamNxkxOk1qGvtwImq5qBeT7Cdq2/DwfJGaARg9ojMUF9OnxhIUQ9yeU+h03vSyIOrx+eqdhw/UCOylQ+k5IXFXmYoUpVsNg9CaQ9wD+b81o9ASh7COS500+19NTTLhEmFqbA7RPzr+7IuvVE/mVaILFPgp2gHZyZhyqBUOETg/e/9n6UULiwddtz7j+9h6XBg5rAM3O1l6XNoVhLG56fA7hDx793ePw/SDKkiBQIpIHQjEKSy3mhXthxwZkUn5sdGeU9aUnxBQWrY/t6QMJCiHpQs751vsGCN6xfmrWHWZN6ZlJE6UdWsWJOvt3v2JFJGqj5CSnuAe4HxjhLfSg0VjRbscPWjLRw7QJVrU8sN0ryn7Wew6Vg1dpU6s1FLFchGSa5zPcY/d5zxe5ZSuPj9JwdxtKIZGUlGPHv9BGh8OCRz7QVSec/3QCrQYZySUI1AONCtP0riLu9F9969SCnrAQykyAMly3tvbTsNm0PE1KI0jM5NVugKlTcwJR5JRh1sDlHusQiUvz1SgQavoii6M1IqB1JjBiYjXq9FfWsHjvtQapDKepMKU5GTHBllPcmV43KQaNDidE0rHvnnHgDOydyKznQbm4MEgxYnq1tUW6gdDKv3lePtb0shCMBfbpjgc//YD8blQq8VcLC8EYfK++/DE0URJdXKDOOUhGoEgnv0Qdf3zanSeqYoPrnX0m7DN65xNFeMCs+1MJ0xkCKPfuDKSn0SQHlv6/Fq/N825yTo28M4GwU4eyGGZztP7h0+r8yMFl8DKenUXovVHlBWrLndBqvrFF26SnOkJHqtBhMLUgD49sYulfUiocm8u0SjDle5lgxXNrXDoNPg55cOUfwxpH+Dq7ZHZtP5mdpW/Oq9vQCAn88agouHZfh8H6mJBswZ6cxIeLPIuKbFiibX6AMpkxSoUGSkmiwdcq9XcU7XjNTEghRoNQLO1rfhXH1o5lupbfOxKljtDhSmJ2BIZlKoL6dfDKTII+kX3Jbj1ajzcbZSQ1sHfv3eXtz06rdoaOvAyAEmXB4B6dkRA5xvWEcVOrnnayBlitNDOg1eH8CaGCkbFafXBLzM2htTfPyEfL4hcst6EmmdCwDcOCVflXVH0mN8uq8cza7BrpGiw+7AL1buQpPFhgsKUvDAFcP9vi/pFOOHu8/1mN/VnZKjDyTyLKkg9kgdcu3Xy0mO65FVTjTqMMZV7ovWdTFyWW9kdthOM++MgRR5NDgzCcU5ZtgdItb6sHvv8wPnccWzG+Xj4bdML8S/fj4DujAcedDdSAVP7omi6POpPa1GQHJ84H1S7v6o4DRoSnv3tp+u9aqfZ83+yC3rSSbkp2DGkHRkmoz4+aVDVXmMSYWpGJyRiFarHasVnuumtmfXHcWu0nqY4nR47scTAxp5Mmt4JtISDahubsfmY9V93vZUtXRiT5lsFODOSNW1dgQtoD3oOrE3ult/lGRyFJf37A4RX7lmqF0eAWU9gIGU15qamjBlyhRMmDABY8eOxSuvvBLqS1Ldla5swSdevIlXNbVj2dvf42dv7URlUzsGZyTi3Z9Nx++uHoMkL6Z6hwNpVYUSs6Sa2m1od5XnfOkLce/bCzwjpXZ/lGRiQSp0GgHlDRaUeXFEXNrlGM679fojCAL+745p2PrryzAgWZ3l24IgyE3nva2lCRdtVju2nazBC+uP4dY3vsNLG04AAP54zbiAS2wGnQZXjXeWUv/Vz0wpKSM1SKH+KMC5skYquwcrKyU3mud4DqSkLHA0ZqR2n6lDTYsVpjid/PcMd5HxGy4MJCQkYOPGjUhISEBrayvGjBmDxYsXIz09PdSXppqFY3Pw/609iq0nalDXYkWqh1/Moiji/e/P4nefHERDWwe0GgE/u2QwfjFnmGKp9WCRTu6dqW1Dc7stoABQKuuZjDqfngc5IxXAmpiaIAdS8QYtxgxMxu4z9dh+urbPX5znGyzY7jpttCBCy3oSjUaABuqWHa65YCD+v7VHsKOkDieqmsOmX6SqqR07S2qx/XQddpTU4cDZBti6ndq87aJBivXAXTspDyu2nsa6gxVoaOuQ/510Jw/jVDAjBTizUnWtDSitbe3Rs6QGqdF8VC8HdKT5bUcrmnt9b45UUlnv0hFZYTm82RMGUl7SarVISHD+47RYLLDb7RF/LLk/gzOTMCrHjIPljfj8wHn8eGrXYZplda147IP92HTUuS5jdK4Zf7xmHMYMDN/TeX1JSzQg02REVVM7jlY04YIAFiv72h8lSZVHIASekVJ79EFnU4vSsPtMPb47VSsPUvRkzX5nNmpyBJf1ginLHIdLh2fiy8OV+OeOMvx6wcigX4PDIeJEVTN2lNRhx+k67CiplRuhu1yryYgpg9IwqTDVdUpXuYBjdK4Zw7OTcLSiGZ/uLe91sK90XYMUmiElyU9NwN6yhqBkpKw2h9yn2dtzmJ5kxJDMRJyoasGOkjpcMSr8e1C9Jc2Purw4Msp6QBiU9l566SWMGzcOZrMZZrMZ06dPx5o1axR9jE2bNmHRokXIzc2FIAj48MMPPd7uxRdfRFFREeLi4jBp0iRs3ry5y/fr6+sxfvx45OXl4dFHH0VGhu+nUCLNleN6Dud0OESs2HIKc/+8CZuOVsGg0+BX80fiw2UXRWwQJZH6pI4G2Cfl6zBOSaoCa2LkqebBDKSkno1+Sg3SDsdIPK0XKlJ5773vey5LVtPJqmbc+fcduOCpdbjiz5vwm/f34b3vy1BS0wpBcA6x/cm0Avz5hvHY/OhsfPvYHPztJxfg9ouLMGZgsqJNwoIgyIuM3+ulvCeKIk5XK1/aA4A813Rzb0rXgTpe2YwOuwhTnE4eveDJ1E7rYqJFaU0rjlY0Q6sRcOlwBlJey8vLw9NPP40dO3Zgx44duOyyy3D11VfjwIEDHm+/ZcsWdHT0/CVz+PBhnD/vuSm6paUF48ePxwsvvNDrdaxatQr3338/Hn/8cezatQszZ87EggULUFpaKt8mJSUFe/bswalTp/CPf/wDFRXKrFAJZ9IvvK0nalDbYsXxyiZc9z/f4MmPD6LVasfUQWlY88uZ+PmlQyImDdsXacL5YYUCKV8zUskKDOUMdo8UAEx2lRpOVrXITfbddT2tx0DKW3OKs5CRZEBVUzs2Hq3q/wcU8tcvj+GLQxWob+1AnF6DaUVpuHf2ULxx2xTs/s+5+PyBS/CHH43FjybmIT8tQfXTVT+aOBAaAdhZUicHTJ3VukYfAO6TdkoJ5nRzuayXY+7zOZ3i5YeXSPKFKxs1ZVCq/F4YCUL+m2/RokVYuHAhhg8fjuHDh+MPf/gDkpKSsG3bth63dTgcWLZsGW666SbY7e5N3EePHsXs2bPx5ptvenyMBQsW4KmnnsLixYt7vY5nn30Wd9xxB+68804UFxfjL3/5C/Lz8/HSSy/1uG12djbGjRuHTZs2+fE3jixFGYkY5Tq998uVu7Dwua+xs6QOSUYdfv/DMVh594Vh07ehhOFSRirAhnNfp5pLUhUYyhmK0l5KgkEOQnv7hCw1mU8uTFWtQTsa6bUaeYFvsJrOrTYHvnT1qjx/40TsfWIeVv1sOh6eNwKzR2T12qOkpixzHGYOc+5c87TI+LQ8+iBO8f7MYM6SknbsdZ9o3p0USO0ra0Cb1d7nbSPFl4elsl5klSpDHkh1ZrfbsXLlSrS0tGD69Ok9vq/RaLB69Wrs2rULt9xyCxwOB06cOIHLLrsMV111FR599FG/HtdqtWLnzp2YO3dul6/PnTsXW7duBQBUVFSgsdH5SaGxsRGbNm3CiBEjPN7f3/72N4waNQpTpkzx63rCjVTe23ysGla7A7NHZGLtA5fgpxcW+rTuIRIoNQKhOuAeqchpNpdMKXJmpXrbu7c6godwhppU3vvyUGWvGT8lbT1RjaZ2GzJNRlw5NgcGXXj8qljsWhnz3vdne6wkOi2PPlC2rAd0niXVpnpvrHvHXt9tEnmp8chJjoPNIWLXmcidfi9ptHTg25PO9w4GUn7Yt28fkpKSYDQasXTpUnzwwQcYNWqUx9vm5uZi/fr12LJlC2666SZcdtllmDNnDl5++WW/H7+6uhp2ux3Z2V3/z8vOzpbLhWVlZbjkkkswfvx4XHzxxbj33nsxbtw4j/e3bNkyHDx4ENu3b/f7msLJ1RNyYXIdAX7uxxPw+q1TkJsSnY3Cw7JMEARnMOLLxvnu/M1IJSuwuLi2xfnY6SovLO6uryPZ5Q1tLOsFYHi2CePzU2BziPh4zznVH+9z12qouaOyw+rD0rzRA2Ay6nC2vq1HSUuN0QeS3JQ4CALQ1mGXP6ioQRTFLqW9vgiCIM+T2n4q8gOpjUeqYHOIGJKZqMr/h2oKi1N7I0aMwO7du1FfX4/33nsPS5YswcaNG3sNpgoKCvDmm29i1qxZGDx4MF577TVF6vPd70MURflrkyZNwu7duwN+jEiUl5qADY9cigSDLiiTskMp3qBFYVoCTte04mhFk88ZJUngp/YC6JFqdjWbJwQ3kJKaXw+ea0STpQOmOHf5Z80+5wcSlvX898MJudhzph6f7C3HbRcVqfY4doeIdQedgdS80eE1oiJOr8WV43KwcvsZvLezDBcOdo+fOSWf2FO2PwoAjDotBpjjUN5gwZnaVmT4+AHJW2V1bWiy2GDQajA0q/+WiamDUvHxnnNRMU9KPq0XgScQwyIjZTAYMHToUEyePBnLly/H+PHj8dxzz/V6+4qKCtx9991YtGgRWltb8cADDwT0+BkZGdBqtT2a1SsrK3tkqWJVepIx6oMoiTRPKpCGc/8DKVePlJ8rYiwddrS4+iWCNdlckpMcj/y0eDhE4PvS+i7fk059SmVi8t2VY3MguJqtz6q4Y+370jpUN7fDHKfrEqiEC2m8xup95Wi1uieNq5mRAjo1nKt4ck/qjxqWneRVOXWK68PL96V1QT3RqTSb3YGvjjgPUkRaWQ8Ik0CqO1EU0d7uuaxSXV2NOXPmoLi4GO+//z7Wr1+Pd999Fw8//LDfj2cwGDBp0iSsW7euy9fXrVuHGTNm+H2/FJmkpukjfi4vtjtEOf3v86k9VxNvXWuHX70YUklQpxFgjg9+wtm9d69G/lp5Qxt2usp6C8YwkPJXljlOXsfz6V71ynuf73d+oJxTnB02vVGdTRmUioK0BLRY7VjrKkGKothpGKc6gZQ0AkHNk3sH+5lo3t3wLBOS4/VotdrlaeiRaEdJHRraOpCaoA9ofl+ohPxfyWOPPYbNmzfj9OnT2LdvHx5//HFs2LABP/nJT3rc1uFwYP78+SgsLMSqVaug0+lQXFyML774AitWrMCf//xnj4/R3NyM3bt3y6W5U6dOYffu3V1GGzz44IN49dVX8frrr+PQoUN44IEHUFpaiqVLl6ry96bwJS0vPlLR7NfP17VaYXeIEATfG76l2U9WmwNtHb6fxKlpds+QCsWyz6keejZWu8p6UwaxrBeoH4xzrkr5eI86u/dEUcRnB5z/f80bHZ6ZAUEQOjWdO0/v1bV2oMnizE4puWevs2CMQJD6o7wdZqrRCJhc6Aw8Irm8t/mYMxs1e0QWtGHUk+etkPdIVVRU4Kc//SnKy8uRnJyMcePG4bPPPsMVV1zR47YajQbLly/HzJkzYTC4f0GNHTsWX3zxRa/rWnbs2IHZs2fLf37wwQcBAEuWLMGKFSsAADfccANqamrwu9/9DuXl5RgzZgxWr16NwsJCBf+2FAmk0t6xiiY4HKLPzbbSqaq0BIPPs7USDVroNAJsDhH1rR1IMPj2TzQUow86k/qkdpfVo91mh1Gn5Wk9BS0YMwBPfHQA+8424HR1i+JlrIPljSira0OcXoNLhmcqet9KWjwxD3/54hi+Pl6N8w0WudSZo8LoA0kwRiDIO/b6ObHX2ZSiNHx5uBLbT9fizpmD1bo0VZ2rtwBwj5+JNCEPpF577TWfbu8pwAKACRMm9Pozl156qVdlknvuuQf33HOPT9dD0WdQegIMOg1arXaU1bWhwMdPuPJUcz8aUgVBQEqCc9N9XavV59ORoRjG2VlRRiIykgyobrZib1kDBqbEY2dJHQSBZT0lpCcZMWNIOjYfq8Yne8/h3suGKXr/0mm9S4Zl+hzEB1NBegKmDkrDd6dr8cGus8g2O/+tqZWNAoD8VKm0p06PVG2LFeUNzoCiOMf7gEIqp+84XdflgFQkqfbzlHO4CHlpjyjc6LQaDHUNGT3sR5+Uv43mkkBO7oViPUxngiB06pOqxZr9PK2ntEXjneW9T/YqX96T+qPmjwmv03qeXDPJXd6TJp0XqXhsXvpAda6+DXaH8rOkpP6owvSELide+zN2YDKMOg1qWqw4UdVz4nskCPQ9M9QYSBF5EMhgzkDfFFIUCKRCVdoD0CWQkpqir2RZTzHzRg2AXivg8PkmHAtwAn9np6pbcKSiCTqNgDkjw7M/qrOFY3Ng1GlwvLIZn7jKx2oM45Rkm+Jg0Gpgc4gob1A+K3Ww3DXR3MtGc4lBp8GE/BQAkdsnxUCKKApJtfojfvyiCjyQ8n8oZ6immncm9Ul9e6oG35fWO8t6DKQUk5ygxyxX/9LHCmalPnc1mU8fkh4Re85McXp5ztXJKnVP7AHOxu6BKpb33BPNfQukAPe/ue29bBUIZx12B2pb/TvlHC4YSBF5MCKQjFSA9X53ac/3QEqeah7CQKo4xwyTUQdLh3OuzZTCNGSbWdZTknR675M95xRbWSIFUnPDbAhnX66ZlNflz4My1OuRApxrWQB1Gs7djea+B1KRvMC4tsUKUQQ0QvCHCCuFgRSRB9IsqVPVLWi3+TaGQKmMVCClvbQgD+PsTKsRcEGhexbMwrGR84s5Ulw+KhtGnQYnq1vkI/OBON9gwS7XENW5ETRZ+uKhGcjq9O+sME3d1SLSyb0yhUcgWDrsOFHlHLfS3449Ty4oTIVGcE5GV6PsqCbp/TI9yRiRow8ABlJEHuUkx8EUp4PNIcplA29JJ1D8XSMh9UjVBdRsHtrSjFRqYFlPHUlGHS4bmQVAmZlS6w46s1EXFKREVPZQqxHwo4nOpvMB5jjVty9Is6RKFQ6kDp9vgkN0ZpKz/PgAlmTUyQHYdxFW3gs0gx8OGEgReSAIgt8N54Gf2nNmpBr8WBPjbjYP7ZvS5cXZ0GsFXF6cHVG/mCOJXN7bG3h5Txp7EG679bxx84WFyDYbsWi8+gF7vjTdXOE1MQc7lfX8HV/Q19LwcBbpjeZAGMyRIgpXw7NN2H66zqeGc6vNIWeS/C7txfuXkbI7RNS3OX8mlM3mgLPHbMuvLoM5PvybliPVZSOzkGDQoqyuDbvP1GOin6s16lut+Oakc6VPJAZS+WkJ+Paxy4PzWCpNN5d27PnTHyWZWpSK17ecwo7Tdf3fOIwEMncvXDAjRdQLfzJSNa5mb51GkAMiX/l7aq+u1dm0Cbgb1kMpy6zelGkC4g1aecFrIDOlvjxUCbtDxMgBJtUW/kYLqUeqsqkdFj9WOPVG6nPzdfRBZ5MKnRmpIxVNaPCjLSBU5GGcEZyRYiBF1At5554PgVTnT1e+rpaRSP1Nvr4ZSmW9lAQ9dD6upqHIJA3n/HRvORx+Dol079aLvGxUsKUm6JFkdBZyyhQq79kdIg6XO99j/Gk0l2SajBickQhRBHaURE55LxpKe3y3JeqFdHLvbH0bmizeBTVKvCmkxLtO7bV1+NT7Ip/Yi9AjxOS7S4ZnwBSnw/lGC3aU+F7SabXasOmoc2EsA6n+CYKg+AiEU9UtaOuwI16vDXgyeySOQWAgRRTFkhP0GOBqlD7qZZ+U+8Se/8GMdGrP7hDR6Npo741Q79mj4DPqtHIA9PGecz7//MYjVWi3OZCfFu/TfrdYpvQIBKmsNzLHFPDx/ykROJiTp/aIopw84fx8s1e3V+LTVZxeizi985+mL+W9cJhqTsH3g3HO02pr9pfDZnf49LPSEM75owdE5LLbUJAbzhUq7cmN5gH0R0mmujJS+842KNrDpSb3e2bkvm8xkCLqg7vh3Luhh0qlqVP9aDivbXaNPgggG0aR56KhGUhN0KO62YptJ73PRFhtDnx5uBIAy3q+kEcgKJWRCmCieXf5afHINhvRYRflAavhzNJhR5Mr656ZFLljUhhIEfVB6pM67GXDuVJpan9O7knrYZiRii16rQbzxzizUp/s9b68983JGjRZbMg0GXGBn6MTYpGSQzlFUey0Y8//RnOJIAgRNU9KaoUwaDUwx0fuNCYGUkR9kHbuHa1o8qrx252RCuzTlTQ6oaHN+9JerasMGKn7qsh/0jDKNfvPw2rzrrwnlfWuGJXt9wnTWCT1SJXWtKLDx1Jqd5VN7ahpsUIjuD+0BUpeYBwBgVTnDH4kl5YZSBH1YWhWEjSCczim9I++L4qV9lwjEOpafM9IsbQXe6YVpSPTZERDWwe2HK/u9/Z2h4i1rmnm81nW80lRRiIykgxoardh5XelAd2XlI0akpmk2Hqbya55Ut+X1PncMxds7nExkf2exUCKqA9xeq08pNCbCefVrj6lQAMpd2nPh2bz5tAvLKbQ0GoELBzj/em9XaV1qG5uhylOhwsHp6t9eVHFoNPgl3OGAQD+8sUxr0ejeKLERPPuRgwwwRSnQ4vVjkPlvq23Cjal3i9DjYEUUT+klHt/gzlbrTY0tzsbJwP9hOVXaU/esxfZn+7IP9JwzrUHK/o9sSWV9eaMzIJBx18Dvvrx1AIMzkxETYsVL2884ff9SKMPRisYSGk1AiYXOnvewn2eVDTMkAIYSBH1S+qT6q/hvLrJGcjE6TXy9GN/+XpqTxRF+bZsNo9NFxSkIic5Ds3tNmw4UtXr7URRlKeZzx/Dsp4/9FoNfj1/JADg1c2nUN7g3yiEA9KJvZzAG807i5R5UlXNFgCRPUMKYCBF1C8pI9XfUE75TUGBxklpKGe9l6W9pnYbOuzOZngGUrFJoxHkmVJ9nd47VN6EM7VtMOo0uGR4ZrAuL+pcMSobUwelod3mwDNrj/r8802WDpTUOE/+KVnaA9zzpLafrvVpO0KwMSNFFCM6n9yz97HPTH5TUODTldQjVe9lRkqaIZVg0HJRcAz7wThnee/LQ5VotXqeii9lo2YNz0SCIXKPnIeaIAh47MpiAMB735fJjePekvqXcpLjFP/wMzYvGQadBjUtVpysblH0vpXUeTdpJGMgRdSPwvREGHUaWDocfc6OUfLTVaorI+VtszmnmhMAjMtLRkFaAto67PjyUKXH26zlkmLFTMhPwQ/G5UAUgeVrDvn0swcVnGjenVGnxYT8FADhXd5jszlRjNBqBAzLTgLQd8O5koGUzxkpNpoTnFkSqbzn6fTe6eoWHD7fBK1GwJzirGBfXlR6dN5I6LUCNh+rxsajvfemdadGo3lnU8N8gbEoiiztEcWSEdnON7s+AynXpysl0tRSj1SjxebVLBhONSeJdHpvw9EqNHY7mi+d1ps+OF0O1ikwBekJWDJ9EABg+epDfZb/Ozug4GoYTyYPcp7cC9fBnC1WO9pcp0tZ2iOKASMH9N9wrmhGyjX+APBuBEJti2uqOQOpmDdygAlDMhNhtTmwzjV0U/K5XNbLDsWlRa17LxsKc5wOh8834b3vy/q9vdXmwLEK5yJ0pU/sSSYVpkIjAGdq23C+waLKYwRCer9MMGiRGOAp51BjIEXkheHyCITeG0qV2rMHADqtBibXm0u9V4GUa6o5A6mYJwiCnJXqfHqvotGC712LbOeyP0pRKQkG3HeZc0jnM2uPoM3a9xyv45XNsNodMBl18hJkpZni9Bia5WxJ6O/EcShIe/YivawHMJAi8oqUkTpd09rrsMNqhev9KYnSCIT++6TczeaR/6ZEgZNO720+Vi2vGVp70JmdmliQgmxzYLsgqadbZhQiLzUeFY3teHXzyT5vK/VHFeeaVd0xJ5X6fRnsGyxKnnIONQZSRF7IMhmRHK+H3SHiRFVzj++r0TgpD+Vs8SYjxWZzchualYSRA0ywOUS5nPf5ftcQTmajVGHUafHIvBEAgJc3nuhzN6c0KkGtRnOJOc73DQnBEi2N5gADKSKvCIIgz5Py1HDe2GaD1dUUrlTjZLKrT8q70h7HH1BXUnnv473n0NDagW0nawBw7IGaFo3Lxbi8ZLRY7Xjuy96HdB5QcfRBZ9J7SPdDB+EgWmZIAQykiLwmlfc8LS+W+qNMcTrFBmKm+jACQQqk2GxOkkWu8t43J2qwakcpbA4RI7JN8hJuUp5GI+Cxhc4hne98dwbHKz1nr92jD9RpNJck+7GzM1iYkSKKQcP7WF6sxptCqg9rYljao+4K0hMwPi8ZDhF4dp0zOzKPu/VUd+HgdFxenA27Q8QfPzvc4/tldW1ostig1wpyM7hazFJGKgwDKTabE8WgkX2U9pQ8sSdJ9nJxsaXDjlbXKaG0JAZS5CY1nVs6nGVnjj0Ijl8vGAmtRsC6gxX41lVSlUjzo4ZlmWDQqfsrWC7ttXleFxRKarxnhgoDKSIvSSMQyhssPVLlocxISSf29FpBHplABABXuqacA0B+WrzqPTnkNDQrCT+ekg8A+K/Vh+DoNKRTWg2jdqM5wNJesDCQIvKSOU6P3GTnsfHuc1nUCaRcPVJtfWekpIXFaYkGVY9SU+TJTYnH5ELnhOt5owbw9RFE918+HIkGLfaUNeCTfeXy16X+KLUmmndmjnd+sAq3QEoURbm0l8FAiii2jJAHc6ofSCVLi4v7GX9Q6yr9pXLlB3nw5FWjcf3kPCy9dEioLyWmZJqM+Nks53P+p88Oo93mLL+7Rx+o22gOhO+pvYa2DnTYnVm6jChoR2AgReQDqbx3tFsgVa1Cvd/bU3vyVPMoeEMi5Y0ZmIw/XTs+Ko6ZR5o7ZxYh22xEWV0b3vqmBHUtVpxzrWsZmWNS/fHDtbQnffBMjtfDqFPmlHMoMZAi8kFvDefyTBQFM1IpXs6RqmnmVHOicJRg0OGhK5xDOv/65TFsPeFsPC9IS5CHZapJeozGto4ufVqhFk39UQADKSKfjMh29jUcqWiCKLrfmNQ4gSJlpFqtdrks4AlHHxCFr2sm5WHkABMaLTY88dF+AMFpNAfc4w8cItBiDZ+Te9L7ZTSU9QAGUkQ+GZKVCK1GQENbByoanW8GdoeIGtcbQ5aCn7BMcTpoXL3BfZ3c41RzovCl1Qj49YKRAIBqV/Y4WKcn4/RaecRCOJX33Bmp6Nj5yECKyAdGnRZFrsnQh887m0ZrW6xwiIAgKBvMaDSCe02MF4EUp5oThadZwzNx8dAM+c+jBwZvDEU49klF0wwpgIEUkc+kk3vSCATp01V6ogE6rbL/pFK9GMrJ0h5ReBMEAb9ZOBKC4PzAFYwTe5JwHMoZbT1SnN5H5KMR2SZ8inJ5BIK73q/8m0KKPJSz/0CKpT2i8DU6Nxkv3zwJVpsD2ebglbTMceE3S4qBFFGM656RqlbxTSFFHoHQ+5tgDTNSRBFh3ujg7zpMDsN9e/IpZzabE8WmEa7lxccqmmF3iKrW+6WMVF0vgVSH3SF/0mRGioi6C8ehnFLTfbRkpBhIEfmoIC0B8Xot2m0OnK5pUTVN3d+aGClTJQju7BURkcQcZs3mdocoDxFmIEUUozQaAcOzkwA4J5yrGUjJQzl7WRMj9UelxOuh1XCPGhF1FW6lvZqWdjhEQCMA6VEyRJiBFJEfhme7d+6pGkgl9n1qr8b1yY5lPSLyJNzGH0jvl2mJhqj58MdAisgPIzqtilGzRyo1oe81Me7RB9HxyY6IlCWtiQmXQErqj4qm3Y88tUfkh5EDnAP1jlY0odaVLVJyz54kJb7vxcUcfUBEfTHLzebhMUcq2kYfAAykiPwyfICzR+p0TQukXaChOLXHqeZE1JdwLe1FUyDF0h6RHzKTjEhLNMhBlF7rXueiJCmQamjt6LIkWcKp5kTUF3N8eA3kZCBFRACcKx+kk3uAs96vUaFxUhp/YLU70Gq19/h+DUt7RNSHcDu1F2179gAGUkR+k/qkAPU+XSUYtDC49vd5OrlX62rcTI+SCcFEpCwpkGq3OWDp6PlhLNjU3AQRKgykiPwkndwD1Pt0JQgCkuV9ez0/UUrBFTNSRORJokEHKVkeDlkpZqSISCbNkgLU/XSV2kcgJZX2UjnVnIg80GiETif3wiCQYkaKiCSdM1JqzkSRVr90L+2Jooi6Fpb2iKhv4TJLqt1ml68hmuZIMZAi8lOSUYe81HgA6n66ktfEdHsTbGyzweY6NsjSHhH1JlxGINS4ejrVOuUcKgykiAJw4eB0AMCoXHM/t/SfvLi4pWtGSloPk2TUwajTqvb4RBTZ3Cf3QjuUUyrrqXXKOVQUHcgpiiKqqqqQlZWl5N0Sha0//GgMls0eiqKMRNUeIyXRc0aKjeZE5I1wmSUVjf1RgI8ZqYSEBFRVVcl/nj9/PsrLy+U/V1ZWIicnR7mrIwpzRp1W1SAKcK+J6d4jJaXJOdWciPoSLqW9aDyxB/gYSFksli7Tlbds2YK2trYut/E0fZmI/NfbqT1ONScib5jDZChn59JeNFG8R0oQoqfuSRQOpFN73RcXc6o5EXkjXE7tVTeztEdEIZDCjBQRBSBsSnvskXJmmzpnnLr/mYiUl9rLHKk6ZqSIyAvJYTKQM1oDKZ9O7YmiiOHDh8vBU3NzMyZOnAiNRiN/n4iUJWWkGto64HCI8rFhlvaIyBtmOSMV4vEHzdHZI+VTIPXGG2+odR1E1AspkHKIQJPFJu/eq2UgRUReSA6TZvNoXFgM+BhILVmyRK3rIKJeGHVaJBi0aLXaUddqZSBFRD4Jh0Cqpd2GFqsdQIwHUp5YLBasWrUKLS0tuOKKKzBs2DAlrouIOkmJ16PVau8ylFOabJ6eGF1vSkSkLHOc81d9U7sNdocIbQimiksn9uL1WiQaomsTg0/N5o888gh++ctfyn+2Wq2YPn067rrrLjz22GOYOHEivvnmG8UvkijWdV9c3Ga1w9LhAACkcWExEfXB3GmvXaiyUp0bzaPtkJpPgdSaNWswZ84c+c9vv/02SkpKcOzYMdTV1eG6667DU089pfhFEsW6VNeamAbXCAQpG2XQaaLu0x0RKUuvdb9PhOrknnsYZ/R98PMpkCotLcWoUaPkP69duxbXXnstCgsLIQgCfvnLX2LXrl2KXyRRrOu+Jkbuj0owRN2nOyJSnjnEs6SidRgn4GMgpdFouow42LZtGy688EL5zykpKairq1Pu6ogIgPvkXp2ckWKjORF5z91wHpoRCNE6QwrwMZAaOXIkPv74YwDAgQMHUFpaitmzZ8vfLykpQXZ2trJXSETyUM4GKSPlWlicHoVpciJSXqjXxLgXFseF5PHV5NOpvUceeQQ33ngjPv30Uxw4cAALFy5EUVGR/P3Vq1dj6tSpil8kUazrnpGSSnzMSBGRN0Jd2pN7pEzR957lU0bqmmuuwerVqzFu3Dg88MADWLVqVZfvJyQkYNmyZYpeIBH1PLXH0h4R+SLUa2KqXFn0zCibag74MUfq8ssvx+WXX+7xe0888QR2794d6DURUTcp3T5NSqW9tAQGUkTUP3O889d9yJrN2SPVt4aGBrz44ouYNGkSJk2apMRdElEn0viDHhkp9kgRkReSQ1jaE0WRzea9Wb9+PW6++Wbk5OTg+eefx4IFC7Bjxw6lro2IXKTSXn2LKyMlTzVnIEVE/QvlmpjGNhusducA4WhbWAz4UdorKyvDihUr8Prrr6OlpQXXX389Ojo68N5773WZMUVEypFKe03tNnTYHXLTeRrXwxCRF0J5aq+q2QIAMMXpEKePvgHCPmWkFi5ciFGjRuHgwYN4/vnnce7cOTz//PNqXRsRuSR3WvHQ0NaBGtdRYjabE5E3QpmRqmpyNZpHYVkP8DEjtXbtWvziF7/Az3/+cy4nJgoinVYDc5wOjRYbqpra0WhxDtVjIEVE3khOkE7tBX8gp3uGVHQGUj5lpDZv3oympiZMnjwZ06ZNwwsvvICqqiq1ro2IOpH6pE5VtwAANIK75EdE1JeQlvaiuNEc8DGQmj59Ol555RWUl5fjZz/7GVauXImBAwfC4XBg3bp1aGpqUus6iWJequsT5cmqZtefDdBouGePiPrX+dRe51VvweBeWMxASpaQkIDbb78dX3/9Nfbt24eHHnoITz/9NLKysnDVVVcpfY1EBHdG6mSVMyPFsh4ReUsKpOwOEa1We1AfO5oXFgMKzJEaMWIE/vSnP6GsrAwrV67kJnoilUhrYk5UM5AiIt/E6TXQa52/n4Nd3ov20p5Pzea33357v7dJT0/3+2KIqHfS4uKTlc7SHgMpIvKWIAhIjtejutmKhrYO5KbEB+2xGUh1smLFChQWFmLixIm91liZkSJSh5SRamrniT0i8p3ZFUgFewRCtJ/a8ymQWrp0KVauXImTJ0/i9ttvx80334y0tDS1ro2IOul+Qo9TzYnIF6E4uWd3iPLcu2jNSPnUI/Xiiy+ivLwcv/rVr/Dxxx8jPz8f119/PT7//POgnwIgijWp3QInZqSIyBeh2LdX12qFQwQEIXrfs3xuNjcajbjxxhuxbt06HDx4EKNHj8Y999yDwsJCNDc3q3GNRISu080BIC1K0+REpA55unkQh3JK/VFpCQbotQGfbwtLAf2tBEGAIAgQRREOh0OpayIiD6Rmc0laQnR+uiMidZjjnd08wcxIRXujOeBHINXe3o533nkHV1xxBUaMGIF9+/bhhRdeQGlpKZKSktS4RiKCh0AqStPkRKSOUOzbi/ZhnICPzeb33HMPVq5ciYKCAtx2221YuXIlxx0QBYm0K0uSnsRAioi8JzWbBzOQivZhnICPgdTLL7+MgoICFBUVYePGjdi4caPH273//vuKXBwRuZnjdNBqBNgdzoMd3TNURER9CUWzeSyU9nwKpG655RbOiSIKEUEQkBKvR02LFaY4HQy66GzcJCJ1hCSQivIZUoAfAzmJKHSSE5yBFPujiMhXZvnUXgh6pEzR+57Fj7REEUQq5zGQIiJfhbS0lxQXtMcMNgZSRBEk1dVwzqnmROQr96m94M2RioVmcwZSRBEkOZ4ZKSLyj3Rqr63DDqtN/dmPVpsDda3O7BcDKSIKCwNTnRvb81ITQnwlRBRpTHE6SOfFglHeq2lxZqN0GqHHrtBo4lOzORGF1h0XFSEvJR7zxw4I9aUQUYTRaASYjDo0WmxotHSoniWS+qPSkwzQaKL3xD8DKaIIkpygx/VT8kN9GUQUoczxejRabEHJSMVCfxTA0h4REVHMCObJPfeJPQZSREREFAWCuW8vFqaaAwykiIiIYkYw9+3FwsJigIEUERFRzAhmaa+62QqAGSkiIiKKEskJ0poY9YdysrRHREREUcUc5zys39AahNJeDCwsBhhIERERxYyQnNpjRoqIiIiigVk6tWdRN5Bqs9rR3O4sH2YwkCIiIqJoYA5SRkoaxmnUaWAyRvfsbwZSREREMSJYpb3KTmU9QYje9TAAAykiIqKYEaw5UrHSHwUwkCIiIooZUkaqqd0Gh0NU7XGkE3vRPowTYCBFREQUM8zxzn4lUQSaVJwlVc2MFBEREUUbo06LOL3zV7+aJ/diZYYUwECKiIgopgSj4Zw9UkRERBSVGEgpi4EUERFRDAnGyT0pkGKzOREREUUVtTNSoijKAzmzmJEiIiKiaKJ2INXUbkO7zQGAGSkiIiKKMmrv25PKeiajDvEGrSqPEU4YSBEREcUQtfftyf1RMVDWAxhIERERxRR3aU+dgZzVMTRDCmAgRUREFFPMcc7p5mqd2oul0QcAAykiIqKYonazOQMpIiIiilrBajZnIEVERERRR8pIqVbaa5aGcRpUuf9ww0CKiIgohnQu7YmiqPj9y83mzEgRERFRtJFKex12EZYOh+L3L5f2kuIUv+9wxECKiIgohiQatNBqBADKN5w7HCKqm60AmJEiIiKiKCQIgmon9+parbA7nOXCdPZIUWdNTU2YMmUKJkyYgLFjx+KVV14J9SURERH5RZ4lpfDJPSkblZqgh14bGyGGLtQXECkSEhKwceNGJCQkoLW1FWPGjMHixYuRnp4e6ksjIiLyiZyRalU2kIq10QcAM1Je02q1SEhIAABYLBbY7XZVTjsQERGpTa19e1XNFgAMpIJq+fLlmDJlCkwmE7KysvDDH/4QR44cUfQxNm3ahEWLFiE3NxeCIODDDz/0eLsXX3wRRUVFiIuLw6RJk7B58+Yu36+vr8f48eORl5eHRx99FBkZGYpeJxERUTCoNZRTXlgcI3v2gDAIpDZu3Ihly5Zh27ZtWLduHWw2G+bOnYuWlhaPt9+yZQs6Onr+H3/48GGcP3/e48+0tLRg/PjxeOGFF3q9jlWrVuH+++/H448/jl27dmHmzJlYsGABSktL5dukpKRgz549OHXqFP7xj3+goqLCx78tERFR6KnVbO4efcBAKmg+++wz3HrrrRg9ejTGjx+PN954A6Wlpdi5c2eP2zocDixbtgw33XQT7Ha7/PWjR49i9uzZePPNNz0+xoIFC/DUU09h8eLFvV7Hs88+izvuuAN33nkniouL8Ze//AX5+fl46aWXetw2Ozsb48aNw6ZNm/z4GxMREYWWWoFUrI0+AMIgkOquoaEBAJCWltbjexqNBqtXr8auXbtwyy23wOFw4MSJE7jssstw1VVX4dFHH/XrMa1WK3bu3Im5c+d2+frcuXOxdetWAEBFRQUaGxsBAI2Njdi0aRNGjBjh8f7+9re/YdSoUZgyZYpf10NERKQmc5y0Jsam6P3GYrN5WJ3aE0URDz74IC6++GKMGTPG421yc3Oxfv16XHLJJbjpppvwzTffYM6cOXj55Zf9ftzq6mrY7XZkZ2d3+Xp2drZcLiwrK8Mdd9wBURQhiiLuvfdejBs3zuP9LVu2DMuWLUNjYyOSk5P9vi4iIiI1qF7aYyAVGvfeey/27t2Lr7/+us/bFRQU4M0338SsWbMwePBgvPbaaxAEIeDH734foijKX5s0aRJ2794d8GMQERGFmlqLi90Li2MnkAqb0t59992Hjz76CF999RXy8vL6vG1FRQXuvvtuLFq0CK2trXjggQcCeuyMjAxotdoezeqVlZU9slRERESRzhyv/EDODrsDda3skQo6qUz2/vvvY/369SgqKurz9tXV1ZgzZw6Ki4vln3n33Xfx8MMP+30NBoMBkyZNwrp167p8fd26dZgxY4bf90tERBSO1Cjt1bZYIYqAViMgNSE21sMAYVDaW7ZsGf7xj3/g3//+N0wmk5wVSk5ORnx8fJfbOhwOzJ8/H4WFhVi1ahV0Oh2Ki4vxxRdfYPbs2Rg4cKDH7FRzczOOHz8u//nUqVPYvXs30tLSUFBQAAB48MEH8dOf/hSTJ0/G9OnT8b//+78oLS3F0qVLVfzbExERBZ8agZTUH5WeaJCXIseCkAdS0niBSy+9tMvX33jjDdx6661dvqbRaLB8+XLMnDkTBoM72h07diy++OKLXte17NixA7Nnz5b//OCDDwIAlixZghUrVgAAbrjhBtTU1OB3v/sdysvLMWbMGKxevRqFhYUB/g2JiIjCi3Rqr9VqR4fdochevFgcxgmEQSDl65qVK664wuPXJ0yY0OvPXHrppV49zj333IN77rnHp+shIiKKNKY496//xrYOpCsQ/MTiiT0gDHqkiIiIKLh0Wg2SjM5gSqnynnRij4EUERERRT15BIJFmaGczEgRERFRzDAr3HB+vsECAMhiIEVERETRzhynbGnvVHULAGBQRqIi9xcpGEgRERHFICWnm9sdIk7VOAOpIRlJAd9fJGEgRUREFIOUnCV1rr4NVpsDBq0GA1Pj+/+BKMJAioiIKAaZ5WbzwAOpk66yXmF6QkwN4wQYSBEREcUkJUt7J6uaAQBFMdYfBTCQIiIiiklKlvakRvPBmbHVHwUwkCIiIopJ5njnqb3GtsDnSJ2scgVSzEgRERFRLFAnI8VAioiIiGKAUoFUm9WOs/VtAFjaIyIiohhhjlPm1N5p1/yo5Hg9UhP0AV9XpGEgRUREFIM6n9pzOES/70fuj8pMhCDE1ugDgIEUERFRTJLmSDlEoNnqf8N5LI8+ABhIERERxaQ4vRYGnTMMCGSWlNRoPiQG+6MABlJEREQxS4mG8xOuQIoZKSIiIoop5jjnLCl/AylRFHHKVdqLxdEHAAMpIiKimOVuOPevR6qmxYpGiw2CAAxKZyBFREREMSTQfXtSf1Rucjzi9FrFriuSMJAiIiKKUeYAe6ROxnhZD2AgRUREFLPkjJSfQzlPVsfujj0JAykiIqIYFeipPfcwztgcfQAwkCIiIopZ0poYfwOpUzE++gBgIEVERBSzAmk2t9kdKKlxr4eJVQykiIiIYlQgzeZldW3osIsw6jTITY5X+tIiBgMpIiKiGGWO938gZ+eynkYTe8uKJQykiIiIYpT71J7vAzlPcPQBAAZSREREMSuQU3tsNHdiIEVERBSjpB4pq80BS4fdp5+VRx9kxO7oA4CBFBERUcxKMuggtTf5enJPzkixtEdERESxSKMR/Dq519Juw/lGC4DYnmoOMJAiIiKKaf4M5ZSyUWmJBqQkGFS5rkjBQIqIiCiG+bNvjzv23BhIERERxTB/Tu6d5OgDGQMpIiKiGCYN5Wxs836WlHv0QWyf2AMYSBEREcU0/zJS3LEnYSBFREQUw3xtNhdFUc5IsUeKgRQREVFMk8YfeDtHqqqpHc3tNmgEoCA9Qc1LiwgMpIiIiGKYr6U96cReXmoCjDqtatcVKRhIERERxTBfB3KyP6orBlJEREQxzD1HyrtTe6eqnaMPYn1ZsYSBFBERUQxL9rFHyp2R4ugDgIEUERFRTDPHOedI+dojNYQZKQAMpIiIiGKalJFqbrfBZnf0edsOuwOlta0AgCL2SAFgIEVERBTTpGZzAGjqp0+qtLYVdoeIeL0WA8xxal9aRGAgRUREFMP0Wg0SDM4xBv2V905VSathEiEIgurXFgkYSBEREcU498m9vgOpk9VcVtwdAykiIqIY5+1QTq6G6YmBFBERUYzzdt/eCY4+6IGBFBERUYxz79vru9lczkixtCdjIEVERBTjvCntNVk6UNXUDoBTzTtjIEVERBTjzPH9D+WUJppnmowwxel7vV2sYSBFREQU47w5tSeV9ZiN6oqBFBERUYzzptn8ZJVz9MEQ9kd1wUCKiIgoxnmzuPgkM1IeMZAiIiKKcV4FUtLogwyOPuiMgRQREVGMM/dzak8URY4+6AUDKSIiohjX3/iD840WtHXYodMIyE9LCOalhT0GUkRERDHOfWrPBlEUe3xfWlZckJYAvZahQ2d8NoiIiGKcNEfK7hDRYrX3+P4JNpr3ioEUERFRjIvXa6HXCgA8N5xLow/YH9UTAykiIqIYJwhCn31S7mGcPLHXHQMpIiIi6nMopzz6gBmpHhhIERERkTwCoXtpr91mR1ldKwBgMHukemAgRURERL2W9kprWuEQgSSjDpkmYyguLawxkCIiIqJeh3Ke7DSIUxCEoF9XuGMgRUREREh2jUBotNi6fF3qj+LoA88YSBEREVGv+/ZOVbtGH/DEnkcMpIiIiKjXU3tyRoon9jxiIEVERES9ZqTkHimW9jxiIEVEREQem83rW62obbECYI9UbxhIERERkcfxB1I2aoA5DolGXUiuK9wxkCIiIiJ3ac/iDqROcaJ5vxhIERERkcdm85OuE3ss6/WOgRQRERHJGSlLhwPtNjsA97LiwZkcfdAbBlJEREQEU5wO0uDyxjbnUE55WTEzUr1iIEVERETQaAQkuRrKG9o64HCInTJSDKR6w0CKiIiIAHQ9uXeuoQ3tNgf0WgEDU+JDfGXhi4EUERERAeh6ck/KRhWmJ0KnZbjQGw6FICIiIgDuk3uNbR2ob3We3uOJvb4xxCQiIiIAXUt7J6tcy4rZH9UnBlJEREQEoOu+PWmq+ZAMjj7oCwMpIiIiAgCY492n9qTRB0XMSPWJgRQREREBcGekKpvaca6hDQBnSPWHgRQREREBcAdSe8saIIqAOU6HtERDiK8qvDGQIiIiIgCA2RVIdV4NI0jjzskjBlJEREQEwB1ISVjW6x8DKSIiIgLgLu1JOPqgfwykiIiICIB7IKdkcCZHH/SHgRQREREB6JmR4lTz/jGQIiIiIgDuOVISBlL9YyBFREREAACjTos4vTM0GJgSjzi9NsRXFP4YSBEREZFMKu+x0dw7DKSIiIhIJjWcs6znHQZSREREJJMzUgykvKLr/yZEREQUKxaNz0VVczvmFGeH+lIigiCKohjqi4hWjY2NSE5ORkNDA8xmc6gvh4iIiLzgy+9vlvaIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPDKSIiIiI/MRAioiIiMhPulBfQDQTRREA0NjYGOIrISIiIm9Jv7el3+N9YSCloqamJgBAfn5+iK+EiIiIfNXU1ITk5OQ+byOI3oRb5BeHw4Fz587BZDJBEARF77uxsRH5+fk4c+YMzGazovcdyfi89I7PjWd8Xjzj89I7PjeeRdPzIooimpqakJubC42m7y4oZqRUpNFokJeXp+pjmM3miH/BqoHPS+/43HjG58UzPi+943PjWbQ8L/1loiRsNiciIiLyEwMpIiIiIj8xkIpQRqMRTzzxBIxGY6gvJazweekdnxvP+Lx4xueld3xuPIvV54XN5kRERER+YkaKiIiIyE8MpIiIiIj8xECKiIiIyE8MpIiIiIj8xEAqAr344osoKipCXFwcJk2ahM2bN4f6kkLuySefhCAIXf4bMGBAqC8r6DZt2oRFixYhNzcXgiDgww8/7PJ9URTx5JNPIjc3F/Hx8bj00ktx4MCB0FxskPX33Nx66609XkMXXnhhaC42iJYvX44pU6bAZDIhKysLP/zhD3HkyJEut4nF1403z0usvmZeeukljBs3Th68OX36dKxZs0b+fqy9XhhIRZhVq1bh/vvvx+OPP45du3Zh5syZWLBgAUpLS0N9aSE3evRolJeXy//t27cv1JcUdC0tLRg/fjxeeOEFj9//05/+hGeffRYvvPACtm/fjgEDBuCKK66Q90JGs/6eGwCYP39+l9fQ6tWrg3iFobFx40YsW7YM27Ztw7p162Cz2TB37ly0tLTIt4nF1403zwsQm6+ZvLw8PP3009ixYwd27NiByy67DFdffbUcLMXc60WkiDJ16lRx6dKlXb42cuRI8de//nWIrig8PPHEE+L48eNDfRlhBYD4wQcfyH92OBzigAEDxKefflr+msViEZOTk8WXX345BFcYOt2fG1EUxSVLlohXX311SK4nnFRWVooAxI0bN4qiyNeNpPvzIop8zXSWmpoqvvrqqzH5emFGKoJYrVbs3LkTc+fO7fL1uXPnYuvWrSG6qvBx7Ngx5ObmoqioCD/+8Y9x8uTJUF9SWDl16hTOnz/f5fVjNBoxa9Ysvn5cNmzYgKysLAwfPhx33XUXKisrQ31JQdfQ0AAASEtLA8DXjaT78yKJ9deM3W7HypUr0dLSgunTp8fk64WBVASprq6G3W5HdnZ2l69nZ2fj/PnzIbqq8DBt2jS8+eab+Pzzz/HKK6/g/PnzmDFjBmpqakJ9aWFDeo3w9ePZggUL8Pbbb2P9+vV45plnsH37dlx22WVob28P9aUFjSiKePDBB3HxxRdjzJgxAPi6ATw/L0Bsv2b27duHpKQkGI1GLF26FB988AFGjRoVk68XXagvgHwnCEKXP4ui2ONrsWbBggXy/x47diymT5+OIUOG4O9//zsefPDBEF5Z+OHrx7MbbrhB/t9jxozB5MmTUVhYiE8//RSLFy8O4ZUFz7333ou9e/fi66+/7vG9WH7d9Pa8xPJrZsSIEdi9ezfq6+vx3nvvYcmSJdi4caP8/Vh6vTAjFUEyMjKg1Wp7RPWVlZU9ov9Yl5iYiLFjx+LYsWOhvpSwIZ1i5OvHOzk5OSgsLIyZ19B9992Hjz76CF999RXy8vLkr8f666a358WTWHrNGAwGDB06FJMnT8by5csxfvx4PPfcczH5emEgFUEMBgMmTZqEdevWdfn6unXrMGPGjBBdVXhqb2/HoUOHkJOTE+pLCRtFRUUYMGBAl9eP1WrFxo0b+frxoKamBmfOnIn615Aoirj33nvx/vvvY/369SgqKury/Vh93fT3vHgSK68ZT0RRRHt7e2y+XkLW5k5+WblypajX68XXXntNPHjwoHj//feLiYmJ4unTp0N9aSH10EMPiRs2bBBPnjwpbtu2TfzBD34gmkymmHtempqaxF27dom7du0SAYjPPvusuGvXLrGkpEQURVF8+umnxeTkZPH9998X9+3bJ954441iTk6O2NjYGOIrV19fz01TU5P40EMPiVu3bhVPnTolfvXVV+L06dPFgQMHRv1z8/Of/1xMTk4WN2zYIJaXl8v/tba2yreJxddNf89LLL9mfvOb34ibNm0ST506Je7du1d87LHHRI1GI65du1YUxdh7vTCQikB/+9vfxMLCQtFgMIgXXHBBl+O4seqGG24Qc3JyRL1eL+bm5oqLFy8WDxw4EOrLCrqvvvpKBNDjvyVLloii6DzK/sQTT4gDBgwQjUajeMkll4j79u0L7UUHSV/PTWtrqzh37lwxMzNT1Ov1YkFBgbhkyRKxtLQ01JetOk/PCQDxjTfekG8Ti6+b/p6XWH7N3H777fLvoMzMTHHOnDlyECWKsfd6EURRFIOX/yIiIiKKHuyRIiIiIvITAykiIiIiPzGQIiIiIvITAykiIiIiPzGQIiIiIvITAykiIiIiPzGQIiIiIvITAykiiiqiKOLuu+9GWloaBEHA7t27Q31JRBTFOJCTiKLKmjVrcPXVV2PDhg0YPHgwMjIyoNPpArrPW2+9FfX19fjwww+VuUgiihqBvbsQEYWZEydOICcnJywXpNrtdgiCAI2GxQCiaMF/zUQUNW699Vbcd999KC0thSAIGDRoEERRxJ/+9CcMHjwY8fHxGD9+PP71r3/JP2O323HHHXegqKgI8fHxGDFiBJ577jn5+08++ST+/ve/49///jcEQYAgCNiwYQM2bNgAQRBQX18v33b37t0QBAGnT58GAKxYsQIpKSn45JNPMGrUKBiNRpSUlMBqteLRRx/FwIEDkZiYiGnTpmHDhg3y/ZSUlGDRokVITU1FYmIiRo8ejdWrV6v99BGRH5iRIqKo8dxzz2HIkCH43//9X2zfvh1arRb/7//9P7z//vt46aWXMGzYMGzatAk333wzMjMzMWvWLDgcDuTl5eHdd99FRkYGtm7dirvvvhs5OTm4/vrr8fDDD+PQoUNobGzEG2+8AQBIS0vD1q1bvbqm1tZWLF++HK+++irS09ORlZWF2267DadPn8bKlSuRm5uLDz74APPnz8e+ffswbNgwLFu2DFarFZs2bUJiYiIOHjyIpKQkNZ86IvITAykiihrJyckwmUzQarUYMGAAWlpa8Oyzz2L9+vWYPn06AGDw4MH4+uuv8T//8z+YNWsW9Ho9fvvb38r3UVRUhK1bt+Ldd9/F9ddfj6SkJMTHx6O9vR0DBgzw+Zo6Ojrw4osvYvz48QCcpcd33nkHZWVlyM3NBQA8/PDD+Oyzz/DGG2/gv/7rv1BaWoprrrkGY8eOla+ZiMITAykiiloHDx6ExWLBFVdc0eXrVqsVEydOlP/88ssv49VXX0VJSQna2tpgtVoxYcIERa7BYDBg3Lhx8p+///57iKKI4cOHd7lde3s70tPTAQC/+MUv8POf/xxr167F5ZdfjmuuuabLfRBR+GAgRURRy+FwAAA+/fRTDBw4sMv3jEYjAODdd9/FAw88gGeeeQbTp0+HyWTCf//3f+Pbb7/t876lhvHOB587Ojp63C4+Ph6CIHS5Jq1Wi507d0Kr1Xa5rVS+u/POOzFv3jx8+umnWLt2LZYvX45nnnkG9913n7d/dSIKEgZSRBS1pAbv0tJSzJo1y+NtNm/ejBkzZuCee+6Rv3bixIkutzEYDLDb7V2+lpmZCQAoLy9HamoqAHg1s2rixImw2+2orKzEzJkze71dfn4+li5diqVLl+I3v/kNXnnlFQZSRGGIgRQRRS2TyYSHH34YDzzwABwOBy6++GI0NjZi69atSEpKwpIlSzB06FC8+eab+Pzzz1FUVIS33noL27dvR1FRkXw/gwYNwueff44jR44gPT0dycnJGDp0KPLz8/Hkk0/iqaeewrFjx/DMM8/0e03Dhw/HT37yE9xyyy145plnMHHiRFRXV2P9+vUYO3YsFi5ciPvvvx8LFizA8OHDUVdXh/Xr16O4uFjNp4qI/MTxB0QU1X7/+9/jP//zP7F8+XIUFxdj3rx5+Pjjj+VAaenSpVi8eDFuuOEGTJs2DTU1NV2yUwBw1113YcSIEZg8eTIyMzOxZcsW6PV6vPPOOzh8+DDGjx+PP/7xj3jqqae8uqY33ngDt9xyCx566CGMGDECV111Fb799lvk5+cDcI5kWLZsGYqLizF//nyMGDECL774orJPDBEpgpPNiYiIiPzEjBQRERGRnxhIEREREfmJgRQRERGRnxhIEREREfmJgRQRERGRnxhIEREREfmJgRQRERGRnxhIEREREfmJgRQRERGRnxhIEREREfmJgRQRERGRnxhIEREREfnp/wePMTGIeb/w/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"50% best MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_mape = mape(y_true, y_pred)\n",
    "plt.plot(cur_mape[cur_mape < np.percentile(cur_mape, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"50% best MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mape[cur_mape <= np.percentile(cur_mape,100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 67), dtype=float32, numpy=\n",
       "array([[ 8.25200696e-04, -2.52360152e-03,  1.24429585e-03,\n",
       "         5.61252143e-03,  2.41480279e-03,  6.91283401e-03,\n",
       "        -1.55929942e-04,  5.05245430e-03, -3.45375156e-03,\n",
       "         2.31756223e-03, -5.02947718e-03,  5.21133933e-03,\n",
       "         2.63487943e-03, -1.15680450e-03, -8.61713605e-04,\n",
       "        -4.27721906e-03,  1.65054473e-04,  1.98029215e-03,\n",
       "         1.16372411e-03, -6.18001819e-03,  1.38662616e-03,\n",
       "        -3.87507980e-03, -5.78831602e-03, -4.70064487e-03,\n",
       "        -4.91938740e-03, -9.45061352e-03, -6.37044199e-03,\n",
       "        -1.24200690e-03, -2.50279880e-03,  6.26629405e-03,\n",
       "         7.07075465e-03,  4.37504100e-03,  8.11321661e-06,\n",
       "         6.27311785e-03, -2.45433138e-03,  6.55709300e-04,\n",
       "         1.01655931e-03,  3.92863574e-03, -7.48858880e-03,\n",
       "        -3.09383660e-03, -3.60715576e-03,  3.58439516e-04,\n",
       "         5.01208124e-04,  4.94992966e-03,  4.09077760e-03,\n",
       "        -1.00721011e-03, -6.26226794e-03, -6.27841754e-03,\n",
       "         5.10353828e-03,  4.80458234e-03, -2.42970185e-03,\n",
       "         3.23574082e-03,  4.15166654e-03,  1.97961787e-03,\n",
       "         2.42814887e-03, -2.23055086e-03, -2.55294633e-03,\n",
       "        -3.07056517e-03, -7.46782962e-03,  4.13405150e-03,\n",
       "         4.82963771e-03,  6.89104025e-04, -1.09297456e-04,\n",
       "         3.91600234e-03, -8.97214864e-04, -1.08612701e-03,\n",
       "         4.65779193e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.zeros(67 * 10).reshape(1, 10, 67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=2, 2, 22, (30608, 67)\n",
      "Before prediction: train_X.shape=(18358, 10, 67), train_y.shape=(18358, 67), test_X.shape=(6119, 10, 67), test_y.shape=(6119, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3112 - val_loss: 0.3270\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2915 - val_loss: 0.3111\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2761 - val_loss: 0.2987\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2646 - val_loss: 0.2898\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2564 - val_loss: 0.2830\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2504 - val_loss: 0.2777\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2456 - val_loss: 0.2732\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2415 - val_loss: 0.2694\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2378 - val_loss: 0.2660\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2345 - val_loss: 0.2630\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2314 - val_loss: 0.2603\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2286 - val_loss: 0.2579\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2262 - val_loss: 0.2559\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2241 - val_loss: 0.2541\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2222 - val_loss: 0.2526\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2206 - val_loss: 0.2513\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2191 - val_loss: 0.2500\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2179 - val_loss: 0.2489\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2167 - val_loss: 0.2478\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2156 - val_loss: 0.2470\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2147 - val_loss: 0.2461\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2138 - val_loss: 0.2453\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2129 - val_loss: 0.2444\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2122 - val_loss: 0.2439\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2115 - val_loss: 0.2432\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2109 - val_loss: 0.2427\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2103 - val_loss: 0.2421\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2097 - val_loss: 0.2416\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2092 - val_loss: 0.2410\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2087 - val_loss: 0.2407\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2082 - val_loss: 0.2401\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2397\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2073 - val_loss: 0.2394\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2069 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2065 - val_loss: 0.2386\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2062 - val_loss: 0.2382\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2058 - val_loss: 0.2380\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2055 - val_loss: 0.2376\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2052 - val_loss: 0.2373\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2049 - val_loss: 0.2370\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6119, 67), test_y.shape=(6119, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1578.0531622950014, my average MASE = 2807.2183134542065\n",
      "Cluster 0, 1578.0531622950014\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4317 - val_loss: 1.2280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4299 - val_loss: 1.2276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4282 - val_loss: 1.2273\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4264 - val_loss: 1.2269\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4247 - val_loss: 1.2266\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 1.2263\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 1.2259\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4198 - val_loss: 1.2256\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4182 - val_loss: 1.2253\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4166 - val_loss: 1.2251\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4151 - val_loss: 1.2248\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4135 - val_loss: 1.2245\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4120 - val_loss: 1.2242\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4105 - val_loss: 1.2239\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4089 - val_loss: 1.2236\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4074 - val_loss: 1.2233\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4060 - val_loss: 1.2229\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4045 - val_loss: 1.2226\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 1.2223\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4017 - val_loss: 1.2220\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4004 - val_loss: 1.2216\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3990 - val_loss: 1.2213\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3977 - val_loss: 1.2210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3964 - val_loss: 1.2207\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3951 - val_loss: 1.2204\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3938 - val_loss: 1.2201\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3926 - val_loss: 1.2198\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3914 - val_loss: 1.2195\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3901 - val_loss: 1.2192\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3889 - val_loss: 1.2189\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3877 - val_loss: 1.2186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3866 - val_loss: 1.2184\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 1.2181\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3842 - val_loss: 1.2178\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3831 - val_loss: 1.2175\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 1.2173\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3809 - val_loss: 1.2170\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3798 - val_loss: 1.2167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3787 - val_loss: 1.2165\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3776 - val_loss: 1.2162\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 708619678.5307182, my average MASE = 1911068024.4320867\n",
      "Cluster 1, 708619678.5307182\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=5, 5, 1026, (269, 67)\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5683 - val_loss: 0.4789\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5669 - val_loss: 0.4779\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5656 - val_loss: 0.4770\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5643 - val_loss: 0.4760\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5631 - val_loss: 0.4751\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5619 - val_loss: 0.4743\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5607 - val_loss: 0.4734\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5595 - val_loss: 0.4726\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5584 - val_loss: 0.4718\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5573 - val_loss: 0.4710\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5562 - val_loss: 0.4702\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5552 - val_loss: 0.4694\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5542 - val_loss: 0.4687\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5532 - val_loss: 0.4679\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5522 - val_loss: 0.4672\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5512 - val_loss: 0.4665\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5502 - val_loss: 0.4658\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5493 - val_loss: 0.4651\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5483 - val_loss: 0.4644\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5474 - val_loss: 0.4637\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5465 - val_loss: 0.4630\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5456 - val_loss: 0.4624\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5447 - val_loss: 0.4617\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5438 - val_loss: 0.4611\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5429 - val_loss: 0.4605\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5421 - val_loss: 0.4598\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5412 - val_loss: 0.4592\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5404 - val_loss: 0.4586\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5396 - val_loss: 0.4579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5388 - val_loss: 0.4573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5379 - val_loss: 0.4567\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5371 - val_loss: 0.4561\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5363 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5355 - val_loss: 0.4549\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5348 - val_loss: 0.4543\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5340 - val_loss: 0.4538\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5332 - val_loss: 0.4532\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5324 - val_loss: 0.4526\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5317 - val_loss: 0.4521\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5309 - val_loss: 0.4515\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.40868807431647, my average MASE = 112470179.11258063\n",
      "Cluster 0, 139.40868807431647\n",
      "Before prediction: train_X.shape=(31, 10, 67), train_y.shape=(31, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3364 - val_loss: 0.3469\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3360 - val_loss: 0.3468\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3355 - val_loss: 0.3468\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3350 - val_loss: 0.3467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3346 - val_loss: 0.3466\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3341 - val_loss: 0.3465\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3337 - val_loss: 0.3464\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3332 - val_loss: 0.3463\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3328 - val_loss: 0.3463\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3323 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3319 - val_loss: 0.3461\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3315 - val_loss: 0.3460\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3310 - val_loss: 0.3459\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3306 - val_loss: 0.3458\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3302 - val_loss: 0.3457\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3298 - val_loss: 0.3457\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3294 - val_loss: 0.3456\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3290 - val_loss: 0.3455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3286 - val_loss: 0.3454\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3282 - val_loss: 0.3453\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3278 - val_loss: 0.3453\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3274 - val_loss: 0.3452\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3270 - val_loss: 0.3451\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3267 - val_loss: 0.3450\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3263 - val_loss: 0.3450\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3259 - val_loss: 0.3449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3255 - val_loss: 0.3448\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3252 - val_loss: 0.3448\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3248 - val_loss: 0.3447\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3245 - val_loss: 0.3446\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3242 - val_loss: 0.3445\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3238 - val_loss: 0.3445\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3235 - val_loss: 0.3444\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3231 - val_loss: 0.3443\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3228 - val_loss: 0.3443\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3225 - val_loss: 0.3442\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3222 - val_loss: 0.3441\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3440\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3216 - val_loss: 0.3440\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3213 - val_loss: 0.3439\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3523641.3982873675, my average MASE = 66808534.66599488\n",
      "Cluster 1, 3523641.3982873675\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1130 - val_loss: 0.1021\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1076 - val_loss: 0.1000\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1032 - val_loss: 0.0984\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0995 - val_loss: 0.0974\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0964 - val_loss: 0.0968\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0912 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0889 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0869 - val_loss: 0.0951\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0834 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0804 - val_loss: 0.0940\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0791 - val_loss: 0.0938\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0936\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0934\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0757 - val_loss: 0.0933\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0748 - val_loss: 0.0931\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0739 - val_loss: 0.0930\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0730 - val_loss: 0.0929\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0722 - val_loss: 0.0927\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0926\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0707 - val_loss: 0.0925\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0701 - val_loss: 0.0924\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0694 - val_loss: 0.0923\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0922\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0922\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0677 - val_loss: 0.0922\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0672 - val_loss: 0.0921\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0921\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0663 - val_loss: 0.0920\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0919\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0656 - val_loss: 0.0919\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0918\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0918\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0646 - val_loss: 0.0917\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0638 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0635 - val_loss: 0.0915\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 869790828.2820631, my average MASE = 17262168691.962505\n",
      "Cluster 2, 869790828.2820631\n",
      "Before prediction: train_X.shape=(2219, 10, 67), train_y.shape=(2219, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5462 - val_loss: 0.4045\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5391 - val_loss: 0.4010\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5333 - val_loss: 0.3979\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5281 - val_loss: 0.3951\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5234 - val_loss: 0.3925\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5190 - val_loss: 0.3900\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5147 - val_loss: 0.3877\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5107 - val_loss: 0.3856\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5068 - val_loss: 0.3835\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5031 - val_loss: 0.3816\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4996 - val_loss: 0.3797\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4961 - val_loss: 0.3780\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4928 - val_loss: 0.3763\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4896 - val_loss: 0.3747\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4865 - val_loss: 0.3732\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4835 - val_loss: 0.3717\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4806 - val_loss: 0.3704\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4778 - val_loss: 0.3691\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4750 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4723 - val_loss: 0.3666\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4697 - val_loss: 0.3655\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4672 - val_loss: 0.3644\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4647 - val_loss: 0.3633\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4623 - val_loss: 0.3624\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4600 - val_loss: 0.3614\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4577 - val_loss: 0.3605\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4556 - val_loss: 0.3596\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4535 - val_loss: 0.3588\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4515 - val_loss: 0.3580\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4495 - val_loss: 0.3572\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4476 - val_loss: 0.3564\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4458 - val_loss: 0.3557\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4440 - val_loss: 0.3551\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4423 - val_loss: 0.3544\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4406 - val_loss: 0.3538\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4390 - val_loss: 0.3532\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4374 - val_loss: 0.3525\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4359 - val_loss: 0.3519\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4343 - val_loss: 0.3514\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4329 - val_loss: 0.3508\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 408.78828000932964, my average MASE = 1218.6998180420371\n",
      "Cluster 3, 408.78828000932964\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5668 - val_loss: 0.4468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5648 - val_loss: 0.4459\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5628 - val_loss: 0.4451\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5609 - val_loss: 0.4443\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5589 - val_loss: 0.4435\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5570 - val_loss: 0.4427\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5551 - val_loss: 0.4419\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5533 - val_loss: 0.4412\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5514 - val_loss: 0.4404\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5496 - val_loss: 0.4397\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5478 - val_loss: 0.4389\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5460 - val_loss: 0.4382\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5442 - val_loss: 0.4374\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5425 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5408 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5391 - val_loss: 0.4352\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5374 - val_loss: 0.4344\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5358 - val_loss: 0.4337\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5342 - val_loss: 0.4329\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.4322\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5310 - val_loss: 0.4315\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5295 - val_loss: 0.4308\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5280 - val_loss: 0.4300\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5264 - val_loss: 0.4293\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5250 - val_loss: 0.4286\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5235 - val_loss: 0.4279\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5221 - val_loss: 0.4273\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5207 - val_loss: 0.4266\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5193 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5179 - val_loss: 0.4254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5165 - val_loss: 0.4248\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5151 - val_loss: 0.4241\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5138 - val_loss: 0.4235\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5125 - val_loss: 0.4229\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5112 - val_loss: 0.4223\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5099 - val_loss: 0.4217\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5086 - val_loss: 0.4212\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5073 - val_loss: 0.4206\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5061 - val_loss: 0.4200\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5048 - val_loss: 0.4194\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2631402082.882854, my average MASE = 5288471031.0194235\n",
      "Cluster 4, 2631402082.882854\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=7, 7, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1149 - val_loss: 0.1029\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1092 - val_loss: 0.1008\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1047 - val_loss: 0.0992\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1009 - val_loss: 0.0980\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0972\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0947 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0922 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0899 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0878 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0859 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0842 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0826 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0812 - val_loss: 0.0939\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0799 - val_loss: 0.0936\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0934\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0775 - val_loss: 0.0931\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0929\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0755 - val_loss: 0.0928\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0746 - val_loss: 0.0926\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0737 - val_loss: 0.0924\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0923\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0922\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0921\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0708 - val_loss: 0.0920\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0919\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0696 - val_loss: 0.0918\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0690 - val_loss: 0.0917\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0685 - val_loss: 0.0916\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0680 - val_loss: 0.0916\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0675 - val_loss: 0.0915\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0670 - val_loss: 0.0915\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0666 - val_loss: 0.0915\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0662 - val_loss: 0.0914\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0658 - val_loss: 0.0914\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0654 - val_loss: 0.0913\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0651 - val_loss: 0.0913\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0648 - val_loss: 0.0912\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0645 - val_loss: 0.0912\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0642 - val_loss: 0.0911\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0911\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 1397145651.915293, my average MASE = 8779028319.064796\n",
      "Cluster 0, 1397145651.915293\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4446 - val_loss: 0.4248\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.4440 - val_loss: 0.4245\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4434 - val_loss: 0.4242\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4429 - val_loss: 0.4239\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4423 - val_loss: 0.4236\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4418 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4413 - val_loss: 0.4231\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4408 - val_loss: 0.4228\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4403 - val_loss: 0.4226\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4398 - val_loss: 0.4223\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4393 - val_loss: 0.4221\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4388 - val_loss: 0.4219\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4383 - val_loss: 0.4216\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4378 - val_loss: 0.4214\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4212\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4369 - val_loss: 0.4209\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4364 - val_loss: 0.4207\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4360 - val_loss: 0.4205\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4355 - val_loss: 0.4202\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4351 - val_loss: 0.4200\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4346 - val_loss: 0.4198\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4342 - val_loss: 0.4195\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.4193\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4333 - val_loss: 0.4191\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4329 - val_loss: 0.4189\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4325 - val_loss: 0.4187\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4321 - val_loss: 0.4184\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4317 - val_loss: 0.4182\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4313 - val_loss: 0.4180\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4309 - val_loss: 0.4178\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4305 - val_loss: 0.4176\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4301 - val_loss: 0.4175\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4297 - val_loss: 0.4173\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4293 - val_loss: 0.4171\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4289 - val_loss: 0.4169\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4286 - val_loss: 0.4167\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4282 - val_loss: 0.4165\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4278 - val_loss: 0.4163\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4274 - val_loss: 0.4161\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4271 - val_loss: 0.4159\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 86.00366340249806, my average MASE = 69691247.07168306\n",
      "Cluster 1, 86.00366340249806\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9826 - val_loss: 1.3468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9801 - val_loss: 1.3460\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9776 - val_loss: 1.3453\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9751 - val_loss: 1.3446\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9726 - val_loss: 1.3439\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9701 - val_loss: 1.3432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9677 - val_loss: 1.3425\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9653 - val_loss: 1.3419\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9628 - val_loss: 1.3413\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9604 - val_loss: 1.3408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9580 - val_loss: 1.3402\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9556 - val_loss: 1.3396\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9532 - val_loss: 1.3390\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9508 - val_loss: 1.3384\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9486 - val_loss: 1.3379\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9463 - val_loss: 1.3374\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9440 - val_loss: 1.3368\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9418 - val_loss: 1.3363\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9397 - val_loss: 1.3358\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9375 - val_loss: 1.3352\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9353 - val_loss: 1.3347\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9331 - val_loss: 1.3341\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9309 - val_loss: 1.3337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9287 - val_loss: 1.3332\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9266 - val_loss: 1.3328\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9245 - val_loss: 1.3324\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9224 - val_loss: 1.3321\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9203 - val_loss: 1.3317\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9183 - val_loss: 1.3314\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9162 - val_loss: 1.3311\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9141 - val_loss: 1.3308\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9120 - val_loss: 1.3305\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9100 - val_loss: 1.3303\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9079 - val_loss: 1.3300\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9059 - val_loss: 1.3298\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9039 - val_loss: 1.3295\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9019 - val_loss: 1.3293\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9000 - val_loss: 1.3291\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8981 - val_loss: 1.3288\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8963 - val_loss: 1.3286\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1.6636413128548868, my average MASE = 8.526439257891766\n",
      "Cluster 2, 1.6636413128548868\n",
      "Before prediction: train_X.shape=(177, 10, 67), train_y.shape=(177, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7327 - val_loss: 0.5966\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7311 - val_loss: 0.5956\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7296 - val_loss: 0.5946\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7281 - val_loss: 0.5936\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7266 - val_loss: 0.5927\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7252 - val_loss: 0.5918\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7239 - val_loss: 0.5909\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7225 - val_loss: 0.5901\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7212 - val_loss: 0.5892\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7199 - val_loss: 0.5884\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7186 - val_loss: 0.5875\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7174 - val_loss: 0.5867\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7162 - val_loss: 0.5859\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7150 - val_loss: 0.5852\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7138 - val_loss: 0.5844\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7127 - val_loss: 0.5837\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7116 - val_loss: 0.5829\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7104 - val_loss: 0.5822\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7093 - val_loss: 0.5815\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7082 - val_loss: 0.5808\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7071 - val_loss: 0.5801\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7061 - val_loss: 0.5794\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7050 - val_loss: 0.5788\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7040 - val_loss: 0.5781\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7030 - val_loss: 0.5775\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7020 - val_loss: 0.5768\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7010 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7000 - val_loss: 0.5756\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6990 - val_loss: 0.5750\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6981 - val_loss: 0.5744\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6971 - val_loss: 0.5738\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6962 - val_loss: 0.5732\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6953 - val_loss: 0.5726\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6944 - val_loss: 0.5721\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6935 - val_loss: 0.5715\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6925 - val_loss: 0.5710\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6917 - val_loss: 0.5704\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6908 - val_loss: 0.5699\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6899 - val_loss: 0.5694\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6890 - val_loss: 0.5688\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 148.95203283848892, my average MASE = 195949093.5023566\n",
      "Cluster 3, 148.95203283848892\n",
      "Before prediction: train_X.shape=(59, 10, 67), train_y.shape=(59, 67), test_X.shape=(20, 10, 67), test_y.shape=(20, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4242 - val_loss: 0.4717\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4237 - val_loss: 0.4716\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4715\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4228 - val_loss: 0.4714\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4223 - val_loss: 0.4713\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4219 - val_loss: 0.4712\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4214 - val_loss: 0.4711\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4210 - val_loss: 0.4710\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.4709\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4201 - val_loss: 0.4708\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4197 - val_loss: 0.4707\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4193 - val_loss: 0.4706\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4189 - val_loss: 0.4705\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.4705\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4180 - val_loss: 0.4704\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4176 - val_loss: 0.4703\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4702\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4168 - val_loss: 0.4701\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4164 - val_loss: 0.4700\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4160 - val_loss: 0.4699\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4157 - val_loss: 0.4698\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4153 - val_loss: 0.4698\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4149 - val_loss: 0.4697\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4145 - val_loss: 0.4696\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4141 - val_loss: 0.4695\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4138 - val_loss: 0.4694\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4134 - val_loss: 0.4694\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4130 - val_loss: 0.4693\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4127 - val_loss: 0.4692\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4123 - val_loss: 0.4691\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4119 - val_loss: 0.4690\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4116 - val_loss: 0.4690\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4112 - val_loss: 0.4689\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.4688\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4105 - val_loss: 0.4687\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4101 - val_loss: 0.4687\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4098 - val_loss: 0.4686\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4094 - val_loss: 0.4685\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4091 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4087 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(20, 67), test_y.shape=(20, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 138.4214035546147, my average MASE = 76438634.40084383\n",
      "Cluster 4, 138.4214035546147\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4144 - val_loss: 0.4072\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4116 - val_loss: 0.4056\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4089 - val_loss: 0.4039\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4061 - val_loss: 0.4022\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4034 - val_loss: 0.4005\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4008 - val_loss: 0.3988\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3982 - val_loss: 0.3971\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3957 - val_loss: 0.3954\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3932 - val_loss: 0.3937\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3908 - val_loss: 0.3920\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3885 - val_loss: 0.3903\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3861 - val_loss: 0.3887\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3838 - val_loss: 0.3870\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3816 - val_loss: 0.3854\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3795 - val_loss: 0.3838\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3775 - val_loss: 0.3822\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3755 - val_loss: 0.3807\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3735 - val_loss: 0.3793\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3716 - val_loss: 0.3779\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3697 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3679 - val_loss: 0.3751\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3661 - val_loss: 0.3737\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3644 - val_loss: 0.3723\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3710\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3611 - val_loss: 0.3697\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3594 - val_loss: 0.3684\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3578 - val_loss: 0.3672\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3562 - val_loss: 0.3659\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3547 - val_loss: 0.3646\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3533 - val_loss: 0.3634\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.3621\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3506 - val_loss: 0.3608\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3493 - val_loss: 0.3596\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3481 - val_loss: 0.3583\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3468 - val_loss: 0.3571\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3456 - val_loss: 0.3558\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3443 - val_loss: 0.3546\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3431 - val_loss: 0.3534\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3419 - val_loss: 0.3521\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3407 - val_loss: 0.3509\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 697989181.1057402, my average MASE = 1714132782.1928625\n",
      "Cluster 5, 697989181.1057402\n",
      "Before prediction: train_X.shape=(95, 10, 67), train_y.shape=(95, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3944 - val_loss: 0.3555\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3937 - val_loss: 0.3552\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3930 - val_loss: 0.3549\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3924 - val_loss: 0.3546\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3917 - val_loss: 0.3543\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3910 - val_loss: 0.3540\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3904 - val_loss: 0.3537\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3898 - val_loss: 0.3534\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3892 - val_loss: 0.3532\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3886 - val_loss: 0.3529\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3880 - val_loss: 0.3526\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3874 - val_loss: 0.3523\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3868 - val_loss: 0.3520\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3863 - val_loss: 0.3518\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3857 - val_loss: 0.3515\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3852 - val_loss: 0.3512\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3846 - val_loss: 0.3510\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3841 - val_loss: 0.3507\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3835 - val_loss: 0.3504\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3830 - val_loss: 0.3502\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3825 - val_loss: 0.3499\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3820 - val_loss: 0.3496\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3815 - val_loss: 0.3494\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3810 - val_loss: 0.3491\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3805 - val_loss: 0.3489\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3799 - val_loss: 0.3486\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3795 - val_loss: 0.3484\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3790 - val_loss: 0.3481\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3785 - val_loss: 0.3479\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.3476\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3776 - val_loss: 0.3474\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3771 - val_loss: 0.3471\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3767 - val_loss: 0.3469\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3762 - val_loss: 0.3466\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3758 - val_loss: 0.3464\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3753 - val_loss: 0.3461\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3749 - val_loss: 0.3459\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3745 - val_loss: 0.3456\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3740 - val_loss: 0.3454\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3736 - val_loss: 0.3451\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 265.33452450872096, my average MASE = 56598015.30805221\n",
      "Cluster 6, 265.33452450872096\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=9, 9, 1486, (3, 67)\n",
      "Before prediction: train_X.shape=(97, 10, 67), train_y.shape=(97, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4153 - val_loss: 0.4398\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.4396\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4138 - val_loss: 0.4393\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4131 - val_loss: 0.4391\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4124 - val_loss: 0.4388\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4118 - val_loss: 0.4386\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4111 - val_loss: 0.4383\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4105 - val_loss: 0.4381\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4099 - val_loss: 0.4378\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4093 - val_loss: 0.4376\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4087 - val_loss: 0.4374\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4081 - val_loss: 0.4371\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.4369\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4069 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4064 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4058 - val_loss: 0.4362\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.4360\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4047 - val_loss: 0.4358\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4042 - val_loss: 0.4356\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4037 - val_loss: 0.4353\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4032 - val_loss: 0.4351\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4349\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4022 - val_loss: 0.4347\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4017 - val_loss: 0.4345\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4012 - val_loss: 0.4343\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4007 - val_loss: 0.4341\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4003 - val_loss: 0.4339\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3998 - val_loss: 0.4337\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3993 - val_loss: 0.4335\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3989 - val_loss: 0.4334\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3984 - val_loss: 0.4332\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3980 - val_loss: 0.4330\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3976 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3967 - val_loss: 0.4324\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3963 - val_loss: 0.4322\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4320\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3955 - val_loss: 0.4318\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3950 - val_loss: 0.4316\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.4314\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 106.62824359839709, my average MASE = 181907103.45341906\n",
      "Cluster 0, 106.62824359839709\n",
      "Before prediction: train_X.shape=(1415, 10, 67), train_y.shape=(1415, 67), test_X.shape=(472, 10, 67), test_y.shape=(472, 67)\n",
      "Epoch 1/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.1435 - val_loss: 0.0272\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1388 - val_loss: 0.0264\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1347 - val_loss: 0.0256\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1311 - val_loss: 0.0250\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1278 - val_loss: 0.0244\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1249 - val_loss: 0.0239\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1221 - val_loss: 0.0234\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1196 - val_loss: 0.0231\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.1173 - val_loss: 0.0227\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.1151 - val_loss: 0.0224\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1132 - val_loss: 0.0221\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1113 - val_loss: 0.0220\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1096 - val_loss: 0.0217\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1080 - val_loss: 0.0216\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1065 - val_loss: 0.0214\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1051 - val_loss: 0.0212\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1038 - val_loss: 0.0211\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1026 - val_loss: 0.0209\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1014 - val_loss: 0.0208\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1004 - val_loss: 0.0206\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0993 - val_loss: 0.0206\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0983 - val_loss: 0.0205\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0974 - val_loss: 0.0204\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0965 - val_loss: 0.0202\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0957 - val_loss: 0.0201\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0949 - val_loss: 0.0200\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0941 - val_loss: 0.0200\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0934 - val_loss: 0.0199\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0927 - val_loss: 0.0198\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0920 - val_loss: 0.0197\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0914 - val_loss: 0.0197\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0907 - val_loss: 0.0196\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0902 - val_loss: 0.0195\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0896 - val_loss: 0.0195\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0890 - val_loss: 0.0195\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0885 - val_loss: 0.0194\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0880 - val_loss: 0.0194\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0875 - val_loss: 0.0193\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0871 - val_loss: 0.0194\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0867 - val_loss: 0.0193\n",
      "15/15 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(472, 67), test_y.shape=(472, 67)\n",
      "average MASE = 484561401.3912065, my average MASE = 2109803098.5295365\n",
      "Cluster 1, 484561401.3912065\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4184 - val_loss: 0.4085\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4174 - val_loss: 0.4084\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4165 - val_loss: 0.4083\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4155 - val_loss: 0.4082\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4146 - val_loss: 0.4082\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4136 - val_loss: 0.4081\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4127 - val_loss: 0.4080\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4118 - val_loss: 0.4079\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4109 - val_loss: 0.4078\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4100 - val_loss: 0.4077\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4091 - val_loss: 0.4077\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4083 - val_loss: 0.4076\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4074 - val_loss: 0.4075\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4066 - val_loss: 0.4074\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4057 - val_loss: 0.4074\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4049 - val_loss: 0.4073\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4041 - val_loss: 0.4072\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4033 - val_loss: 0.4071\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4025 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4017 - val_loss: 0.4069\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4009 - val_loss: 0.4069\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4001 - val_loss: 0.4068\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3994 - val_loss: 0.4067\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3986 - val_loss: 0.4066\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3979 - val_loss: 0.4065\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3971 - val_loss: 0.4065\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3964 - val_loss: 0.4064\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3957 - val_loss: 0.4063\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3949 - val_loss: 0.4062\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3942 - val_loss: 0.4062\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3936 - val_loss: 0.4061\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3929 - val_loss: 0.4060\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3922 - val_loss: 0.4059\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4058\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3909 - val_loss: 0.4058\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3902 - val_loss: 0.4057\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3896 - val_loss: 0.4056\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3889 - val_loss: 0.4055\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3883 - val_loss: 0.4055\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3877 - val_loss: 0.4054\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 146.41485105295615, my average MASE = 90287364.09726365\n",
      "Cluster 2, 146.41485105295615\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5429 - val_loss: 0.4489\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5408 - val_loss: 0.4477\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5388 - val_loss: 0.4466\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5367 - val_loss: 0.4454\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5348 - val_loss: 0.4443\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5328 - val_loss: 0.4432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5308 - val_loss: 0.4421\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5289 - val_loss: 0.4410\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5270 - val_loss: 0.4399\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5251 - val_loss: 0.4389\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5232 - val_loss: 0.4378\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5214 - val_loss: 0.4368\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5195 - val_loss: 0.4357\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5177 - val_loss: 0.4347\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5159 - val_loss: 0.4336\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5140 - val_loss: 0.4326\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5123 - val_loss: 0.4316\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5105 - val_loss: 0.4306\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5087 - val_loss: 0.4296\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5069 - val_loss: 0.4287\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5052 - val_loss: 0.4277\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5034 - val_loss: 0.4268\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5017 - val_loss: 0.4258\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5000 - val_loss: 0.4249\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4983 - val_loss: 0.4240\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4967 - val_loss: 0.4230\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4950 - val_loss: 0.4221\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4934 - val_loss: 0.4212\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4918 - val_loss: 0.4204\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4903 - val_loss: 0.4195\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4887 - val_loss: 0.4186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.4177\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4857 - val_loss: 0.4169\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4843 - val_loss: 0.4161\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4828 - val_loss: 0.4152\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4814 - val_loss: 0.4144\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4800 - val_loss: 0.4136\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4786 - val_loss: 0.4127\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4772 - val_loss: 0.4119\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4758 - val_loss: 0.4111\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1177081/3287276626.py:67: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 10))\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3556660081.750684, my average MASE = 7865462670.190711\n",
      "Cluster 3, 3556660081.750684\n",
      "Before prediction: train_X.shape=(173, 10, 67), train_y.shape=(173, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7286 - val_loss: 0.5747\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7270 - val_loss: 0.5740\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7256 - val_loss: 0.5733\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7243 - val_loss: 0.5725\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7229 - val_loss: 0.5718\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7216 - val_loss: 0.5712\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7203 - val_loss: 0.5705\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7190 - val_loss: 0.5698\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7178 - val_loss: 0.5692\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7166 - val_loss: 0.5686\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7154 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7142 - val_loss: 0.5673\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7130 - val_loss: 0.5667\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7119 - val_loss: 0.5662\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7108 - val_loss: 0.5656\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7096 - val_loss: 0.5650\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7086 - val_loss: 0.5645\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7075 - val_loss: 0.5639\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7064 - val_loss: 0.5634\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7054 - val_loss: 0.5629\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7044 - val_loss: 0.5624\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7034 - val_loss: 0.5619\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5614\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7014 - val_loss: 0.5609\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7004 - val_loss: 0.5604\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6995 - val_loss: 0.5599\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6986 - val_loss: 0.5595\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6976 - val_loss: 0.5590\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6967 - val_loss: 0.5585\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6958 - val_loss: 0.5581\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6949 - val_loss: 0.5576\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6940 - val_loss: 0.5571\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6931 - val_loss: 0.5567\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5562\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6914 - val_loss: 0.5558\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6905 - val_loss: 0.5553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6896 - val_loss: 0.5549\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6887 - val_loss: 0.5545\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6879 - val_loss: 0.5540\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5536\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 122.19340890523425, my average MASE = 115345826.80728418\n",
      "Cluster 4, 122.19340890523425\n",
      "Before prediction: train_X.shape=(1562, 10, 67), train_y.shape=(1562, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2392 - val_loss: 0.2772\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2287 - val_loss: 0.2673\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2207 - val_loss: 0.2595\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2144 - val_loss: 0.2534\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2094 - val_loss: 0.2481\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2050 - val_loss: 0.2435\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2013 - val_loss: 0.2394\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1978 - val_loss: 0.2357\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1947 - val_loss: 0.2322\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1919 - val_loss: 0.2289\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1892 - val_loss: 0.2259\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1867 - val_loss: 0.2231\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2204\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1821 - val_loss: 0.2179\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1800 - val_loss: 0.2156\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1761 - val_loss: 0.2114\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1743 - val_loss: 0.2096\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1727 - val_loss: 0.2078\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1712 - val_loss: 0.2062\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1698 - val_loss: 0.2047\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2033\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1672 - val_loss: 0.2020\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1661 - val_loss: 0.2007\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1650 - val_loss: 0.1996\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1640 - val_loss: 0.1985\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1631 - val_loss: 0.1974\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1622 - val_loss: 0.1964\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1614 - val_loss: 0.1954\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1598 - val_loss: 0.1936\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1578 - val_loss: 0.1912\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1572 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1566 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1560 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1554 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1549 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1544 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 151.79409601094594, my average MASE = 3866050940.760538\n",
      "Cluster 5, 151.79409601094594\n",
      "Before prediction: train_X.shape=(83, 10, 67), train_y.shape=(83, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4279 - val_loss: 0.5018\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4270 - val_loss: 0.5012\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4262 - val_loss: 0.5006\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4254 - val_loss: 0.5000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4246 - val_loss: 0.4995\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4239 - val_loss: 0.4989\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4231 - val_loss: 0.4984\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4224 - val_loss: 0.4978\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4217 - val_loss: 0.4973\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4968\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4203 - val_loss: 0.4962\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4197 - val_loss: 0.4958\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4191 - val_loss: 0.4953\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4184 - val_loss: 0.4948\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4178 - val_loss: 0.4943\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4939\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4167 - val_loss: 0.4934\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4161 - val_loss: 0.4930\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4155 - val_loss: 0.4926\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4150 - val_loss: 0.4921\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4144 - val_loss: 0.4917\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4139 - val_loss: 0.4913\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4133 - val_loss: 0.4908\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4128 - val_loss: 0.4904\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4123 - val_loss: 0.4900\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4118 - val_loss: 0.4895\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4113 - val_loss: 0.4891\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4107 - val_loss: 0.4887\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4103 - val_loss: 0.4883\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4098 - val_loss: 0.4879\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4093 - val_loss: 0.4875\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4088 - val_loss: 0.4871\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4083 - val_loss: 0.4867\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4079 - val_loss: 0.4863\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4074 - val_loss: 0.4859\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4069 - val_loss: 0.4855\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4065 - val_loss: 0.4851\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4061 - val_loss: 0.4848\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4056 - val_loss: 0.4844\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4052 - val_loss: 0.4840\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 155.68618683798326, my average MASE = 97738271.39222205\n",
      "Cluster 6, 155.68618683798326\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2911 - val_loss: 0.2917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2907 - val_loss: 0.2915\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2902 - val_loss: 0.2913\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2897 - val_loss: 0.2911\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2892 - val_loss: 0.2909\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2888 - val_loss: 0.2907\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2883 - val_loss: 0.2905\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2878 - val_loss: 0.2903\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2874 - val_loss: 0.2901\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2869 - val_loss: 0.2899\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2865 - val_loss: 0.2898\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2861 - val_loss: 0.2896\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2856 - val_loss: 0.2894\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2852 - val_loss: 0.2892\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2848 - val_loss: 0.2890\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2844 - val_loss: 0.2889\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2840 - val_loss: 0.2887\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2836 - val_loss: 0.2885\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2832 - val_loss: 0.2883\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2828 - val_loss: 0.2882\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2824 - val_loss: 0.2880\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2820 - val_loss: 0.2878\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2816 - val_loss: 0.2877\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2812 - val_loss: 0.2875\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2808 - val_loss: 0.2874\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2804 - val_loss: 0.2872\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2800 - val_loss: 0.2870\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2796 - val_loss: 0.2869\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2793 - val_loss: 0.2867\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2789 - val_loss: 0.2865\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2785 - val_loss: 0.2864\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2781 - val_loss: 0.2862\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2778 - val_loss: 0.2861\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2774 - val_loss: 0.2859\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2770 - val_loss: 0.2858\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2767 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2763 - val_loss: 0.2855\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2759 - val_loss: 0.2853\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2756 - val_loss: 0.2852\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2752 - val_loss: 0.2851\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 112.24086700274312, my average MASE = 119826311.76187374\n",
      "Cluster 8, 112.24086700274312\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=11, 11, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1118 - val_loss: 0.1019\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1064 - val_loss: 0.0996\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1022 - val_loss: 0.0982\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0987 - val_loss: 0.0973\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0956 - val_loss: 0.0966\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0930 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0885 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0866 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0848 - val_loss: 0.0949\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0832 - val_loss: 0.0946\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0818 - val_loss: 0.0944\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0804 - val_loss: 0.0941\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0792 - val_loss: 0.0939\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0780 - val_loss: 0.0937\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0769 - val_loss: 0.0936\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0759 - val_loss: 0.0934\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0749 - val_loss: 0.0933\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0740 - val_loss: 0.0932\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0732 - val_loss: 0.0931\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0724 - val_loss: 0.0929\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0716 - val_loss: 0.0928\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0927\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0926\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0696 - val_loss: 0.0926\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0690 - val_loss: 0.0925\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0924\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0923\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0674 - val_loss: 0.0923\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0922\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0921\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0662 - val_loss: 0.0921\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0658 - val_loss: 0.0920\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0919\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0651 - val_loss: 0.0919\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0648 - val_loss: 0.0918\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0645 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0642 - val_loss: 0.0917\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0637 - val_loss: 0.0916\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 876211806.5152007, my average MASE = 21477700395.128197\n",
      "Cluster 0, 876211806.5152007\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7012 - val_loss: 0.5689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7001 - val_loss: 0.5688\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6990 - val_loss: 0.5687\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6979 - val_loss: 0.5686\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6968 - val_loss: 0.5685\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6958 - val_loss: 0.5684\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6947 - val_loss: 0.5683\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6936 - val_loss: 0.5682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6926 - val_loss: 0.5681\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6916 - val_loss: 0.5680\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6906 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6896 - val_loss: 0.5678\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6887 - val_loss: 0.5677\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6877 - val_loss: 0.5676\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6868 - val_loss: 0.5675\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6859 - val_loss: 0.5674\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6849 - val_loss: 0.5673\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6840 - val_loss: 0.5672\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6831 - val_loss: 0.5671\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6822 - val_loss: 0.5670\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6813 - val_loss: 0.5669\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6805 - val_loss: 0.5668\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6796 - val_loss: 0.5667\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6787 - val_loss: 0.5666\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6779 - val_loss: 0.5665\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6771 - val_loss: 0.5665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6762 - val_loss: 0.5664\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6754 - val_loss: 0.5663\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6746 - val_loss: 0.5662\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6738 - val_loss: 0.5661\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6730 - val_loss: 0.5660\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6722 - val_loss: 0.5659\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6715 - val_loss: 0.5658\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6707 - val_loss: 0.5657\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6699 - val_loss: 0.5656\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6691 - val_loss: 0.5655\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6684 - val_loss: 0.5654\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6676 - val_loss: 0.5653\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6668 - val_loss: 0.5652\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6661 - val_loss: 0.5651\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1104923.1929255812, my average MASE = 35973487.14565515\n",
      "Cluster 1, 1104923.1929255812\n",
      "Before prediction: train_X.shape=(134, 10, 67), train_y.shape=(134, 67), test_X.shape=(45, 10, 67), test_y.shape=(45, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4388 - val_loss: 0.7635\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4381 - val_loss: 0.7630\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4375 - val_loss: 0.7625\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4369 - val_loss: 0.7620\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4363 - val_loss: 0.7616\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4358 - val_loss: 0.7611\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4353 - val_loss: 0.7607\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4348 - val_loss: 0.7603\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4343 - val_loss: 0.7598\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4338 - val_loss: 0.7594\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4333 - val_loss: 0.7590\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4328 - val_loss: 0.7585\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4323 - val_loss: 0.7581\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4318 - val_loss: 0.7576\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4314 - val_loss: 0.7572\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4309 - val_loss: 0.7568\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4305 - val_loss: 0.7564\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4301 - val_loss: 0.7561\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4296 - val_loss: 0.7557\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4292 - val_loss: 0.7554\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4288 - val_loss: 0.7550\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4284 - val_loss: 0.7546\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4280 - val_loss: 0.7543\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4276 - val_loss: 0.7539\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4272 - val_loss: 0.7535\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4268 - val_loss: 0.7532\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4264 - val_loss: 0.7528\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4260 - val_loss: 0.7525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4257 - val_loss: 0.7521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4253 - val_loss: 0.7517\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4249 - val_loss: 0.7514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4245 - val_loss: 0.7511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4242 - val_loss: 0.7508\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4238 - val_loss: 0.7505\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4235 - val_loss: 0.7502\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4231 - val_loss: 0.7499\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4228 - val_loss: 0.7496\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4225 - val_loss: 0.7492\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4221 - val_loss: 0.7489\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4218 - val_loss: 0.7486\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(45, 67), test_y.shape=(45, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 134.01886625392066, my average MASE = 180554408.61752364\n",
      "Cluster 2, 134.01886625392066\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3365 - val_loss: 0.4571\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3346 - val_loss: 0.4566\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3328 - val_loss: 0.4560\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.4555\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3293 - val_loss: 0.4550\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.4544\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3260 - val_loss: 0.4539\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.4534\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3229 - val_loss: 0.4528\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3213 - val_loss: 0.4523\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3197 - val_loss: 0.4518\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3182 - val_loss: 0.4512\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3166 - val_loss: 0.4507\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3152 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3137 - val_loss: 0.4496\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3123 - val_loss: 0.4490\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3109 - val_loss: 0.4485\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3095 - val_loss: 0.4479\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3082 - val_loss: 0.4473\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3070 - val_loss: 0.4468\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3058 - val_loss: 0.4462\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3045 - val_loss: 0.4456\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.4450\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3021 - val_loss: 0.4444\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3009 - val_loss: 0.4438\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2998 - val_loss: 0.4432\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2986 - val_loss: 0.4426\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2974 - val_loss: 0.4420\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2963 - val_loss: 0.4414\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2952 - val_loss: 0.4407\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2940 - val_loss: 0.4401\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2929 - val_loss: 0.4395\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.4389\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2907 - val_loss: 0.4384\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2896 - val_loss: 0.4379\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2885 - val_loss: 0.4373\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2875 - val_loss: 0.4369\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2865 - val_loss: 0.4364\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2854 - val_loss: 0.4359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2844 - val_loss: 0.4355\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.28495017155315366, my average MASE = 0.3992586255016426\n",
      "Cluster 3, 0.28495017155315366\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6320 - val_loss: 1.0222\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6307 - val_loss: 1.0218\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 1.0214\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6284 - val_loss: 1.0211\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6273 - val_loss: 1.0208\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6262 - val_loss: 1.0205\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6252 - val_loss: 1.0201\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6241 - val_loss: 1.0198\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6231 - val_loss: 1.0195\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6221 - val_loss: 1.0192\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6212 - val_loss: 1.0188\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6202 - val_loss: 1.0185\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6193 - val_loss: 1.0182\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6183 - val_loss: 1.0179\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6174 - val_loss: 1.0176\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6166 - val_loss: 1.0172\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6157 - val_loss: 1.0169\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6148 - val_loss: 1.0166\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6139 - val_loss: 1.0162\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6131 - val_loss: 1.0159\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6122 - val_loss: 1.0155\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6114 - val_loss: 1.0152\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6106 - val_loss: 1.0148\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6097 - val_loss: 1.0145\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6089 - val_loss: 1.0141\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6081 - val_loss: 1.0138\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6073 - val_loss: 1.0134\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6066 - val_loss: 1.0131\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6057 - val_loss: 1.0127\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6050 - val_loss: 1.0124\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6042 - val_loss: 1.0121\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6035 - val_loss: 1.0118\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6027 - val_loss: 1.0114\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6020 - val_loss: 1.0111\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6013 - val_loss: 1.0108\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6005 - val_loss: 1.0104\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5998 - val_loss: 1.0101\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5991 - val_loss: 1.0098\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5984 - val_loss: 1.0094\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5977 - val_loss: 1.0091\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 98.33747704062574, my average MASE = 204772160.73570046\n",
      "Cluster 4, 98.33747704062574\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4785 - val_loss: 0.4645\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4760 - val_loss: 0.4629\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4734 - val_loss: 0.4612\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4709 - val_loss: 0.4596\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4684 - val_loss: 0.4580\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4661 - val_loss: 0.4564\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4638 - val_loss: 0.4548\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4615 - val_loss: 0.4532\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4593 - val_loss: 0.4516\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4572 - val_loss: 0.4500\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4551 - val_loss: 0.4484\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4530 - val_loss: 0.4468\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4509 - val_loss: 0.4453\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4489 - val_loss: 0.4438\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4469 - val_loss: 0.4422\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4449 - val_loss: 0.4407\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4429 - val_loss: 0.4393\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4410 - val_loss: 0.4380\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4391 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4371 - val_loss: 0.4354\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4353 - val_loss: 0.4343\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4335 - val_loss: 0.4332\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4317 - val_loss: 0.4322\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4300 - val_loss: 0.4311\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4282 - val_loss: 0.4301\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4265 - val_loss: 0.4291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4248 - val_loss: 0.4281\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 0.4270\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4197 - val_loss: 0.4250\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4181 - val_loss: 0.4240\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4165 - val_loss: 0.4229\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4149 - val_loss: 0.4218\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4134 - val_loss: 0.4208\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4118 - val_loss: 0.4197\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4103 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4088 - val_loss: 0.4176\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.4167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4060 - val_loss: 0.4157\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4046 - val_loss: 0.4148\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 931833756.986838, my average MASE = 2420970654.4710827\n",
      "Cluster 5, 931833756.986838\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4346 - val_loss: 0.4628\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4334 - val_loss: 0.4625\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4323 - val_loss: 0.4621\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4312 - val_loss: 0.4618\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4301 - val_loss: 0.4615\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4290 - val_loss: 0.4612\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4280 - val_loss: 0.4609\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4269 - val_loss: 0.4605\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4259 - val_loss: 0.4602\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4249 - val_loss: 0.4599\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4239 - val_loss: 0.4596\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4228 - val_loss: 0.4593\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4218 - val_loss: 0.4590\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4208 - val_loss: 0.4587\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4198 - val_loss: 0.4584\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4188 - val_loss: 0.4582\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4179 - val_loss: 0.4579\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4169 - val_loss: 0.4576\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4160 - val_loss: 0.4573\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4151 - val_loss: 0.4570\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4141 - val_loss: 0.4567\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4132 - val_loss: 0.4564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4123 - val_loss: 0.4561\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4114 - val_loss: 0.4558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4106 - val_loss: 0.4555\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4097 - val_loss: 0.4552\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4089 - val_loss: 0.4549\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4080 - val_loss: 0.4546\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4072 - val_loss: 0.4544\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4063 - val_loss: 0.4541\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4055 - val_loss: 0.4538\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4047 - val_loss: 0.4536\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4039 - val_loss: 0.4533\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4031 - val_loss: 0.4531\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4023 - val_loss: 0.4529\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4015 - val_loss: 0.4527\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4007 - val_loss: 0.4526\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3999 - val_loss: 0.4524\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3991 - val_loss: 0.4522\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3983 - val_loss: 0.4520\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 806621.4868706047, my average MASE = 27017424.126969155\n",
      "Cluster 6, 806621.4868706047\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8616 - val_loss: 0.8556\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8588 - val_loss: 0.8539\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8561 - val_loss: 0.8522\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8534 - val_loss: 0.8505\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8508 - val_loss: 0.8489\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8484 - val_loss: 0.8472\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8459 - val_loss: 0.8456\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8435 - val_loss: 0.8440\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8412 - val_loss: 0.8424\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8389 - val_loss: 0.8408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8366 - val_loss: 0.8392\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8343 - val_loss: 0.8376\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8320 - val_loss: 0.8361\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8298 - val_loss: 0.8345\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8276 - val_loss: 0.8329\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8254 - val_loss: 0.8314\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8232 - val_loss: 0.8298\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8210 - val_loss: 0.8283\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 0.8267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8168 - val_loss: 0.8253\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8146 - val_loss: 0.8238\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8125 - val_loss: 0.8224\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8104 - val_loss: 0.8210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8084 - val_loss: 0.8197\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8064 - val_loss: 0.8184\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8045 - val_loss: 0.8170\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8025 - val_loss: 0.8157\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8006 - val_loss: 0.8143\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7987 - val_loss: 0.8129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7969 - val_loss: 0.8115\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7950 - val_loss: 0.8102\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7932 - val_loss: 0.8089\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7913 - val_loss: 0.8077\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7894 - val_loss: 0.8065\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7876 - val_loss: 0.8053\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7857 - val_loss: 0.8041\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7839 - val_loss: 0.8030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7821 - val_loss: 0.8019\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7803 - val_loss: 0.8008\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7785 - val_loss: 0.7997\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 964635493.0745914, my average MASE = 2107611139.389815\n",
      "Cluster 7, 964635493.0745914\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3952 - val_loss: 0.3689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3946 - val_loss: 0.3689\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3941 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3935 - val_loss: 0.3687\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3930 - val_loss: 0.3687\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3924 - val_loss: 0.3686\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3919 - val_loss: 0.3685\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3914 - val_loss: 0.3685\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3909 - val_loss: 0.3684\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3903 - val_loss: 0.3684\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3898 - val_loss: 0.3683\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3893 - val_loss: 0.3682\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3888 - val_loss: 0.3682\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3883 - val_loss: 0.3681\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3878 - val_loss: 0.3680\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3873 - val_loss: 0.3680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3869 - val_loss: 0.3679\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3864 - val_loss: 0.3679\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3855 - val_loss: 0.3677\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3850 - val_loss: 0.3677\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3845 - val_loss: 0.3676\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3841 - val_loss: 0.3676\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3836 - val_loss: 0.3675\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3832 - val_loss: 0.3674\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3828 - val_loss: 0.3674\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3823 - val_loss: 0.3673\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3819 - val_loss: 0.3673\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3815 - val_loss: 0.3672\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3811 - val_loss: 0.3672\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3806 - val_loss: 0.3671\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3802 - val_loss: 0.3670\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3798 - val_loss: 0.3670\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.3669\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3790 - val_loss: 0.3669\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3786 - val_loss: 0.3668\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3782 - val_loss: 0.3668\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3778 - val_loss: 0.3667\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3774 - val_loss: 0.3666\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3770 - val_loss: 0.3666\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 51.171495934252626, my average MASE = 30811708.472042836\n",
      "Cluster 8, 51.171495934252626\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4416 - val_loss: 0.4387\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4409 - val_loss: 0.4386\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4402 - val_loss: 0.4384\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4395 - val_loss: 0.4383\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4388 - val_loss: 0.4381\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4382 - val_loss: 0.4380\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4375 - val_loss: 0.4379\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4368 - val_loss: 0.4377\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4362 - val_loss: 0.4376\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4355 - val_loss: 0.4375\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4348 - val_loss: 0.4373\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4342 - val_loss: 0.4372\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4335 - val_loss: 0.4371\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4329 - val_loss: 0.4370\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4323 - val_loss: 0.4368\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4316 - val_loss: 0.4367\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4310 - val_loss: 0.4366\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4304 - val_loss: 0.4365\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4298 - val_loss: 0.4364\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4292 - val_loss: 0.4363\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4286 - val_loss: 0.4362\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4280 - val_loss: 0.4361\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4274 - val_loss: 0.4359\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4268 - val_loss: 0.4358\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4262 - val_loss: 0.4357\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4256 - val_loss: 0.4356\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4250 - val_loss: 0.4355\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4245 - val_loss: 0.4354\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4239 - val_loss: 0.4353\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4352\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4227 - val_loss: 0.4351\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4221 - val_loss: 0.4350\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.4349\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4348\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4204 - val_loss: 0.4347\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4199 - val_loss: 0.4346\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4193 - val_loss: 0.4345\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4187 - val_loss: 0.4345\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4182 - val_loss: 0.4344\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4176 - val_loss: 0.4343\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 67.68630348587587, my average MASE = 34346224.36796317\n",
      "Cluster 9, 67.68630348587587\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=2, 2, 18, (30610, 67)\n",
      "Before prediction: train_X.shape=(18359, 10, 67), train_y.shape=(18359, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3046 - val_loss: 0.3213\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2853 - val_loss: 0.3058\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2698 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2588 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2516 - val_loss: 0.2788\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2460 - val_loss: 0.2736\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2412 - val_loss: 0.2691\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2371 - val_loss: 0.2652\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2335 - val_loss: 0.2618\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2301 - val_loss: 0.2588\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2271 - val_loss: 0.2562\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2243 - val_loss: 0.2538\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2219 - val_loss: 0.2516\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2199 - val_loss: 0.2498\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2181 - val_loss: 0.2483\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2166 - val_loss: 0.2469\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2153 - val_loss: 0.2458\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2142 - val_loss: 0.2448\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2122 - val_loss: 0.2430\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2114 - val_loss: 0.2422\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2106 - val_loss: 0.2414\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2099 - val_loss: 0.2407\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2092 - val_loss: 0.2401\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2086 - val_loss: 0.2395\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2080 - val_loss: 0.2389\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2074 - val_loss: 0.2385\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2069 - val_loss: 0.2380\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2064 - val_loss: 0.2376\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2059 - val_loss: 0.2370\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2054 - val_loss: 0.2367\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2050 - val_loss: 0.2362\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2046 - val_loss: 0.2359\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2042 - val_loss: 0.2356\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2038 - val_loss: 0.2351\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2034 - val_loss: 0.2349\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2031 - val_loss: 0.2345\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2021 - val_loss: 0.2337\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1675.644817755528, my average MASE = 2652.7812514268226\n",
      "Cluster 0, 1675.644817755528\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4228 - val_loss: 1.1321\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4209 - val_loss: 1.1320\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4191 - val_loss: 1.1319\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4173 - val_loss: 1.1318\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 1.1317\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4139 - val_loss: 1.1315\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4122 - val_loss: 1.1314\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4106 - val_loss: 1.1313\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4090 - val_loss: 1.1311\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4075 - val_loss: 1.1310\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4059 - val_loss: 1.1308\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4044 - val_loss: 1.1306\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4030 - val_loss: 1.1304\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4015 - val_loss: 1.1302\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4001 - val_loss: 1.1300\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 1.1298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3973 - val_loss: 1.1296\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3960 - val_loss: 1.1294\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3946 - val_loss: 1.1292\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3933 - val_loss: 1.1290\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 1.1288\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3907 - val_loss: 1.1286\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3895 - val_loss: 1.1283\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3883 - val_loss: 1.1281\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3871 - val_loss: 1.1279\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 1.1277\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3847 - val_loss: 1.1275\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3836 - val_loss: 1.1272\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3825 - val_loss: 1.1270\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3814 - val_loss: 1.1268\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3803 - val_loss: 1.1266\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3792 - val_loss: 1.1264\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3781 - val_loss: 1.1262\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3771 - val_loss: 1.1259\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3761 - val_loss: 1.1257\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3750 - val_loss: 1.1255\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3740 - val_loss: 1.1253\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 1.1251\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3721 - val_loss: 1.1249\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3711 - val_loss: 1.1247\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 993839931.13901, my average MASE = 2723871222.022616\n",
      "Cluster 1, 993839931.13901\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=5, 5, 75, (319, 67)\n",
      "Before prediction: train_X.shape=(185, 10, 67), train_y.shape=(185, 67), test_X.shape=(62, 10, 67), test_y.shape=(62, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6944 - val_loss: 0.6444\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6929 - val_loss: 0.6434\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6914 - val_loss: 0.6425\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6901 - val_loss: 0.6415\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6887 - val_loss: 0.6406\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6874 - val_loss: 0.6397\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6860 - val_loss: 0.6388\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6847 - val_loss: 0.6380\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6834 - val_loss: 0.6372\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6822 - val_loss: 0.6363\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6810 - val_loss: 0.6355\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6798 - val_loss: 0.6347\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.6340\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6775 - val_loss: 0.6332\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.6325\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6753 - val_loss: 0.6318\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6742 - val_loss: 0.6310\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6732 - val_loss: 0.6303\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6721 - val_loss: 0.6296\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6711 - val_loss: 0.6289\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6701 - val_loss: 0.6283\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6692 - val_loss: 0.6276\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6682 - val_loss: 0.6270\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6672 - val_loss: 0.6263\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6663 - val_loss: 0.6257\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6654 - val_loss: 0.6251\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.6244\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6636 - val_loss: 0.6238\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6627 - val_loss: 0.6232\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6618 - val_loss: 0.6226\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6610 - val_loss: 0.6220\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6601 - val_loss: 0.6214\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6593 - val_loss: 0.6208\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6584 - val_loss: 0.6202\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6576 - val_loss: 0.6196\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6568 - val_loss: 0.6191\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6559 - val_loss: 0.6185\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6551 - val_loss: 0.6179\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6543 - val_loss: 0.6173\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6535 - val_loss: 0.6167\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(62, 67), test_y.shape=(62, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 141.38884780958514, my average MASE = 173942620.82410374\n",
      "Cluster 0, 141.38884780958514\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0665 - val_loss: 0.0455\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0607 - val_loss: 0.0424\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0575 - val_loss: 0.0402\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0551 - val_loss: 0.0384\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0531 - val_loss: 0.0370\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0515 - val_loss: 0.0358\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0502 - val_loss: 0.0347\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0491 - val_loss: 0.0338\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0481 - val_loss: 0.0331\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0473 - val_loss: 0.0324\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0466 - val_loss: 0.0319\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0460 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0454 - val_loss: 0.0311\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0449 - val_loss: 0.0307\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0304\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0301\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0437 - val_loss: 0.0299\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0433 - val_loss: 0.0297\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0294\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0292\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0424 - val_loss: 0.0290\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0422 - val_loss: 0.0288\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0420 - val_loss: 0.0287\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0418 - val_loss: 0.0285\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0416 - val_loss: 0.0284\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0414 - val_loss: 0.0283\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0412 - val_loss: 0.0281\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0411 - val_loss: 0.0280\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0279\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0278\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0278\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0277\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0276\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0403 - val_loss: 0.0276\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0275\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0401 - val_loss: 0.0274\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0274\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0273\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0273\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0272\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1157555182.6490364, my average MASE = 73085160895.13536\n",
      "Cluster 1, 1157555182.6490364\n",
      "Before prediction: train_X.shape=(37, 10, 67), train_y.shape=(37, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5516 - val_loss: 0.5380\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5498 - val_loss: 0.5365\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5480 - val_loss: 0.5350\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5462 - val_loss: 0.5335\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5444 - val_loss: 0.5321\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5427 - val_loss: 0.5306\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5410 - val_loss: 0.5292\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5393 - val_loss: 0.5278\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5376 - val_loss: 0.5264\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5360 - val_loss: 0.5250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5343 - val_loss: 0.5237\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5328 - val_loss: 0.5223\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5312 - val_loss: 0.5210\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5297 - val_loss: 0.5197\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5281 - val_loss: 0.5184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5266 - val_loss: 0.5171\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5252 - val_loss: 0.5158\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5237 - val_loss: 0.5146\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5223 - val_loss: 0.5133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5208 - val_loss: 0.5121\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5194 - val_loss: 0.5109\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5181 - val_loss: 0.5098\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5167 - val_loss: 0.5086\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5154 - val_loss: 0.5075\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5141 - val_loss: 0.5063\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5128 - val_loss: 0.5052\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5115 - val_loss: 0.5041\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5103 - val_loss: 0.5031\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5091 - val_loss: 0.5020\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5078 - val_loss: 0.5010\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.5000\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5055 - val_loss: 0.4990\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5043 - val_loss: 0.4980\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5031 - val_loss: 0.4970\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5020 - val_loss: 0.4961\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5008 - val_loss: 0.4952\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.4943\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4986 - val_loss: 0.4934\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4975 - val_loss: 0.4926\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4964 - val_loss: 0.4917\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4324881186.205308, my average MASE = 10393885205.318085\n",
      "Cluster 2, 4324881186.205308\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4066 - val_loss: 0.3845\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4060 - val_loss: 0.3840\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.3836\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4048 - val_loss: 0.3831\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4042 - val_loss: 0.3826\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4036 - val_loss: 0.3822\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 0.3817\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4025 - val_loss: 0.3812\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4019 - val_loss: 0.3808\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4014 - val_loss: 0.3803\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3799\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4003 - val_loss: 0.3795\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3791\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3992 - val_loss: 0.3787\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 0.3783\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3982 - val_loss: 0.3779\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3977 - val_loss: 0.3775\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.3772\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3966 - val_loss: 0.3768\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3764\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3956 - val_loss: 0.3761\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3757\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3946 - val_loss: 0.3754\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3942 - val_loss: 0.3751\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3937 - val_loss: 0.3747\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3932 - val_loss: 0.3744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3927 - val_loss: 0.3741\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3922 - val_loss: 0.3738\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3918 - val_loss: 0.3735\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3913 - val_loss: 0.3732\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3908 - val_loss: 0.3729\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3903 - val_loss: 0.3726\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.3723\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3894 - val_loss: 0.3720\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3890 - val_loss: 0.3718\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3885 - val_loss: 0.3715\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3881 - val_loss: 0.3712\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3877 - val_loss: 0.3709\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3872 - val_loss: 0.3706\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3868 - val_loss: 0.3704\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n",
      "average MASE = 1110146.2653270473, my average MASE = 43278995.990564056\n",
      "Cluster 3, 1110146.2653270473\n",
      "Before prediction: train_X.shape=(25, 10, 67), train_y.shape=(25, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5208 - val_loss: 0.4711\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5196 - val_loss: 0.4707\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5184 - val_loss: 0.4702\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5173 - val_loss: 0.4698\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5161 - val_loss: 0.4694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5150 - val_loss: 0.4690\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4686\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5127 - val_loss: 0.4682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5116 - val_loss: 0.4678\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5105 - val_loss: 0.4675\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5094 - val_loss: 0.4671\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5084 - val_loss: 0.4667\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5073 - val_loss: 0.4664\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5063 - val_loss: 0.4660\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5052 - val_loss: 0.4657\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5042 - val_loss: 0.4654\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5031 - val_loss: 0.4651\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4648\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5011 - val_loss: 0.4645\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5001 - val_loss: 0.4643\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4991 - val_loss: 0.4641\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.4638\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4971 - val_loss: 0.4636\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4962 - val_loss: 0.4634\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.4632\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4942 - val_loss: 0.4629\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4933 - val_loss: 0.4627\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4923 - val_loss: 0.4625\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4914 - val_loss: 0.4623\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4904 - val_loss: 0.4621\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4895 - val_loss: 0.4619\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4886 - val_loss: 0.4617\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4876 - val_loss: 0.4616\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4867 - val_loss: 0.4614\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4858 - val_loss: 0.4613\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4849 - val_loss: 0.4611\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4841 - val_loss: 0.4610\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4608\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4823 - val_loss: 0.4607\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4815 - val_loss: 0.4605\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 111.6892159594304, my average MASE = 112347014.53903662\n",
      "Cluster 4, 111.6892159594304\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=7, 7, 884, (12, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0672 - val_loss: 0.0440\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0611 - val_loss: 0.0410\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0576 - val_loss: 0.0390\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0552 - val_loss: 0.0374\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0533 - val_loss: 0.0361\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0517 - val_loss: 0.0350\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0504 - val_loss: 0.0340\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0493 - val_loss: 0.0332\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0484 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0476 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0469 - val_loss: 0.0313\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0462 - val_loss: 0.0308\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0457 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0447 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0442 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0435 - val_loss: 0.0287\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0285\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0283\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0281\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0280\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0278\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0277\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0275\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0274\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0273\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0411 - val_loss: 0.0271\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0270\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0408 - val_loss: 0.0269\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0268\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0267\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0405 - val_loss: 0.0266\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0403 - val_loss: 0.0265\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0401 - val_loss: 0.0264\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0263\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0399 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1103404601.9868512, my average MASE = 55700347192.937294\n",
      "Cluster 1, 1103404601.9868512\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5205 - val_loss: 0.4218\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5186 - val_loss: 0.4208\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5167 - val_loss: 0.4198\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5148 - val_loss: 0.4189\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5129 - val_loss: 0.4179\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5111 - val_loss: 0.4170\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5093 - val_loss: 0.4161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5074 - val_loss: 0.4152\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5057 - val_loss: 0.4143\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5039 - val_loss: 0.4134\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5022 - val_loss: 0.4125\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5004 - val_loss: 0.4117\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4987 - val_loss: 0.4108\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4971 - val_loss: 0.4100\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4954 - val_loss: 0.4092\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4938 - val_loss: 0.4083\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4922 - val_loss: 0.4075\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4906 - val_loss: 0.4067\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4890 - val_loss: 0.4060\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4875 - val_loss: 0.4052\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4860 - val_loss: 0.4044\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4845 - val_loss: 0.4036\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4830 - val_loss: 0.4028\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4815 - val_loss: 0.4021\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4800 - val_loss: 0.4013\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4771 - val_loss: 0.3999\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4757 - val_loss: 0.3992\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4743 - val_loss: 0.3985\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4730 - val_loss: 0.3978\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4716 - val_loss: 0.3971\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4703 - val_loss: 0.3964\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4689 - val_loss: 0.3958\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.3951\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.3945\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4650 - val_loss: 0.3939\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4637 - val_loss: 0.3932\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4625 - val_loss: 0.3926\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4612 - val_loss: 0.3920\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4600 - val_loss: 0.3913\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3560489905.356454, my average MASE = 9030960108.787361\n",
      "Cluster 2, 3560489905.356454\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3774 - val_loss: 0.3465\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3767 - val_loss: 0.3460\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3759 - val_loss: 0.3456\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3752 - val_loss: 0.3452\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3744 - val_loss: 0.3448\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3737 - val_loss: 0.3444\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 0.3440\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3723 - val_loss: 0.3436\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3716 - val_loss: 0.3432\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3710 - val_loss: 0.3429\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3703 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3696 - val_loss: 0.3421\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.3418\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3683 - val_loss: 0.3415\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3411\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3671 - val_loss: 0.3408\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3665 - val_loss: 0.3405\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3659 - val_loss: 0.3401\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3653 - val_loss: 0.3398\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3647 - val_loss: 0.3395\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3641 - val_loss: 0.3392\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3635 - val_loss: 0.3389\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3630 - val_loss: 0.3386\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.3383\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.3380\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3613 - val_loss: 0.3377\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3608 - val_loss: 0.3374\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3602 - val_loss: 0.3371\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3597 - val_loss: 0.3368\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3592 - val_loss: 0.3365\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3362\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3581 - val_loss: 0.3359\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3576 - val_loss: 0.3356\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3571 - val_loss: 0.3353\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3566 - val_loss: 0.3350\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3561 - val_loss: 0.3347\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3556 - val_loss: 0.3344\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3551 - val_loss: 0.3342\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3546 - val_loss: 0.3339\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3541 - val_loss: 0.3336\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 332.8608286989534, my average MASE = 85442913.95523748\n",
      "Cluster 3, 332.8608286989534\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7187 - val_loss: 0.5712\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7172 - val_loss: 0.5706\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7158 - val_loss: 0.5700\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7145 - val_loss: 0.5694\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7132 - val_loss: 0.5688\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7119 - val_loss: 0.5682\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7107 - val_loss: 0.5677\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7095 - val_loss: 0.5671\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7083 - val_loss: 0.5666\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7071 - val_loss: 0.5660\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7060 - val_loss: 0.5655\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7049 - val_loss: 0.5650\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7038 - val_loss: 0.5646\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7028 - val_loss: 0.5641\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7018 - val_loss: 0.5636\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7008 - val_loss: 0.5631\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6999 - val_loss: 0.5627\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6989 - val_loss: 0.5622\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6980 - val_loss: 0.5618\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6971 - val_loss: 0.5613\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5609\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6953 - val_loss: 0.5604\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6944 - val_loss: 0.5600\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6935 - val_loss: 0.5596\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6927 - val_loss: 0.5592\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6918 - val_loss: 0.5587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6910 - val_loss: 0.5583\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6902 - val_loss: 0.5579\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6894 - val_loss: 0.5576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6886 - val_loss: 0.5572\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6878 - val_loss: 0.5568\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5564\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6862 - val_loss: 0.5560\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6854 - val_loss: 0.5557\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6846 - val_loss: 0.5553\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6839 - val_loss: 0.5549\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6831 - val_loss: 0.5546\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6824 - val_loss: 0.5542\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6816 - val_loss: 0.5538\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6809 - val_loss: 0.5535\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.45484282658396, my average MASE = 350849744.5231373\n",
      "Cluster 4, 139.45484282658396\n",
      "Before prediction: train_X.shape=(133, 10, 67), train_y.shape=(133, 67), test_X.shape=(44, 10, 67), test_y.shape=(44, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4266 - val_loss: 0.6651\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4259 - val_loss: 0.6645\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4253 - val_loss: 0.6639\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4247 - val_loss: 0.6633\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4242 - val_loss: 0.6628\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4236 - val_loss: 0.6623\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4231 - val_loss: 0.6618\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4226 - val_loss: 0.6613\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4221 - val_loss: 0.6608\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4216 - val_loss: 0.6603\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4211 - val_loss: 0.6599\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4206 - val_loss: 0.6594\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4201 - val_loss: 0.6590\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4197 - val_loss: 0.6585\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4192 - val_loss: 0.6581\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4188 - val_loss: 0.6576\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4184 - val_loss: 0.6572\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4180 - val_loss: 0.6568\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4175 - val_loss: 0.6564\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4171 - val_loss: 0.6559\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4167 - val_loss: 0.6554\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4163 - val_loss: 0.6550\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4159 - val_loss: 0.6545\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4155 - val_loss: 0.6541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4151 - val_loss: 0.6537\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4147 - val_loss: 0.6533\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4143 - val_loss: 0.6529\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4139 - val_loss: 0.6525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4135 - val_loss: 0.6521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4131 - val_loss: 0.6518\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4128 - val_loss: 0.6514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4124 - val_loss: 0.6511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4120 - val_loss: 0.6507\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4117 - val_loss: 0.6504\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4114 - val_loss: 0.6501\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4110 - val_loss: 0.6498\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4107 - val_loss: 0.6494\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4103 - val_loss: 0.6491\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4100 - val_loss: 0.6487\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4096 - val_loss: 0.6484\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(44, 67), test_y.shape=(44, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 116.65244791791511, my average MASE = 142786035.78420427\n",
      "Cluster 5, 116.65244791791511\n",
      "Before prediction: train_X.shape=(78, 10, 67), train_y.shape=(78, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4078 - val_loss: 0.4868\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4070 - val_loss: 0.4862\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4062 - val_loss: 0.4856\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4055 - val_loss: 0.4850\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4048 - val_loss: 0.4845\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4041 - val_loss: 0.4839\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.4833\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4828\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4021 - val_loss: 0.4823\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4015 - val_loss: 0.4818\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4008 - val_loss: 0.4813\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4002 - val_loss: 0.4808\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3997 - val_loss: 0.4803\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3991 - val_loss: 0.4798\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3985 - val_loss: 0.4794\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3980 - val_loss: 0.4789\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3974 - val_loss: 0.4785\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3969 - val_loss: 0.4780\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3964 - val_loss: 0.4776\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4772\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3954 - val_loss: 0.4768\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3949 - val_loss: 0.4764\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3944 - val_loss: 0.4760\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.4757\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3934 - val_loss: 0.4753\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3930 - val_loss: 0.4750\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3925 - val_loss: 0.4747\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3921 - val_loss: 0.4743\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3916 - val_loss: 0.4740\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3912 - val_loss: 0.4737\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3907 - val_loss: 0.4733\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3903 - val_loss: 0.4730\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.4727\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3895 - val_loss: 0.4724\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3890 - val_loss: 0.4721\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3886 - val_loss: 0.4718\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4715\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3878 - val_loss: 0.4712\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.4709\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3870 - val_loss: 0.4706\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 221.65144919995234, my average MASE = 102271349.10812314\n",
      "Cluster 6, 221.65144919995234\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=9, 9, 14, (3245, 67)\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1141 - val_loss: 0.1031\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1086 - val_loss: 0.1010\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1042 - val_loss: 0.0995\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1005 - val_loss: 0.0982\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0973 - val_loss: 0.0973\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0945 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0920 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0897 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0877 - val_loss: 0.0950\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0858 - val_loss: 0.0947\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0841 - val_loss: 0.0943\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0826 - val_loss: 0.0941\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0812 - val_loss: 0.0938\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0798 - val_loss: 0.0935\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0786 - val_loss: 0.0933\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0930\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0765 - val_loss: 0.0928\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0755 - val_loss: 0.0926\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0746 - val_loss: 0.0925\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0737 - val_loss: 0.0923\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0729 - val_loss: 0.0921\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0722 - val_loss: 0.0920\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0715 - val_loss: 0.0919\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0708 - val_loss: 0.0917\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0916\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0915\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0691 - val_loss: 0.0914\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0686 - val_loss: 0.0913\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0681 - val_loss: 0.0912\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0676 - val_loss: 0.0911\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0910\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0668 - val_loss: 0.0910\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0664 - val_loss: 0.0909\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0660 - val_loss: 0.0909\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0656 - val_loss: 0.0908\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0653 - val_loss: 0.0908\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0650 - val_loss: 0.0907\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0647 - val_loss: 0.0907\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0644 - val_loss: 0.0907\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0906\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1289233887.8234715, my average MASE = 15636865244.557127\n",
      "Cluster 0, 1289233887.8234715\n",
      "Before prediction: train_X.shape=(29, 10, 67), train_y.shape=(29, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4693 - val_loss: 0.6570\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4687 - val_loss: 0.6567\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4680 - val_loss: 0.6563\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4674 - val_loss: 0.6560\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4668 - val_loss: 0.6557\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4662 - val_loss: 0.6554\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4656 - val_loss: 0.6551\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4650 - val_loss: 0.6548\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4644 - val_loss: 0.6545\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4638 - val_loss: 0.6542\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4633 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4627 - val_loss: 0.6536\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4621 - val_loss: 0.6533\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.6530\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4610 - val_loss: 0.6527\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4605 - val_loss: 0.6524\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4599 - val_loss: 0.6521\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4594 - val_loss: 0.6519\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4588 - val_loss: 0.6516\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4583 - val_loss: 0.6513\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4578 - val_loss: 0.6510\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4573 - val_loss: 0.6508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4568 - val_loss: 0.6505\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4563 - val_loss: 0.6502\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4558 - val_loss: 0.6499\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4553 - val_loss: 0.6496\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4548 - val_loss: 0.6493\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4543 - val_loss: 0.6491\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4538 - val_loss: 0.6488\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4533 - val_loss: 0.6485\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4528 - val_loss: 0.6483\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4524 - val_loss: 0.6480\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4519 - val_loss: 0.6478\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4514 - val_loss: 0.6475\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4510 - val_loss: 0.6473\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4505 - val_loss: 0.6470\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4500 - val_loss: 0.6468\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4496 - val_loss: 0.6465\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4492 - val_loss: 0.6463\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.6460\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 10049120.449906044, my average MASE = 246733533.9412494\n",
      "Cluster 1, 10049120.449906044\n",
      "Before prediction: train_X.shape=(1564, 10, 67), train_y.shape=(1564, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2359 - val_loss: 0.2748\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2264 - val_loss: 0.2656\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2192 - val_loss: 0.2584\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2135 - val_loss: 0.2523\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2087 - val_loss: 0.2471\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2045 - val_loss: 0.2424\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2007 - val_loss: 0.2382\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1973 - val_loss: 0.2342\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1941 - val_loss: 0.2307\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1912 - val_loss: 0.2273\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1884 - val_loss: 0.2242\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1858 - val_loss: 0.2214\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1833 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1810 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1789 - val_loss: 0.2140\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1769 - val_loss: 0.2119\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1750 - val_loss: 0.2100\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1733 - val_loss: 0.2082\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1717 - val_loss: 0.2066\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1702 - val_loss: 0.2051\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1689 - val_loss: 0.2038\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1677 - val_loss: 0.2024\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2012\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2001\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1645 - val_loss: 0.1989\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1979\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1627 - val_loss: 0.1969\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1619 - val_loss: 0.1959\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1611 - val_loss: 0.1950\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1603 - val_loss: 0.1941\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1596 - val_loss: 0.1933\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1589 - val_loss: 0.1925\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1582 - val_loss: 0.1917\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1576 - val_loss: 0.1910\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1570 - val_loss: 0.1903\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1564 - val_loss: 0.1895\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1558 - val_loss: 0.1889\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1553 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1548 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1543 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 187.65491616156584, my average MASE = 1727876346.7517292\n",
      "Cluster 2, 187.65491616156584\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5179 - val_loss: 0.4772\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5158 - val_loss: 0.4757\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4743\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5118 - val_loss: 0.4729\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5098 - val_loss: 0.4715\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5079 - val_loss: 0.4701\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5059 - val_loss: 0.4687\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5040 - val_loss: 0.4673\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4660\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5002 - val_loss: 0.4646\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4984 - val_loss: 0.4633\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4966 - val_loss: 0.4620\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4948 - val_loss: 0.4607\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4931 - val_loss: 0.4594\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4913 - val_loss: 0.4581\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4896 - val_loss: 0.4568\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4879 - val_loss: 0.4555\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4862 - val_loss: 0.4543\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4845 - val_loss: 0.4531\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4828 - val_loss: 0.4518\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4812 - val_loss: 0.4506\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4795 - val_loss: 0.4495\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4779 - val_loss: 0.4483\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4763 - val_loss: 0.4471\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4747 - val_loss: 0.4460\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4731 - val_loss: 0.4449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4716 - val_loss: 0.4438\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4700 - val_loss: 0.4427\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4685 - val_loss: 0.4416\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4670 - val_loss: 0.4405\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4655 - val_loss: 0.4395\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4640 - val_loss: 0.4385\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4626 - val_loss: 0.4374\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4611 - val_loss: 0.4364\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4597 - val_loss: 0.4354\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4582 - val_loss: 0.4344\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4568 - val_loss: 0.4334\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4555 - val_loss: 0.4324\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4541 - val_loss: 0.4314\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4527 - val_loss: 0.4304\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3258333520.23763, my average MASE = 7487984704.271554\n",
      "Cluster 3, 3258333520.23763\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3367 - val_loss: 0.3564\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3362 - val_loss: 0.3564\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3356 - val_loss: 0.3564\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3351 - val_loss: 0.3563\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3346 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3340 - val_loss: 0.3563\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3335 - val_loss: 0.3563\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3330 - val_loss: 0.3562\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3325 - val_loss: 0.3562\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3319 - val_loss: 0.3562\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3314 - val_loss: 0.3561\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3309 - val_loss: 0.3561\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3304 - val_loss: 0.3561\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3560\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3294 - val_loss: 0.3560\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3289 - val_loss: 0.3560\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.3559\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3280 - val_loss: 0.3559\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3275 - val_loss: 0.3559\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3270 - val_loss: 0.3559\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3266 - val_loss: 0.3558\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3261 - val_loss: 0.3558\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3256 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3252 - val_loss: 0.3558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3248 - val_loss: 0.3558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3243 - val_loss: 0.3557\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3239 - val_loss: 0.3557\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.3557\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3230 - val_loss: 0.3557\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3226 - val_loss: 0.3557\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3222 - val_loss: 0.3556\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3218 - val_loss: 0.3556\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3214 - val_loss: 0.3556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3556\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3205 - val_loss: 0.3556\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3201 - val_loss: 0.3556\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.3556\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3193 - val_loss: 0.3555\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3189 - val_loss: 0.3555\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3185 - val_loss: 0.3555\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 544.8910068645505, my average MASE = 25915172.7591836\n",
      "Cluster 4, 544.8910068645505\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5189 - val_loss: 0.8510\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5183 - val_loss: 0.8507\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5176 - val_loss: 0.8503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5170 - val_loss: 0.8500\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5163 - val_loss: 0.8496\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5157 - val_loss: 0.8493\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5151 - val_loss: 0.8490\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5145 - val_loss: 0.8487\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5138 - val_loss: 0.8484\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5132 - val_loss: 0.8481\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5126 - val_loss: 0.8478\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5120 - val_loss: 0.8476\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5114 - val_loss: 0.8473\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5108 - val_loss: 0.8471\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5102 - val_loss: 0.8468\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5096 - val_loss: 0.8466\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5090 - val_loss: 0.8463\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5084 - val_loss: 0.8461\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5078 - val_loss: 0.8458\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5072 - val_loss: 0.8456\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.8454\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5060 - val_loss: 0.8451\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5055 - val_loss: 0.8449\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5049 - val_loss: 0.8447\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5043 - val_loss: 0.8445\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5038 - val_loss: 0.8443\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5032 - val_loss: 0.8441\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5027 - val_loss: 0.8439\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5021 - val_loss: 0.8437\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5016 - val_loss: 0.8435\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5010 - val_loss: 0.8433\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5005 - val_loss: 0.8431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4999 - val_loss: 0.8429\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4994 - val_loss: 0.8428\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4989 - val_loss: 0.8426\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4983 - val_loss: 0.8424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4978 - val_loss: 0.8422\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4973 - val_loss: 0.8420\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4967 - val_loss: 0.8419\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4962 - val_loss: 0.8417\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1963484.3822421303, my average MASE = 64800710.430740915\n",
      "Cluster 5, 1963484.3822421303\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8495 - val_loss: 4.3516\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8473 - val_loss: 4.3510\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8451 - val_loss: 4.3503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8429 - val_loss: 4.3497\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8408 - val_loss: 4.3491\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8386 - val_loss: 4.3485\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8365 - val_loss: 4.3479\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8344 - val_loss: 4.3473\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8323 - val_loss: 4.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8301 - val_loss: 4.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8280 - val_loss: 4.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8259 - val_loss: 4.3451\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8238 - val_loss: 4.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8217 - val_loss: 4.3440\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8197 - val_loss: 4.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8176 - val_loss: 4.3428\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8156 - val_loss: 4.3423\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8136 - val_loss: 4.3417\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8117 - val_loss: 4.3412\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8098 - val_loss: 4.3407\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 4.3403\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8061 - val_loss: 4.3399\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8042 - val_loss: 4.3395\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8023 - val_loss: 4.3390\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8004 - val_loss: 4.3386\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7986 - val_loss: 4.3382\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7967 - val_loss: 4.3378\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7949 - val_loss: 4.3374\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7930 - val_loss: 4.3370\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7912 - val_loss: 4.3365\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7893 - val_loss: 4.3361\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7874 - val_loss: 4.3357\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7856 - val_loss: 4.3353\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7839 - val_loss: 4.3349\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7822 - val_loss: 4.3345\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7805 - val_loss: 4.3341\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7787 - val_loss: 4.3338\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7771 - val_loss: 4.3334\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7754 - val_loss: 4.3330\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7738 - val_loss: 4.3327\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4.116072897890656, my average MASE = 12.21206426084865\n",
      "Cluster 6, 4.116072897890656\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3660 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3652 - val_loss: 0.3455\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3645 - val_loss: 0.3451\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3638 - val_loss: 0.3448\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3632 - val_loss: 0.3445\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3625 - val_loss: 0.3441\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3619 - val_loss: 0.3438\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3435\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3606 - val_loss: 0.3431\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3599 - val_loss: 0.3428\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3593 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3422\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3581 - val_loss: 0.3419\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3576 - val_loss: 0.3416\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3570 - val_loss: 0.3413\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3564 - val_loss: 0.3410\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3558 - val_loss: 0.3407\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3553 - val_loss: 0.3404\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3547 - val_loss: 0.3401\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3542 - val_loss: 0.3398\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3536 - val_loss: 0.3395\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3531 - val_loss: 0.3393\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3526 - val_loss: 0.3390\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3521 - val_loss: 0.3387\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3516 - val_loss: 0.3384\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3511 - val_loss: 0.3382\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3506 - val_loss: 0.3379\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3501 - val_loss: 0.3376\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3496 - val_loss: 0.3373\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3491 - val_loss: 0.3371\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3487 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3482 - val_loss: 0.3366\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3477 - val_loss: 0.3363\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3473 - val_loss: 0.3360\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3464 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3459 - val_loss: 0.3353\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3455 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3451 - val_loss: 0.3348\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3446 - val_loss: 0.3345\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 266.09609302896547, my average MASE = 71685898.00003502\n",
      "Cluster 8, 266.09609302896547\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=11, 11, 663, (11, 67)\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3610 - val_loss: 0.4969\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3601 - val_loss: 0.4969\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3592 - val_loss: 0.4970\n",
      "Epoch 3: early stopping\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.35712691602972574, my average MASE = 0.5241910168311086\n",
      "Cluster 0, 0.35712691602972574\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2752 - val_loss: 0.2714\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2747 - val_loss: 0.2712\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2742 - val_loss: 0.2710\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2737 - val_loss: 0.2707\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2733 - val_loss: 0.2705\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2728 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2723 - val_loss: 0.2701\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2718 - val_loss: 0.2699\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2714 - val_loss: 0.2697\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2709 - val_loss: 0.2695\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2704 - val_loss: 0.2693\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2700 - val_loss: 0.2691\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2695 - val_loss: 0.2690\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2691 - val_loss: 0.2688\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2687 - val_loss: 0.2686\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2682 - val_loss: 0.2684\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2678 - val_loss: 0.2682\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2673 - val_loss: 0.2680\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2669 - val_loss: 0.2678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2665 - val_loss: 0.2676\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2661 - val_loss: 0.2674\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.2672\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2653 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2649 - val_loss: 0.2669\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2645 - val_loss: 0.2667\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2641 - val_loss: 0.2665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2637 - val_loss: 0.2663\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2633 - val_loss: 0.2662\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2629 - val_loss: 0.2660\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2625 - val_loss: 0.2658\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2621 - val_loss: 0.2656\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2618 - val_loss: 0.2655\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2614 - val_loss: 0.2653\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2610 - val_loss: 0.2652\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2606 - val_loss: 0.2650\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2602 - val_loss: 0.2649\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2599 - val_loss: 0.2647\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2595 - val_loss: 0.2646\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2591 - val_loss: 0.2644\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2588 - val_loss: 0.2643\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 114.92828938190037, my average MASE = 64775351.69732988\n",
      "Cluster 1, 114.92828938190037\n",
      "Before prediction: train_X.shape=(21, 10, 67), train_y.shape=(21, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6587 - val_loss: 0.2666\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6569 - val_loss: 0.2655\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6551 - val_loss: 0.2645\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6533 - val_loss: 0.2635\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6515 - val_loss: 0.2624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6497 - val_loss: 0.2614\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6480 - val_loss: 0.2604\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6463 - val_loss: 0.2594\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6446 - val_loss: 0.2584\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6429 - val_loss: 0.2574\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6412 - val_loss: 0.2565\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6395 - val_loss: 0.2555\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6379 - val_loss: 0.2546\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6363 - val_loss: 0.2538\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6346 - val_loss: 0.2529\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6331 - val_loss: 0.2520\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6315 - val_loss: 0.2512\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6300 - val_loss: 0.2504\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6285 - val_loss: 0.2496\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6270 - val_loss: 0.2488\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6255 - val_loss: 0.2480\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6240 - val_loss: 0.2473\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6225 - val_loss: 0.2466\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6211 - val_loss: 0.2458\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6197 - val_loss: 0.2451\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6182 - val_loss: 0.2444\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6168 - val_loss: 0.2437\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6155 - val_loss: 0.2430\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6141 - val_loss: 0.2423\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6127 - val_loss: 0.2416\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6114 - val_loss: 0.2410\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6101 - val_loss: 0.2403\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6088 - val_loss: 0.2397\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6075 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6063 - val_loss: 0.2384\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6050 - val_loss: 0.2378\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6038 - val_loss: 0.2372\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6026 - val_loss: 0.2365\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6014 - val_loss: 0.2359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6002 - val_loss: 0.2353\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 26456338.054780327, my average MASE = 1170397376.6808207\n",
      "Cluster 2, 26456338.054780327\n",
      "Before prediction: train_X.shape=(62, 10, 67), train_y.shape=(62, 67), test_X.shape=(21, 10, 67), test_y.shape=(21, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3828 - val_loss: 0.5067\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3824 - val_loss: 0.5064\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3820 - val_loss: 0.5062\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3816 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3812 - val_loss: 0.5056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3808 - val_loss: 0.5053\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3804 - val_loss: 0.5051\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3801 - val_loss: 0.5048\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3797 - val_loss: 0.5045\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3793 - val_loss: 0.5043\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3790 - val_loss: 0.5040\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3786 - val_loss: 0.5038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3783 - val_loss: 0.5035\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3779 - val_loss: 0.5032\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3776 - val_loss: 0.5030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3772 - val_loss: 0.5027\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3769 - val_loss: 0.5025\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3765 - val_loss: 0.5022\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3762 - val_loss: 0.5020\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3758 - val_loss: 0.5017\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3755 - val_loss: 0.5015\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3752 - val_loss: 0.5012\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3748 - val_loss: 0.5010\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3745 - val_loss: 0.5008\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3742 - val_loss: 0.5005\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3738 - val_loss: 0.5003\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3735 - val_loss: 0.5000\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3732 - val_loss: 0.4998\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3729 - val_loss: 0.4995\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3726 - val_loss: 0.4993\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3722 - val_loss: 0.4991\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3719 - val_loss: 0.4988\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3716 - val_loss: 0.4986\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3713 - val_loss: 0.4984\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3710 - val_loss: 0.4982\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3707 - val_loss: 0.4979\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3704 - val_loss: 0.4977\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3701 - val_loss: 0.4975\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3698 - val_loss: 0.4973\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3695 - val_loss: 0.4971\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(21, 67), test_y.shape=(21, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 88.873907317969, my average MASE = 105114880.66517946\n",
      "Cluster 3, 88.873907317969\n",
      "Before prediction: train_X.shape=(58, 10, 67), train_y.shape=(58, 67), test_X.shape=(19, 10, 67), test_y.shape=(19, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6113 - val_loss: 0.3397\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6107 - val_loss: 0.3395\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6100 - val_loss: 0.3394\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6094 - val_loss: 0.3393\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6087 - val_loss: 0.3392\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6081 - val_loss: 0.3391\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6075 - val_loss: 0.3390\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6069 - val_loss: 0.3389\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6062 - val_loss: 0.3388\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6056 - val_loss: 0.3387\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6050 - val_loss: 0.3386\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6044 - val_loss: 0.3385\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6038 - val_loss: 0.3384\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6032 - val_loss: 0.3383\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6026 - val_loss: 0.3382\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6020 - val_loss: 0.3381\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6014 - val_loss: 0.3380\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6009 - val_loss: 0.3379\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6003 - val_loss: 0.3378\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5997 - val_loss: 0.3377\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5992 - val_loss: 0.3376\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5986 - val_loss: 0.3375\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5981 - val_loss: 0.3374\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5976 - val_loss: 0.3373\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5970 - val_loss: 0.3372\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5965 - val_loss: 0.3372\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5960 - val_loss: 0.3371\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5955 - val_loss: 0.3370\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5949 - val_loss: 0.3369\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5944 - val_loss: 0.3369\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5939 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5934 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5929 - val_loss: 0.3366\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5924 - val_loss: 0.3366\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5919 - val_loss: 0.3365\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5915 - val_loss: 0.3364\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5910 - val_loss: 0.3364\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5905 - val_loss: 0.3363\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5900 - val_loss: 0.3362\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5895 - val_loss: 0.3362\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(19, 67), test_y.shape=(19, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2288977.9462372796, my average MASE = 275894539.3328722\n",
      "Cluster 4, 2288977.9462372796\n",
      "Before prediction: train_X.shape=(22, 10, 67), train_y.shape=(22, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6507 - val_loss: 0.5866\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6499 - val_loss: 0.5864\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6491 - val_loss: 0.5862\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6483 - val_loss: 0.5861\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6475 - val_loss: 0.5859\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6467 - val_loss: 0.5857\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6459 - val_loss: 0.5855\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6451 - val_loss: 0.5854\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6443 - val_loss: 0.5852\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6435 - val_loss: 0.5851\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6427 - val_loss: 0.5849\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6420 - val_loss: 0.5848\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6412 - val_loss: 0.5846\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6405 - val_loss: 0.5844\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6397 - val_loss: 0.5843\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6389 - val_loss: 0.5841\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6382 - val_loss: 0.5840\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6374 - val_loss: 0.5838\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6367 - val_loss: 0.5837\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6359 - val_loss: 0.5836\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6352 - val_loss: 0.5834\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6345 - val_loss: 0.5833\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6337 - val_loss: 0.5832\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6330 - val_loss: 0.5830\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6323 - val_loss: 0.5829\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6316 - val_loss: 0.5827\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6309 - val_loss: 0.5826\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6302 - val_loss: 0.5825\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 0.5824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6288 - val_loss: 0.5822\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6281 - val_loss: 0.5821\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6275 - val_loss: 0.5820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6268 - val_loss: 0.5819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6261 - val_loss: 0.5818\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6254 - val_loss: 0.5816\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6248 - val_loss: 0.5815\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6241 - val_loss: 0.5814\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6235 - val_loss: 0.5813\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6228 - val_loss: 0.5811\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6222 - val_loss: 0.5810\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 56.939779008571485, my average MASE = 37107546.21609385\n",
      "Cluster 5, 56.939779008571485\n",
      "Before prediction: train_X.shape=(4681, 10, 67), train_y.shape=(4681, 67), test_X.shape=(1560, 10, 67), test_y.shape=(1560, 67)\n",
      "Epoch 1/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0785 - val_loss: 0.0245\n",
      "Epoch 2/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0726 - val_loss: 0.0222\n",
      "Epoch 3/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0688 - val_loss: 0.0210\n",
      "Epoch 4/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0661 - val_loss: 0.0201\n",
      "Epoch 5/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0638 - val_loss: 0.0195\n",
      "Epoch 6/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0620 - val_loss: 0.0189\n",
      "Epoch 7/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0604 - val_loss: 0.0185\n",
      "Epoch 8/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0590 - val_loss: 0.0182\n",
      "Epoch 9/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0579 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0569 - val_loss: 0.0176\n",
      "Epoch 11/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0560 - val_loss: 0.0174\n",
      "Epoch 12/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0552 - val_loss: 0.0172\n",
      "Epoch 13/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0545 - val_loss: 0.0171\n",
      "Epoch 14/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0539 - val_loss: 0.0169\n",
      "Epoch 15/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0533 - val_loss: 0.0168\n",
      "Epoch 16/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0528 - val_loss: 0.0167\n",
      "Epoch 17/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0524 - val_loss: 0.0166\n",
      "Epoch 18/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0519 - val_loss: 0.0165\n",
      "Epoch 19/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0516 - val_loss: 0.0165\n",
      "Epoch 20/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0512 - val_loss: 0.0164\n",
      "Epoch 21/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0509 - val_loss: 0.0163\n",
      "Epoch 22/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0505 - val_loss: 0.0163\n",
      "Epoch 23/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0502 - val_loss: 0.0162\n",
      "Epoch 24/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0500 - val_loss: 0.0162\n",
      "Epoch 25/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0497 - val_loss: 0.0161\n",
      "Epoch 26/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0495 - val_loss: 0.0161\n",
      "Epoch 27/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0492 - val_loss: 0.0161\n",
      "Epoch 28/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0490 - val_loss: 0.0160\n",
      "Epoch 29/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0488 - val_loss: 0.0160\n",
      "Epoch 30/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0486 - val_loss: 0.0159\n",
      "Epoch 31/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0485 - val_loss: 0.0159\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0483 - val_loss: 0.0158\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0481 - val_loss: 0.0158\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0480 - val_loss: 0.0158\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0479 - val_loss: 0.0157\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0477 - val_loss: 0.0157\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0476 - val_loss: 0.0157\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0475 - val_loss: 0.0156\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0474 - val_loss: 0.0156\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0473 - val_loss: 0.0156\n",
      "49/49 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1560, 67), test_y.shape=(1560, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 149408746.52177918, my average MASE = 566572768.961764\n",
      "Cluster 6, 149408746.52177918\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5377 - val_loss: 0.4682\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5358 - val_loss: 0.4667\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5339 - val_loss: 0.4653\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5320 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5302 - val_loss: 0.4624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5283 - val_loss: 0.4609\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5265 - val_loss: 0.4595\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5247 - val_loss: 0.4581\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5229 - val_loss: 0.4567\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5211 - val_loss: 0.4554\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5194 - val_loss: 0.4540\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5177 - val_loss: 0.4527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5160 - val_loss: 0.4514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5143 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5126 - val_loss: 0.4488\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5110 - val_loss: 0.4475\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5093 - val_loss: 0.4462\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5077 - val_loss: 0.4450\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5062 - val_loss: 0.4438\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5046 - val_loss: 0.4425\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5030 - val_loss: 0.4413\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5015 - val_loss: 0.4401\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5000 - val_loss: 0.4390\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4985 - val_loss: 0.4378\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4970 - val_loss: 0.4367\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4955 - val_loss: 0.4355\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4940 - val_loss: 0.4344\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4925 - val_loss: 0.4334\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4911 - val_loss: 0.4323\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4897 - val_loss: 0.4312\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4882 - val_loss: 0.4302\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4868 - val_loss: 0.4292\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4854 - val_loss: 0.4281\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4840 - val_loss: 0.4271\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4826 - val_loss: 0.4261\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4813 - val_loss: 0.4251\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4242\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4232\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4772 - val_loss: 0.4223\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4759 - val_loss: 0.4214\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3453236106.5511885, my average MASE = 6985920382.132476\n",
      "Cluster 7, 3453236106.5511885\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3084 - val_loss: 0.3104\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3075 - val_loss: 0.3100\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3066 - val_loss: 0.3095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3058 - val_loss: 0.3091\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3050 - val_loss: 0.3086\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3042 - val_loss: 0.3082\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3034 - val_loss: 0.3077\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3026 - val_loss: 0.3073\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3018 - val_loss: 0.3068\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3010 - val_loss: 0.3064\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3002 - val_loss: 0.3059\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2995 - val_loss: 0.3055\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2987 - val_loss: 0.3051\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2980 - val_loss: 0.3047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2973 - val_loss: 0.3043\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2965 - val_loss: 0.3039\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2958 - val_loss: 0.3035\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2951 - val_loss: 0.3031\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2944 - val_loss: 0.3027\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2937 - val_loss: 0.3024\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2930 - val_loss: 0.3020\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2924 - val_loss: 0.3017\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2917 - val_loss: 0.3014\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2911 - val_loss: 0.3011\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2904 - val_loss: 0.3008\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2898 - val_loss: 0.3006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2891 - val_loss: 0.3003\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2885 - val_loss: 0.3001\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2878 - val_loss: 0.2998\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2872 - val_loss: 0.2996\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2866 - val_loss: 0.2994\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2859 - val_loss: 0.2992\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2853 - val_loss: 0.2990\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2846 - val_loss: 0.2988\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2840 - val_loss: 0.2985\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2834 - val_loss: 0.2983\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2827 - val_loss: 0.2981\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2822 - val_loss: 0.2979\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2816 - val_loss: 0.2977\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2810 - val_loss: 0.2975\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2112740905793214, my average MASE = 0.3813496945040607\n",
      "Cluster 8, 0.2112740905793214\n",
      "Before prediction: train_X.shape=(33, 10, 67), train_y.shape=(33, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5052 - val_loss: 0.6961\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5045 - val_loss: 0.6956\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5038 - val_loss: 0.6950\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5030 - val_loss: 0.6945\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5023 - val_loss: 0.6939\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5016 - val_loss: 0.6934\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5009 - val_loss: 0.6928\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5002 - val_loss: 0.6923\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4995 - val_loss: 0.6918\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4988 - val_loss: 0.6913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.6908\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4975 - val_loss: 0.6903\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4968 - val_loss: 0.6898\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4961 - val_loss: 0.6893\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4955 - val_loss: 0.6888\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4948 - val_loss: 0.6883\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4942 - val_loss: 0.6879\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4935 - val_loss: 0.6874\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4929 - val_loss: 0.6869\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4923 - val_loss: 0.6865\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.6860\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4910 - val_loss: 0.6855\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4904 - val_loss: 0.6851\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4898 - val_loss: 0.6846\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4892 - val_loss: 0.6842\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4886 - val_loss: 0.6837\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4880 - val_loss: 0.6833\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4874 - val_loss: 0.6829\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4868 - val_loss: 0.6824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4863 - val_loss: 0.6820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4857 - val_loss: 0.6816\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4851 - val_loss: 0.6811\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4845 - val_loss: 0.6807\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4840 - val_loss: 0.6803\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4834 - val_loss: 0.6799\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4828 - val_loss: 0.6794\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6790\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4817 - val_loss: 0.6786\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4811 - val_loss: 0.6782\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4806 - val_loss: 0.6778\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 74.79960857799604, my average MASE = 23518054.91533832\n",
      "Cluster 9, 74.79960857799604\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3521 - val_loss: 0.2993\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3508 - val_loss: 0.2987\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3496 - val_loss: 0.2982\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3483 - val_loss: 0.2976\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3470 - val_loss: 0.2971\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3458 - val_loss: 0.2966\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3446 - val_loss: 0.2961\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3435 - val_loss: 0.2957\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3423 - val_loss: 0.2954\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3412 - val_loss: 0.2950\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3400 - val_loss: 0.2946\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3389 - val_loss: 0.2943\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3378 - val_loss: 0.2939\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3368 - val_loss: 0.2935\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3357 - val_loss: 0.2932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3347 - val_loss: 0.2928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3337 - val_loss: 0.2925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3326 - val_loss: 0.2921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3317 - val_loss: 0.2918\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3307 - val_loss: 0.2915\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3298 - val_loss: 0.2912\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3289 - val_loss: 0.2910\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3279 - val_loss: 0.2908\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.2905\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3261 - val_loss: 0.2903\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3252 - val_loss: 0.2901\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3244 - val_loss: 0.2899\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.2897\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3227 - val_loss: 0.2895\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3219 - val_loss: 0.2894\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3211 - val_loss: 0.2892\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3203 - val_loss: 0.2891\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3195 - val_loss: 0.2890\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3187 - val_loss: 0.2889\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3179 - val_loss: 0.2888\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3171 - val_loss: 0.2887\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3163 - val_loss: 0.2886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3155 - val_loss: 0.2886\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.2885\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3139 - val_loss: 0.2885\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.1864435054204945, my average MASE = 0.27675363785512175\n",
      "Cluster 10, 0.1864435054204945\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=2, 2, 18, (30612, 67)\n",
      "Before prediction: train_X.shape=(18361, 10, 67), train_y.shape=(18361, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.3015 - val_loss: 0.3194\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2836 - val_loss: 0.3051\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2695 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2585 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2510 - val_loss: 0.2789\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2456 - val_loss: 0.2737\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2410 - val_loss: 0.2693\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2369 - val_loss: 0.2653\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2332 - val_loss: 0.2616\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2298 - val_loss: 0.2584\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2267 - val_loss: 0.2555\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2238 - val_loss: 0.2531\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2212 - val_loss: 0.2509\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2190 - val_loss: 0.2490\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2172 - val_loss: 0.2474\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2156 - val_loss: 0.2461\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2143 - val_loss: 0.2448\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2120 - val_loss: 0.2428\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2110 - val_loss: 0.2420\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2101 - val_loss: 0.2412\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2092 - val_loss: 0.2404\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2084 - val_loss: 0.2395\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2077 - val_loss: 0.2390\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2070 - val_loss: 0.2383\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2064 - val_loss: 0.2377\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2058 - val_loss: 0.2371\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2052 - val_loss: 0.2365\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2047 - val_loss: 0.2361\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2041 - val_loss: 0.2356\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2352\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2032 - val_loss: 0.2348\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2020 - val_loss: 0.2336\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2016 - val_loss: 0.2332\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2013 - val_loss: 0.2329\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2009 - val_loss: 0.2327\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2006 - val_loss: 0.2324\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2321\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2046.5122369835897, my average MASE = 2805.5341357338157\n",
      "Cluster 0, 2046.5122369835897\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5756 - val_loss: 1.2952\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5738 - val_loss: 1.2950\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5721 - val_loss: 1.2949\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5703 - val_loss: 1.2948\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5686 - val_loss: 1.2947\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5670 - val_loss: 1.2946\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5653 - val_loss: 1.2945\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5637 - val_loss: 1.2944\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5621 - val_loss: 1.2943\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5605 - val_loss: 1.2941\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5589 - val_loss: 1.2940\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5573 - val_loss: 1.2939\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5558 - val_loss: 1.2937\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5542 - val_loss: 1.2936\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5527 - val_loss: 1.2934\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5512 - val_loss: 1.2932\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5497 - val_loss: 1.2930\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 1.2929\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5468 - val_loss: 1.2927\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 1.2925\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5440 - val_loss: 1.2924\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5426 - val_loss: 1.2922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5413 - val_loss: 1.2921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5400 - val_loss: 1.2920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5386 - val_loss: 1.2919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5374 - val_loss: 1.2918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 1.2918\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5349 - val_loss: 1.2917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5337 - val_loss: 1.2916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5325 - val_loss: 1.2915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5314 - val_loss: 1.2914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5302 - val_loss: 1.2912\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5290 - val_loss: 1.2911\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5279 - val_loss: 1.2909\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5268 - val_loss: 1.2907\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5256 - val_loss: 1.2905\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5246 - val_loss: 1.2903\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5235 - val_loss: 1.2902\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5224 - val_loss: 1.2901\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5213 - val_loss: 1.2900\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 950350834.5172157, my average MASE = 2745439088.6097794\n",
      "Cluster 1, 950350834.5172157\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=5, 5, 599, (8, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3119 - val_loss: 0.2829\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3116 - val_loss: 0.2829\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3112 - val_loss: 0.2828\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3109 - val_loss: 0.2828\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3106 - val_loss: 0.2828\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3102 - val_loss: 0.2827\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3099 - val_loss: 0.2827\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3096 - val_loss: 0.2827\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3092 - val_loss: 0.2827\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3089 - val_loss: 0.2826\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3086 - val_loss: 0.2826\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3083 - val_loss: 0.2826\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3080 - val_loss: 0.2826\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3077 - val_loss: 0.2825\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3074 - val_loss: 0.2825\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3070 - val_loss: 0.2825\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3067 - val_loss: 0.2825\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3064 - val_loss: 0.2824\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3061 - val_loss: 0.2824\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3058 - val_loss: 0.2824\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3055 - val_loss: 0.2823\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3052 - val_loss: 0.2823\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3049 - val_loss: 0.2823\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3047 - val_loss: 0.2822\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3044 - val_loss: 0.2822\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3041 - val_loss: 0.2822\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3038 - val_loss: 0.2821\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3035 - val_loss: 0.2821\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3032 - val_loss: 0.2821\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3029 - val_loss: 0.2820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3027 - val_loss: 0.2820\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3024 - val_loss: 0.2820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3021 - val_loss: 0.2819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.2819\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3016 - val_loss: 0.2818\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3013 - val_loss: 0.2818\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3010 - val_loss: 0.2818\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3008 - val_loss: 0.2817\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3005 - val_loss: 0.2817\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3002 - val_loss: 0.2816\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 104.97029321074898, my average MASE = 15924142.879668588\n",
      "Cluster 0, 104.97029321074898\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5420 - val_loss: 0.4071\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5399 - val_loss: 0.4062\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5378 - val_loss: 0.4054\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5357 - val_loss: 0.4045\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5337 - val_loss: 0.4037\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5316 - val_loss: 0.4029\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5296 - val_loss: 0.4021\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5276 - val_loss: 0.4013\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5257 - val_loss: 0.4005\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5237 - val_loss: 0.3998\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5218 - val_loss: 0.3990\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5199 - val_loss: 0.3983\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5179 - val_loss: 0.3975\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5161 - val_loss: 0.3968\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5142 - val_loss: 0.3961\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5124 - val_loss: 0.3954\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5106 - val_loss: 0.3947\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5088 - val_loss: 0.3940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5070 - val_loss: 0.3933\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5052 - val_loss: 0.3926\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5035 - val_loss: 0.3919\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5018 - val_loss: 0.3913\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5001 - val_loss: 0.3906\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4985 - val_loss: 0.3899\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4968 - val_loss: 0.3892\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.3886\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4936 - val_loss: 0.3879\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4920 - val_loss: 0.3873\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4905 - val_loss: 0.3866\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4889 - val_loss: 0.3860\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4874 - val_loss: 0.3853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4858 - val_loss: 0.3847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4843 - val_loss: 0.3840\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4828 - val_loss: 0.3834\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4813 - val_loss: 0.3828\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4798 - val_loss: 0.3821\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4783 - val_loss: 0.3815\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4769 - val_loss: 0.3809\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4754 - val_loss: 0.3803\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4740 - val_loss: 0.3797\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3145368812.0062547, my average MASE = 5974295545.526059\n",
      "Cluster 1, 3145368812.0062547\n",
      "Before prediction: train_X.shape=(2220, 10, 67), train_y.shape=(2220, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.5043 - val_loss: 0.3721\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4967 - val_loss: 0.3684\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4907 - val_loss: 0.3653\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4855 - val_loss: 0.3625\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4810 - val_loss: 0.3601\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4769 - val_loss: 0.3579\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4731 - val_loss: 0.3558\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4695 - val_loss: 0.3540\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4661 - val_loss: 0.3522\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4629 - val_loss: 0.3506\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4598 - val_loss: 0.3490\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4568 - val_loss: 0.3476\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4539 - val_loss: 0.3462\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4510 - val_loss: 0.3448\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4483 - val_loss: 0.3435\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4455 - val_loss: 0.3422\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4429 - val_loss: 0.3410\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4402 - val_loss: 0.3398\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4376 - val_loss: 0.3386\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4351 - val_loss: 0.3375\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4326 - val_loss: 0.3363\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4302 - val_loss: 0.3352\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4278 - val_loss: 0.3342\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4255 - val_loss: 0.3331\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4232 - val_loss: 0.3321\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4211 - val_loss: 0.3311\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4189 - val_loss: 0.3302\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4169 - val_loss: 0.3292\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4149 - val_loss: 0.3284\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4129 - val_loss: 0.3276\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4111 - val_loss: 0.3268\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4093 - val_loss: 0.3260\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4076 - val_loss: 0.3253\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4060 - val_loss: 0.3246\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4044 - val_loss: 0.3240\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4029 - val_loss: 0.3234\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4014 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4000 - val_loss: 0.3222\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3986 - val_loss: 0.3217\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3972 - val_loss: 0.3211\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 487.922050733615, my average MASE = 1880.6635092100216\n",
      "Cluster 2, 487.922050733615\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1089 - val_loss: 0.0991\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1039 - val_loss: 0.0970\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0998 - val_loss: 0.0956\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0965 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0938\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0911 - val_loss: 0.0932\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0889 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0869 - val_loss: 0.0924\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0852 - val_loss: 0.0922\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0836 - val_loss: 0.0920\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0821 - val_loss: 0.0918\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0808 - val_loss: 0.0917\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0795 - val_loss: 0.0915\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0783 - val_loss: 0.0913\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0773 - val_loss: 0.0912\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0763 - val_loss: 0.0910\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0908\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0744 - val_loss: 0.0907\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0736 - val_loss: 0.0905\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0903\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0901\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0900\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0708 - val_loss: 0.0899\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0897\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0696 - val_loss: 0.0896\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0690 - val_loss: 0.0895\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0894\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0680 - val_loss: 0.0893\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0675 - val_loss: 0.0892\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0892\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0666 - val_loss: 0.0891\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0661 - val_loss: 0.0890\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0658 - val_loss: 0.0890\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0654 - val_loss: 0.0889\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0650 - val_loss: 0.0889\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0647 - val_loss: 0.0888\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0644 - val_loss: 0.0888\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0888\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0887\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0636 - val_loss: 0.0887\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1152398695.5185678, my average MASE = 7118534712.468365\n",
      "Cluster 3, 1152398695.5185678\n",
      "Before prediction: train_X.shape=(156, 10, 67), train_y.shape=(156, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5146 - val_loss: 0.4378\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5133 - val_loss: 0.4370\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5122 - val_loss: 0.4361\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5111 - val_loss: 0.4352\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5100 - val_loss: 0.4344\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5089 - val_loss: 0.4335\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5078 - val_loss: 0.4327\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5068 - val_loss: 0.4319\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5057 - val_loss: 0.4311\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4303\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5037 - val_loss: 0.4296\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5028 - val_loss: 0.4288\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5018 - val_loss: 0.4281\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5008 - val_loss: 0.4273\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4999 - val_loss: 0.4266\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4990 - val_loss: 0.4259\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4981 - val_loss: 0.4252\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4972 - val_loss: 0.4245\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4963 - val_loss: 0.4238\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4954 - val_loss: 0.4232\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4945 - val_loss: 0.4225\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4937 - val_loss: 0.4219\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4929 - val_loss: 0.4213\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4920 - val_loss: 0.4207\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4912 - val_loss: 0.4201\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4905 - val_loss: 0.4195\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4897 - val_loss: 0.4189\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4889 - val_loss: 0.4183\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4881 - val_loss: 0.4177\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4874 - val_loss: 0.4172\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4867 - val_loss: 0.4166\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4859 - val_loss: 0.4161\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4852 - val_loss: 0.4155\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4845 - val_loss: 0.4150\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4838 - val_loss: 0.4145\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4831 - val_loss: 0.4139\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4824 - val_loss: 0.4134\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4817 - val_loss: 0.4129\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4811 - val_loss: 0.4124\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4804 - val_loss: 0.4119\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 117.29272898284657, my average MASE = 138077149.3198319\n",
      "Cluster 4, 117.29272898284657\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=7, 7, 49, (317, 67)\n",
      "Before prediction: train_X.shape=(184, 10, 67), train_y.shape=(184, 67), test_X.shape=(61, 10, 67), test_y.shape=(61, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6997 - val_loss: 0.6374\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6982 - val_loss: 0.6363\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6968 - val_loss: 0.6352\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6954 - val_loss: 0.6341\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.6331\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6927 - val_loss: 0.6320\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.6310\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6901 - val_loss: 0.6300\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6889 - val_loss: 0.6290\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6876 - val_loss: 0.6281\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6864 - val_loss: 0.6272\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6852 - val_loss: 0.6262\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6840 - val_loss: 0.6253\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6829 - val_loss: 0.6244\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6818 - val_loss: 0.6235\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6807 - val_loss: 0.6227\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6796 - val_loss: 0.6218\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6785 - val_loss: 0.6210\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6774 - val_loss: 0.6202\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6763 - val_loss: 0.6194\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.6186\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6743 - val_loss: 0.6178\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6733 - val_loss: 0.6171\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6723 - val_loss: 0.6163\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6713 - val_loss: 0.6156\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6704 - val_loss: 0.6149\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6694 - val_loss: 0.6142\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6685 - val_loss: 0.6135\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6676 - val_loss: 0.6127\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6666 - val_loss: 0.6121\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6658 - val_loss: 0.6114\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6649 - val_loss: 0.6107\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6640 - val_loss: 0.6100\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6631 - val_loss: 0.6093\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6622 - val_loss: 0.6086\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6614 - val_loss: 0.6079\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6605 - val_loss: 0.6073\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6597 - val_loss: 0.6066\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6588 - val_loss: 0.6060\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6580 - val_loss: 0.6053\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(61, 67), test_y.shape=(61, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 140.79883300988942, my average MASE = 132025753.41047312\n",
      "Cluster 0, 140.79883300988942\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5180 - val_loss: 0.4305\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5161 - val_loss: 0.4294\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5142 - val_loss: 0.4283\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5123 - val_loss: 0.4272\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5104 - val_loss: 0.4261\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5085 - val_loss: 0.4251\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5067 - val_loss: 0.4241\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5049 - val_loss: 0.4230\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.4221\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5013 - val_loss: 0.4211\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4996 - val_loss: 0.4202\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4978 - val_loss: 0.4193\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4961 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4944 - val_loss: 0.4175\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4927 - val_loss: 0.4166\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4911 - val_loss: 0.4158\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4895 - val_loss: 0.4149\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4879 - val_loss: 0.4141\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4863 - val_loss: 0.4133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4847 - val_loss: 0.4126\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4118\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4816 - val_loss: 0.4110\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4801 - val_loss: 0.4103\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4787 - val_loss: 0.4095\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4772 - val_loss: 0.4088\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4758 - val_loss: 0.4080\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4743 - val_loss: 0.4073\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4729 - val_loss: 0.4066\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4715 - val_loss: 0.4058\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4701 - val_loss: 0.4051\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4687 - val_loss: 0.4044\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4673 - val_loss: 0.4038\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4660 - val_loss: 0.4031\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4646 - val_loss: 0.4024\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4633 - val_loss: 0.4017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4620 - val_loss: 0.4010\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4607 - val_loss: 0.4004\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4594 - val_loss: 0.3997\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4582 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4569 - val_loss: 0.3985\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3225148693.3924103, my average MASE = 6345532768.562708\n",
      "Cluster 1, 3225148693.3924103\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1129 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1075 - val_loss: 0.0981\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1032 - val_loss: 0.0968\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0996 - val_loss: 0.0960\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0965 - val_loss: 0.0953\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0938 - val_loss: 0.0949\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0913 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0892 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0872 - val_loss: 0.0938\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0854 - val_loss: 0.0935\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0838 - val_loss: 0.0933\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0823 - val_loss: 0.0931\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0809 - val_loss: 0.0928\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0796 - val_loss: 0.0926\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0784 - val_loss: 0.0924\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0773 - val_loss: 0.0921\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0762 - val_loss: 0.0919\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0752 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0743 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0734 - val_loss: 0.0913\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0726 - val_loss: 0.0912\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0719 - val_loss: 0.0910\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0907\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0699 - val_loss: 0.0906\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0693 - val_loss: 0.0904\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0687 - val_loss: 0.0903\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0682 - val_loss: 0.0903\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0677 - val_loss: 0.0902\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0901\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0668 - val_loss: 0.0901\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0663 - val_loss: 0.0900\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0899\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0655 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0898\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0648 - val_loss: 0.0897\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0645 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0636 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1209643109.1461504, my average MASE = 20216236756.2103\n",
      "Cluster 2, 1209643109.1461504\n",
      "Before prediction: train_X.shape=(47, 10, 67), train_y.shape=(47, 67), test_X.shape=(16, 10, 67), test_y.shape=(16, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4112 - val_loss: 0.3544\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.3542\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4104 - val_loss: 0.3540\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4100 - val_loss: 0.3538\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4095 - val_loss: 0.3536\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4091 - val_loss: 0.3534\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4087 - val_loss: 0.3533\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4083 - val_loss: 0.3531\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4079 - val_loss: 0.3529\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4075 - val_loss: 0.3527\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4071 - val_loss: 0.3525\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4067 - val_loss: 0.3524\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4063 - val_loss: 0.3522\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4059 - val_loss: 0.3520\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4055 - val_loss: 0.3519\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4051 - val_loss: 0.3517\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4047 - val_loss: 0.3515\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4043 - val_loss: 0.3514\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4039 - val_loss: 0.3512\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3511\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4032 - val_loss: 0.3509\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4028 - val_loss: 0.3508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4024 - val_loss: 0.3506\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4020 - val_loss: 0.3505\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4017 - val_loss: 0.3503\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4009 - val_loss: 0.3501\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4006 - val_loss: 0.3499\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4002 - val_loss: 0.3498\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3999 - val_loss: 0.3497\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.3495\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3992 - val_loss: 0.3494\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.3493\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3985 - val_loss: 0.3492\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3982 - val_loss: 0.3491\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3978 - val_loss: 0.3489\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3975 - val_loss: 0.3488\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3972 - val_loss: 0.3487\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3968 - val_loss: 0.3486\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3965 - val_loss: 0.3485\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(16, 67), test_y.shape=(16, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 66.79284837728264, my average MASE = 54990938.33317367\n",
      "Cluster 3, 66.79284837728264\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5009 - val_loss: 0.4222\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4998 - val_loss: 0.4214\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4988 - val_loss: 0.4207\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4978 - val_loss: 0.4200\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4968 - val_loss: 0.4193\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4958 - val_loss: 0.4186\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4949 - val_loss: 0.4179\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4939 - val_loss: 0.4172\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4930 - val_loss: 0.4165\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4921 - val_loss: 0.4159\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4912 - val_loss: 0.4153\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4903 - val_loss: 0.4146\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4894 - val_loss: 0.4140\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4886 - val_loss: 0.4134\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4877 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4869 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4861 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4853 - val_loss: 0.4111\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4845 - val_loss: 0.4105\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4837 - val_loss: 0.4100\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4829 - val_loss: 0.4094\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4822 - val_loss: 0.4089\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4814 - val_loss: 0.4084\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4807 - val_loss: 0.4078\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4799 - val_loss: 0.4073\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4792 - val_loss: 0.4068\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4785 - val_loss: 0.4063\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4777 - val_loss: 0.4058\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4770 - val_loss: 0.4052\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4763 - val_loss: 0.4047\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4756 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4749 - val_loss: 0.4037\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4742 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4735 - val_loss: 0.4027\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4728 - val_loss: 0.4023\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4721 - val_loss: 0.4018\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4715 - val_loss: 0.4013\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4708 - val_loss: 0.4008\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4701 - val_loss: 0.4003\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4695 - val_loss: 0.3999\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.45341483860946, my average MASE = 95916870.45268953\n",
      "Cluster 4, 127.45341483860946\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2476 - val_loss: 0.2883\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2353 - val_loss: 0.2762\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2258 - val_loss: 0.2666\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2185 - val_loss: 0.2589\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2127 - val_loss: 0.2526\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2078 - val_loss: 0.2473\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2036 - val_loss: 0.2426\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1999 - val_loss: 0.2383\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1966 - val_loss: 0.2346\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1935 - val_loss: 0.2311\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1907 - val_loss: 0.2280\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1881 - val_loss: 0.2251\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1857 - val_loss: 0.2225\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1834 - val_loss: 0.2200\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1813 - val_loss: 0.2178\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1794 - val_loss: 0.2157\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1777 - val_loss: 0.2137\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1760 - val_loss: 0.2120\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1746 - val_loss: 0.2103\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1732 - val_loss: 0.2087\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1719 - val_loss: 0.2072\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1707 - val_loss: 0.2058\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1695 - val_loss: 0.2045\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2032\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1674 - val_loss: 0.2020\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1664 - val_loss: 0.2009\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1655 - val_loss: 0.1998\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1646 - val_loss: 0.1988\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1638 - val_loss: 0.1978\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1630 - val_loss: 0.1968\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1622 - val_loss: 0.1960\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1614 - val_loss: 0.1951\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1607 - val_loss: 0.1943\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1600 - val_loss: 0.1935\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1594 - val_loss: 0.1927\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1587 - val_loss: 0.1920\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1913\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1575 - val_loss: 0.1906\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1570 - val_loss: 0.1899\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1893\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 224.71735313764052, my average MASE = 374017026.3746446\n",
      "Cluster 5, 224.71735313764052\n",
      "Before prediction: train_X.shape=(51, 10, 67), train_y.shape=(51, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4065 - val_loss: 0.3790\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4060 - val_loss: 0.3788\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4055 - val_loss: 0.3787\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4049 - val_loss: 0.3786\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4044 - val_loss: 0.3784\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4038 - val_loss: 0.3783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4033 - val_loss: 0.3782\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4028 - val_loss: 0.3780\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4023 - val_loss: 0.3779\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4018 - val_loss: 0.3778\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4013 - val_loss: 0.3776\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3775\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4003 - val_loss: 0.3774\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3773\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3993 - val_loss: 0.3771\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3988 - val_loss: 0.3770\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3984 - val_loss: 0.3769\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3768\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3975 - val_loss: 0.3767\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3970 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3966 - val_loss: 0.3764\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3763\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3762\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3953 - val_loss: 0.3761\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3949 - val_loss: 0.3760\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3945 - val_loss: 0.3759\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3941 - val_loss: 0.3757\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3937 - val_loss: 0.3756\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3933 - val_loss: 0.3755\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3929 - val_loss: 0.3754\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3925 - val_loss: 0.3753\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3921 - val_loss: 0.3752\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3917 - val_loss: 0.3751\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3913 - val_loss: 0.3750\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3749\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3905 - val_loss: 0.3748\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3902 - val_loss: 0.3747\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3898 - val_loss: 0.3745\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3894 - val_loss: 0.3744\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3891 - val_loss: 0.3743\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 82.26261385879712, my average MASE = 20260153.97451399\n",
      "Cluster 6, 82.26261385879712\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=9, 9, 48, (301, 67)\n",
      "Before prediction: train_X.shape=(174, 10, 67), train_y.shape=(174, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7089 - val_loss: 0.5627\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7074 - val_loss: 0.5619\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7059 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7045 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7031 - val_loss: 0.5598\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7017 - val_loss: 0.5591\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7004 - val_loss: 0.5585\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6991 - val_loss: 0.5578\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6979 - val_loss: 0.5572\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6966 - val_loss: 0.5566\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6954 - val_loss: 0.5559\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.5553\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6930 - val_loss: 0.5548\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6918 - val_loss: 0.5542\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6907 - val_loss: 0.5536\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6895 - val_loss: 0.5531\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6884 - val_loss: 0.5525\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6873 - val_loss: 0.5520\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6863 - val_loss: 0.5515\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6852 - val_loss: 0.5509\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6842 - val_loss: 0.5504\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6831 - val_loss: 0.5499\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6821 - val_loss: 0.5494\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6811 - val_loss: 0.5489\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6801 - val_loss: 0.5484\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6792 - val_loss: 0.5479\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6782 - val_loss: 0.5475\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6772 - val_loss: 0.5470\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.5465\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.5461\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6744 - val_loss: 0.5456\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6735 - val_loss: 0.5452\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6726 - val_loss: 0.5447\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5443\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6707 - val_loss: 0.5439\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6698 - val_loss: 0.5434\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6689 - val_loss: 0.5430\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6680 - val_loss: 0.5426\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6671 - val_loss: 0.5422\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6663 - val_loss: 0.5417\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 144.45290178213432, my average MASE = 192607450.5447097\n",
      "Cluster 0, 144.45290178213432\n",
      "Before prediction: train_X.shape=(86, 10, 67), train_y.shape=(86, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3954 - val_loss: 0.4825\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3947 - val_loss: 0.4820\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3940 - val_loss: 0.4815\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3933 - val_loss: 0.4810\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3927 - val_loss: 0.4806\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3921 - val_loss: 0.4801\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4797\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3909 - val_loss: 0.4793\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3903 - val_loss: 0.4789\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3898 - val_loss: 0.4785\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3892 - val_loss: 0.4781\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3887 - val_loss: 0.4777\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4774\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3877 - val_loss: 0.4770\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3872 - val_loss: 0.4767\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4763\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3862 - val_loss: 0.4760\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.4757\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3853 - val_loss: 0.4753\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3848 - val_loss: 0.4750\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3844 - val_loss: 0.4747\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3840 - val_loss: 0.4744\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3835 - val_loss: 0.4741\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3831 - val_loss: 0.4738\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3827 - val_loss: 0.4735\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3822 - val_loss: 0.4732\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3818 - val_loss: 0.4729\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3814 - val_loss: 0.4726\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3810 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3806 - val_loss: 0.4720\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3802 - val_loss: 0.4717\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3798 - val_loss: 0.4714\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.4711\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3790 - val_loss: 0.4708\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3786 - val_loss: 0.4705\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3783 - val_loss: 0.4703\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3779 - val_loss: 0.4700\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3775 - val_loss: 0.4697\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3771 - val_loss: 0.4695\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3768 - val_loss: 0.4692\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 261.83661307224526, my average MASE = 165152999.01271424\n",
      "Cluster 1, 261.83661307224526\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3860 - val_loss: 0.4764\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3839 - val_loss: 0.4752\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3818 - val_loss: 0.4741\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3798 - val_loss: 0.4730\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3778 - val_loss: 0.4719\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3758 - val_loss: 0.4709\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3738 - val_loss: 0.4699\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3718 - val_loss: 0.4689\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3699 - val_loss: 0.4680\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3680 - val_loss: 0.4670\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4660\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3643 - val_loss: 0.4650\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.4640\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3606 - val_loss: 0.4630\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3588 - val_loss: 0.4620\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3570 - val_loss: 0.4610\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3553 - val_loss: 0.4599\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3535 - val_loss: 0.4588\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3518 - val_loss: 0.4578\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3501 - val_loss: 0.4567\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3484 - val_loss: 0.4557\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.4547\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3452 - val_loss: 0.4537\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3437 - val_loss: 0.4528\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3422 - val_loss: 0.4521\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3407 - val_loss: 0.4513\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.4506\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3378 - val_loss: 0.4498\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3363 - val_loss: 0.4493\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3349 - val_loss: 0.4487\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3336 - val_loss: 0.4481\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3323 - val_loss: 0.4475\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3311 - val_loss: 0.4470\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3299 - val_loss: 0.4464\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3287 - val_loss: 0.4459\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3276 - val_loss: 0.4453\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3264 - val_loss: 0.4447\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3253 - val_loss: 0.4441\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3241 - val_loss: 0.4436\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3231 - val_loss: 0.4430\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.29600762869721386, my average MASE = 0.4272698543687938\n",
      "Cluster 2, 0.29600762869721386\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4866 - val_loss: 0.4310\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4848 - val_loss: 0.4300\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4830 - val_loss: 0.4290\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4812 - val_loss: 0.4280\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.4271\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4777 - val_loss: 0.4261\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4760 - val_loss: 0.4252\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4744 - val_loss: 0.4243\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4727 - val_loss: 0.4235\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4711 - val_loss: 0.4226\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4695 - val_loss: 0.4217\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4679 - val_loss: 0.4209\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4663 - val_loss: 0.4200\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4648 - val_loss: 0.4192\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4633 - val_loss: 0.4184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4618 - val_loss: 0.4175\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4603 - val_loss: 0.4167\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4589 - val_loss: 0.4159\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4574 - val_loss: 0.4150\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4560 - val_loss: 0.4142\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4546 - val_loss: 0.4134\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4532 - val_loss: 0.4126\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4518 - val_loss: 0.4118\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4504 - val_loss: 0.4109\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4491 - val_loss: 0.4101\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4477 - val_loss: 0.4093\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4464 - val_loss: 0.4085\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4451 - val_loss: 0.4077\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4438 - val_loss: 0.4069\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4425 - val_loss: 0.4061\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4412 - val_loss: 0.4053\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4399 - val_loss: 0.4045\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4387 - val_loss: 0.4037\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4029\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4362 - val_loss: 0.4021\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4350 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4337 - val_loss: 0.4006\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4325 - val_loss: 0.3998\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4313 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4301 - val_loss: 0.3983\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3346396028.9972167, my average MASE = 7814754000.575592\n",
      "Cluster 3, 3346396028.9972167\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3142 - val_loss: 0.7771\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3138 - val_loss: 0.7770\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3135 - val_loss: 0.7769\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3131 - val_loss: 0.7768\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3127 - val_loss: 0.7767\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3123 - val_loss: 0.7765\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3119 - val_loss: 0.7764\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3116 - val_loss: 0.7763\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3112 - val_loss: 0.7762\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3108 - val_loss: 0.7761\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3105 - val_loss: 0.7759\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3101 - val_loss: 0.7758\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3097 - val_loss: 0.7757\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3094 - val_loss: 0.7756\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3090 - val_loss: 0.7755\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3087 - val_loss: 0.7754\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3083 - val_loss: 0.7753\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3080 - val_loss: 0.7752\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3076 - val_loss: 0.7751\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3073 - val_loss: 0.7749\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3069 - val_loss: 0.7748\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3066 - val_loss: 0.7747\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3063 - val_loss: 0.7746\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3059 - val_loss: 0.7746\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3056 - val_loss: 0.7745\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3053 - val_loss: 0.7744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3049 - val_loss: 0.7743\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3046 - val_loss: 0.7742\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3043 - val_loss: 0.7741\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3040 - val_loss: 0.7740\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3037 - val_loss: 0.7739\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3033 - val_loss: 0.7739\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3030 - val_loss: 0.7738\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3027 - val_loss: 0.7737\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3024 - val_loss: 0.7736\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3021 - val_loss: 0.7735\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.7734\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3015 - val_loss: 0.7733\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3012 - val_loss: 0.7732\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3009 - val_loss: 0.7731\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 93.69104182165661, my average MASE = 20945629.206220664\n",
      "Cluster 4, 93.69104182165661\n",
      "Before prediction: train_X.shape=(89, 10, 67), train_y.shape=(89, 67), test_X.shape=(30, 10, 67), test_y.shape=(30, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3424 - val_loss: 0.3360\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3416 - val_loss: 0.3355\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3408 - val_loss: 0.3350\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3400 - val_loss: 0.3346\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.3341\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3386 - val_loss: 0.3337\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3379 - val_loss: 0.3333\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3372 - val_loss: 0.3329\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3365 - val_loss: 0.3324\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3358 - val_loss: 0.3320\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3351 - val_loss: 0.3316\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3344 - val_loss: 0.3312\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3338 - val_loss: 0.3309\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3331 - val_loss: 0.3305\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3325 - val_loss: 0.3301\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3319 - val_loss: 0.3297\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3312 - val_loss: 0.3293\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3306 - val_loss: 0.3290\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3300 - val_loss: 0.3286\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3294 - val_loss: 0.3282\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3288 - val_loss: 0.3279\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3282 - val_loss: 0.3275\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3276 - val_loss: 0.3272\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3271 - val_loss: 0.3268\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3265 - val_loss: 0.3265\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3260 - val_loss: 0.3262\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3254 - val_loss: 0.3258\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3249 - val_loss: 0.3255\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3244 - val_loss: 0.3252\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.3249\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3234 - val_loss: 0.3246\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3228 - val_loss: 0.3243\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3223 - val_loss: 0.3240\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3237\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3214 - val_loss: 0.3234\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3231\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3204 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3199 - val_loss: 0.3225\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3195 - val_loss: 0.3222\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3190 - val_loss: 0.3219\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(30, 67), test_y.shape=(30, 67)\n",
      "average MASE = 188.45046029060867, my average MASE = 121680879.21353056\n",
      "Cluster 5, 188.45046029060867\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1120 - val_loss: 0.1007\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0987\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1025 - val_loss: 0.0974\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0990 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0960 - val_loss: 0.0954\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0933 - val_loss: 0.0947\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0942\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0888 - val_loss: 0.0938\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0868 - val_loss: 0.0934\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0931\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0834 - val_loss: 0.0928\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0819 - val_loss: 0.0926\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0806 - val_loss: 0.0923\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0793 - val_loss: 0.0921\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0781 - val_loss: 0.0919\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0770 - val_loss: 0.0917\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0759 - val_loss: 0.0916\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0749 - val_loss: 0.0914\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0740 - val_loss: 0.0912\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0732 - val_loss: 0.0911\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0724 - val_loss: 0.0910\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0716 - val_loss: 0.0909\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0709 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0908\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0695 - val_loss: 0.0907\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0689 - val_loss: 0.0906\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0683 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0678 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0673 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0660 - val_loss: 0.0902\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0901\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0900\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0645 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0637 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0634 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1073797047.1669116, my average MASE = 13075073766.705614\n",
      "Cluster 6, 1073797047.1669116\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2348 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2252 - val_loss: 0.2653\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2178 - val_loss: 0.2575\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2120 - val_loss: 0.2511\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2071 - val_loss: 0.2457\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2029 - val_loss: 0.2409\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1991 - val_loss: 0.2366\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1956 - val_loss: 0.2328\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1924 - val_loss: 0.2293\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1895 - val_loss: 0.2261\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1868 - val_loss: 0.2231\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2203\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1820 - val_loss: 0.2178\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1799 - val_loss: 0.2155\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1762 - val_loss: 0.2114\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1745 - val_loss: 0.2096\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1730 - val_loss: 0.2079\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1715 - val_loss: 0.2063\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1702 - val_loss: 0.2048\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1689 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1678 - val_loss: 0.2020\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1666 - val_loss: 0.2007\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1656 - val_loss: 0.1995\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1646 - val_loss: 0.1984\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1636 - val_loss: 0.1973\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1627 - val_loss: 0.1962\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1619 - val_loss: 0.1952\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1610 - val_loss: 0.1943\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1934\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1595 - val_loss: 0.1925\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1588 - val_loss: 0.1917\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1909\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1574 - val_loss: 0.1901\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1568 - val_loss: 0.1894\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1886\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1556 - val_loss: 0.1880\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1550 - val_loss: 0.1873\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1867\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1539 - val_loss: 0.1860\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 180.26488918007823, my average MASE = 179278352.44392422\n",
      "Cluster 7, 180.26488918007823\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=11, 11, 904, (6, 67)\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3401 - val_loss: 0.3875\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3395 - val_loss: 0.3872\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3390 - val_loss: 0.3870\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3385 - val_loss: 0.3868\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3380 - val_loss: 0.3866\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3375 - val_loss: 0.3863\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3370 - val_loss: 0.3861\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3366 - val_loss: 0.3859\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3361 - val_loss: 0.3856\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3357 - val_loss: 0.3854\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3352 - val_loss: 0.3852\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3348 - val_loss: 0.3850\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3343 - val_loss: 0.3848\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3339 - val_loss: 0.3846\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3335 - val_loss: 0.3844\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3331 - val_loss: 0.3842\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3327 - val_loss: 0.3840\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3323 - val_loss: 0.3837\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3318 - val_loss: 0.3835\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3314 - val_loss: 0.3833\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.3831\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3307 - val_loss: 0.3829\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3303 - val_loss: 0.3827\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3825\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3295 - val_loss: 0.3823\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3292 - val_loss: 0.3821\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3288 - val_loss: 0.3820\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3284 - val_loss: 0.3818\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3281 - val_loss: 0.3816\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.3814\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3274 - val_loss: 0.3812\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.3810\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3267 - val_loss: 0.3808\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3263 - val_loss: 0.3806\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3260 - val_loss: 0.3805\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3257 - val_loss: 0.3803\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3254 - val_loss: 0.3801\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3250 - val_loss: 0.3799\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3247 - val_loss: 0.3798\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.3796\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 122.2598699731945, my average MASE = 164200403.28208458\n",
      "Cluster 0, 122.2598699731945\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5011 - val_loss: 0.7038\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5005 - val_loss: 0.7036\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4998 - val_loss: 0.7034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4991 - val_loss: 0.7032\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4984 - val_loss: 0.7030\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4978 - val_loss: 0.7028\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4971 - val_loss: 0.7026\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4964 - val_loss: 0.7024\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4958 - val_loss: 0.7022\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4951 - val_loss: 0.7020\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4945 - val_loss: 0.7017\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4938 - val_loss: 0.7015\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4932 - val_loss: 0.7014\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4926 - val_loss: 0.7012\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4919 - val_loss: 0.7010\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4913 - val_loss: 0.7008\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4907 - val_loss: 0.7006\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4901 - val_loss: 0.7004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4894 - val_loss: 0.7002\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4888 - val_loss: 0.7000\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4882 - val_loss: 0.6998\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4877 - val_loss: 0.6997\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4871 - val_loss: 0.6995\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4865 - val_loss: 0.6993\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4859 - val_loss: 0.6991\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4853 - val_loss: 0.6989\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4847 - val_loss: 0.6988\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4842 - val_loss: 0.6986\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4836 - val_loss: 0.6984\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4831 - val_loss: 0.6983\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4825 - val_loss: 0.6981\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4820 - val_loss: 0.6979\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4815 - val_loss: 0.6978\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4809 - val_loss: 0.6976\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4804 - val_loss: 0.6974\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4799 - val_loss: 0.6973\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4794 - val_loss: 0.6971\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4789 - val_loss: 0.6970\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4783 - val_loss: 0.6968\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4778 - val_loss: 0.6966\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2966824.6919978233, my average MASE = 79205816.45072892\n",
      "Cluster 1, 2966824.6919978233\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1998 - val_loss: 0.3035\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1993 - val_loss: 0.3034\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1988 - val_loss: 0.3034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1982 - val_loss: 0.3033\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1977 - val_loss: 0.3033\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1972 - val_loss: 0.3032\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1967 - val_loss: 0.3032\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1962 - val_loss: 0.3032\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1957 - val_loss: 0.3031\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1952 - val_loss: 0.3031\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1947 - val_loss: 0.3031\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1942 - val_loss: 0.3031\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1938 - val_loss: 0.3030\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1933 - val_loss: 0.3030\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1928 - val_loss: 0.3030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1924 - val_loss: 0.3030\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1919 - val_loss: 0.3030\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1915 - val_loss: 0.3030\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1911 - val_loss: 0.3030\n",
      "Epoch 19: early stopping\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 130.97936905502368, my average MASE = 132554988.34305501\n",
      "Cluster 2, 130.97936905502368\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4496 - val_loss: 0.4061\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4490 - val_loss: 0.4060\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4484 - val_loss: 0.4058\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4478 - val_loss: 0.4057\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4472 - val_loss: 0.4056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4466 - val_loss: 0.4055\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4461 - val_loss: 0.4054\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4455 - val_loss: 0.4053\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4450 - val_loss: 0.4052\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4444 - val_loss: 0.4051\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4439 - val_loss: 0.4050\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4433 - val_loss: 0.4049\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4428 - val_loss: 0.4048\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4423 - val_loss: 0.4047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4417 - val_loss: 0.4046\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4412 - val_loss: 0.4045\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4407 - val_loss: 0.4044\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4402 - val_loss: 0.4043\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4397 - val_loss: 0.4042\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4041\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4387 - val_loss: 0.4040\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4382 - val_loss: 0.4039\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4377 - val_loss: 0.4038\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4372 - val_loss: 0.4037\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4367 - val_loss: 0.4036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4362 - val_loss: 0.4035\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4357 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4352 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4032\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4343 - val_loss: 0.4031\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4338 - val_loss: 0.4030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4333 - val_loss: 0.4029\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4329 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4028\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4027\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4315 - val_loss: 0.4026\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4311 - val_loss: 0.4025\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4306 - val_loss: 0.4024\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4302 - val_loss: 0.4023\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4297 - val_loss: 0.4022\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1437.7621485075726, my average MASE = 33408169.939470924\n",
      "Cluster 3, 1437.7621485075726\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3791 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3768 - val_loss: 0.4780\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3745 - val_loss: 0.4765\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4750\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3700 - val_loss: 0.4735\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3678 - val_loss: 0.4721\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3657 - val_loss: 0.4707\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3636 - val_loss: 0.4693\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3616 - val_loss: 0.4679\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3595 - val_loss: 0.4665\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3576 - val_loss: 0.4652\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3556 - val_loss: 0.4639\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3537 - val_loss: 0.4626\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.4614\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3500 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3482 - val_loss: 0.4590\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3464 - val_loss: 0.4578\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3447 - val_loss: 0.4567\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3430 - val_loss: 0.4556\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3414 - val_loss: 0.4545\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3398 - val_loss: 0.4534\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3382 - val_loss: 0.4524\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3366 - val_loss: 0.4513\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3351 - val_loss: 0.4504\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3335 - val_loss: 0.4494\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3320 - val_loss: 0.4484\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3305 - val_loss: 0.4475\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3291 - val_loss: 0.4466\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3277 - val_loss: 0.4457\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3263 - val_loss: 0.4448\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3249 - val_loss: 0.4439\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3236 - val_loss: 0.4431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3222 - val_loss: 0.4422\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3209 - val_loss: 0.4413\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.4404\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3184 - val_loss: 0.4395\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3171 - val_loss: 0.4386\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3159 - val_loss: 0.4378\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.4369\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3135 - val_loss: 0.4360\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1399316882.5162897, my average MASE = 3857319737.5045514\n",
      "Cluster 4, 1399316882.5162897\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2312 - val_loss: 0.2708\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2231 - val_loss: 0.2627\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2165 - val_loss: 0.2559\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2110 - val_loss: 0.2500\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2061 - val_loss: 0.2449\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2018 - val_loss: 0.2403\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1979 - val_loss: 0.2361\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1944 - val_loss: 0.2322\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1912 - val_loss: 0.2287\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1882 - val_loss: 0.2255\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1854 - val_loss: 0.2224\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1829 - val_loss: 0.2197\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1806 - val_loss: 0.2172\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1785 - val_loss: 0.2150\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1767 - val_loss: 0.2129\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1750 - val_loss: 0.2110\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1734 - val_loss: 0.2093\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1720 - val_loss: 0.2077\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1707 - val_loss: 0.2061\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1695 - val_loss: 0.2047\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1683 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1672 - val_loss: 0.2021\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1661 - val_loss: 0.2009\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1651 - val_loss: 0.1997\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1641 - val_loss: 0.1986\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1632 - val_loss: 0.1975\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1623 - val_loss: 0.1965\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1615 - val_loss: 0.1955\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1599 - val_loss: 0.1937\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1577 - val_loss: 0.1912\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1570 - val_loss: 0.1904\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1897\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1558 - val_loss: 0.1890\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1552 - val_loss: 0.1883\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1547 - val_loss: 0.1877\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1542 - val_loss: 0.1871\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1537 - val_loss: 0.1864\n",
      "17/17 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n",
      "average MASE = 146.93947390831542, my average MASE = 534465305.08164215\n",
      "Cluster 5, 146.93947390831542\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3864 - val_loss: 0.3280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.3279\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3849 - val_loss: 0.3278\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3842 - val_loss: 0.3277\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3834 - val_loss: 0.3276\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3827 - val_loss: 0.3275\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3820 - val_loss: 0.3274\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3813 - val_loss: 0.3274\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.3273\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3799 - val_loss: 0.3272\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.3272\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3785 - val_loss: 0.3271\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3778 - val_loss: 0.3270\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3772 - val_loss: 0.3270\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3765 - val_loss: 0.3269\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.3269\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3753 - val_loss: 0.3268\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3746 - val_loss: 0.3268\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3740 - val_loss: 0.3267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3734 - val_loss: 0.3266\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3728 - val_loss: 0.3266\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3722 - val_loss: 0.3265\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3717 - val_loss: 0.3265\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3711 - val_loss: 0.3264\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3705 - val_loss: 0.3264\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3699 - val_loss: 0.3263\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3694 - val_loss: 0.3263\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3688 - val_loss: 0.3262\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3682 - val_loss: 0.3262\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3262\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3671 - val_loss: 0.3261\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3666 - val_loss: 0.3261\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3660 - val_loss: 0.3260\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3655 - val_loss: 0.3260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3649 - val_loss: 0.3260\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3643 - val_loss: 0.3259\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3632 - val_loss: 0.3259\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3259\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3621 - val_loss: 0.3259\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 304.5484747914777, my average MASE = 15252291.46578898\n",
      "Cluster 6, 304.5484747914777\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8703 - val_loss: 8.9197\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8672 - val_loss: 8.9197\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8642 - val_loss: 8.9196\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8613 - val_loss: 8.9196\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8586 - val_loss: 8.9196\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8558 - val_loss: 8.9195\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8532 - val_loss: 8.9194\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8506 - val_loss: 8.9194\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8480 - val_loss: 8.9193\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8455 - val_loss: 8.9192\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8431 - val_loss: 8.9192\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8407 - val_loss: 8.9191\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8383 - val_loss: 8.9190\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8360 - val_loss: 8.9189\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8337 - val_loss: 8.9188\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8315 - val_loss: 8.9187\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8293 - val_loss: 8.9187\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8271 - val_loss: 8.9186\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8250 - val_loss: 8.9185\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 8.9184\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8209 - val_loss: 8.9184\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 8.9183\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8170 - val_loss: 8.9182\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8150 - val_loss: 8.9181\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8131 - val_loss: 8.9180\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8113 - val_loss: 8.9179\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8095 - val_loss: 8.9179\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 8.9178\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8062 - val_loss: 8.9177\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8046 - val_loss: 8.9176\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8031 - val_loss: 8.9175\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8016 - val_loss: 8.9175\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8000 - val_loss: 8.9174\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7985 - val_loss: 8.9173\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7970 - val_loss: 8.9172\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7955 - val_loss: 8.9171\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7941 - val_loss: 8.9171\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7927 - val_loss: 8.9170\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7913 - val_loss: 8.9170\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7899 - val_loss: 8.9170\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 192382848.4747458, my average MASE = 882590618.8453726\n",
      "Cluster 7, 192382848.4747458\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1119 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0986\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1024 - val_loss: 0.0973\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0988 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0957 - val_loss: 0.0956\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0930 - val_loss: 0.0950\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0905 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0883 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0863 - val_loss: 0.0937\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0933\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0828 - val_loss: 0.0930\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0813 - val_loss: 0.0928\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0799 - val_loss: 0.0925\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0787 - val_loss: 0.0924\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0775 - val_loss: 0.0922\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0764 - val_loss: 0.0920\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0754 - val_loss: 0.0918\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0744 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0735 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0727 - val_loss: 0.0914\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0719 - val_loss: 0.0913\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0711 - val_loss: 0.0912\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0705 - val_loss: 0.0910\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0909\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0692 - val_loss: 0.0908\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0687 - val_loss: 0.0907\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0677 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0660 - val_loss: 0.0901\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0900\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0653 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0646 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0898\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0897\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0896\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0635 - val_loss: 0.0896\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1222984943.0994627, my average MASE = 34180380931.05725\n",
      "Cluster 8, 1222984943.0994627\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3097 - val_loss: 0.3956\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3089 - val_loss: 0.3954\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3081 - val_loss: 0.3952\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3074 - val_loss: 0.3950\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3066 - val_loss: 0.3948\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3059 - val_loss: 0.3945\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3051 - val_loss: 0.3943\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3044 - val_loss: 0.3941\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3037 - val_loss: 0.3939\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3030 - val_loss: 0.3937\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.3935\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3017 - val_loss: 0.3934\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3010 - val_loss: 0.3933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3003 - val_loss: 0.3931\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2997 - val_loss: 0.3930\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2990 - val_loss: 0.3929\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2984 - val_loss: 0.3927\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2977 - val_loss: 0.3926\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2971 - val_loss: 0.3925\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2965 - val_loss: 0.3924\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2959 - val_loss: 0.3923\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2953 - val_loss: 0.3922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2947 - val_loss: 0.3921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2941 - val_loss: 0.3920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2935 - val_loss: 0.3919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2930 - val_loss: 0.3918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2924 - val_loss: 0.3917\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.3917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2913 - val_loss: 0.3916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2907 - val_loss: 0.3915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2902 - val_loss: 0.3914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2896 - val_loss: 0.3914\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2891 - val_loss: 0.3913\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2885 - val_loss: 0.3912\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2880 - val_loss: 0.3911\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2875 - val_loss: 0.3910\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2870 - val_loss: 0.3909\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2865 - val_loss: 0.3908\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2859 - val_loss: 0.3907\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2854 - val_loss: 0.3907\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 561.7864488366092, my average MASE = 24722978.57949824\n",
      "Cluster 10, 561.7864488366092\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=2, 2, 13, (10045, 67)\n",
      "Before prediction: train_X.shape=(6020, 10, 67), train_y.shape=(6020, 67), test_X.shape=(2007, 10, 67), test_y.shape=(2007, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0647 - val_loss: 0.0484\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0596 - val_loss: 0.0453\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0565 - val_loss: 0.0429\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0542 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0523 - val_loss: 0.0394\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0508 - val_loss: 0.0381\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0495 - val_loss: 0.0370\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0484 - val_loss: 0.0360\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0475 - val_loss: 0.0351\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0467 - val_loss: 0.0344\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0461 - val_loss: 0.0338\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0454 - val_loss: 0.0333\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0328\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0444 - val_loss: 0.0323\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0440 - val_loss: 0.0320\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0435 - val_loss: 0.0316\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0313\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0428 - val_loss: 0.0311\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0308\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0306\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0304\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0415 - val_loss: 0.0303\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0412 - val_loss: 0.0301\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0410 - val_loss: 0.0300\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0298\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0297\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0296\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0294\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0293\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0292\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0397 - val_loss: 0.0291\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0396 - val_loss: 0.0291\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0395 - val_loss: 0.0290\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0394 - val_loss: 0.0289\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0393 - val_loss: 0.0289\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0288\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0287\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0390 - val_loss: 0.0287\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0389 - val_loss: 0.0286\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0388 - val_loss: 0.0286\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2007, 67), test_y.shape=(2007, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 124611449.52884135, my average MASE = 52097635280.213745\n",
      "Cluster 0, 124611449.52884135\n",
      "Before prediction: train_X.shape=(18364, 10, 67), train_y.shape=(18364, 67), test_X.shape=(6121, 10, 67), test_y.shape=(6121, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3019 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2812 - val_loss: 0.3011\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2652 - val_loss: 0.2888\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2545 - val_loss: 0.2808\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2479 - val_loss: 0.2750\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2428 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2385 - val_loss: 0.2663\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2348 - val_loss: 0.2629\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2315 - val_loss: 0.2599\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2283 - val_loss: 0.2570\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2254 - val_loss: 0.2544\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2226 - val_loss: 0.2520\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2201 - val_loss: 0.2499\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2179 - val_loss: 0.2480\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2161 - val_loss: 0.2464\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2145 - val_loss: 0.2449\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2436\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2118 - val_loss: 0.2425\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2107 - val_loss: 0.2414\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2096 - val_loss: 0.2403\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2087 - val_loss: 0.2395\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2387\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2070 - val_loss: 0.2379\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2063 - val_loss: 0.2371\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2056 - val_loss: 0.2364\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2049 - val_loss: 0.2358\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2352\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2038 - val_loss: 0.2346\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2032 - val_loss: 0.2342\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2027 - val_loss: 0.2337\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2023 - val_loss: 0.2332\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2018 - val_loss: 0.2329\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2014 - val_loss: 0.2325\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2321\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2006 - val_loss: 0.2318\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2314\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1999 - val_loss: 0.2311\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1996 - val_loss: 0.2308\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.1993 - val_loss: 0.2305\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1990 - val_loss: 0.2302\n",
      "192/192 [==============================] - 2s 11ms/step\n",
      "predicted_original.shape=(6121, 67), test_y.shape=(6121, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1515.0877642124253, my average MASE = 2752.3099444505265\n",
      "Cluster 1, 1515.0877642124253\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=5, 5, 12, (3253, 67)\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1101 - val_loss: 0.0983\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1050 - val_loss: 0.0966\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1009 - val_loss: 0.0954\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0975 - val_loss: 0.0944\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0945 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0919 - val_loss: 0.0931\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0895 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0923\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0855 - val_loss: 0.0921\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0838 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0915\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0807 - val_loss: 0.0912\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0794 - val_loss: 0.0910\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0782 - val_loss: 0.0908\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0771 - val_loss: 0.0906\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0760 - val_loss: 0.0904\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0750 - val_loss: 0.0902\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0741 - val_loss: 0.0901\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0733 - val_loss: 0.0899\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0725 - val_loss: 0.0898\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0717 - val_loss: 0.0897\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0710 - val_loss: 0.0895\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0704 - val_loss: 0.0895\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0894\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0691 - val_loss: 0.0893\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0686 - val_loss: 0.0892\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0681 - val_loss: 0.0892\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0891\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0671 - val_loss: 0.0891\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0890\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0662 - val_loss: 0.0889\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0658 - val_loss: 0.0889\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0888\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0651 - val_loss: 0.0887\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0647 - val_loss: 0.0887\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0644 - val_loss: 0.0886\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0641 - val_loss: 0.0885\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0638 - val_loss: 0.0885\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0636 - val_loss: 0.0884\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0633 - val_loss: 0.0883\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n",
      "average MASE = 1286975259.8033035, my average MASE = 26869301348.284866\n",
      "Cluster 0, 1286975259.8033035\n",
      "Before prediction: train_X.shape=(2221, 10, 67), train_y.shape=(2221, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5056 - val_loss: 0.3755\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4985 - val_loss: 0.3720\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4926 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4874 - val_loss: 0.3660\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4828 - val_loss: 0.3635\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4785 - val_loss: 0.3611\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4745 - val_loss: 0.3590\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4707 - val_loss: 0.3570\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4671 - val_loss: 0.3552\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4637 - val_loss: 0.3535\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4604 - val_loss: 0.3519\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4572 - val_loss: 0.3504\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4542 - val_loss: 0.3489\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4512 - val_loss: 0.3475\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4483 - val_loss: 0.3462\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4455 - val_loss: 0.3449\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4428 - val_loss: 0.3436\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4401 - val_loss: 0.3424\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4375 - val_loss: 0.3412\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4350 - val_loss: 0.3401\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4325 - val_loss: 0.3390\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4301 - val_loss: 0.3380\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4278 - val_loss: 0.3370\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4255 - val_loss: 0.3360\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4233 - val_loss: 0.3350\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4211 - val_loss: 0.3341\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4190 - val_loss: 0.3332\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4170 - val_loss: 0.3324\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4150 - val_loss: 0.3315\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4131 - val_loss: 0.3307\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4113 - val_loss: 0.3299\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4095 - val_loss: 0.3292\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4078 - val_loss: 0.3285\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4061 - val_loss: 0.3278\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4045 - val_loss: 0.3271\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4030 - val_loss: 0.3265\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4014 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3999 - val_loss: 0.3253\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3985 - val_loss: 0.3247\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3971 - val_loss: 0.3242\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 455.57479189703486, my average MASE = 880.739926655778\n",
      "Cluster 1, 455.57479189703486\n",
      "Before prediction: train_X.shape=(41, 10, 67), train_y.shape=(41, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4961 - val_loss: 0.6170\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4945 - val_loss: 0.6160\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4928 - val_loss: 0.6151\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4912 - val_loss: 0.6141\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4896 - val_loss: 0.6132\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4880 - val_loss: 0.6123\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4864 - val_loss: 0.6114\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4849 - val_loss: 0.6105\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4834 - val_loss: 0.6096\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4818 - val_loss: 0.6088\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4803 - val_loss: 0.6080\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4788 - val_loss: 0.6071\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4774 - val_loss: 0.6063\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4759 - val_loss: 0.6055\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4745 - val_loss: 0.6047\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4731 - val_loss: 0.6040\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4717 - val_loss: 0.6033\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4703 - val_loss: 0.6025\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4689 - val_loss: 0.6018\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4676 - val_loss: 0.6012\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4663 - val_loss: 0.6005\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4649 - val_loss: 0.5998\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4636 - val_loss: 0.5992\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4624 - val_loss: 0.5985\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4611 - val_loss: 0.5979\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4598 - val_loss: 0.5973\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4586 - val_loss: 0.5967\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4574 - val_loss: 0.5961\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4561 - val_loss: 0.5955\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4549 - val_loss: 0.5950\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4537 - val_loss: 0.5944\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4525 - val_loss: 0.5939\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4513 - val_loss: 0.5933\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4501 - val_loss: 0.5928\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4489 - val_loss: 0.5922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4478 - val_loss: 0.5917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4466 - val_loss: 0.5912\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4455 - val_loss: 0.5907\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4443 - val_loss: 0.5902\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4432 - val_loss: 0.5897\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3633974576.8812943, my average MASE = 9316750037.661146\n",
      "Cluster 2, 3633974576.8812943\n",
      "Before prediction: train_X.shape=(158, 10, 67), train_y.shape=(158, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5152 - val_loss: 0.4273\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5139 - val_loss: 0.4265\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5128 - val_loss: 0.4257\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5117 - val_loss: 0.4249\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5105 - val_loss: 0.4241\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5095 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5084 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5074 - val_loss: 0.4219\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5064 - val_loss: 0.4212\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5054 - val_loss: 0.4204\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5044 - val_loss: 0.4197\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5034 - val_loss: 0.4191\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5025 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5015 - val_loss: 0.4178\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5006 - val_loss: 0.4171\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4997 - val_loss: 0.4165\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4988 - val_loss: 0.4159\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4979 - val_loss: 0.4153\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4970 - val_loss: 0.4147\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4961 - val_loss: 0.4141\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4953 - val_loss: 0.4135\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4944 - val_loss: 0.4129\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4936 - val_loss: 0.4123\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4928 - val_loss: 0.4118\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4920 - val_loss: 0.4112\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4912 - val_loss: 0.4107\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4904 - val_loss: 0.4101\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4096\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4889 - val_loss: 0.4091\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4882 - val_loss: 0.4086\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4874 - val_loss: 0.4080\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4867 - val_loss: 0.4075\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4860 - val_loss: 0.4070\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4852 - val_loss: 0.4065\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4845 - val_loss: 0.4060\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4838 - val_loss: 0.4055\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4831 - val_loss: 0.4050\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4045\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4818 - val_loss: 0.4040\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4811 - val_loss: 0.4036\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 113.07393682707622, my average MASE = 188079219.47717956\n",
      "Cluster 3, 113.07393682707622\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7117 - val_loss: 0.7129\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7087 - val_loss: 0.7117\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7057 - val_loss: 0.7104\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7028 - val_loss: 0.7094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7000 - val_loss: 0.7084\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6972 - val_loss: 0.7075\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6945 - val_loss: 0.7066\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6918 - val_loss: 0.7056\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6891 - val_loss: 0.7047\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6865 - val_loss: 0.7037\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6838 - val_loss: 0.7028\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6811 - val_loss: 0.7018\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6785 - val_loss: 0.7009\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6758 - val_loss: 0.6999\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6732 - val_loss: 0.6990\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6706 - val_loss: 0.6981\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6680 - val_loss: 0.6971\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6654 - val_loss: 0.6961\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6628 - val_loss: 0.6951\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6604 - val_loss: 0.6942\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6580 - val_loss: 0.6934\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6556 - val_loss: 0.6926\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6534 - val_loss: 0.6918\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6512 - val_loss: 0.6910\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6491 - val_loss: 0.6902\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6470 - val_loss: 0.6894\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6449 - val_loss: 0.6886\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6429 - val_loss: 0.6877\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6409 - val_loss: 0.6869\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6389 - val_loss: 0.6861\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6369 - val_loss: 0.6853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6350 - val_loss: 0.6847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6332 - val_loss: 0.6841\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6314 - val_loss: 0.6836\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6297 - val_loss: 0.6831\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6280 - val_loss: 0.6827\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6263 - val_loss: 0.6825\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6246 - val_loss: 0.6824\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6229 - val_loss: 0.6823\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6212 - val_loss: 0.6822\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2798887382418345, my average MASE = 0.5334982550486497\n",
      "Cluster 4, 0.2798887382418345\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=7, 7, 431, (13, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(180, 10, 67), train_y.shape=(180, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6852 - val_loss: 0.5575\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6838 - val_loss: 0.5569\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6824 - val_loss: 0.5563\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6811 - val_loss: 0.5557\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6799 - val_loss: 0.5551\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6786 - val_loss: 0.5545\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6774 - val_loss: 0.5540\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6762 - val_loss: 0.5534\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6750 - val_loss: 0.5528\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6739 - val_loss: 0.5523\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6727 - val_loss: 0.5518\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5512\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6705 - val_loss: 0.5507\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6694 - val_loss: 0.5501\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6684 - val_loss: 0.5496\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6673 - val_loss: 0.5491\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6663 - val_loss: 0.5486\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6653 - val_loss: 0.5481\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6643 - val_loss: 0.5475\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6632 - val_loss: 0.5470\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6623 - val_loss: 0.5465\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6613 - val_loss: 0.5461\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6603 - val_loss: 0.5456\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6594 - val_loss: 0.5451\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6584 - val_loss: 0.5446\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6575 - val_loss: 0.5441\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6566 - val_loss: 0.5437\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6557 - val_loss: 0.5432\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6548 - val_loss: 0.5427\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6539 - val_loss: 0.5423\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6531 - val_loss: 0.5418\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6522 - val_loss: 0.5414\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6513 - val_loss: 0.5409\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6505 - val_loss: 0.5405\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6497 - val_loss: 0.5400\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6489 - val_loss: 0.5396\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6480 - val_loss: 0.5392\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6472 - val_loss: 0.5387\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6464 - val_loss: 0.5383\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6456 - val_loss: 0.5379\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 161.0036674860674, my average MASE = 412096886.9283237\n",
      "Cluster 1, 161.0036674860674\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6031 - val_loss: 0.4390\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6002 - val_loss: 0.4369\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5975 - val_loss: 0.4349\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5947 - val_loss: 0.4328\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5919 - val_loss: 0.4307\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5892 - val_loss: 0.4287\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5864 - val_loss: 0.4267\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5838 - val_loss: 0.4248\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5812 - val_loss: 0.4230\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5786 - val_loss: 0.4213\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5761 - val_loss: 0.4196\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5736 - val_loss: 0.4180\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5712 - val_loss: 0.4164\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5687 - val_loss: 0.4148\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5663 - val_loss: 0.4132\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5638 - val_loss: 0.4116\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5614 - val_loss: 0.4101\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5590 - val_loss: 0.4085\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5566 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5542 - val_loss: 0.4054\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5518 - val_loss: 0.4039\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5494 - val_loss: 0.4024\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5471 - val_loss: 0.4008\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5448 - val_loss: 0.3992\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5424 - val_loss: 0.3977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5401 - val_loss: 0.3961\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5378 - val_loss: 0.3945\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5355 - val_loss: 0.3930\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5333 - val_loss: 0.3914\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5310 - val_loss: 0.3898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5288 - val_loss: 0.3883\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5266 - val_loss: 0.3868\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5243 - val_loss: 0.3855\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5221 - val_loss: 0.3842\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5199 - val_loss: 0.3830\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5176 - val_loss: 0.3817\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5154 - val_loss: 0.3804\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5133 - val_loss: 0.3792\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5111 - val_loss: 0.3780\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5089 - val_loss: 0.3770\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.22679251401977166, my average MASE = 0.3179573135228401\n",
      "Cluster 2, 0.22679251401977166\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4783 - val_loss: 0.4457\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4766 - val_loss: 0.4444\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4750 - val_loss: 0.4432\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4734 - val_loss: 0.4420\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4719 - val_loss: 0.4408\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4703 - val_loss: 0.4397\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4687 - val_loss: 0.4385\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4672 - val_loss: 0.4374\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4657 - val_loss: 0.4362\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4642 - val_loss: 0.4351\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4627 - val_loss: 0.4340\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4613 - val_loss: 0.4329\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4598 - val_loss: 0.4318\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4584 - val_loss: 0.4307\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4296\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4555 - val_loss: 0.4286\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4541 - val_loss: 0.4275\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4527 - val_loss: 0.4265\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4513 - val_loss: 0.4255\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4499 - val_loss: 0.4245\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4486 - val_loss: 0.4235\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4472 - val_loss: 0.4225\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4459 - val_loss: 0.4215\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4445 - val_loss: 0.4205\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4432 - val_loss: 0.4195\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4186\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4406 - val_loss: 0.4176\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4167\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4380 - val_loss: 0.4158\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4368 - val_loss: 0.4149\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4355 - val_loss: 0.4139\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4343 - val_loss: 0.4130\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4330 - val_loss: 0.4121\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4318 - val_loss: 0.4112\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4306 - val_loss: 0.4103\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4294 - val_loss: 0.4094\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4282 - val_loss: 0.4085\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4270 - val_loss: 0.4077\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4258 - val_loss: 0.4068\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4246 - val_loss: 0.4059\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3532936323.38913, my average MASE = 7800622104.848636\n",
      "Cluster 3, 3532936323.38913\n",
      "Before prediction: train_X.shape=(152, 10, 67), train_y.shape=(152, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3354 - val_loss: 0.2774\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3344 - val_loss: 0.2769\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3336 - val_loss: 0.2763\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3328 - val_loss: 0.2758\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3320 - val_loss: 0.2753\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3312 - val_loss: 0.2747\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3304 - val_loss: 0.2742\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3297 - val_loss: 0.2737\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3290 - val_loss: 0.2733\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3282 - val_loss: 0.2728\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3275 - val_loss: 0.2723\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3268 - val_loss: 0.2718\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3262 - val_loss: 0.2714\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3255 - val_loss: 0.2709\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3248 - val_loss: 0.2705\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3242 - val_loss: 0.2700\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3235 - val_loss: 0.2696\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3229 - val_loss: 0.2692\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3223 - val_loss: 0.2687\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3217 - val_loss: 0.2683\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3210 - val_loss: 0.2678\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3204 - val_loss: 0.2674\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3198 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3192 - val_loss: 0.2666\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3187 - val_loss: 0.2662\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3181 - val_loss: 0.2658\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3175 - val_loss: 0.2654\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3170 - val_loss: 0.2650\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3164 - val_loss: 0.2647\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3158 - val_loss: 0.2643\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3153 - val_loss: 0.2639\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3148 - val_loss: 0.2635\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3142 - val_loss: 0.2632\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3137 - val_loss: 0.2628\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3132 - val_loss: 0.2624\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3127 - val_loss: 0.2621\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3122 - val_loss: 0.2617\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3117 - val_loss: 0.2614\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3112 - val_loss: 0.2610\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3107 - val_loss: 0.2607\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 185.09520141259705, my average MASE = 132066880.5161765\n",
      "Cluster 4, 185.09520141259705\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0679 - val_loss: 0.0461\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0619 - val_loss: 0.0426\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0586 - val_loss: 0.0401\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0561 - val_loss: 0.0381\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0542 - val_loss: 0.0366\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0527 - val_loss: 0.0352\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0514 - val_loss: 0.0341\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0503 - val_loss: 0.0333\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0312\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0473 - val_loss: 0.0307\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0468 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0463 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0459 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0455 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0452 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0448 - val_loss: 0.0288\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0286\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0443 - val_loss: 0.0284\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0283\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0281\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0436 - val_loss: 0.0279\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0434 - val_loss: 0.0278\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0277\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0276\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0274\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0273\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0426 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0425 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0423 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0422 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0421 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0420 - val_loss: 0.0269\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0419 - val_loss: 0.0268\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0267\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 1042799882.6542007, my average MASE = 20591462481.802387\n",
      "Cluster 5, 1042799882.6542007\n",
      "Before prediction: train_X.shape=(82, 10, 67), train_y.shape=(82, 67), test_X.shape=(27, 10, 67), test_y.shape=(27, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3924 - val_loss: 0.4859\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3915 - val_loss: 0.4852\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3907 - val_loss: 0.4846\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3899 - val_loss: 0.4840\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3891 - val_loss: 0.4835\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3883 - val_loss: 0.4829\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3876 - val_loss: 0.4824\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3868 - val_loss: 0.4818\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3861 - val_loss: 0.4813\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 0.4808\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3847 - val_loss: 0.4802\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3841 - val_loss: 0.4797\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3834 - val_loss: 0.4792\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3828 - val_loss: 0.4787\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3821 - val_loss: 0.4783\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3815 - val_loss: 0.4778\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3809 - val_loss: 0.4773\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3804 - val_loss: 0.4769\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3798 - val_loss: 0.4764\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.4760\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3787 - val_loss: 0.4755\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3781 - val_loss: 0.4751\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4747\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3771 - val_loss: 0.4743\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3766 - val_loss: 0.4738\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3761 - val_loss: 0.4734\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3756 - val_loss: 0.4731\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3751 - val_loss: 0.4727\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3746 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3741 - val_loss: 0.4719\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3737 - val_loss: 0.4715\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3732 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3728 - val_loss: 0.4707\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3723 - val_loss: 0.4703\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3719 - val_loss: 0.4699\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3715 - val_loss: 0.4696\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3710 - val_loss: 0.4692\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3706 - val_loss: 0.4688\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3702 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3698 - val_loss: 0.4681\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(27, 67), test_y.shape=(27, 67)\n",
      "average MASE = 307.7375965485456, my average MASE = 158440912.42565766\n",
      "Cluster 6, 307.7375965485456\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=9, 9, 32, (76, 67)\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4763 - val_loss: 0.4497\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4746 - val_loss: 0.4487\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4729 - val_loss: 0.4477\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4713 - val_loss: 0.4467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4696 - val_loss: 0.4458\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4680 - val_loss: 0.4448\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.4439\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4647 - val_loss: 0.4429\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4631 - val_loss: 0.4420\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.4410\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4600 - val_loss: 0.4401\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4585 - val_loss: 0.4392\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4554 - val_loss: 0.4373\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4539 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4524 - val_loss: 0.4355\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4510 - val_loss: 0.4345\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4495 - val_loss: 0.4336\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4481 - val_loss: 0.4327\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.4319\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4453 - val_loss: 0.4310\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4439 - val_loss: 0.4301\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4425 - val_loss: 0.4293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4412 - val_loss: 0.4284\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4398 - val_loss: 0.4276\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4385 - val_loss: 0.4267\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4371 - val_loss: 0.4259\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4358 - val_loss: 0.4251\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.4243\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4332 - val_loss: 0.4234\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4226\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4307 - val_loss: 0.4218\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4294 - val_loss: 0.4210\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4282 - val_loss: 0.4202\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4270 - val_loss: 0.4195\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4258 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4246 - val_loss: 0.4179\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4234 - val_loss: 0.4172\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4222 - val_loss: 0.4164\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4211 - val_loss: 0.4157\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3502979890.5184355, my average MASE = 5633924620.870799\n",
      "Cluster 0, 3502979890.5184355\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1163 - val_loss: 0.0998\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1111 - val_loss: 0.0974\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1069 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1034 - val_loss: 0.0946\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1003 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0952 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0929 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0909 - val_loss: 0.0914\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0891 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0907\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0859 - val_loss: 0.0904\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0902\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0831 - val_loss: 0.0900\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0808 - val_loss: 0.0896\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0797 - val_loss: 0.0894\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0787 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0778 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0769 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0761 - val_loss: 0.0890\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0889\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0745 - val_loss: 0.0888\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0738 - val_loss: 0.0887\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0731 - val_loss: 0.0886\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0725 - val_loss: 0.0886\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0885\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0713 - val_loss: 0.0885\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0707 - val_loss: 0.0884\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0702 - val_loss: 0.0884\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0697 - val_loss: 0.0883\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0692 - val_loss: 0.0883\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0882\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0683 - val_loss: 0.0882\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0881\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0881\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0880\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0880\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0665 - val_loss: 0.0879\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0662 - val_loss: 0.0879\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1199834821.8603294, my average MASE = 15362171394.25593\n",
      "Cluster 1, 1199834821.8603294\n",
      "Before prediction: train_X.shape=(1567, 10, 67), train_y.shape=(1567, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2378 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2280 - val_loss: 0.2658\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2204 - val_loss: 0.2582\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2142 - val_loss: 0.2520\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2091 - val_loss: 0.2467\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2046 - val_loss: 0.2420\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2006 - val_loss: 0.2378\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1971 - val_loss: 0.2340\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1938 - val_loss: 0.2304\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1908 - val_loss: 0.2272\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1880 - val_loss: 0.2241\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1853 - val_loss: 0.2213\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1829 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1806 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1784 - val_loss: 0.2141\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1765 - val_loss: 0.2121\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1747 - val_loss: 0.2103\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1730 - val_loss: 0.2086\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1715 - val_loss: 0.2071\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1702 - val_loss: 0.2056\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1689 - val_loss: 0.2042\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1677 - val_loss: 0.2029\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2016\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2005\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1645 - val_loss: 0.1993\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1983\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1626 - val_loss: 0.1973\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1618 - val_loss: 0.1962\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1610 - val_loss: 0.1953\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1944\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1594 - val_loss: 0.1935\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1587 - val_loss: 0.1927\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1580 - val_loss: 0.1919\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1573 - val_loss: 0.1911\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1567 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1555 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1550 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1539 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 164.5516081334958, my average MASE = 793528060.8539205\n",
      "Cluster 2, 164.5516081334958\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3929 - val_loss: 0.4650\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 0.4646\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3912 - val_loss: 0.4642\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3904 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3896 - val_loss: 0.4635\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3889 - val_loss: 0.4631\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3881 - val_loss: 0.4627\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3874 - val_loss: 0.4624\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4621\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.4617\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3854 - val_loss: 0.4614\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3847 - val_loss: 0.4611\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3841 - val_loss: 0.4608\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3835 - val_loss: 0.4605\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3829 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3823 - val_loss: 0.4600\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3817 - val_loss: 0.4597\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3812 - val_loss: 0.4594\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.4591\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3800 - val_loss: 0.4588\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3795 - val_loss: 0.4585\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3790 - val_loss: 0.4583\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3785 - val_loss: 0.4580\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.4578\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3775 - val_loss: 0.4575\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3770 - val_loss: 0.4572\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3765 - val_loss: 0.4570\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3761 - val_loss: 0.4567\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3756 - val_loss: 0.4565\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3752 - val_loss: 0.4563\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3747 - val_loss: 0.4560\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3738 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3734 - val_loss: 0.4553\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3730 - val_loss: 0.4551\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3725 - val_loss: 0.4549\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3721 - val_loss: 0.4547\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3717 - val_loss: 0.4545\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3713 - val_loss: 0.4542\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3709 - val_loss: 0.4540\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 177.05816941536048, my average MASE = 104373067.45181417\n",
      "Cluster 3, 177.05816941536048\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4712 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4689 - val_loss: 0.3159\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.3148\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4644 - val_loss: 0.3137\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4621 - val_loss: 0.3125\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4598 - val_loss: 0.3114\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4576 - val_loss: 0.3103\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4553 - val_loss: 0.3092\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4531 - val_loss: 0.3081\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4509 - val_loss: 0.3071\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.3062\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4465 - val_loss: 0.3053\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4444 - val_loss: 0.3044\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4422 - val_loss: 0.3036\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4401 - val_loss: 0.3028\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4379 - val_loss: 0.3020\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4358 - val_loss: 0.3012\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.3004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4317 - val_loss: 0.2996\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4297 - val_loss: 0.2988\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4278 - val_loss: 0.2979\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4259 - val_loss: 0.2970\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4240 - val_loss: 0.2961\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4222 - val_loss: 0.2952\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4204 - val_loss: 0.2943\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4186 - val_loss: 0.2934\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4168 - val_loss: 0.2924\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4151 - val_loss: 0.2915\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4134 - val_loss: 0.2906\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4118 - val_loss: 0.2898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4102 - val_loss: 0.2890\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4086 - val_loss: 0.2883\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4070 - val_loss: 0.2876\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.2869\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4039 - val_loss: 0.2863\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4009 - val_loss: 0.2850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.2845\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3980 - val_loss: 0.2840\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3966 - val_loss: 0.2835\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 254.89087963107983, my average MASE = 19795911.088192035\n",
      "Cluster 5, 254.89087963107983\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(176, 10, 67), train_y.shape=(176, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7010 - val_loss: 0.5674\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6997 - val_loss: 0.5667\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6984 - val_loss: 0.5660\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6972 - val_loss: 0.5654\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6960 - val_loss: 0.5647\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6948 - val_loss: 0.5641\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6937 - val_loss: 0.5635\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6925 - val_loss: 0.5629\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.5623\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6903 - val_loss: 0.5617\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6893 - val_loss: 0.5611\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6882 - val_loss: 0.5605\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6871 - val_loss: 0.5599\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6861 - val_loss: 0.5594\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6851 - val_loss: 0.5588\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6841 - val_loss: 0.5583\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6831 - val_loss: 0.5577\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6821 - val_loss: 0.5572\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6811 - val_loss: 0.5567\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6802 - val_loss: 0.5562\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6792 - val_loss: 0.5556\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6783 - val_loss: 0.5551\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6774 - val_loss: 0.5546\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6765 - val_loss: 0.5541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6756 - val_loss: 0.5536\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6747 - val_loss: 0.5531\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6738 - val_loss: 0.5526\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6729 - val_loss: 0.5521\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6720 - val_loss: 0.5516\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6712 - val_loss: 0.5512\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6703 - val_loss: 0.5507\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6695 - val_loss: 0.5502\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6686 - val_loss: 0.5497\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6678 - val_loss: 0.5493\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6670 - val_loss: 0.5488\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6661 - val_loss: 0.5483\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6653 - val_loss: 0.5479\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.5474\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6637 - val_loss: 0.5469\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6629 - val_loss: 0.5464\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 154.34881195949765, my average MASE = 318959730.30915844\n",
      "Cluster 7, 154.34881195949765\n",
      "Before prediction: train_X.shape=(150, 10, 67), train_y.shape=(150, 67), test_X.shape=(50, 10, 67), test_y.shape=(50, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3127 - val_loss: 0.2620\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3118 - val_loss: 0.2614\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3110 - val_loss: 0.2608\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3103 - val_loss: 0.2603\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3096 - val_loss: 0.2597\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3088 - val_loss: 0.2592\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3081 - val_loss: 0.2587\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3074 - val_loss: 0.2582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3067 - val_loss: 0.2577\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3060 - val_loss: 0.2572\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3054 - val_loss: 0.2567\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3047 - val_loss: 0.2563\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3041 - val_loss: 0.2558\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3035 - val_loss: 0.2554\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3029 - val_loss: 0.2549\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3023 - val_loss: 0.2545\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3017 - val_loss: 0.2541\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3011 - val_loss: 0.2537\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3005 - val_loss: 0.2533\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3000 - val_loss: 0.2529\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2994 - val_loss: 0.2525\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2988 - val_loss: 0.2521\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2983 - val_loss: 0.2517\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2978 - val_loss: 0.2513\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2973 - val_loss: 0.2509\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2967 - val_loss: 0.2505\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2962 - val_loss: 0.2502\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2957 - val_loss: 0.2498\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2952 - val_loss: 0.2494\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2948 - val_loss: 0.2491\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2943 - val_loss: 0.2487\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2938 - val_loss: 0.2484\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2933 - val_loss: 0.2480\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2929 - val_loss: 0.2477\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2924 - val_loss: 0.2473\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2920 - val_loss: 0.2470\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2915 - val_loss: 0.2467\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2911 - val_loss: 0.2463\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2907 - val_loss: 0.2460\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2902 - val_loss: 0.2457\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(50, 67), test_y.shape=(50, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 222.6692241509544, my average MASE = 77008768.33506098\n",
      "Cluster 8, 222.6692241509544\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=11, 11, 435, (11, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4436 - val_loss: 0.3307\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4426 - val_loss: 0.3306\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4417 - val_loss: 0.3306\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4408 - val_loss: 0.3305\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4398 - val_loss: 0.3305\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4389 - val_loss: 0.3304\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4380 - val_loss: 0.3303\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4371 - val_loss: 0.3303\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4362 - val_loss: 0.3302\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4354 - val_loss: 0.3301\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.3301\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4337 - val_loss: 0.3300\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4329 - val_loss: 0.3299\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4320 - val_loss: 0.3299\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4312 - val_loss: 0.3298\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4304 - val_loss: 0.3298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4296 - val_loss: 0.3297\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4288 - val_loss: 0.3296\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4280 - val_loss: 0.3295\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4273 - val_loss: 0.3295\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4265 - val_loss: 0.3294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4258 - val_loss: 0.3293\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4250 - val_loss: 0.3293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4243 - val_loss: 0.3292\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4235 - val_loss: 0.3291\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4228 - val_loss: 0.3291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4221 - val_loss: 0.3290\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4213 - val_loss: 0.3290\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.3289\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4199 - val_loss: 0.3288\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4191 - val_loss: 0.3288\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4184 - val_loss: 0.3287\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4177 - val_loss: 0.3287\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4170 - val_loss: 0.3286\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4163 - val_loss: 0.3286\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 0.3285\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4149 - val_loss: 0.3285\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4143 - val_loss: 0.3285\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4136 - val_loss: 0.3284\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4129 - val_loss: 0.3284\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 623.4242587364998, my average MASE = 13116998.58946489\n",
      "Cluster 0, 623.4242587364998\n",
      "Before prediction: train_X.shape=(18, 10, 67), train_y.shape=(18, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4512 - val_loss: 0.5917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4491 - val_loss: 0.5900\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4470 - val_loss: 0.5884\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4449 - val_loss: 0.5867\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4429 - val_loss: 0.5851\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4408 - val_loss: 0.5835\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.5818\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4369 - val_loss: 0.5802\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4349 - val_loss: 0.5786\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4330 - val_loss: 0.5770\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4311 - val_loss: 0.5755\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4293 - val_loss: 0.5739\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4275 - val_loss: 0.5724\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4257 - val_loss: 0.5709\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4239 - val_loss: 0.5694\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4222 - val_loss: 0.5680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4205 - val_loss: 0.5666\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4188 - val_loss: 0.5652\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4171 - val_loss: 0.5638\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4155 - val_loss: 0.5625\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4139 - val_loss: 0.5611\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4123 - val_loss: 0.5598\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4107 - val_loss: 0.5584\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4092 - val_loss: 0.5571\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4077 - val_loss: 0.5558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4062 - val_loss: 0.5545\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4047 - val_loss: 0.5532\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4032 - val_loss: 0.5519\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4017 - val_loss: 0.5506\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4003 - val_loss: 0.5494\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.5482\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5470\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3960 - val_loss: 0.5458\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.5446\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3933 - val_loss: 0.5435\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3920 - val_loss: 0.5424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3906 - val_loss: 0.5414\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3893 - val_loss: 0.5403\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3881 - val_loss: 0.5393\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3868 - val_loss: 0.5382\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1669347283.8471758, my average MASE = 4344504132.76493\n",
      "Cluster 1, 1669347283.8471758\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0678 - val_loss: 0.0460\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0618 - val_loss: 0.0427\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0585 - val_loss: 0.0404\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0561 - val_loss: 0.0385\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0542 - val_loss: 0.0369\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0527 - val_loss: 0.0355\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0514 - val_loss: 0.0344\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0503 - val_loss: 0.0335\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0327\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0321\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0315\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0473 - val_loss: 0.0310\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0468 - val_loss: 0.0306\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0463 - val_loss: 0.0302\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0458 - val_loss: 0.0299\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0454 - val_loss: 0.0296\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0293\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0447 - val_loss: 0.0291\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0444 - val_loss: 0.0289\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0442 - val_loss: 0.0287\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0439 - val_loss: 0.0285\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0283\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0434 - val_loss: 0.0281\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0430 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0427 - val_loss: 0.0276\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0423 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0419 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0266\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0415 - val_loss: 0.0265\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0264\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0263\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 811440996.3412759, my average MASE = 40052487777.48425\n",
      "Cluster 2, 811440996.3412759\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1986 - val_loss: 0.8095\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1967 - val_loss: 0.8095\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1948 - val_loss: 0.8095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1930 - val_loss: 0.8094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1912 - val_loss: 0.8094\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1894 - val_loss: 0.8094\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1876 - val_loss: 0.8094\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1858 - val_loss: 0.8094\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1840 - val_loss: 0.8094\n",
      "Epoch 9: early stopping\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 72.88641883174732, my average MASE = 50002377.286928184\n",
      "Cluster 3, 72.88641883174732\n",
      "Before prediction: train_X.shape=(87, 10, 67), train_y.shape=(87, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5691 - val_loss: 0.5072\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5682 - val_loss: 0.5068\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5674 - val_loss: 0.5063\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5666 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5659 - val_loss: 0.5055\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5651 - val_loss: 0.5051\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5643 - val_loss: 0.5047\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5636 - val_loss: 0.5042\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5628 - val_loss: 0.5038\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5621 - val_loss: 0.5034\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5614 - val_loss: 0.5030\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5606 - val_loss: 0.5026\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5600 - val_loss: 0.5022\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5592 - val_loss: 0.5018\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5586 - val_loss: 0.5014\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5579 - val_loss: 0.5011\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5572 - val_loss: 0.5007\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5565 - val_loss: 0.5003\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5558 - val_loss: 0.4999\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5552 - val_loss: 0.4996\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5545 - val_loss: 0.4993\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5539 - val_loss: 0.4989\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5532 - val_loss: 0.4986\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5526 - val_loss: 0.4983\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5520 - val_loss: 0.4979\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5513 - val_loss: 0.4976\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5507 - val_loss: 0.4973\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5501 - val_loss: 0.4970\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5495 - val_loss: 0.4967\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5489 - val_loss: 0.4964\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5483 - val_loss: 0.4961\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5477 - val_loss: 0.4958\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5471 - val_loss: 0.4956\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5465 - val_loss: 0.4953\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5459 - val_loss: 0.4950\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5453 - val_loss: 0.4947\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5447 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5442 - val_loss: 0.4942\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.4939\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5430 - val_loss: 0.4936\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 98.29689269118158, my average MASE = 78492579.83265808\n",
      "Cluster 4, 98.29689269118158\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4003 - val_loss: 0.3997\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3997 - val_loss: 0.3991\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3991 - val_loss: 0.3986\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3985 - val_loss: 0.3981\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3976\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3973 - val_loss: 0.3971\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3968 - val_loss: 0.3967\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3962\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3957 - val_loss: 0.3958\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3953\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3946 - val_loss: 0.3949\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3940 - val_loss: 0.3945\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3935 - val_loss: 0.3941\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3930 - val_loss: 0.3937\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3924 - val_loss: 0.3932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3919 - val_loss: 0.3928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3914 - val_loss: 0.3925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3904 - val_loss: 0.3917\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3899 - val_loss: 0.3913\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3894 - val_loss: 0.3909\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3889 - val_loss: 0.3906\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3884 - val_loss: 0.3902\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3879 - val_loss: 0.3898\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3870 - val_loss: 0.3891\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3865 - val_loss: 0.3887\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.3883\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3856 - val_loss: 0.3880\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3851 - val_loss: 0.3876\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3847 - val_loss: 0.3872\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3842 - val_loss: 0.3869\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3838 - val_loss: 0.3865\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3833 - val_loss: 0.3861\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3829 - val_loss: 0.3857\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3824 - val_loss: 0.3853\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 0.3850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3815 - val_loss: 0.3846\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3811 - val_loss: 0.3842\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3807 - val_loss: 0.3838\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 517837.8778283109, my average MASE = 16943290.739345513\n",
      "Cluster 6, 517837.8778283109\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2151 - val_loss: 0.4042\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2146 - val_loss: 0.4041\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2142 - val_loss: 0.4041\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2137 - val_loss: 0.4040\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2133 - val_loss: 0.4040\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2128 - val_loss: 0.4040\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2124 - val_loss: 0.4039\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2119 - val_loss: 0.4039\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2115 - val_loss: 0.4038\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2111 - val_loss: 0.4038\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2107 - val_loss: 0.4038\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2103 - val_loss: 0.4038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2099 - val_loss: 0.4037\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2096 - val_loss: 0.4037\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2092 - val_loss: 0.4037\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2088 - val_loss: 0.4036\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2084 - val_loss: 0.4036\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2081 - val_loss: 0.4036\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2077 - val_loss: 0.4035\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2074 - val_loss: 0.4035\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2070 - val_loss: 0.4035\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2067 - val_loss: 0.4035\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2063 - val_loss: 0.4035\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2060 - val_loss: 0.4034\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2057 - val_loss: 0.4034\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2054 - val_loss: 0.4034\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2050 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2047 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2044 - val_loss: 0.4033\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2041 - val_loss: 0.4033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2038 - val_loss: 0.4032\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2035 - val_loss: 0.4032\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2032 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2029 - val_loss: 0.4031\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2026 - val_loss: 0.4031\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2023 - val_loss: 0.4031\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2020 - val_loss: 0.4030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2017 - val_loss: 0.4030\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2014 - val_loss: 0.4029\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2011 - val_loss: 0.4029\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 181.01448499364625, my average MASE = 73613295.18701741\n",
      "Cluster 7, 181.01448499364625\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2941 - val_loss: 0.3652\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2932 - val_loss: 0.3650\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2923 - val_loss: 0.3648\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2914 - val_loss: 0.3646\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2905 - val_loss: 0.3644\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2897 - val_loss: 0.3641\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2888 - val_loss: 0.3639\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2880 - val_loss: 0.3638\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2872 - val_loss: 0.3636\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2864 - val_loss: 0.3634\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2856 - val_loss: 0.3632\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2848 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2840 - val_loss: 0.3629\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2832 - val_loss: 0.3628\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2824 - val_loss: 0.3626\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2817 - val_loss: 0.3625\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2809 - val_loss: 0.3624\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2802 - val_loss: 0.3622\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2794 - val_loss: 0.3621\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2787 - val_loss: 0.3620\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2780 - val_loss: 0.3619\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2772 - val_loss: 0.3618\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2765 - val_loss: 0.3617\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2758 - val_loss: 0.3616\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2751 - val_loss: 0.3615\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2744 - val_loss: 0.3615\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2738 - val_loss: 0.3614\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2731 - val_loss: 0.3613\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2725 - val_loss: 0.3613\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2718 - val_loss: 0.3612\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2712 - val_loss: 0.3612\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2705 - val_loss: 0.3611\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2699 - val_loss: 0.3611\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2693 - val_loss: 0.3610\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2687 - val_loss: 0.3610\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2681 - val_loss: 0.3610\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2675 - val_loss: 0.3609\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2669 - val_loss: 0.3609\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2663 - val_loss: 0.3608\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.3608\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 679.6913673037432, my average MASE = 68962615.13093176\n",
      "Cluster 9, 679.6913673037432\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=2, 2, 11, (10056, 67)\n",
      "Before prediction: train_X.shape=(6027, 10, 67), train_y.shape=(6027, 67), test_X.shape=(2009, 10, 67), test_y.shape=(2009, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0641 - val_loss: 0.0494\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0590 - val_loss: 0.0459\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0558 - val_loss: 0.0432\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0535 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0516 - val_loss: 0.0393\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0501 - val_loss: 0.0378\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0489 - val_loss: 0.0366\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0478 - val_loss: 0.0357\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0470 - val_loss: 0.0348\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0462 - val_loss: 0.0341\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0455 - val_loss: 0.0335\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0330\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0443 - val_loss: 0.0325\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0321\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0317\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0314\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0311\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0423 - val_loss: 0.0308\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0419 - val_loss: 0.0305\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0303\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0414 - val_loss: 0.0300\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0298\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0296\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0406 - val_loss: 0.0294\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0404 - val_loss: 0.0293\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0403 - val_loss: 0.0291\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0401 - val_loss: 0.0290\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0399 - val_loss: 0.0289\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0397 - val_loss: 0.0287\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0396 - val_loss: 0.0286\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0394 - val_loss: 0.0286\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0393 - val_loss: 0.0285\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0392 - val_loss: 0.0284\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0391 - val_loss: 0.0283\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0389 - val_loss: 0.0282\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0388 - val_loss: 0.0282\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0387 - val_loss: 0.0281\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0386 - val_loss: 0.0281\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0385 - val_loss: 0.0280\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0384 - val_loss: 0.0280\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2009, 67), test_y.shape=(2009, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 137177179.8661396, my average MASE = 15662264218.215044\n",
      "Cluster 0, 137177179.8661396\n",
      "Before prediction: train_X.shape=(18366, 10, 67), train_y.shape=(18366, 67), test_X.shape=(6122, 10, 67), test_y.shape=(6122, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3004 - val_loss: 0.3159\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2809 - val_loss: 0.3004\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2655 - val_loss: 0.2878\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2540 - val_loss: 0.2790\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2465 - val_loss: 0.2727\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2409 - val_loss: 0.2676\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2364 - val_loss: 0.2633\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2324 - val_loss: 0.2598\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2290 - val_loss: 0.2567\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2259 - val_loss: 0.2539\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2230 - val_loss: 0.2514\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2204 - val_loss: 0.2493\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2181 - val_loss: 0.2474\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2161 - val_loss: 0.2457\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2144 - val_loss: 0.2442\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2129 - val_loss: 0.2429\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2115 - val_loss: 0.2418\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2103 - val_loss: 0.2406\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2092 - val_loss: 0.2396\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2083 - val_loss: 0.2386\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2073 - val_loss: 0.2378\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2065 - val_loss: 0.2370\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2057 - val_loss: 0.2363\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2050 - val_loss: 0.2356\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2350\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2344\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2031 - val_loss: 0.2338\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2025 - val_loss: 0.2333\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2020 - val_loss: 0.2328\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2015 - val_loss: 0.2324\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2319\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2006 - val_loss: 0.2314\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2002 - val_loss: 0.2311\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1998 - val_loss: 0.2307\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.1994 - val_loss: 0.2304\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1991 - val_loss: 0.2301\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.1987 - val_loss: 0.2298\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1984 - val_loss: 0.2294\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1981 - val_loss: 0.2291\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1978 - val_loss: 0.2290\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6122, 67), test_y.shape=(6122, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1800.7465590842255, my average MASE = 3633.615501921918\n",
      "Cluster 1, 1800.7465590842255\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=5, 5, 58, (3715, 67)\n",
      "Before prediction: train_X.shape=(2222, 10, 67), train_y.shape=(2222, 67), test_X.shape=(741, 10, 67), test_y.shape=(741, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5001 - val_loss: 0.3691\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4918 - val_loss: 0.3651\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4851 - val_loss: 0.3618\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4795 - val_loss: 0.3589\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4744 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4699 - val_loss: 0.3539\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4657 - val_loss: 0.3517\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4618 - val_loss: 0.3497\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4582 - val_loss: 0.3478\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4548 - val_loss: 0.3460\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4516 - val_loss: 0.3443\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4485 - val_loss: 0.3427\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4455 - val_loss: 0.3412\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4426 - val_loss: 0.3398\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4398 - val_loss: 0.3384\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4370 - val_loss: 0.3370\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4342 - val_loss: 0.3357\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4315 - val_loss: 0.3345\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4289 - val_loss: 0.3332\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4263 - val_loss: 0.3321\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4237 - val_loss: 0.3309\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4213 - val_loss: 0.3298\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4189 - val_loss: 0.3287\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4166 - val_loss: 0.3277\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4143 - val_loss: 0.3266\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4120 - val_loss: 0.3256\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4099 - val_loss: 0.3247\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4079 - val_loss: 0.3238\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4059 - val_loss: 0.3230\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4040 - val_loss: 0.3222\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4022 - val_loss: 0.3214\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4005 - val_loss: 0.3206\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3988 - val_loss: 0.3199\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3972 - val_loss: 0.3193\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3956 - val_loss: 0.3186\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3941 - val_loss: 0.3180\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3927 - val_loss: 0.3175\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3912 - val_loss: 0.3169\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3899 - val_loss: 0.3163\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3885 - val_loss: 0.3158\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(741, 67), test_y.shape=(741, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 461.9721639366225, my average MASE = 1222.9207656733142\n",
      "Cluster 0, 461.9721639366225\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1169 - val_loss: 0.0965\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1118 - val_loss: 0.0947\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1077 - val_loss: 0.0935\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1043 - val_loss: 0.0926\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1013 - val_loss: 0.0919\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0987 - val_loss: 0.0913\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0964 - val_loss: 0.0909\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0942 - val_loss: 0.0906\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0923 - val_loss: 0.0904\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0901\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0890 - val_loss: 0.0899\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0875 - val_loss: 0.0897\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0861 - val_loss: 0.0895\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0849 - val_loss: 0.0894\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0837 - val_loss: 0.0892\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0826 - val_loss: 0.0891\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0816 - val_loss: 0.0889\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0807 - val_loss: 0.0888\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0798 - val_loss: 0.0886\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0790 - val_loss: 0.0885\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0782 - val_loss: 0.0884\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0883\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0881\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0761 - val_loss: 0.0880\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0755 - val_loss: 0.0879\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0749 - val_loss: 0.0878\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0743 - val_loss: 0.0877\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0738 - val_loss: 0.0876\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0732 - val_loss: 0.0875\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0727 - val_loss: 0.0875\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0722 - val_loss: 0.0874\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0718 - val_loss: 0.0874\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0713 - val_loss: 0.0874\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0873\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0705 - val_loss: 0.0873\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0873\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0872\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0695 - val_loss: 0.0872\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0689 - val_loss: 0.0871\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 979857680.8759673, my average MASE = 20246393999.460716\n",
      "Cluster 1, 979857680.8759673\n",
      "Before prediction: train_X.shape=(160, 10, 67), train_y.shape=(160, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5150 - val_loss: 0.4228\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5137 - val_loss: 0.4220\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5125 - val_loss: 0.4212\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5113 - val_loss: 0.4205\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5101 - val_loss: 0.4197\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5090 - val_loss: 0.4189\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5079 - val_loss: 0.4182\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5068 - val_loss: 0.4175\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5058 - val_loss: 0.4168\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4161\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5037 - val_loss: 0.4154\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5026 - val_loss: 0.4148\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5016 - val_loss: 0.4141\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5006 - val_loss: 0.4135\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4997 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4987 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4977 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4968 - val_loss: 0.4110\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4958 - val_loss: 0.4104\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4949 - val_loss: 0.4098\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4940 - val_loss: 0.4092\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4931 - val_loss: 0.4086\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4923 - val_loss: 0.4081\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4914 - val_loss: 0.4075\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4905 - val_loss: 0.4069\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4064\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4888 - val_loss: 0.4059\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4880 - val_loss: 0.4053\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4871 - val_loss: 0.4048\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4863 - val_loss: 0.4043\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4855 - val_loss: 0.4038\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4847 - val_loss: 0.4033\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4840 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4832 - val_loss: 0.4023\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4018\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4817 - val_loss: 0.4013\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4809 - val_loss: 0.4008\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4802 - val_loss: 0.4003\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4795 - val_loss: 0.3998\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4787 - val_loss: 0.3994\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.13783551729924, my average MASE = 51951538.633395046\n",
      "Cluster 2, 127.13783551729924\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8383 - val_loss: 0.5938\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8360 - val_loss: 0.5928\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8338 - val_loss: 0.5919\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8316 - val_loss: 0.5910\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8294 - val_loss: 0.5901\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8272 - val_loss: 0.5891\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8251 - val_loss: 0.5882\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 0.5873\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8208 - val_loss: 0.5864\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8187 - val_loss: 0.5855\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8167 - val_loss: 0.5847\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8146 - val_loss: 0.5838\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8126 - val_loss: 0.5830\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8107 - val_loss: 0.5821\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8087 - val_loss: 0.5812\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8068 - val_loss: 0.5803\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8048 - val_loss: 0.5794\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8029 - val_loss: 0.5786\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8009 - val_loss: 0.5777\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7989 - val_loss: 0.5768\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7970 - val_loss: 0.5760\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7951 - val_loss: 0.5751\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7932 - val_loss: 0.5743\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7913 - val_loss: 0.5735\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7894 - val_loss: 0.5727\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7875 - val_loss: 0.5720\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7857 - val_loss: 0.5712\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7839 - val_loss: 0.5704\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7820 - val_loss: 0.5697\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7802 - val_loss: 0.5690\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7784 - val_loss: 0.5682\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7767 - val_loss: 0.5675\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7749 - val_loss: 0.5668\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7732 - val_loss: 0.5661\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7715 - val_loss: 0.5655\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7698 - val_loss: 0.5648\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7681 - val_loss: 0.5641\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7664 - val_loss: 0.5635\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7647 - val_loss: 0.5629\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7630 - val_loss: 0.5623\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1378.9503839591846, my average MASE = 44152799.2879618\n",
      "Cluster 3, 1378.9503839591846\n",
      "Before prediction: train_X.shape=(44, 10, 67), train_y.shape=(44, 67), test_X.shape=(15, 10, 67), test_y.shape=(15, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5170 - val_loss: 0.7315\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5154 - val_loss: 0.7308\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.7300\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5122 - val_loss: 0.7293\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5107 - val_loss: 0.7285\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5092 - val_loss: 0.7278\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5077 - val_loss: 0.7271\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5062 - val_loss: 0.7264\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5047 - val_loss: 0.7257\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5033 - val_loss: 0.7250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5018 - val_loss: 0.7243\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.7236\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4990 - val_loss: 0.7229\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4977 - val_loss: 0.7222\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4963 - val_loss: 0.7215\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4949 - val_loss: 0.7209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4936 - val_loss: 0.7202\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4923 - val_loss: 0.7196\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4910 - val_loss: 0.7189\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4897 - val_loss: 0.7183\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4884 - val_loss: 0.7177\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.7170\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4859 - val_loss: 0.7164\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4847 - val_loss: 0.7158\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4835 - val_loss: 0.7152\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4823 - val_loss: 0.7146\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4811 - val_loss: 0.7140\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4799 - val_loss: 0.7135\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4788 - val_loss: 0.7129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4776 - val_loss: 0.7123\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4765 - val_loss: 0.7118\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4753 - val_loss: 0.7113\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4742 - val_loss: 0.7107\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4731 - val_loss: 0.7102\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4720 - val_loss: 0.7097\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4709 - val_loss: 0.7092\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4698 - val_loss: 0.7087\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4687 - val_loss: 0.7082\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.7077\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.7073\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(15, 67), test_y.shape=(15, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2846600473.0797715, my average MASE = 8256296780.299102\n",
      "Cluster 4, 2846600473.0797715\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=7, 7, 176, (267, 67)\n",
      "Before prediction: train_X.shape=(154, 10, 67), train_y.shape=(154, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3225 - val_loss: 0.2694\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3217 - val_loss: 0.2689\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3209 - val_loss: 0.2684\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3201 - val_loss: 0.2679\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3194 - val_loss: 0.2674\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3187 - val_loss: 0.2669\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3179 - val_loss: 0.2664\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3172 - val_loss: 0.2659\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3165 - val_loss: 0.2655\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3159 - val_loss: 0.2650\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3152 - val_loss: 0.2646\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3145 - val_loss: 0.2641\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3139 - val_loss: 0.2637\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3133 - val_loss: 0.2633\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3127 - val_loss: 0.2629\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3121 - val_loss: 0.2624\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3115 - val_loss: 0.2620\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3109 - val_loss: 0.2616\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3103 - val_loss: 0.2612\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3098 - val_loss: 0.2609\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3092 - val_loss: 0.2605\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3087 - val_loss: 0.2601\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3081 - val_loss: 0.2598\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3076 - val_loss: 0.2594\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3071 - val_loss: 0.2590\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3066 - val_loss: 0.2587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3061 - val_loss: 0.2584\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3056 - val_loss: 0.2580\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3051 - val_loss: 0.2576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3046 - val_loss: 0.2573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3041 - val_loss: 0.2569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3037 - val_loss: 0.2566\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3032 - val_loss: 0.2563\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3027 - val_loss: 0.2559\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3023 - val_loss: 0.2556\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3018 - val_loss: 0.2553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3013 - val_loss: 0.2550\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3009 - val_loss: 0.2546\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3005 - val_loss: 0.2543\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3000 - val_loss: 0.2540\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 173.3029589389659, my average MASE = 89033224.06135572\n",
      "Cluster 0, 173.3029589389659\n",
      "Before prediction: train_X.shape=(5960, 10, 67), train_y.shape=(5960, 67), test_X.shape=(1987, 10, 67), test_y.shape=(1987, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0675 - val_loss: 0.0464\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0617 - val_loss: 0.0432\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0584 - val_loss: 0.0410\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0560 - val_loss: 0.0393\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0541 - val_loss: 0.0377\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0525 - val_loss: 0.0364\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0512 - val_loss: 0.0353\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0501 - val_loss: 0.0343\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0492 - val_loss: 0.0335\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0484 - val_loss: 0.0327\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0477 - val_loss: 0.0321\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0471 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0466 - val_loss: 0.0310\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0461 - val_loss: 0.0306\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0457 - val_loss: 0.0302\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0453 - val_loss: 0.0299\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0449 - val_loss: 0.0296\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0445 - val_loss: 0.0293\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0442 - val_loss: 0.0291\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0288\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0286\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0284\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0432 - val_loss: 0.0282\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0424 - val_loss: 0.0275\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0421 - val_loss: 0.0272\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0420 - val_loss: 0.0271\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0419 - val_loss: 0.0270\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0417 - val_loss: 0.0269\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0268\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0413 - val_loss: 0.0265\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0412 - val_loss: 0.0264\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0409 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1987, 67), test_y.shape=(1987, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 783030752.0753396, my average MASE = 36192993113.38622\n",
      "Cluster 1, 783030752.0753396\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5458 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.3449\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.3440\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5391 - val_loss: 0.3431\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5369 - val_loss: 0.3422\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5348 - val_loss: 0.3413\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.3405\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5304 - val_loss: 0.3396\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5283 - val_loss: 0.3387\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5261 - val_loss: 0.3379\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5240 - val_loss: 0.3371\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5219 - val_loss: 0.3362\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5198 - val_loss: 0.3354\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5177 - val_loss: 0.3346\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5157 - val_loss: 0.3338\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5137 - val_loss: 0.3330\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5117 - val_loss: 0.3322\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5097 - val_loss: 0.3314\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5078 - val_loss: 0.3308\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5059 - val_loss: 0.3301\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5041 - val_loss: 0.3295\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5022 - val_loss: 0.3290\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.3284\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4986 - val_loss: 0.3279\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4968 - val_loss: 0.3274\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4951 - val_loss: 0.3269\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4933 - val_loss: 0.3264\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.3260\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4900 - val_loss: 0.3257\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4884 - val_loss: 0.3254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4868 - val_loss: 0.3251\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4852 - val_loss: 0.3249\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4836 - val_loss: 0.3247\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4821 - val_loss: 0.3245\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4805 - val_loss: 0.3244\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4790 - val_loss: 0.3242\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4775 - val_loss: 0.3241\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4760 - val_loss: 0.3240\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4745 - val_loss: 0.3239\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4730 - val_loss: 0.3238\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 300.2247881778862, my average MASE = 45822553.10580316\n",
      "Cluster 2, 300.2247881778862\n",
      "Before prediction: train_X.shape=(85, 10, 67), train_y.shape=(85, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3796 - val_loss: 0.4594\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3789 - val_loss: 0.4589\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3782 - val_loss: 0.4585\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4581\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3770 - val_loss: 0.4577\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3764 - val_loss: 0.4573\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.4569\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3753 - val_loss: 0.4565\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3748 - val_loss: 0.4561\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3737 - val_loss: 0.4554\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3732 - val_loss: 0.4550\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3727 - val_loss: 0.4547\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4543\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3717 - val_loss: 0.4540\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3713 - val_loss: 0.4537\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3708 - val_loss: 0.4533\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3703 - val_loss: 0.4530\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3699 - val_loss: 0.4527\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3694 - val_loss: 0.4524\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.4521\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3685 - val_loss: 0.4517\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3681 - val_loss: 0.4514\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3677 - val_loss: 0.4512\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3673 - val_loss: 0.4509\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3669 - val_loss: 0.4506\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3664 - val_loss: 0.4503\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4501\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3657 - val_loss: 0.4498\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3653 - val_loss: 0.4495\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3649 - val_loss: 0.4493\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3645 - val_loss: 0.4490\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3641 - val_loss: 0.4487\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.4485\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3634 - val_loss: 0.4482\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3630 - val_loss: 0.4480\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.4478\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3623 - val_loss: 0.4475\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.4473\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3616 - val_loss: 0.4470\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n",
      "average MASE = 329.8443195642471, my average MASE = 91063731.05477783\n",
      "Cluster 3, 329.8443195642471\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6262 - val_loss: 0.5214\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6239 - val_loss: 0.5202\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6216 - val_loss: 0.5190\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6193 - val_loss: 0.5179\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6170 - val_loss: 0.5167\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6148 - val_loss: 0.5156\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6125 - val_loss: 0.5145\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6102 - val_loss: 0.5134\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6080 - val_loss: 0.5123\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6058 - val_loss: 0.5112\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6036 - val_loss: 0.5101\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6015 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5994 - val_loss: 0.5080\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5973 - val_loss: 0.5070\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5953 - val_loss: 0.5060\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5932 - val_loss: 0.5051\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5912 - val_loss: 0.5041\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5892 - val_loss: 0.5032\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5872 - val_loss: 0.5023\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5853 - val_loss: 0.5015\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5834 - val_loss: 0.5006\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5816 - val_loss: 0.4999\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5799 - val_loss: 0.4991\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5782 - val_loss: 0.4984\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5765 - val_loss: 0.4977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5749 - val_loss: 0.4970\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5732 - val_loss: 0.4963\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5716 - val_loss: 0.4957\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5699 - val_loss: 0.4951\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5683 - val_loss: 0.4946\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5667 - val_loss: 0.4941\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5651 - val_loss: 0.4936\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5635 - val_loss: 0.4931\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5619 - val_loss: 0.4927\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5604 - val_loss: 0.4922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5588 - val_loss: 0.4917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5573 - val_loss: 0.4913\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5557 - val_loss: 0.4909\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5542 - val_loss: 0.4906\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5526 - val_loss: 0.4902\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32309710873507563, my average MASE = 0.5656513264705396\n",
      "Cluster 4, 0.32309710873507563\n",
      "Before prediction: train_X.shape=(43, 10, 67), train_y.shape=(43, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5119 - val_loss: 0.6850\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5101 - val_loss: 0.6839\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5083 - val_loss: 0.6829\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5066 - val_loss: 0.6819\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5048 - val_loss: 0.6808\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.6798\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5014 - val_loss: 0.6788\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.6778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4980 - val_loss: 0.6769\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4964 - val_loss: 0.6759\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4948 - val_loss: 0.6749\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4931 - val_loss: 0.6740\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4915 - val_loss: 0.6730\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4900 - val_loss: 0.6721\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4884 - val_loss: 0.6711\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4869 - val_loss: 0.6702\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4853 - val_loss: 0.6693\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4838 - val_loss: 0.6683\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6674\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4808 - val_loss: 0.6665\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.6656\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4779 - val_loss: 0.6647\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4765 - val_loss: 0.6639\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4751 - val_loss: 0.6630\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4737 - val_loss: 0.6622\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4723 - val_loss: 0.6613\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4710 - val_loss: 0.6605\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4697 - val_loss: 0.6596\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4683 - val_loss: 0.6588\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4670 - val_loss: 0.6580\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4657 - val_loss: 0.6572\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4644 - val_loss: 0.6564\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4631 - val_loss: 0.6556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4619 - val_loss: 0.6548\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4606 - val_loss: 0.6540\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4594 - val_loss: 0.6532\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4581 - val_loss: 0.6525\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4569 - val_loss: 0.6517\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4557 - val_loss: 0.6510\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4545 - val_loss: 0.6502\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2340337256.388025, my average MASE = 7806499481.251814\n",
      "Cluster 5, 2340337256.388025\n",
      "Before prediction: train_X.shape=(181, 10, 67), train_y.shape=(181, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6846 - val_loss: 0.5744\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6833 - val_loss: 0.5737\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6820 - val_loss: 0.5730\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6807 - val_loss: 0.5723\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6795 - val_loss: 0.5716\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6783 - val_loss: 0.5709\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6771 - val_loss: 0.5703\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6760 - val_loss: 0.5696\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6749 - val_loss: 0.5690\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6737 - val_loss: 0.5683\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6727 - val_loss: 0.5677\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6716 - val_loss: 0.5671\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6705 - val_loss: 0.5666\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6695 - val_loss: 0.5660\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6685 - val_loss: 0.5654\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6675 - val_loss: 0.5648\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6664 - val_loss: 0.5643\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6654 - val_loss: 0.5637\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6645 - val_loss: 0.5632\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6635 - val_loss: 0.5626\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6626 - val_loss: 0.5621\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.6616 - val_loss: 0.5615\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6607 - val_loss: 0.5610\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6597 - val_loss: 0.5605\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6588 - val_loss: 0.5600\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6579 - val_loss: 0.5594\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6570 - val_loss: 0.5589\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6561 - val_loss: 0.5584\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6553 - val_loss: 0.5579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6544 - val_loss: 0.5574\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6536 - val_loss: 0.5569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6527 - val_loss: 0.5563\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6519 - val_loss: 0.5558\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6510 - val_loss: 0.5553\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6502 - val_loss: 0.5548\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6493 - val_loss: 0.5543\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6485 - val_loss: 0.5538\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6477 - val_loss: 0.5533\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6468 - val_loss: 0.5528\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6460 - val_loss: 0.5523\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 153.88341287865387, my average MASE = 335532064.75560737\n",
      "Cluster 6, 153.88341287865387\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=9, 9, 3, (61, 67)\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5800 - val_loss: 0.4525\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5784 - val_loss: 0.4515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5768 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5753 - val_loss: 0.4496\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5738 - val_loss: 0.4487\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5722 - val_loss: 0.4477\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5707 - val_loss: 0.4468\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5692 - val_loss: 0.4459\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5678 - val_loss: 0.4450\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5663 - val_loss: 0.4441\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5648 - val_loss: 0.4433\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5634 - val_loss: 0.4424\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5619 - val_loss: 0.4415\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5605 - val_loss: 0.4407\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5590 - val_loss: 0.4398\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5576 - val_loss: 0.4390\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5562 - val_loss: 0.4382\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5548 - val_loss: 0.4374\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5534 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5520 - val_loss: 0.4359\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5507 - val_loss: 0.4352\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5493 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5480 - val_loss: 0.4337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5467 - val_loss: 0.4329\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 0.4322\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5441 - val_loss: 0.4315\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5428 - val_loss: 0.4308\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5415 - val_loss: 0.4301\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5403 - val_loss: 0.4294\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5390 - val_loss: 0.4287\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5378 - val_loss: 0.4280\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5366 - val_loss: 0.4273\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5354 - val_loss: 0.4266\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5342 - val_loss: 0.4260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5330 - val_loss: 0.4253\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5318 - val_loss: 0.4246\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5307 - val_loss: 0.4240\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5295 - val_loss: 0.4234\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5284 - val_loss: 0.4227\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5273 - val_loss: 0.4221\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 35650627.66244785, my average MASE = 4899168813.139491\n",
      "Cluster 0, 35650627.66244785\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7142 - val_loss: 0.5624\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7129 - val_loss: 0.5618\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7116 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7104 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7092 - val_loss: 0.5599\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7080 - val_loss: 0.5593\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7069 - val_loss: 0.5588\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7057 - val_loss: 0.5582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7046 - val_loss: 0.5576\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7035 - val_loss: 0.5571\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5565\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7013 - val_loss: 0.5560\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7002 - val_loss: 0.5555\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6993 - val_loss: 0.5550\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6982 - val_loss: 0.5545\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6972 - val_loss: 0.5540\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5535\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6952 - val_loss: 0.5530\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6942 - val_loss: 0.5525\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6932 - val_loss: 0.5520\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5516\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6913 - val_loss: 0.5511\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6903 - val_loss: 0.5506\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6894 - val_loss: 0.5502\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6885 - val_loss: 0.5498\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6875 - val_loss: 0.5493\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6866 - val_loss: 0.5489\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6857 - val_loss: 0.5485\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6848 - val_loss: 0.5481\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6839 - val_loss: 0.5477\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6830 - val_loss: 0.5472\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6821 - val_loss: 0.5468\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6812 - val_loss: 0.5464\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6803 - val_loss: 0.5460\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6794 - val_loss: 0.5456\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.5452\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6777 - val_loss: 0.5449\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6768 - val_loss: 0.5445\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6759 - val_loss: 0.5441\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6751 - val_loss: 0.5437\n",
      "2/2 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n",
      "average MASE = 167.81473432422789, my average MASE = 220460085.3598021\n",
      "Cluster 1, 167.81473432422789\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4267 - val_loss: 0.6677\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4246 - val_loss: 0.6662\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4226 - val_loss: 0.6647\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4205 - val_loss: 0.6632\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.6618\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4166 - val_loss: 0.6605\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4146 - val_loss: 0.6592\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4127 - val_loss: 0.6578\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4107 - val_loss: 0.6565\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4088 - val_loss: 0.6552\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4070 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4051 - val_loss: 0.6527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4033 - val_loss: 0.6514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4014 - val_loss: 0.6502\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3997 - val_loss: 0.6490\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3979 - val_loss: 0.6478\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3961 - val_loss: 0.6466\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3944 - val_loss: 0.6455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3927 - val_loss: 0.6444\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3910 - val_loss: 0.6433\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3893 - val_loss: 0.6423\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3877 - val_loss: 0.6412\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3861 - val_loss: 0.6402\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3845 - val_loss: 0.6392\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3829 - val_loss: 0.6383\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3814 - val_loss: 0.6374\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3799 - val_loss: 0.6364\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3784 - val_loss: 0.6356\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3769 - val_loss: 0.6347\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3754 - val_loss: 0.6338\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3740 - val_loss: 0.6330\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3725 - val_loss: 0.6322\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3711 - val_loss: 0.6314\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3697 - val_loss: 0.6305\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3683 - val_loss: 0.6297\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3669 - val_loss: 0.6289\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.6281\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3642 - val_loss: 0.6273\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3629 - val_loss: 0.6264\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3616 - val_loss: 0.6256\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1967377505.4498963, my average MASE = 5262000054.755049\n",
      "Cluster 2, 1967377505.4498963\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6328 - val_loss: 0.7373\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6300 - val_loss: 0.7359\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6272 - val_loss: 0.7344\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6245 - val_loss: 0.7330\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6218 - val_loss: 0.7316\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6191 - val_loss: 0.7301\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6164 - val_loss: 0.7287\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6137 - val_loss: 0.7273\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6111 - val_loss: 0.7259\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6085 - val_loss: 0.7245\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6058 - val_loss: 0.7230\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6033 - val_loss: 0.7216\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6009 - val_loss: 0.7202\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5985 - val_loss: 0.7188\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5961 - val_loss: 0.7174\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5938 - val_loss: 0.7159\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5915 - val_loss: 0.7146\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5892 - val_loss: 0.7133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5869 - val_loss: 0.7119\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5847 - val_loss: 0.7106\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5825 - val_loss: 0.7092\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5803 - val_loss: 0.7078\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5781 - val_loss: 0.7064\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5759 - val_loss: 0.7050\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5738 - val_loss: 0.7036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5716 - val_loss: 0.7022\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5695 - val_loss: 0.7009\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5674 - val_loss: 0.6996\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5653 - val_loss: 0.6983\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5632 - val_loss: 0.6971\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5611 - val_loss: 0.6959\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5590 - val_loss: 0.6946\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5569 - val_loss: 0.6934\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5549 - val_loss: 0.6922\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5528 - val_loss: 0.6910\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5509 - val_loss: 0.6898\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5490 - val_loss: 0.6886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5472 - val_loss: 0.6874\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5454 - val_loss: 0.6862\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.6850\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.27232041656941225, my average MASE = 0.501167640234202\n",
      "Cluster 3, 0.27232041656941225\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4602 - val_loss: 0.3734\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4580 - val_loss: 0.3723\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4558 - val_loss: 0.3714\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4536 - val_loss: 0.3704\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4515 - val_loss: 0.3694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4494 - val_loss: 0.3685\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4474 - val_loss: 0.3675\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4454 - val_loss: 0.3666\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4435 - val_loss: 0.3657\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4416 - val_loss: 0.3648\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4397 - val_loss: 0.3640\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4379 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4361 - val_loss: 0.3623\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4344 - val_loss: 0.3616\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4328 - val_loss: 0.3608\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4312 - val_loss: 0.3601\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4296 - val_loss: 0.3594\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4279 - val_loss: 0.3587\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4263 - val_loss: 0.3581\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4247 - val_loss: 0.3575\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4231 - val_loss: 0.3569\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.3564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4200 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4184 - val_loss: 0.3553\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4169 - val_loss: 0.3547\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4154 - val_loss: 0.3542\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4138 - val_loss: 0.3537\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4123 - val_loss: 0.3533\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4109 - val_loss: 0.3528\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4094 - val_loss: 0.3524\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4080 - val_loss: 0.3520\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4066 - val_loss: 0.3516\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4053 - val_loss: 0.3512\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4039 - val_loss: 0.3508\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4026 - val_loss: 0.3505\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4000 - val_loss: 0.3498\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3987 - val_loss: 0.3495\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3974 - val_loss: 0.3492\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3490\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 363.8540679781247, my average MASE = 17706113.36217601\n",
      "Cluster 4, 363.8540679781247\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4172 - val_loss: 0.5128\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4165 - val_loss: 0.5124\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4158 - val_loss: 0.5121\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4151 - val_loss: 0.5117\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.5113\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4139 - val_loss: 0.5110\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4132 - val_loss: 0.5107\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4126 - val_loss: 0.5103\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4120 - val_loss: 0.5100\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4114 - val_loss: 0.5096\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4108 - val_loss: 0.5093\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4102 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4097 - val_loss: 0.5086\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4091 - val_loss: 0.5083\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4085 - val_loss: 0.5080\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4080 - val_loss: 0.5077\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.5074\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4069 - val_loss: 0.5071\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4064 - val_loss: 0.5068\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4059 - val_loss: 0.5065\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.5062\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4048 - val_loss: 0.5059\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4043 - val_loss: 0.5056\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4038 - val_loss: 0.5053\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.5051\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4029 - val_loss: 0.5048\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4019 - val_loss: 0.5042\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4014 - val_loss: 0.5039\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4010 - val_loss: 0.5036\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4005 - val_loss: 0.5033\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4000 - val_loss: 0.5030\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3996 - val_loss: 0.5028\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3991 - val_loss: 0.5025\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3987 - val_loss: 0.5022\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3983 - val_loss: 0.5019\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3978 - val_loss: 0.5016\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5013\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3969 - val_loss: 0.5011\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3965 - val_loss: 0.5008\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 210.04101539413423, my average MASE = 60624707.44207928\n",
      "Cluster 5, 210.04101539413423\n",
      "Before prediction: train_X.shape=(104, 10, 67), train_y.shape=(104, 67), test_X.shape=(35, 10, 67), test_y.shape=(35, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3090 - val_loss: 0.2755\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3084 - val_loss: 0.2752\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3078 - val_loss: 0.2749\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3072 - val_loss: 0.2745\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3066 - val_loss: 0.2742\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3061 - val_loss: 0.2739\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3055 - val_loss: 0.2736\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3049 - val_loss: 0.2733\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3044 - val_loss: 0.2730\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3039 - val_loss: 0.2727\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.2724\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3028 - val_loss: 0.2722\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.2719\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3018 - val_loss: 0.2716\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3013 - val_loss: 0.2713\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3008 - val_loss: 0.2711\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3003 - val_loss: 0.2708\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2998 - val_loss: 0.2705\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2994 - val_loss: 0.2703\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2989 - val_loss: 0.2700\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2984 - val_loss: 0.2698\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2980 - val_loss: 0.2695\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2975 - val_loss: 0.2693\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2971 - val_loss: 0.2690\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2966 - val_loss: 0.2688\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2962 - val_loss: 0.2686\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2958 - val_loss: 0.2683\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2953 - val_loss: 0.2681\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2949 - val_loss: 0.2678\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2945 - val_loss: 0.2676\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2941 - val_loss: 0.2674\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2937 - val_loss: 0.2671\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2933 - val_loss: 0.2669\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2929 - val_loss: 0.2667\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2925 - val_loss: 0.2664\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2921 - val_loss: 0.2662\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2917 - val_loss: 0.2660\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2913 - val_loss: 0.2658\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2909 - val_loss: 0.2656\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2906 - val_loss: 0.2654\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(35, 67), test_y.shape=(35, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 554.2347835476104, my average MASE = 43885073.200175166\n",
      "Cluster 6, 554.2347835476104\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6507 - val_loss: 0.5207\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6481 - val_loss: 0.5200\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6456 - val_loss: 0.5192\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6431 - val_loss: 0.5184\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6407 - val_loss: 0.5176\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6383 - val_loss: 0.5169\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6360 - val_loss: 0.5161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6338 - val_loss: 0.5154\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6316 - val_loss: 0.5147\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6293 - val_loss: 0.5140\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6271 - val_loss: 0.5133\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6249 - val_loss: 0.5126\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6227 - val_loss: 0.5119\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6206 - val_loss: 0.5112\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6185 - val_loss: 0.5105\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6164 - val_loss: 0.5099\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6145 - val_loss: 0.5093\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6125 - val_loss: 0.5087\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6107 - val_loss: 0.5082\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6088 - val_loss: 0.5076\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6069 - val_loss: 0.5071\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6051 - val_loss: 0.5067\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6032 - val_loss: 0.5062\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6014 - val_loss: 0.5058\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5996 - val_loss: 0.5053\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5978 - val_loss: 0.5049\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5959 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5941 - val_loss: 0.5040\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5923 - val_loss: 0.5036\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5905 - val_loss: 0.5033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5888 - val_loss: 0.5030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5871 - val_loss: 0.5027\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5853 - val_loss: 0.5024\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5837 - val_loss: 0.5021\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5822 - val_loss: 0.5017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5806 - val_loss: 0.5014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5791 - val_loss: 0.5011\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5775 - val_loss: 0.5009\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5760 - val_loss: 0.5006\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5745 - val_loss: 0.5004\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2390672605525707, my average MASE = 0.4689912396588464\n",
      "Cluster 7, 0.2390672605525707\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1191 - val_loss: 0.0992\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1138 - val_loss: 0.0972\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1096 - val_loss: 0.0959\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1060 - val_loss: 0.0949\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1029 - val_loss: 0.0942\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1002 - val_loss: 0.0935\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0977 - val_loss: 0.0930\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0955 - val_loss: 0.0925\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0916 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0899 - val_loss: 0.0913\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0884 - val_loss: 0.0909\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0870 - val_loss: 0.0906\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0856 - val_loss: 0.0903\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0844 - val_loss: 0.0900\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0833 - val_loss: 0.0898\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0896\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0812 - val_loss: 0.0894\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0803 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0778 - val_loss: 0.0887\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0771 - val_loss: 0.0886\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0764 - val_loss: 0.0885\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0757 - val_loss: 0.0884\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0751 - val_loss: 0.0883\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0745 - val_loss: 0.0882\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0739 - val_loss: 0.0881\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0880\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0879\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0723 - val_loss: 0.0879\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0878\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0877\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0711 - val_loss: 0.0876\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0707 - val_loss: 0.0876\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0703 - val_loss: 0.0875\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0700 - val_loss: 0.0874\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0873\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0694 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 1385618831.00148, my average MASE = 22365614226.60064\n",
      "Cluster 8, 1385618831.00148\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=11, 11, 68, (49, 67)\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5560 - val_loss: 0.4967\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5553 - val_loss: 0.4965\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5546 - val_loss: 0.4963\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5538 - val_loss: 0.4961\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5531 - val_loss: 0.4960\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5524 - val_loss: 0.4958\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5517 - val_loss: 0.4956\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5510 - val_loss: 0.4955\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5503 - val_loss: 0.4953\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5496 - val_loss: 0.4952\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5489 - val_loss: 0.4950\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 0.4949\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5476 - val_loss: 0.4947\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5469 - val_loss: 0.4946\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5463 - val_loss: 0.4945\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5456 - val_loss: 0.4943\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5450 - val_loss: 0.4942\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5443 - val_loss: 0.4940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5437 - val_loss: 0.4939\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5431 - val_loss: 0.4938\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5425 - val_loss: 0.4936\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5419 - val_loss: 0.4935\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.4934\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5407 - val_loss: 0.4933\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5401 - val_loss: 0.4932\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5395 - val_loss: 0.4930\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5389 - val_loss: 0.4929\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5384 - val_loss: 0.4928\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5378 - val_loss: 0.4927\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5372 - val_loss: 0.4926\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5367 - val_loss: 0.4925\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 0.4923\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5356 - val_loss: 0.4922\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5351 - val_loss: 0.4921\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5345 - val_loss: 0.4920\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5340 - val_loss: 0.4919\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5335 - val_loss: 0.4918\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5329 - val_loss: 0.4917\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5324 - val_loss: 0.4915\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5319 - val_loss: 0.4914\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 62.874751666083846, my average MASE = 63681940.89448814\n",
      "Cluster 0, 62.874751666083846\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3794 - val_loss: 0.4534\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3770 - val_loss: 0.4520\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3747 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3724 - val_loss: 0.4494\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3701 - val_loss: 0.4481\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3678 - val_loss: 0.4468\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.4455\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3634 - val_loss: 0.4443\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3612 - val_loss: 0.4430\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3591 - val_loss: 0.4418\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3571 - val_loss: 0.4406\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3551 - val_loss: 0.4394\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3531 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3511 - val_loss: 0.4371\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3492 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3473 - val_loss: 0.4348\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3454 - val_loss: 0.4337\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3436 - val_loss: 0.4326\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3418 - val_loss: 0.4315\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3400 - val_loss: 0.4305\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3382 - val_loss: 0.4294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3365 - val_loss: 0.4284\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3349 - val_loss: 0.4273\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3332 - val_loss: 0.4263\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3316 - val_loss: 0.4253\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3300 - val_loss: 0.4243\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.4233\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3269 - val_loss: 0.4224\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3254 - val_loss: 0.4214\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.4205\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3224 - val_loss: 0.4196\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.4186\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3195 - val_loss: 0.4177\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3181 - val_loss: 0.4168\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3166 - val_loss: 0.4159\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3153 - val_loss: 0.4151\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3139 - val_loss: 0.4142\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3125 - val_loss: 0.4134\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3112 - val_loss: 0.4125\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3098 - val_loss: 0.4117\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1188796320.3185039, my average MASE = 2779981174.701244\n",
      "Cluster 1, 1188796320.3185039\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6283 - val_loss: 0.6105\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6261 - val_loss: 0.6091\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6239 - val_loss: 0.6076\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6218 - val_loss: 0.6062\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6196 - val_loss: 0.6047\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6175 - val_loss: 0.6033\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6153 - val_loss: 0.6018\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6132 - val_loss: 0.6004\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6110 - val_loss: 0.5990\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6089 - val_loss: 0.5976\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6067 - val_loss: 0.5961\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6046 - val_loss: 0.5947\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6026 - val_loss: 0.5933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6005 - val_loss: 0.5919\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5985 - val_loss: 0.5905\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5964 - val_loss: 0.5891\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5944 - val_loss: 0.5877\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5923 - val_loss: 0.5866\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5903 - val_loss: 0.5854\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5882 - val_loss: 0.5842\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5861 - val_loss: 0.5831\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5841 - val_loss: 0.5819\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5820 - val_loss: 0.5808\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5799 - val_loss: 0.5796\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5778 - val_loss: 0.5784\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5758 - val_loss: 0.5773\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5737 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5717 - val_loss: 0.5751\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5697 - val_loss: 0.5740\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5676 - val_loss: 0.5731\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5656 - val_loss: 0.5721\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5636 - val_loss: 0.5712\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5616 - val_loss: 0.5703\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5597 - val_loss: 0.5694\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5577 - val_loss: 0.5686\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5558 - val_loss: 0.5678\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5538 - val_loss: 0.5670\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5519 - val_loss: 0.5663\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5499 - val_loss: 0.5655\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5480 - val_loss: 0.5647\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32481366416229096, my average MASE = 0.6312112420260654\n",
      "Cluster 2, 0.32481366416229096\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4564 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4555 - val_loss: 0.4793\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4547 - val_loss: 0.4791\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4538 - val_loss: 0.4788\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4529 - val_loss: 0.4786\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4521 - val_loss: 0.4783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4512 - val_loss: 0.4781\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4504 - val_loss: 0.4778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4496 - val_loss: 0.4776\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4487 - val_loss: 0.4773\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4479 - val_loss: 0.4771\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4471 - val_loss: 0.4768\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4463 - val_loss: 0.4766\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4455 - val_loss: 0.4763\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4447 - val_loss: 0.4760\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4439 - val_loss: 0.4758\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4431 - val_loss: 0.4755\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4423 - val_loss: 0.4753\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4415 - val_loss: 0.4750\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4407 - val_loss: 0.4747\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4400 - val_loss: 0.4745\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4742\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4385 - val_loss: 0.4739\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4377 - val_loss: 0.4736\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4370 - val_loss: 0.4733\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4362 - val_loss: 0.4730\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4355 - val_loss: 0.4727\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4724\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4341 - val_loss: 0.4721\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4334 - val_loss: 0.4717\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4327 - val_loss: 0.4714\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4320 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4313 - val_loss: 0.4708\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4307 - val_loss: 0.4705\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4300 - val_loss: 0.4701\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4293 - val_loss: 0.4698\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4286 - val_loss: 0.4694\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4280 - val_loss: 0.4691\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4273 - val_loss: 0.4688\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4266 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1418783.6078857174, my average MASE = 35875462.94910899\n",
      "Cluster 3, 1418783.6078857174\n",
      "Before prediction: train_X.shape=(27, 10, 67), train_y.shape=(27, 67), test_X.shape=(9, 10, 67), test_y.shape=(9, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3810 - val_loss: 0.3926\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3805 - val_loss: 0.3924\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3799 - val_loss: 0.3923\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3794 - val_loss: 0.3921\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3789 - val_loss: 0.3920\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3784 - val_loss: 0.3918\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3779 - val_loss: 0.3917\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3774 - val_loss: 0.3916\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3769 - val_loss: 0.3914\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3764 - val_loss: 0.3913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3759 - val_loss: 0.3911\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3754 - val_loss: 0.3910\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3749 - val_loss: 0.3909\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3744 - val_loss: 0.3907\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3739 - val_loss: 0.3906\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3734 - val_loss: 0.3905\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3729 - val_loss: 0.3903\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3725 - val_loss: 0.3902\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3720 - val_loss: 0.3901\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3715 - val_loss: 0.3900\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3711 - val_loss: 0.3899\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3706 - val_loss: 0.3898\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3701 - val_loss: 0.3896\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3697 - val_loss: 0.3895\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3692 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3688 - val_loss: 0.3893\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3683 - val_loss: 0.3892\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3679 - val_loss: 0.3891\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3674 - val_loss: 0.3890\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3670 - val_loss: 0.3889\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3666 - val_loss: 0.3888\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3661 - val_loss: 0.3887\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3657 - val_loss: 0.3886\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3653 - val_loss: 0.3885\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3648 - val_loss: 0.3884\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3644 - val_loss: 0.3883\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3640 - val_loss: 0.3882\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3636 - val_loss: 0.3881\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3632 - val_loss: 0.3880\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3627 - val_loss: 0.3879\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(9, 67), test_y.shape=(9, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 73.99923698083529, my average MASE = 28273926.299095076\n",
      "Cluster 4, 73.99923698083529\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1188 - val_loss: 0.0994\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1133 - val_loss: 0.0973\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1090 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1053 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1021 - val_loss: 0.0936\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0993 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0969 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0946 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0893 - val_loss: 0.0908\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0878 - val_loss: 0.0906\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0864 - val_loss: 0.0903\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0852 - val_loss: 0.0901\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0841 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0830 - val_loss: 0.0897\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0820 - val_loss: 0.0895\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0811 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0802 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0888\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0772 - val_loss: 0.0887\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0886\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0759 - val_loss: 0.0885\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0753 - val_loss: 0.0884\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0747 - val_loss: 0.0884\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0742 - val_loss: 0.0883\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0737 - val_loss: 0.0882\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0881\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0881\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0724 - val_loss: 0.0880\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0720 - val_loss: 0.0880\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0716 - val_loss: 0.0879\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0879\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0879\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0878\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0877\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0699 - val_loss: 0.0877\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0877\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 772933595.2163092, my average MASE = 33112652144.926693\n",
      "Cluster 5, 772933595.2163092\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6742 - val_loss: 0.5426\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6711 - val_loss: 0.5410\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6680 - val_loss: 0.5395\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6649 - val_loss: 0.5381\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6619 - val_loss: 0.5366\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6589 - val_loss: 0.5352\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6560 - val_loss: 0.5338\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6532 - val_loss: 0.5324\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6503 - val_loss: 0.5310\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6475 - val_loss: 0.5296\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6447 - val_loss: 0.5282\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6420 - val_loss: 0.5269\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6393 - val_loss: 0.5255\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6367 - val_loss: 0.5242\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6340 - val_loss: 0.5229\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6314 - val_loss: 0.5216\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6289 - val_loss: 0.5203\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6264 - val_loss: 0.5190\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6240 - val_loss: 0.5178\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6215 - val_loss: 0.5165\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6191 - val_loss: 0.5153\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6168 - val_loss: 0.5141\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6145 - val_loss: 0.5128\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6122 - val_loss: 0.5115\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6098 - val_loss: 0.5102\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6076 - val_loss: 0.5089\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6054 - val_loss: 0.5076\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6033 - val_loss: 0.5062\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6011 - val_loss: 0.5049\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5989 - val_loss: 0.5035\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5968 - val_loss: 0.5022\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5947 - val_loss: 0.5009\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5928 - val_loss: 0.4996\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5908 - val_loss: 0.4982\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5889 - val_loss: 0.4969\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5869 - val_loss: 0.4956\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5850 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5831 - val_loss: 0.4932\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5812 - val_loss: 0.4921\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5794 - val_loss: 0.4911\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.24234404135098125, my average MASE = 0.42071116848846357\n",
      "Cluster 6, 0.24234404135098125\n",
      "Before prediction: train_X.shape=(50, 10, 67), train_y.shape=(50, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4441 - val_loss: 0.4379\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4435 - val_loss: 0.4378\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4430 - val_loss: 0.4376\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4425 - val_loss: 0.4374\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4372\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4414 - val_loss: 0.4371\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4409 - val_loss: 0.4369\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4404 - val_loss: 0.4367\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4398 - val_loss: 0.4366\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4364\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.4362\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4383 - val_loss: 0.4361\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4378 - val_loss: 0.4359\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4373 - val_loss: 0.4357\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4368 - val_loss: 0.4356\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4363 - val_loss: 0.4354\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4358 - val_loss: 0.4352\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4353 - val_loss: 0.4351\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4348 - val_loss: 0.4349\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4343 - val_loss: 0.4348\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4339 - val_loss: 0.4346\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4334 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4329 - val_loss: 0.4343\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4341\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4320 - val_loss: 0.4340\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4315 - val_loss: 0.4338\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4310 - val_loss: 0.4337\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4306 - val_loss: 0.4335\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4301 - val_loss: 0.4334\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4296 - val_loss: 0.4332\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4292 - val_loss: 0.4331\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4287 - val_loss: 0.4329\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4283 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4278 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4274 - val_loss: 0.4325\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4269 - val_loss: 0.4323\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4265 - val_loss: 0.4322\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4261 - val_loss: 0.4320\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4256 - val_loss: 0.4319\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4252 - val_loss: 0.4317\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 191.2474349797922, my average MASE = 74799483.45709221\n",
      "Cluster 7, 191.2474349797922\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2212 - val_loss: 0.1239\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2202 - val_loss: 0.1236\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2192 - val_loss: 0.1233\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2183 - val_loss: 0.1230\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2174 - val_loss: 0.1228\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2165 - val_loss: 0.1225\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2156 - val_loss: 0.1223\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2147 - val_loss: 0.1221\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2138 - val_loss: 0.1219\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2129 - val_loss: 0.1217\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2120 - val_loss: 0.1215\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2111 - val_loss: 0.1213\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2102 - val_loss: 0.1212\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2093 - val_loss: 0.1211\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2085 - val_loss: 0.1210\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2076 - val_loss: 0.1209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2068 - val_loss: 0.1208\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2059 - val_loss: 0.1207\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2051 - val_loss: 0.1207\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2042 - val_loss: 0.1206\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2034 - val_loss: 0.1206\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2026 - val_loss: 0.1205\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2018 - val_loss: 0.1204\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2010 - val_loss: 0.1204\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2002 - val_loss: 0.1203\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1995 - val_loss: 0.1203\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1987 - val_loss: 0.1203\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1980 - val_loss: 0.1203\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1973 - val_loss: 0.1203\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1965 - val_loss: 0.1203\n",
      "Epoch 30: early stopping\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.15391611936993946, my average MASE = 0.29566028544300293\n",
      "Cluster 8, 0.15391611936993946\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5076 - val_loss: 0.4286\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5055 - val_loss: 0.4276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5036 - val_loss: 0.4266\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5017 - val_loss: 0.4256\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4998 - val_loss: 0.4246\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4980 - val_loss: 0.4236\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4962 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4944 - val_loss: 0.4217\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4926 - val_loss: 0.4208\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4908 - val_loss: 0.4199\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4890 - val_loss: 0.4191\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4871 - val_loss: 0.4182\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4853 - val_loss: 0.4173\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4835 - val_loss: 0.4164\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4817 - val_loss: 0.4156\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4148\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4782 - val_loss: 0.4140\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4765 - val_loss: 0.4133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4749 - val_loss: 0.4126\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4732 - val_loss: 0.4118\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4717 - val_loss: 0.4111\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4701 - val_loss: 0.4104\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4686 - val_loss: 0.4097\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4671 - val_loss: 0.4089\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4656 - val_loss: 0.4082\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4641 - val_loss: 0.4075\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4627 - val_loss: 0.4068\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4613 - val_loss: 0.4061\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4600 - val_loss: 0.4054\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4587 - val_loss: 0.4048\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4573 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4560 - val_loss: 0.4036\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4546 - val_loss: 0.4030\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4533 - val_loss: 0.4025\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4520 - val_loss: 0.4019\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4506 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4493 - val_loss: 0.4009\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4480 - val_loss: 0.4004\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.3999\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4454 - val_loss: 0.3994\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2425229695624874, my average MASE = 0.5232189989788755\n",
      "Cluster 9, 0.2425229695624874\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4116 - val_loss: 0.3522\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4095 - val_loss: 0.3515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.3508\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4055 - val_loss: 0.3501\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3494\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4016 - val_loss: 0.3488\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3996 - val_loss: 0.3481\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3977 - val_loss: 0.3475\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3920 - val_loss: 0.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3902 - val_loss: 0.3450\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3884 - val_loss: 0.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3865 - val_loss: 0.3439\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3847 - val_loss: 0.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3829 - val_loss: 0.3430\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3811 - val_loss: 0.3425\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3793 - val_loss: 0.3420\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3776 - val_loss: 0.3416\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3759 - val_loss: 0.3411\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3742 - val_loss: 0.3407\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3725 - val_loss: 0.3402\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3708 - val_loss: 0.3398\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3692 - val_loss: 0.3394\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3675 - val_loss: 0.3390\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3659 - val_loss: 0.3386\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3644 - val_loss: 0.3382\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3628 - val_loss: 0.3379\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3376\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3597 - val_loss: 0.3373\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3583 - val_loss: 0.3370\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3568 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3554 - val_loss: 0.3364\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3540 - val_loss: 0.3361\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3526 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3512 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3498 - val_loss: 0.3352\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3484 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3471 - val_loss: 0.3347\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3457 - val_loss: 0.3344\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 624.4867423423187, my average MASE = 18127046.32229549\n",
      "Cluster 10, 624.4867423423187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maes = defaultdict(lambda: [])\n",
    "mases = defaultdict(lambda: [])\n",
    "mapes = defaultdict(lambda: [])\n",
    "answers = {}\n",
    "bad_values = np.zeros(dataset.shape[1])\n",
    "\n",
    "dif=True\n",
    "\n",
    "for window_size in window_sizes_for_clustering:\n",
    "    for N_clusters in Ns_clusters:\n",
    "        dataset_windows, dataset_y = Forecasting.create_windows(dataset, window_size=window_size)\n",
    "        clusters_labels = Clustering.KMeans_for_windows(dataset_windows, W=window_size, N_clusters=N_clusters, max_iter=50)\n",
    "        print(f\"{clusters_labels.shape=}\")\n",
    "        datasets_clusters = Clustering.flatten_from_interceting_windows(dataset_windows, clusters_labels, W=window_size, \\\n",
    "                N_clusters=N_clusters)\n",
    "        # list of list of ndarrays [N_i, Q], dataset_clusters[cluster_num][i] - i-th part of dataset for cluster_num\n",
    "\n",
    "        print(f\"{N_clusters=}, {len(datasets_clusters)}, {len(datasets_clusters[0])}, {datasets_clusters[0][0].shape}\")\n",
    "        ###window_size for model\n",
    "        errors = [1] * N_clusters\n",
    "        for cluster_num in range(N_clusters):\n",
    "            sc = Forecasting.MyStandardScaler(dif=dif)\n",
    "            #datasets_clusters[cluster_num] - list of [N_i, Q] ndarrays\n",
    "            sc.fit(datasets_clusters[cluster_num])\n",
    "            prepared_data = sc.transform(datasets_clusters[cluster_num])\n",
    "            data_X, data_y = Forecasting.create_windows(prepared_data, window_size=10)\n",
    "            #data_X - list of [N_i-W, W, Q] ndarrays\n",
    "            train_X, train_y, valid_X, valid_y, test_X, test_y, ind = Forecasting.split_to_train_test(data_X, data_y, part_of_test=0.2, part_of_valid=0.2)\n",
    "            #ndarrays [N_i, W, Q] or [N_i, Q]\n",
    "            ind = np.array(ind) + window_size\n",
    "            print(f\"Before prediction: {train_X.shape=}, {train_y.shape=}, {test_X.shape=}, {test_y.shape=}\")\n",
    "            try:\n",
    "                assert(len(test_X.shape) == 3 and test_X.shape[0] > 0)\n",
    "                assert(len(valid_X.shape) == 3 and valid_X.shape[0] > 0)\n",
    "                assert(len(train_X.shape) == 3 and train_X.shape[0] > 0)\n",
    "            except AssertionError:\n",
    "                print(f\"FAIL - {test_X.shape=}, {valid_X.shape=}, {train_X.shape=}\")\n",
    "                errors[cluster_num] = np.Inf\n",
    "                continue\n",
    "            model, history = Forecasting.learn(train_X, train_y, valid_X=valid_X, valid_y=valid_y)\n",
    "            predicted = model.predict(test_X)\n",
    "            predicted_original = sc.inverse_transform(predicted)[0]\n",
    "            #inverse_trasform returns list of ndarrays \n",
    "            # if dif:\n",
    "                #константа при дифференцировании\n",
    "                # predicted_original = sc.add_first_element(predicted_original, ind)[0]\n",
    "            print(f\"{predicted_original.shape=}, {test_y.shape=}\")\n",
    "\n",
    "            #calc all metrics\n",
    "            cur_mae = mae(test_y, predicted_original, multioutput='raw_values')\n",
    "#             error_out = mase(test_y, predicted_original, y_train=test_y)\n",
    "#             error_in = mase(test_y, predicted_original, y_train=train_y)\n",
    "            # cur_mase = mase(test_y, predicted_original, y_train=test_y)\n",
    "            cur_mape = mape(test_y, predicted_original)\n",
    "            cur_mase = Forecasting.my_mase(test_y, predicted_original, multioutput='raw_values')\n",
    "            maes[(window_size, N_clusters)].append(cur_mae)\n",
    "#             mases[(window_size, N_clusters)].append((error_in, error_out))\n",
    "            mapes[(window_size, N_clusters)].append(cur_mape)\n",
    "#             errors[cluster_num] = mase_uni(test_y, predicted_original, y_train=test_y)\n",
    "            tmp_bad = cur_mase > np.percentile(cur_mase, 90)\n",
    "            bad_values += tmp_bad\n",
    "            cur_mase[tmp_bad] = -1\n",
    "#             errors[cluster_num] = Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')\n",
    "            errors[cluster_num] = np.mean(cur_mase[~tmp_bad])\n",
    "            \n",
    "            #show all metrics\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.suptitle(f\"K={N_clusters}, W={window_size}, C={cluster_num}\")\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(cur_mae, color=\"green\", label=\"library\")\n",
    "            plt.plot(Forecasting.my_mae(test_y, predicted_original, multioutput='raw_values'), color=\"red\", label=\"custom\")\n",
    "            plt.title(\"MAE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "#             plt.plot(error_in, label=\"library, in\")\n",
    "#             plt.plot(error_out, label=\"library, out\")\n",
    "            plt.plot(cur_mase, label=\"custom, out\")\n",
    "            plt.title(\"MASE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(cur_mape)\n",
    "            plt.title(\"MAPE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f\"plots/Dataset2/K={N_clusters}  W={window_size} C={cluster_num}.png\")\n",
    "#             plt.show()    \n",
    "            plt.clf()\n",
    "            # print(f\"{cur_mae=}, {cur_mase=}, {cur_mape=}\")\n",
    "            # my_mase = mase()\n",
    "            # print(f\"MASE in_sample = {error_in}, MASE out_sample = {error_out}\")\n",
    "            print(f\"average MASE = {errors[cluster_num]}, my average MASE = {Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')}\")\n",
    "            print(f\"Cluster {cluster_num}, {errors[cluster_num]}\")\n",
    "        answers[(window_size, N_clusters)] = errors\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.suptitle(f\"K={N_clusters}, W={window_size}\")\n",
    "        plt.subplot(2, 2, 1)\n",
    "\n",
    "        plt.bar(np.arange(N_clusters), [np.sum(clusters_labels == i) for i in range(N_clusters)], color='blue')\n",
    "        plt.title(\"Размеры кластеров\")\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.bar(np.arange(N_clusters), [len(datasets_clusters[i]) for i in range(N_clusters)], color=\"green\")\n",
    "        plt.title(\"Количество непрерывных отрезков\")\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.bar(np.arange(N_clusters), errors, color=\"red\")\n",
    "        plt.title(\"MASE на тесте каждого из кластеров\")\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        plt.table(cellText= [[f\"{x:.2f}\"] for x in errors],\n",
    "                      rowLabels=list(range(N_clusters)),\n",
    "                      loc='center')\n",
    "#         plt.show()\n",
    "        plt.savefig(f\"plots/Dataset2/method1: {N_clusters=}  W={window_size}.png\")\n",
    "        #         plt.show()\n",
    "        plt.clf()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.bar(np.arange(bad_values.shape[0]), bad_values)\n",
    "plt.title(\"Количество раз, когда переменная имела максимум MASE\")\n",
    "plt.savefig(f\"plots/Dataset2/bad_values.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([ 2,  4,  7,  8, 11, 14, 18, 21, 23, 25, 28, 30, 33, 37, 39, 43, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 5)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33,\n",
      "       39, 48, 50, 53, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 28, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 33, 37, 39,\n",
      "       41, 43, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 9)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 30, 31, 33, 35, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 12, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 23, 25, 26, 28, 30, 39, 41, 42, 48,\n",
      "       51, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(3, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 13, 14, 15, 18, 21, 23, 25, 26, 28, 30, 33,\n",
      "       37, 39, 41, 42, 44, 48, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 5)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 26, 28, 30, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 7)\n",
      "     (array([ 2, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 35, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 9)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 23, 25, 28, 30, 31, 33, 35, 39,\n",
      "       41, 43, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(3, 11)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 37, 39, 44, 48,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 2)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 12, 14, 18, 21, 23, 25, 30, 31, 33, 37, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 5)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 31, 39, 60, 61,\n",
      "       62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(5, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 16, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 23, 25, 28, 30, 33, 35, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "(5, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 14, 15, 16, 18, 19, 21, 23, 25, 27, 28, 30,\n",
      "       39, 42, 44, 47, 48, 52, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 15, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35,\n",
      "       37, 39, 60, 61, 62, 63, 65]),)\n",
      "(5, 11)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 28, 30, 31, 33, 39,\n",
      "       41, 42, 49, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(10, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 11, 13, 14, 18, 21, 23, 25, 28, 30, 31, 33,\n",
      "       35, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 5)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 22, 23, 25, 28, 30, 31, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 7)\n",
      "     (array([ 2,  4,  8,  9, 14, 16, 18, 19, 30, 58, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "(10, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 23, 24, 25, 26, 28, 30, 31,\n",
      "       33, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(10, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 12, 14, 18, 21, 22, 23, 25, 28, 30, 39, 56, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in maes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in mases.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c[0] < 1)}, {np.where(val_c[1] < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([14, 18, 25, 30, 31, 33, 35, 37, 43]),)\n",
      "     (array([14, 30]),)\n",
      "(1, 5)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(1, 7)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 11, 14]),)\n",
      "     (array([14]),)\n",
      "(1, 9)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 4,  8, 14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14, 60, 61]),)\n",
      "(1, 11)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(3, 2)\n",
      "     (array([ 4, 14, 18, 30, 31, 33, 35, 37, 42, 62]),)\n",
      "     (array([14, 30]),)\n",
      "(3, 5)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(3, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61]),)\n",
      "(3, 9)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 28, 39, 62]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 19, 30]),)\n",
      "(3, 11)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 23, 28, 39, 62, 65]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "(5, 2)\n",
      "     (array([12, 14, 18, 30, 31, 33, 35, 37, 60, 62, 65]),)\n",
      "     (array([14, 30]),)\n",
      "(5, 5)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "(5, 7)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 9, 11, 14, 18, 19, 21, 23, 25, 30, 39, 42, 44, 47, 52, 60, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 11)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 21, 23, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "(10, 2)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "(10, 5)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 14]),)\n",
      "(10, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 11)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in mapes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anna",
   "language": "python",
   "name": "anna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
