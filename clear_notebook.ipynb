{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 12:19:25.061699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSet2.csv\", sep=\";\")#, parse_dates=['Timestamp']) #, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'ARO', 'SATUR_PRESSURE', 'BOIL_PERCENT', 'OCTANE_NUMBER',\n",
       "       'percent_01_LAB', 'percent_04_LAB', 'quality_01_LAB', 'pressure_01_LAB',\n",
       "       'consumption_09', 'consumption_05', 'consumption_08', 'consumption_02',\n",
       "       'consumption_04', 'consumption_03', 'consumption_07', 'percent_13',\n",
       "       'percent_05', 'pressure_06', 'pressure_03', 'percent_14', 'pressure_08',\n",
       "       'percent_12', 'pressure_05', 'percent_08', 'pressure_07', 'percent_10',\n",
       "       'pressure_10', 'pressure_02', 'percent_02', 'pressure_09',\n",
       "       'pressure_04', 'percent_09', 'consumption_05.1', 'percent_06',\n",
       "       'temperature_25', 'percent_07', 'temperature_27', 'percent_11',\n",
       "       'consumption_06', 'percent_03', 'temperature_29', 'temperature_09',\n",
       "       'temperature_05', 'temperature_07', 'temperature_17', 'temperature_10',\n",
       "       'temperature_11', 'temperature_02', 'temperature_13', 'temperature_15',\n",
       "       'temperature_03', 'temperature_12', 'temperature_06', 'temperature_04',\n",
       "       'temperature_16', 'temperature_19', 'temperature_18', 'temperature_08',\n",
       "       'temperature_14', 'temperature_01_LAB', 'temperature_21',\n",
       "       'temperature_22', 'temperature_23', 'temperature_24', 'consumption_01',\n",
       "       'pressure_11', 'temperature_20'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns\n",
    "#CV, DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metafile = open(\"DataSet2_fix.json\")\n",
    "metafile = json.load(metafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_DV = [x[0] for x in metafile['ColumnKind'].items() if x[1] == \"CV\" or x[1] == \"DV\"]\n",
    "CV_DV = [x for x in list(columns) if x in CV_DV]\n",
    "data = data[CV_DV]\n",
    "CV_DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "df = data.groupby(data.index // K).mean() #усреднение\n",
    "df_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError, MeanAbsolutePercentageError\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mase = MeanAbsoluteScaledError(multioutput='raw_values')\n",
    "mase_uni = MeanAbsoluteScaledError(multioutput='uniform_average')\n",
    "mape = MeanAbsolutePercentageError(multioutput='raw_values')\n",
    "# mae = MeanAbsoluteError()\n",
    "\n",
    "\n",
    "#if ‘raw_values’, returns a full set of errors in case of multioutput input. If ‘uniform_average’, errors of all outputs are averaged with uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68016, 67)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_np[:, :]\n",
    "# dataset = np.concatenate((dataset[:, :8], dataset[:, 9:]), axis=1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**__Отбор признаков на минималках__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68016, 65)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удаление константных\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(0.001)\n",
    "dataset1 = selector.fit_transform(dataset) \n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 14}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(range(dataset1.shape[-1])) - set(selector.get_feature_names_out(input_features=np.arange(dataset.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset[:, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(dataset[:, 8], color=\"green\")\n",
    "plt.plot(np.concatenate((dataset[:32714, 8], dataset[32717:, 8])))\n",
    "plt.title(\"consumption_09\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = np.unique(dataset[:, 8])\n",
    "# print(values)\n",
    "# print([len(np.argwhere(dataset[:, 8] == val)) for val in values])\n",
    "# print(f\"Изменение только в {np.argwhere(dataset[1:, 8] - dataset[:-1, 8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Эти датчики пока выкинем из-за константности: ** \n",
    "\n",
    "8: consumption_09\n",
    "\n",
    "14 : consumption_07 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('consumption_07', 'consumption_09')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[15], columns[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f44b36eebe0>]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset[7])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import correlate\n",
    "# a = np.array([np.sin(x + 1) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 2) for x in range(10)])\n",
    "# c = correlate(a, b, mode=\"full\") #mode='same'\n",
    "# plt.plot(a, label=\"a\")\n",
    "# plt.plot(b, label=\"b\")\n",
    "# plt.plot(c, label=\"correlation\")\n",
    "# plt.legend()\n",
    "# c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68016, 65)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прогнозирование**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68016, 65)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1[:]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f44b3654760>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset[..., 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "window_sizes_for_clustering = 10\n",
    "# X, y = dataset[:-window_sizes_for_clustering, ...], dataset[window_sizes_for_clustering:, ...]\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "n_split = round(0.2 * dataset.shape[0])\n",
    "dataset_train, dataset_test = dataset[:-n_split, ...], dataset[-n_split:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54413, 65), (13603, 65))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes_for_clustering = [1, 5, 10]#[1, 5, 10, 15] #[1, 3, 5, 10, 15]\n",
    "Ns_clusters = [3, 5, 7] #, 3 5, 7]#[2, 5, 7, 9, 11, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusterization __init__: W=1, <class 'int'>\n",
      "Clusterization __init__: W=1, <class 'int'>\n",
      "Clusterization __init__: W=1, <class 'int'>\n",
      "Clusterization __init__: W=5, <class 'int'>\n",
      "Clusterization __init__: W=5, <class 'int'>\n",
      "Clusterization __init__: W=5, <class 'int'>\n",
      "Clusterization __init__: W=10, <class 'int'>\n",
      "Clusterization __init__: W=10, <class 'int'>\n",
      "Clusterization __init__: W=10, <class 'int'>\n",
      "Clusterization __init__: W=1, <class 'int'>\n",
      "Clusterization __init__: W=1, <class 'int'>\n",
      "Clusterization __init__: W=1, <class 'int'>\n",
      "Clusterization __init__: W=5, <class 'int'>\n",
      "Clusterization __init__: W=5, <class 'int'>\n",
      "Clusterization __init__: W=5, <class 'int'>\n",
      "Clusterization __init__: W=10, <class 'int'>\n",
      "Clusterization __init__: W=10, <class 'int'>\n",
      "Clusterization __init__: W=10, <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "clusters_algorithms = [\"MeanShift\", \"Kmeans\"] #[\"Agglomerative\"] #[\"MeanShift\"]\n",
    "clustering_algorithms = []\n",
    "clustering_algorithms += [Clustering.Kmeans_for_windows(W=W, N_clusters=N_cluster) for W in window_sizes_for_clustering for N_cluster in Ns_clusters]\n",
    "# clustering_algorithms += [Clustering.MeanShift_for_windows(W=W) for W in window_sizes_for_clustering]\n",
    "clustering_algorithms += [Clustering.AgglomerativeClustering_for_windows(W=W, N_clusters=N_cluster) for W in window_sizes_for_clustering for N_cluster in Ns_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_algorithms[0].N_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns_clusters = [2]\n",
    "# window_sizes_for_clustering = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, M, Q = 100, 100, 2\n",
    "# dataset_train = np.column_stack([[np.sin(x / 40) for x in range(N)], [0.01 + np.sin(x / 20) for x in range(N)]])\n",
    "# # dataset_train = np.array([np.sin(x / 10000) for x in range(N)])[:, None]\n",
    "# # dataset_train = np.column_stack(([np.sqrt(x / 10) for x in range(N)], [x + ])\n",
    "# dataset_test = np.column_stack([[np.sin(x / 30) for x in range(M)], [0.01 + np.sin(x / 30)*1.01 for x in range(M)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54413, 65)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# a = Clustering.MeanShift_for_windows(W=W).fit_predict(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans_for_windows: (54413, 65)\n",
      "Done\n",
      "Kmeans_for_windows: (54413, 65)\n",
      "Done\n",
      "Kmeans_for_windows: (54413, 65)\n",
      "Done\n",
      "Kmeans_for_windows: (54413, 65)\n",
      "Done\n",
      "Kmeans_for_windows: (54413, 65)\n",
      "Done\n",
      "Kmeans_for_windows: (54413, 65)\n",
      "Done\n",
      "Kmeans_for_windows: (54413, 65)\n",
      "Done\n",
      "Kmeans_for_windows: (54413, 65)\n",
      "Done\n",
      "Kmeans_for_windows: (54413, 65)\n",
      "Done\n",
      "<Clustering.AgglomerativeClustering_for_windows object at 0x7f44b367e9a0>: (54413, 65)\n",
      "Done\n",
      "<Clustering.AgglomerativeClustering_for_windows object at 0x7f44b367e640>: (54413, 65)\n",
      "Done\n",
      "<Clustering.AgglomerativeClustering_for_windows object at 0x7f44b3736820>: (54413, 65)\n",
      "Done\n",
      "<Clustering.AgglomerativeClustering_for_windows object at 0x7f44b36fb940>: (54413, 65)\n",
      "Done\n",
      "<Clustering.AgglomerativeClustering_for_windows object at 0x7f44b36fb880>: (54413, 65)\n",
      "Done\n",
      "<Clustering.AgglomerativeClustering_for_windows object at 0x7f44b3867670>: (54413, 65)\n",
      "Done\n",
      "<Clustering.AgglomerativeClustering_for_windows object at 0x7f44b3647640>: (54413, 65)\n",
      "Done\n",
      "<Clustering.AgglomerativeClustering_for_windows object at 0x7f44b3647550>: (54413, 65)\n",
      "Done\n",
      "<Clustering.AgglomerativeClustering_for_windows object at 0x7f44b3654c40>: (54413, 65)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#clusters_labels, clusters_model \n",
    "# clustering_results = [Clustering.apply_clustering(dataset, cur_cluster_alg) for cur_cluster_alg in clustering_algorithms]\n",
    "# clusters_labels = [x[0] for x in clustering_results]\n",
    "# clusters_models = [x[1] for x in clustering_results]\n",
    "clustering_results = [cur_cluster_alg.fit_predict(dataset_train) for cur_cluster_alg in clustering_algorithms]\n",
    "clusters_labels = clustering_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1478.,     0.,     0.,     0.,     0.,  2815.,     0.,     0.,\n",
       "            0., 22913.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(clustering_results[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_clusters=3\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=2952, 2952\n",
      "IN Clustering.split_to_clusters: mask.sum()=45891, 45891\n",
      "IN Clustering.split_to_clusters: mask.sum()=5559, 5559\n",
      "In split_to_train_test: dataset_X.shape=(2952, 10, 65), dataset_y.shape=(2952, 65)\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.3452 - val_loss: 0.7779\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.3378 - val_loss: 0.7711\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.3318 - val_loss: 0.7652\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3267 - val_loss: 0.7599\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3223 - val_loss: 0.7550\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3183 - val_loss: 0.7507\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3148 - val_loss: 0.7465\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3116 - val_loss: 0.7427\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3087 - val_loss: 0.7391\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3060 - val_loss: 0.7359\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3035 - val_loss: 0.7328\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3011 - val_loss: 0.7298\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2989 - val_loss: 0.7269\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2968 - val_loss: 0.7242\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2948 - val_loss: 0.7216\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2930 - val_loss: 0.7191\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2912 - val_loss: 0.7167\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2895 - val_loss: 0.7144\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2879 - val_loss: 0.7121\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.2863 - val_loss: 0.7098\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2849 - val_loss: 0.7077\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2835 - val_loss: 0.7056\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2821 - val_loss: 0.7036\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2809 - val_loss: 0.7018\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2796 - val_loss: 0.6997\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2785 - val_loss: 0.6978\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2774 - val_loss: 0.6960\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2763 - val_loss: 0.6941\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.2753 - val_loss: 0.6922\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2743 - val_loss: 0.6904\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2733 - val_loss: 0.6887\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2724 - val_loss: 0.6868\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2714 - val_loss: 0.6851\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2706 - val_loss: 0.6834\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2697 - val_loss: 0.6817\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2689 - val_loss: 0.6799\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2681 - val_loss: 0.6783\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2673 - val_loss: 0.6767\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2666 - val_loss: 0.6751\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2658 - val_loss: 0.6735\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2651 - val_loss: 0.6721\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2644 - val_loss: 0.6706\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2638 - val_loss: 0.6692\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2631 - val_loss: 0.6678\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2625 - val_loss: 0.6663\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2618 - val_loss: 0.6650\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2612 - val_loss: 0.6637\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2606 - val_loss: 0.6625\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2600 - val_loss: 0.6613\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2595 - val_loss: 0.6601\n",
      "In calc_results: 1771, 591, 590, sum = 2952\n",
      "In split_to_train_test: dataset_X.shape=(45891, 10, 65), dataset_y.shape=(45891, 65)\n",
      "Epoch 1/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2823 - val_loss: 0.2698\n",
      "Epoch 2/50\n",
      "431/431 [==============================] - 13s 29ms/step - loss: 0.2688 - val_loss: 0.2633\n",
      "Epoch 3/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2627 - val_loss: 0.2598\n",
      "Epoch 4/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2591 - val_loss: 0.2573\n",
      "Epoch 5/50\n",
      "431/431 [==============================] - 13s 31ms/step - loss: 0.2564 - val_loss: 0.2553\n",
      "Epoch 6/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2543 - val_loss: 0.2537\n",
      "Epoch 7/50\n",
      "431/431 [==============================] - 14s 32ms/step - loss: 0.2524 - val_loss: 0.2522\n",
      "Epoch 8/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2507 - val_loss: 0.2509\n",
      "Epoch 9/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2491 - val_loss: 0.2496\n",
      "Epoch 10/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2475 - val_loss: 0.2485\n",
      "Epoch 11/50\n",
      "431/431 [==============================] - 13s 29ms/step - loss: 0.2460 - val_loss: 0.2474\n",
      "Epoch 12/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2446 - val_loss: 0.2464\n",
      "Epoch 13/50\n",
      "431/431 [==============================] - 14s 32ms/step - loss: 0.2433 - val_loss: 0.2455\n",
      "Epoch 14/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2420 - val_loss: 0.2446\n",
      "Epoch 15/50\n",
      "431/431 [==============================] - 13s 29ms/step - loss: 0.2408 - val_loss: 0.2438\n",
      "Epoch 16/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2397 - val_loss: 0.2431\n",
      "Epoch 17/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2387 - val_loss: 0.2424\n",
      "Epoch 18/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2378 - val_loss: 0.2419\n",
      "Epoch 19/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2370 - val_loss: 0.2414\n",
      "Epoch 20/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2363 - val_loss: 0.2409\n",
      "Epoch 21/50\n",
      "431/431 [==============================] - 13s 29ms/step - loss: 0.2356 - val_loss: 0.2405\n",
      "Epoch 22/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2351 - val_loss: 0.2402\n",
      "Epoch 23/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2346 - val_loss: 0.2399\n",
      "Epoch 24/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2342 - val_loss: 0.2396\n",
      "Epoch 25/50\n",
      "431/431 [==============================] - 13s 29ms/step - loss: 0.2338 - val_loss: 0.2394\n",
      "Epoch 26/50\n",
      "431/431 [==============================] - 13s 29ms/step - loss: 0.2334 - val_loss: 0.2391\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431/431 [==============================] - 13s 31ms/step - loss: 0.2331 - val_loss: 0.2389\n",
      "Epoch 28/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2327 - val_loss: 0.2387\n",
      "Epoch 29/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2324 - val_loss: 0.2385\n",
      "Epoch 30/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2321 - val_loss: 0.2383\n",
      "Epoch 31/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2319 - val_loss: 0.2382\n",
      "Epoch 32/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2316 - val_loss: 0.2380\n",
      "Epoch 33/50\n",
      "431/431 [==============================] - 13s 31ms/step - loss: 0.2314 - val_loss: 0.2378\n",
      "Epoch 34/50\n",
      "431/431 [==============================] - 13s 31ms/step - loss: 0.2311 - val_loss: 0.2378\n",
      "Epoch 35/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2309 - val_loss: 0.2377\n",
      "Epoch 36/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2307 - val_loss: 0.2375\n",
      "Epoch 37/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2305 - val_loss: 0.2374\n",
      "Epoch 38/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2303 - val_loss: 0.2372\n",
      "Epoch 39/50\n",
      "431/431 [==============================] - 13s 29ms/step - loss: 0.2301 - val_loss: 0.2371\n",
      "Epoch 40/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2299 - val_loss: 0.2371\n",
      "Epoch 41/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2297 - val_loss: 0.2369\n",
      "Epoch 42/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2295 - val_loss: 0.2369\n",
      "Epoch 43/50\n",
      "431/431 [==============================] - 13s 29ms/step - loss: 0.2293 - val_loss: 0.2368\n",
      "Epoch 44/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2292 - val_loss: 0.2367\n",
      "Epoch 45/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2290 - val_loss: 0.2366\n",
      "Epoch 46/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2289 - val_loss: 0.2365\n",
      "Epoch 47/50\n",
      "431/431 [==============================] - 12s 29ms/step - loss: 0.2287 - val_loss: 0.2364\n",
      "Epoch 48/50\n",
      "431/431 [==============================] - 13s 30ms/step - loss: 0.2285 - val_loss: 0.2364\n",
      "Epoch 49/50\n",
      "431/431 [==============================] - 13s 31ms/step - loss: 0.2284 - val_loss: 0.2363\n",
      "Epoch 50/50\n",
      "431/431 [==============================] - 13s 29ms/step - loss: 0.2283 - val_loss: 0.2362\n",
      "In calc_results: 27535, 9178, 9178, sum = 45891\n",
      "In split_to_train_test: dataset_X.shape=(5559, 10, 65), dataset_y.shape=(5559, 65)\n",
      "Epoch 1/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.2237 - val_loss: 0.2346\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.2170 - val_loss: 0.2303\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.2122 - val_loss: 0.2271\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.2086 - val_loss: 0.2246\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.2057 - val_loss: 0.2226\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.2033 - val_loss: 0.2209\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.2012 - val_loss: 0.2194\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1994 - val_loss: 0.2181\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1978 - val_loss: 0.2170\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1964 - val_loss: 0.2160\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1951 - val_loss: 0.2151\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1940 - val_loss: 0.2143\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1929 - val_loss: 0.2135\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1919 - val_loss: 0.2128\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1909 - val_loss: 0.2121\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1900 - val_loss: 0.2114\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1891 - val_loss: 0.2108\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1883 - val_loss: 0.2102\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1875 - val_loss: 0.2096\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1868 - val_loss: 0.2090\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1860 - val_loss: 0.2085\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1853 - val_loss: 0.2080\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1846 - val_loss: 0.2074\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1839 - val_loss: 0.2069\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1832 - val_loss: 0.2064\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1825 - val_loss: 0.2060\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1819 - val_loss: 0.2054\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1812 - val_loss: 0.2050\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1806 - val_loss: 0.2045\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1800 - val_loss: 0.2040\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1793 - val_loss: 0.2036\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1787 - val_loss: 0.2032\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1781 - val_loss: 0.2027\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1775 - val_loss: 0.2023\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1769 - val_loss: 0.2018\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1764 - val_loss: 0.2014\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1758 - val_loss: 0.2010\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1753 - val_loss: 0.2006\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1747 - val_loss: 0.2002\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1742 - val_loss: 0.1999\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1737 - val_loss: 0.1995\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1732 - val_loss: 0.1991\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1727 - val_loss: 0.1988\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1722 - val_loss: 0.1984\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1717 - val_loss: 0.1981\n",
      "Epoch 46/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1713 - val_loss: 0.1978\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1708 - val_loss: 0.1974\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1704 - val_loss: 0.1971\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.1699 - val_loss: 0.1968\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1695 - val_loss: 0.1965\n",
      "In calc_results: 3335, 1112, 1112, sum = 5559\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=42315, 42315\n",
      "IN Clustering.split_to_clusters: mask.sum()=5154, 5154\n",
      "IN Clustering.split_to_clusters: mask.sum()=1995, 1995\n",
      "IN Clustering.split_to_clusters: mask.sum()=2060, 2060\n",
      "IN Clustering.split_to_clusters: mask.sum()=2878, 2878\n",
      "In split_to_train_test: dataset_X.shape=(42315, 10, 65), dataset_y.shape=(42315, 65)\n",
      "Epoch 1/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2576 - val_loss: 0.2384\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2441 - val_loss: 0.2324\n",
      "Epoch 3/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2385 - val_loss: 0.2291\n",
      "Epoch 4/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2350 - val_loss: 0.2268\n",
      "Epoch 5/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2324 - val_loss: 0.2249\n",
      "Epoch 6/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2301 - val_loss: 0.2232\n",
      "Epoch 7/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2281 - val_loss: 0.2216\n",
      "Epoch 8/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2262 - val_loss: 0.2202\n",
      "Epoch 9/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2244 - val_loss: 0.2189\n",
      "Epoch 10/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2228 - val_loss: 0.2178\n",
      "Epoch 11/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2213 - val_loss: 0.2167\n",
      "Epoch 12/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2199 - val_loss: 0.2158\n",
      "Epoch 13/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2186 - val_loss: 0.2149\n",
      "Epoch 14/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2174 - val_loss: 0.2141\n",
      "Epoch 15/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2163 - val_loss: 0.2135\n",
      "Epoch 16/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2153 - val_loss: 0.2128\n",
      "Epoch 17/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2144 - val_loss: 0.2123\n",
      "Epoch 18/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2135 - val_loss: 0.2118\n",
      "Epoch 19/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2129 - val_loss: 0.2114\n",
      "Epoch 20/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2122 - val_loss: 0.2111\n",
      "Epoch 21/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2117 - val_loss: 0.2108\n",
      "Epoch 22/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2112 - val_loss: 0.2104\n",
      "Epoch 23/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2108 - val_loss: 0.2101\n",
      "Epoch 24/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2104 - val_loss: 0.2099\n",
      "Epoch 25/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2100 - val_loss: 0.2097\n",
      "Epoch 26/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2097 - val_loss: 0.2095\n",
      "Epoch 27/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2094 - val_loss: 0.2093\n",
      "Epoch 28/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2091 - val_loss: 0.2091\n",
      "Epoch 29/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2088 - val_loss: 0.2090\n",
      "Epoch 30/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2086 - val_loss: 0.2089\n",
      "Epoch 31/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2083 - val_loss: 0.2087\n",
      "Epoch 32/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2081 - val_loss: 0.2086\n",
      "Epoch 33/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2079 - val_loss: 0.2084\n",
      "Epoch 34/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2077 - val_loss: 0.2084\n",
      "Epoch 35/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2074 - val_loss: 0.2082\n",
      "Epoch 36/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2073 - val_loss: 0.2081\n",
      "Epoch 37/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2071 - val_loss: 0.2081\n",
      "Epoch 38/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2069 - val_loss: 0.2079\n",
      "Epoch 39/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2067 - val_loss: 0.2078\n",
      "Epoch 40/50\n",
      "397/397 [==============================] - 13s 33ms/step - loss: 0.2066 - val_loss: 0.2077\n",
      "Epoch 41/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2064 - val_loss: 0.2077\n",
      "Epoch 42/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2062 - val_loss: 0.2075\n",
      "Epoch 43/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2061 - val_loss: 0.2075\n",
      "Epoch 44/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2060 - val_loss: 0.2074\n",
      "Epoch 45/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2058 - val_loss: 0.2073\n",
      "Epoch 46/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2057 - val_loss: 0.2072\n",
      "Epoch 47/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2055 - val_loss: 0.2072\n",
      "Epoch 48/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2054 - val_loss: 0.2071\n",
      "Epoch 49/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2053 - val_loss: 0.2070\n",
      "Epoch 50/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2052 - val_loss: 0.2071\n",
      "In calc_results: 25389, 8463, 8463, sum = 42315\n",
      "In split_to_train_test: dataset_X.shape=(5154, 10, 65), dataset_y.shape=(5154, 65)\n",
      "Epoch 1/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2221 - val_loss: 0.3271\n",
      "Epoch 2/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.2175 - val_loss: 0.3229\n",
      "Epoch 3/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.2139 - val_loss: 0.3196\n",
      "Epoch 4/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2110 - val_loss: 0.3169\n",
      "Epoch 5/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2086 - val_loss: 0.3147\n",
      "Epoch 6/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2065 - val_loss: 0.3128\n",
      "Epoch 7/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2047 - val_loss: 0.3111\n",
      "Epoch 8/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.2031 - val_loss: 0.3097\n",
      "Epoch 9/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2017 - val_loss: 0.3084\n",
      "Epoch 10/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2004 - val_loss: 0.3073\n",
      "Epoch 11/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1993 - val_loss: 0.3063\n",
      "Epoch 12/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1982 - val_loss: 0.3055\n",
      "Epoch 13/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1972 - val_loss: 0.3047\n",
      "Epoch 14/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1963 - val_loss: 0.3039\n",
      "Epoch 15/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1954 - val_loss: 0.3033\n",
      "Epoch 16/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1945 - val_loss: 0.3027\n",
      "Epoch 17/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1937 - val_loss: 0.3021\n",
      "Epoch 18/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1929 - val_loss: 0.3016\n",
      "Epoch 19/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1921 - val_loss: 0.3011\n",
      "Epoch 20/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1914 - val_loss: 0.3007\n",
      "Epoch 21/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1906 - val_loss: 0.3003\n",
      "Epoch 22/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1899 - val_loss: 0.2999\n",
      "Epoch 23/50\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.1891 - val_loss: 0.2995\n",
      "Epoch 24/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1884 - val_loss: 0.2991\n",
      "Epoch 25/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1877 - val_loss: 0.2988\n",
      "Epoch 26/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1870 - val_loss: 0.2986\n",
      "Epoch 27/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1863 - val_loss: 0.2983\n",
      "Epoch 28/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1856 - val_loss: 0.2980\n",
      "Epoch 29/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1850 - val_loss: 0.2978\n",
      "Epoch 30/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1843 - val_loss: 0.2976\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1837 - val_loss: 0.2974\n",
      "Epoch 32/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1830 - val_loss: 0.2972\n",
      "Epoch 33/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1824 - val_loss: 0.2970\n",
      "Epoch 34/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1818 - val_loss: 0.2968\n",
      "Epoch 35/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1812 - val_loss: 0.2967\n",
      "Epoch 36/50\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.1806 - val_loss: 0.2965\n",
      "Epoch 37/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.1800 - val_loss: 0.2963\n",
      "Epoch 38/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1794 - val_loss: 0.2962\n",
      "Epoch 39/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.1788 - val_loss: 0.2960\n",
      "Epoch 40/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1783 - val_loss: 0.2959\n",
      "Epoch 41/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1777 - val_loss: 0.2957\n",
      "Epoch 42/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1772 - val_loss: 0.2956\n",
      "Epoch 43/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1767 - val_loss: 0.2954\n",
      "Epoch 44/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1762 - val_loss: 0.2953\n",
      "Epoch 45/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1757 - val_loss: 0.2952\n",
      "Epoch 46/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1753 - val_loss: 0.2950\n",
      "Epoch 47/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1748 - val_loss: 0.2949\n",
      "Epoch 48/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1744 - val_loss: 0.2947\n",
      "Epoch 49/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.1740 - val_loss: 0.2946\n",
      "Epoch 50/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1735 - val_loss: 0.2944\n",
      "In calc_results: 3092, 1031, 1031, sum = 5154\n",
      "In split_to_train_test: dataset_X.shape=(1995, 10, 65), dataset_y.shape=(1995, 65)\n",
      "Epoch 1/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.8269 - val_loss: 0.7470\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.8213 - val_loss: 0.7430\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.8162 - val_loss: 0.7394\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.8117 - val_loss: 0.7362\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.8075 - val_loss: 0.7333\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.8038 - val_loss: 0.7306\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.8003 - val_loss: 0.7281\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7970 - val_loss: 0.7258\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7940 - val_loss: 0.7237\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7912 - val_loss: 0.7216\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7884 - val_loss: 0.7196\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7859 - val_loss: 0.7177\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7834 - val_loss: 0.7160\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7811 - val_loss: 0.7143\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7788 - val_loss: 0.7127\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7767 - val_loss: 0.7111\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7746 - val_loss: 0.7096\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7727 - val_loss: 0.7082\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7707 - val_loss: 0.7068\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7689 - val_loss: 0.7054\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7671 - val_loss: 0.7041\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7654 - val_loss: 0.7028\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.7637 - val_loss: 0.7015\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.7621 - val_loss: 0.7003\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.7605 - val_loss: 0.6992\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.7590 - val_loss: 0.6980\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.7575 - val_loss: 0.6969\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7560 - val_loss: 0.6958\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.7547 - val_loss: 0.6946\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.7532 - val_loss: 0.6936\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.7519 - val_loss: 0.6926\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7506 - val_loss: 0.6916\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7493 - val_loss: 0.6906\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.7481 - val_loss: 0.6896\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7468 - val_loss: 0.6887\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7457 - val_loss: 0.6877\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7445 - val_loss: 0.6868\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7433 - val_loss: 0.6859\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7422 - val_loss: 0.6850\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7411 - val_loss: 0.6841\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7400 - val_loss: 0.6833\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.7390 - val_loss: 0.6825\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.7379 - val_loss: 0.6816\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.7369 - val_loss: 0.6808\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7359 - val_loss: 0.6800\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7349 - val_loss: 0.6792\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7339 - val_loss: 0.6784\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7329 - val_loss: 0.6776\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7319 - val_loss: 0.6768\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7309 - val_loss: 0.6760\n",
      "In calc_results: 1197, 399, 399, sum = 1995\n",
      "In split_to_train_test: dataset_X.shape=(2060, 10, 65), dataset_y.shape=(2060, 65)\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2555 - val_loss: 0.2430\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2513 - val_loss: 0.2407\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2479 - val_loss: 0.2386\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2450 - val_loss: 0.2367\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2425 - val_loss: 0.2350\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2403 - val_loss: 0.2335\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2383 - val_loss: 0.2321\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2365 - val_loss: 0.2308\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2347 - val_loss: 0.2296\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2331 - val_loss: 0.2284\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2317 - val_loss: 0.2273\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2303 - val_loss: 0.2264\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2290 - val_loss: 0.2255\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2278 - val_loss: 0.2246\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2266 - val_loss: 0.2238\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2256 - val_loss: 0.2230\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2245 - val_loss: 0.2223\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2236 - val_loss: 0.2216\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2227 - val_loss: 0.2210\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2218 - val_loss: 0.2204\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2210 - val_loss: 0.2199\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2202 - val_loss: 0.2194\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2194 - val_loss: 0.2189\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2187 - val_loss: 0.2184\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2180 - val_loss: 0.2180\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2174 - val_loss: 0.2176\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2167 - val_loss: 0.2172\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2161 - val_loss: 0.2168\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2155 - val_loss: 0.2164\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2150 - val_loss: 0.2160\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2144 - val_loss: 0.2157\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2139 - val_loss: 0.2153\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2134 - val_loss: 0.2150\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2129 - val_loss: 0.2147\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2124 - val_loss: 0.2143\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2120 - val_loss: 0.2140\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2115 - val_loss: 0.2137\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2111 - val_loss: 0.2134\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2106 - val_loss: 0.2131\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2102 - val_loss: 0.2128\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2098 - val_loss: 0.2125\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2093 - val_loss: 0.2122\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2089 - val_loss: 0.2120\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2085 - val_loss: 0.2117\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2081 - val_loss: 0.2114\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2078 - val_loss: 0.2112\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2074 - val_loss: 0.2109\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2070 - val_loss: 0.2107\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2066 - val_loss: 0.2104\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2062 - val_loss: 0.2101\n",
      "In calc_results: 1236, 412, 412, sum = 2060\n",
      "In split_to_train_test: dataset_X.shape=(2878, 10, 65), dataset_y.shape=(2878, 65)\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.3218 - val_loss: 0.6768\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.3151 - val_loss: 0.6712\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.3097 - val_loss: 0.6663\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.3051 - val_loss: 0.6617\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.3010 - val_loss: 0.6575\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2973 - val_loss: 0.6537\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2940 - val_loss: 0.6501\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2910 - val_loss: 0.6468\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2882 - val_loss: 0.6436\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2857 - val_loss: 0.6406\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2833 - val_loss: 0.6378\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2811 - val_loss: 0.6351\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2791 - val_loss: 0.6325\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2772 - val_loss: 0.6301\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2754 - val_loss: 0.6276\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2737 - val_loss: 0.6254\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2722 - val_loss: 0.6231\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2707 - val_loss: 0.6211\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2693 - val_loss: 0.6191\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2680 - val_loss: 0.6171\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2667 - val_loss: 0.6152\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2655 - val_loss: 0.6133\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2644 - val_loss: 0.6115\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2633 - val_loss: 0.6098\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2622 - val_loss: 0.6080\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2612 - val_loss: 0.6063\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2603 - val_loss: 0.6046\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2593 - val_loss: 0.6031\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2584 - val_loss: 0.6014\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2575 - val_loss: 0.5999\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2567 - val_loss: 0.5983\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2558 - val_loss: 0.5967\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2550 - val_loss: 0.5954\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2542 - val_loss: 0.5938\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2534 - val_loss: 0.5924\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2527 - val_loss: 0.5910\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2519 - val_loss: 0.5895\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2512 - val_loss: 0.5881\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2505 - val_loss: 0.5867\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2498 - val_loss: 0.5854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2492 - val_loss: 0.5840\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2485 - val_loss: 0.5827\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2479 - val_loss: 0.5814\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2472 - val_loss: 0.5801\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2466 - val_loss: 0.5789\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2460 - val_loss: 0.5775\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2453 - val_loss: 0.5764\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2447 - val_loss: 0.5753\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2441 - val_loss: 0.5742\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2436 - val_loss: 0.5731\n",
      "In calc_results: 1727, 575, 576, sum = 2878\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=23537, 23537\n",
      "IN Clustering.split_to_clusters: mask.sum()=1796, 1796\n",
      "IN Clustering.split_to_clusters: mask.sum()=4098, 4098\n",
      "IN Clustering.split_to_clusters: mask.sum()=2870, 2870\n",
      "IN Clustering.split_to_clusters: mask.sum()=15613, 15613\n",
      "IN Clustering.split_to_clusters: mask.sum()=5292, 5292\n",
      "IN Clustering.split_to_clusters: mask.sum()=1196, 1196\n",
      "In split_to_train_test: dataset_X.shape=(23537, 10, 65), dataset_y.shape=(23537, 65)\n",
      "Epoch 1/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2628 - val_loss: 0.2434\n",
      "Epoch 2/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2500 - val_loss: 0.2363\n",
      "Epoch 3/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2434 - val_loss: 0.2322\n",
      "Epoch 4/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2393 - val_loss: 0.2295\n",
      "Epoch 5/50\n",
      "221/221 [==============================] - 7s 30ms/step - loss: 0.2364 - val_loss: 0.2276\n",
      "Epoch 6/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2343 - val_loss: 0.2260\n",
      "Epoch 7/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2324 - val_loss: 0.2247\n",
      "Epoch 8/50\n",
      "221/221 [==============================] - 7s 30ms/step - loss: 0.2309 - val_loss: 0.2235\n",
      "Epoch 9/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2294 - val_loss: 0.2224\n",
      "Epoch 10/50\n",
      "221/221 [==============================] - 7s 30ms/step - loss: 0.2281 - val_loss: 0.2214\n",
      "Epoch 11/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2268 - val_loss: 0.2204\n",
      "Epoch 12/50\n",
      "221/221 [==============================] - 7s 30ms/step - loss: 0.2255 - val_loss: 0.2195\n",
      "Epoch 13/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2243 - val_loss: 0.2186\n",
      "Epoch 14/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2231 - val_loss: 0.2178\n",
      "Epoch 15/50\n",
      "221/221 [==============================] - 7s 30ms/step - loss: 0.2220 - val_loss: 0.2170\n",
      "Epoch 16/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2208 - val_loss: 0.2162\n",
      "Epoch 17/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2196 - val_loss: 0.2154\n",
      "Epoch 18/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2185 - val_loss: 0.2148\n",
      "Epoch 19/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2174 - val_loss: 0.2141\n",
      "Epoch 20/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2163 - val_loss: 0.2136\n",
      "Epoch 21/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2153 - val_loss: 0.2130\n",
      "Epoch 22/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2144 - val_loss: 0.2125\n",
      "Epoch 23/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2135 - val_loss: 0.2121\n",
      "Epoch 24/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2126 - val_loss: 0.2117\n",
      "Epoch 25/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2119 - val_loss: 0.2112\n",
      "Epoch 26/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2112 - val_loss: 0.2109\n",
      "Epoch 27/50\n",
      "221/221 [==============================] - 6s 28ms/step - loss: 0.2106 - val_loss: 0.2105\n",
      "Epoch 28/50\n",
      "221/221 [==============================] - 7s 30ms/step - loss: 0.2100 - val_loss: 0.2101\n",
      "Epoch 29/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2095 - val_loss: 0.2099\n",
      "Epoch 30/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2091 - val_loss: 0.2095\n",
      "Epoch 31/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2086 - val_loss: 0.2093\n",
      "Epoch 32/50\n",
      "221/221 [==============================] - 7s 32ms/step - loss: 0.2082 - val_loss: 0.2090\n",
      "Epoch 33/50\n",
      "221/221 [==============================] - 7s 29ms/step - loss: 0.2078 - val_loss: 0.2087\n",
      "Epoch 34/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2075 - val_loss: 0.2085\n",
      "Epoch 35/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2071 - val_loss: 0.2084\n",
      "Epoch 36/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2068 - val_loss: 0.2082\n",
      "Epoch 37/50\n",
      "221/221 [==============================] - 7s 31ms/step - loss: 0.2065 - val_loss: 0.2079\n",
      "Epoch 38/50\n",
      "221/221 [==============================] - 7s 33ms/step - loss: 0.2062 - val_loss: 0.2077\n",
      "Epoch 39/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2059 - val_loss: 0.2075\n",
      "Epoch 40/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2057 - val_loss: 0.2074\n",
      "Epoch 41/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2054 - val_loss: 0.2072\n",
      "Epoch 42/50\n",
      "221/221 [==============================] - 7s 31ms/step - loss: 0.2052 - val_loss: 0.2071\n",
      "Epoch 43/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2049 - val_loss: 0.2069\n",
      "Epoch 44/50\n",
      "221/221 [==============================] - 7s 30ms/step - loss: 0.2047 - val_loss: 0.2068\n",
      "Epoch 45/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2045 - val_loss: 0.2066\n",
      "Epoch 46/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2043 - val_loss: 0.2066\n",
      "Epoch 47/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2041 - val_loss: 0.2064\n",
      "Epoch 48/50\n",
      "221/221 [==============================] - 7s 30ms/step - loss: 0.2039 - val_loss: 0.2063\n",
      "Epoch 49/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2037 - val_loss: 0.2061\n",
      "Epoch 50/50\n",
      "221/221 [==============================] - 6s 29ms/step - loss: 0.2035 - val_loss: 0.2061\n",
      "In calc_results: 14122, 4708, 4707, sum = 23537\n",
      "In split_to_train_test: dataset_X.shape=(1796, 10, 65), dataset_y.shape=(1796, 65)\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.2573 - val_loss: 0.2403\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2537 - val_loss: 0.2386\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.2506 - val_loss: 0.2371\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.2479 - val_loss: 0.2357\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.2455 - val_loss: 0.2344\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2433 - val_loss: 0.2332\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 1s 35ms/step - loss: 0.2413 - val_loss: 0.2321\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2395 - val_loss: 0.2310\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2378 - val_loss: 0.2300\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2362 - val_loss: 0.2291\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2348 - val_loss: 0.2282\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.2334 - val_loss: 0.2274\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2321 - val_loss: 0.2266\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.2309 - val_loss: 0.2259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2297 - val_loss: 0.2253\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2286 - val_loss: 0.2246\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.2276 - val_loss: 0.2240\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.2266 - val_loss: 0.2235\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2257 - val_loss: 0.2230\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2248 - val_loss: 0.2225\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.2240 - val_loss: 0.2220\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2232 - val_loss: 0.2215\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2224 - val_loss: 0.2211\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2217 - val_loss: 0.2207\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2210 - val_loss: 0.2203\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2203 - val_loss: 0.2200\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2196 - val_loss: 0.2196\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2190 - val_loss: 0.2193\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2184 - val_loss: 0.2189\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2178 - val_loss: 0.2186\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2173 - val_loss: 0.2183\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2167 - val_loss: 0.2179\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2162 - val_loss: 0.2176\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2157 - val_loss: 0.2173\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2151 - val_loss: 0.2170\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2147 - val_loss: 0.2168\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2142 - val_loss: 0.2165\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2137 - val_loss: 0.2162\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2133 - val_loss: 0.2159\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2128 - val_loss: 0.2157\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2124 - val_loss: 0.2154\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2119 - val_loss: 0.2152\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2115 - val_loss: 0.2149\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2111 - val_loss: 0.2147\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.2107 - val_loss: 0.2144\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.2103 - val_loss: 0.2142\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.2099 - val_loss: 0.2140\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.2095 - val_loss: 0.2138\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 1s 36ms/step - loss: 0.2091 - val_loss: 0.2135\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 1s 37ms/step - loss: 0.2087 - val_loss: 0.2134\n",
      "In calc_results: 1078, 359, 359, sum = 1796\n",
      "In split_to_train_test: dataset_X.shape=(4098, 10, 65), dataset_y.shape=(4098, 65)\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.2114 - val_loss: 0.2943\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.2071 - val_loss: 0.2913\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.2038 - val_loss: 0.2889\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.2011 - val_loss: 0.2869\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1988 - val_loss: 0.2853\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1969 - val_loss: 0.2838\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1952 - val_loss: 0.2826\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1936 - val_loss: 0.2814\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1922 - val_loss: 0.2804\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1909 - val_loss: 0.2795\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1897 - val_loss: 0.2786\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1886 - val_loss: 0.2778\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.1876 - val_loss: 0.2771\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.1866 - val_loss: 0.2764\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1857 - val_loss: 0.2757\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 1s 33ms/step - loss: 0.1849 - val_loss: 0.2751\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1840 - val_loss: 0.2745\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1832 - val_loss: 0.2740\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1825 - val_loss: 0.2734\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1817 - val_loss: 0.2729\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1810 - val_loss: 0.2724\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1803 - val_loss: 0.2719\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1796 - val_loss: 0.2715\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.1789 - val_loss: 0.2710\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.1783 - val_loss: 0.2706\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.1776 - val_loss: 0.2701\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.1770 - val_loss: 0.2697\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.1763 - val_loss: 0.2693\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.1757 - val_loss: 0.2689\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.1750 - val_loss: 0.2685\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1744 - val_loss: 0.2681\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1738 - val_loss: 0.2677\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1732 - val_loss: 0.2674\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1726 - val_loss: 0.2670\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1719 - val_loss: 0.2667\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1713 - val_loss: 0.2664\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1707 - val_loss: 0.2660\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1701 - val_loss: 0.2657\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1695 - val_loss: 0.2654\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1689 - val_loss: 0.2651\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1683 - val_loss: 0.2648\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1677 - val_loss: 0.2645\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1672 - val_loss: 0.2642\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1666 - val_loss: 0.2639\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1661 - val_loss: 0.2636\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1655 - val_loss: 0.2634\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1650 - val_loss: 0.2631\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1645 - val_loss: 0.2628\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1640 - val_loss: 0.2626\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1635 - val_loss: 0.2623\n",
      "In calc_results: 2459, 819, 820, sum = 4098\n",
      "In split_to_train_test: dataset_X.shape=(2870, 10, 65), dataset_y.shape=(2870, 65)\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.3230 - val_loss: 0.6708\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.3165 - val_loss: 0.6652\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.3112 - val_loss: 0.6607\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.3068 - val_loss: 0.6567\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.3028 - val_loss: 0.6530\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2993 - val_loss: 0.6497\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2962 - val_loss: 0.6466\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2933 - val_loss: 0.6437\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2907 - val_loss: 0.6410\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2883 - val_loss: 0.6383\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2861 - val_loss: 0.6359\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2840 - val_loss: 0.6334\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2820 - val_loss: 0.6312\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2801 - val_loss: 0.6289\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2784 - val_loss: 0.6268\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2767 - val_loss: 0.6247\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2751 - val_loss: 0.6226\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2736 - val_loss: 0.6207\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2721 - val_loss: 0.6188\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2707 - val_loss: 0.6170\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2694 - val_loss: 0.6152\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2682 - val_loss: 0.6133\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2670 - val_loss: 0.6117\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2658 - val_loss: 0.6101\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2647 - val_loss: 0.6085\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2637 - val_loss: 0.6069\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2627 - val_loss: 0.6053\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2617 - val_loss: 0.6038\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2608 - val_loss: 0.6023\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2599 - val_loss: 0.6009\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2590 - val_loss: 0.5994\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2582 - val_loss: 0.5980\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2574 - val_loss: 0.5967\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2566 - val_loss: 0.5953\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2559 - val_loss: 0.5940\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2551 - val_loss: 0.5926\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2544 - val_loss: 0.5913\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2537 - val_loss: 0.5900\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2530 - val_loss: 0.5887\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2524 - val_loss: 0.5875\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2517 - val_loss: 0.5862\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2510 - val_loss: 0.5850\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2504 - val_loss: 0.5838\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2498 - val_loss: 0.5825\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2491 - val_loss: 0.5813\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2485 - val_loss: 0.5800\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2479 - val_loss: 0.5789\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2474 - val_loss: 0.5777\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2468 - val_loss: 0.5765\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2462 - val_loss: 0.5754\n",
      "In calc_results: 1722, 574, 574, sum = 2870\n",
      "In split_to_train_test: dataset_X.shape=(15613, 10, 65), dataset_y.shape=(15613, 65)\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 5s 33ms/step - loss: 0.2446 - val_loss: 0.2586\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.2355 - val_loss: 0.2526\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2300 - val_loss: 0.2487\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 5s 31ms/step - loss: 0.2263 - val_loss: 0.2460\n",
      "Epoch 5/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2236 - val_loss: 0.2439\n",
      "Epoch 6/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2215 - val_loss: 0.2423\n",
      "Epoch 7/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2198 - val_loss: 0.2410\n",
      "Epoch 8/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.2184 - val_loss: 0.2399\n",
      "Epoch 9/50\n",
      "147/147 [==============================] - 5s 31ms/step - loss: 0.2171 - val_loss: 0.2389\n",
      "Epoch 10/50\n",
      "147/147 [==============================] - 5s 31ms/step - loss: 0.2160 - val_loss: 0.2380\n",
      "Epoch 11/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2150 - val_loss: 0.2372\n",
      "Epoch 12/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2141 - val_loss: 0.2364\n",
      "Epoch 13/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.2132 - val_loss: 0.2357\n",
      "Epoch 14/50\n",
      "147/147 [==============================] - 5s 31ms/step - loss: 0.2124 - val_loss: 0.2350\n",
      "Epoch 15/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2116 - val_loss: 0.2343\n",
      "Epoch 16/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2108 - val_loss: 0.2337\n",
      "Epoch 17/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2101 - val_loss: 0.2331\n",
      "Epoch 18/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2094 - val_loss: 0.2324\n",
      "Epoch 19/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.2087 - val_loss: 0.2319\n",
      "Epoch 20/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2081 - val_loss: 0.2313\n",
      "Epoch 21/50\n",
      "147/147 [==============================] - 4s 28ms/step - loss: 0.2074 - val_loss: 0.2307\n",
      "Epoch 22/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.2068 - val_loss: 0.2302\n",
      "Epoch 23/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2062 - val_loss: 0.2296\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2056 - val_loss: 0.2292\n",
      "Epoch 25/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2050 - val_loss: 0.2287\n",
      "Epoch 26/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2044 - val_loss: 0.2282\n",
      "Epoch 27/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2039 - val_loss: 0.2277\n",
      "Epoch 28/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.2034 - val_loss: 0.2273\n",
      "Epoch 29/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2028 - val_loss: 0.2269\n",
      "Epoch 30/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2023 - val_loss: 0.2265\n",
      "Epoch 31/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2019 - val_loss: 0.2261\n",
      "Epoch 32/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.2014 - val_loss: 0.2257\n",
      "Epoch 33/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2010 - val_loss: 0.2254\n",
      "Epoch 34/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.2005 - val_loss: 0.2251\n",
      "Epoch 35/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.2001 - val_loss: 0.2248\n",
      "Epoch 36/50\n",
      "147/147 [==============================] - 4s 28ms/step - loss: 0.1997 - val_loss: 0.2244\n",
      "Epoch 37/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.1993 - val_loss: 0.2241\n",
      "Epoch 38/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.1989 - val_loss: 0.2238\n",
      "Epoch 39/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.1985 - val_loss: 0.2236\n",
      "Epoch 40/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.1982 - val_loss: 0.2233\n",
      "Epoch 41/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.1978 - val_loss: 0.2230\n",
      "Epoch 42/50\n",
      "147/147 [==============================] - 5s 31ms/step - loss: 0.1975 - val_loss: 0.2228\n",
      "Epoch 43/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.1972 - val_loss: 0.2225\n",
      "Epoch 44/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.1968 - val_loss: 0.2223\n",
      "Epoch 45/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.1965 - val_loss: 0.2221\n",
      "Epoch 46/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.1962 - val_loss: 0.2218\n",
      "Epoch 47/50\n",
      "147/147 [==============================] - 4s 30ms/step - loss: 0.1959 - val_loss: 0.2216\n",
      "Epoch 48/50\n",
      "147/147 [==============================] - 4s 29ms/step - loss: 0.1956 - val_loss: 0.2214\n",
      "Epoch 49/50\n",
      "147/147 [==============================] - 4s 28ms/step - loss: 0.1953 - val_loss: 0.2212\n",
      "Epoch 50/50\n",
      "147/147 [==============================] - 5s 35ms/step - loss: 0.1950 - val_loss: 0.2211\n",
      "In calc_results: 9368, 3122, 3123, sum = 15613\n",
      "In split_to_train_test: dataset_X.shape=(5292, 10, 65), dataset_y.shape=(5292, 65)\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 2s 33ms/step - loss: 0.3245 - val_loss: 0.4779\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.3192 - val_loss: 0.4737\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.3150 - val_loss: 0.4703\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.3116 - val_loss: 0.4676\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.3088 - val_loss: 0.4652\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.3064 - val_loss: 0.4631\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.3043 - val_loss: 0.4613\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.3025 - val_loss: 0.4597\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.3009 - val_loss: 0.4583\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2994 - val_loss: 0.4570\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2981 - val_loss: 0.4558\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2969 - val_loss: 0.4547\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2957 - val_loss: 0.4537\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.2947 - val_loss: 0.4527\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.2937 - val_loss: 0.4518\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2928 - val_loss: 0.4510\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2920 - val_loss: 0.4503\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2912 - val_loss: 0.4496\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.2904 - val_loss: 0.4489\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.2897 - val_loss: 0.4483\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2890 - val_loss: 0.4477\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2883 - val_loss: 0.4472\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2876 - val_loss: 0.4467\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2870 - val_loss: 0.4462\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2865 - val_loss: 0.4458\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2859 - val_loss: 0.4454\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.2853 - val_loss: 0.4450\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2848 - val_loss: 0.4447\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2843 - val_loss: 0.4443\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.2838 - val_loss: 0.4440\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.2833 - val_loss: 0.4437\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2828 - val_loss: 0.4434\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2824 - val_loss: 0.4432\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2819 - val_loss: 0.4429\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2815 - val_loss: 0.4427\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.2811 - val_loss: 0.4425\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2806 - val_loss: 0.4423\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2802 - val_loss: 0.4420\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 2s 31ms/step - loss: 0.2798 - val_loss: 0.4418\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 2s 30ms/step - loss: 0.2794 - val_loss: 0.4417\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2790 - val_loss: 0.4415\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2786 - val_loss: 0.4413\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 2s 32ms/step - loss: 0.2782 - val_loss: 0.4411\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2779 - val_loss: 0.4410\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2775 - val_loss: 0.4408\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2771 - val_loss: 0.4406\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2768 - val_loss: 0.4405\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 1s 29ms/step - loss: 0.2764 - val_loss: 0.4403\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2761 - val_loss: 0.4402\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 0.2757 - val_loss: 0.4401\n",
      "In calc_results: 3175, 1059, 1058, sum = 5292\n",
      "In split_to_train_test: dataset_X.shape=(1196, 10, 65), dataset_y.shape=(1196, 65)\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.0375 - val_loss: 0.5130\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0312 - val_loss: 0.5101\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 33ms/step - loss: 1.0255 - val_loss: 0.5074\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0205 - val_loss: 0.5049\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 1.0158 - val_loss: 0.5027\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0115 - val_loss: 0.5007\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.0075 - val_loss: 0.4988\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0037 - val_loss: 0.4970\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0002 - val_loss: 0.4953\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9969 - val_loss: 0.4938\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9937 - val_loss: 0.4923\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.9907 - val_loss: 0.4910\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.9878 - val_loss: 0.4896\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9850 - val_loss: 0.4883\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.9823 - val_loss: 0.4870\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9797 - val_loss: 0.4859\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9772 - val_loss: 0.4847\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9748 - val_loss: 0.4836\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9725 - val_loss: 0.4825\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.9702 - val_loss: 0.4815\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.9680 - val_loss: 0.4805\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.9658 - val_loss: 0.4795\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9637 - val_loss: 0.4786\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9617 - val_loss: 0.4776\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.9597 - val_loss: 0.4766\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9577 - val_loss: 0.4758\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9558 - val_loss: 0.4749\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9540 - val_loss: 0.4740\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9521 - val_loss: 0.4732\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9503 - val_loss: 0.4724\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9486 - val_loss: 0.4716\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9468 - val_loss: 0.4708\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9451 - val_loss: 0.4701\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9434 - val_loss: 0.4693\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9418 - val_loss: 0.4686\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9402 - val_loss: 0.4679\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9386 - val_loss: 0.4672\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.9370 - val_loss: 0.4666\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9355 - val_loss: 0.4659\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9341 - val_loss: 0.4653\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9326 - val_loss: 0.4647\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9311 - val_loss: 0.4641\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9297 - val_loss: 0.4635\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9283 - val_loss: 0.4629\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.9269 - val_loss: 0.4623\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9255 - val_loss: 0.4618\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9241 - val_loss: 0.4613\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9227 - val_loss: 0.4607\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9214 - val_loss: 0.4602\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9201 - val_loss: 0.4597\n",
      "In calc_results: 718, 239, 239, sum = 1196\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=45857, 45857\n",
      "IN Clustering.split_to_clusters: mask.sum()=2958, 2958\n",
      "IN Clustering.split_to_clusters: mask.sum()=5587, 5587\n",
      "In split_to_train_test: dataset_X.shape=(45857, 10, 65), dataset_y.shape=(45857, 65)\n",
      "Epoch 1/50\n",
      "430/430 [==============================] - 14s 31ms/step - loss: 0.2833 - val_loss: 0.2705\n",
      "Epoch 2/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2695 - val_loss: 0.2636\n",
      "Epoch 3/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2635 - val_loss: 0.2600\n",
      "Epoch 4/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2599 - val_loss: 0.2576\n",
      "Epoch 5/50\n",
      "430/430 [==============================] - 14s 32ms/step - loss: 0.2573 - val_loss: 0.2556\n",
      "Epoch 6/50\n",
      "430/430 [==============================] - 14s 32ms/step - loss: 0.2551 - val_loss: 0.2539\n",
      "Epoch 7/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2532 - val_loss: 0.2524\n",
      "Epoch 8/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2515 - val_loss: 0.2510\n",
      "Epoch 9/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2498 - val_loss: 0.2497\n",
      "Epoch 10/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2483 - val_loss: 0.2485\n",
      "Epoch 11/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2468 - val_loss: 0.2474\n",
      "Epoch 12/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2454 - val_loss: 0.2464\n",
      "Epoch 13/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2441 - val_loss: 0.2455\n",
      "Epoch 14/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2428 - val_loss: 0.2446\n",
      "Epoch 15/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2416 - val_loss: 0.2439\n",
      "Epoch 16/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2406 - val_loss: 0.2431\n",
      "Epoch 17/50\n",
      "430/430 [==============================] - 14s 31ms/step - loss: 0.2396 - val_loss: 0.2426\n",
      "Epoch 18/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2387 - val_loss: 0.2420\n",
      "Epoch 19/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2379 - val_loss: 0.2415\n",
      "Epoch 20/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2372 - val_loss: 0.2411\n",
      "Epoch 21/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2366 - val_loss: 0.2408\n",
      "Epoch 22/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2361 - val_loss: 0.2404\n",
      "Epoch 23/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2356 - val_loss: 0.2402\n",
      "Epoch 24/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2351 - val_loss: 0.2399\n",
      "Epoch 25/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2347 - val_loss: 0.2397\n",
      "Epoch 26/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2343 - val_loss: 0.2394\n",
      "Epoch 27/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2340 - val_loss: 0.2392\n",
      "Epoch 28/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2336 - val_loss: 0.2390\n",
      "Epoch 29/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2333 - val_loss: 0.2388\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2331 - val_loss: 0.2387\n",
      "Epoch 31/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2328 - val_loss: 0.2385\n",
      "Epoch 32/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2325 - val_loss: 0.2383\n",
      "Epoch 33/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2322 - val_loss: 0.2382\n",
      "Epoch 34/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2320 - val_loss: 0.2381\n",
      "Epoch 35/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2317 - val_loss: 0.2380\n",
      "Epoch 36/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2315 - val_loss: 0.2378\n",
      "Epoch 37/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2313 - val_loss: 0.2376\n",
      "Epoch 38/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2311 - val_loss: 0.2375\n",
      "Epoch 39/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2309 - val_loss: 0.2375\n",
      "Epoch 40/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2307 - val_loss: 0.2374\n",
      "Epoch 41/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2305 - val_loss: 0.2372\n",
      "Epoch 42/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2303 - val_loss: 0.2371\n",
      "Epoch 43/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2301 - val_loss: 0.2370\n",
      "Epoch 44/50\n",
      "430/430 [==============================] - 14s 31ms/step - loss: 0.2300 - val_loss: 0.2369\n",
      "Epoch 45/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2298 - val_loss: 0.2367\n",
      "Epoch 46/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2296 - val_loss: 0.2368\n",
      "Epoch 47/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2294 - val_loss: 0.2366\n",
      "Epoch 48/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2293 - val_loss: 0.2366\n",
      "Epoch 49/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2291 - val_loss: 0.2364\n",
      "Epoch 50/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2290 - val_loss: 0.2364\n",
      "In calc_results: 27514, 9172, 9171, sum = 45857\n",
      "In split_to_train_test: dataset_X.shape=(2958, 10, 65), dataset_y.shape=(2958, 65)\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.3391 - val_loss: 0.7693\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.3324 - val_loss: 0.7622\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.3266 - val_loss: 0.7556\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3217 - val_loss: 0.7497\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3172 - val_loss: 0.7448\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3133 - val_loss: 0.7402\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3097 - val_loss: 0.7360\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3064 - val_loss: 0.7317\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3034 - val_loss: 0.7279\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3007 - val_loss: 0.7243\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2981 - val_loss: 0.7208\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2958 - val_loss: 0.7176\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2935 - val_loss: 0.7144\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2914 - val_loss: 0.7114\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2895 - val_loss: 0.7088\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2876 - val_loss: 0.7062\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2859 - val_loss: 0.7039\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2843 - val_loss: 0.7016\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2827 - val_loss: 0.6994\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2813 - val_loss: 0.6974\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2799 - val_loss: 0.6953\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2786 - val_loss: 0.6933\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2774 - val_loss: 0.6914\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2762 - val_loss: 0.6895\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2751 - val_loss: 0.6877\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.2741 - val_loss: 0.6858\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2731 - val_loss: 0.6841\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.2721 - val_loss: 0.6824\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2712 - val_loss: 0.6808\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2702 - val_loss: 0.6791\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2694 - val_loss: 0.6774\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2685 - val_loss: 0.6758\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2677 - val_loss: 0.6742\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2669 - val_loss: 0.6726\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2661 - val_loss: 0.6710\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2654 - val_loss: 0.6695\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2646 - val_loss: 0.6680\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2639 - val_loss: 0.6664\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2632 - val_loss: 0.6650\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2625 - val_loss: 0.6634\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2618 - val_loss: 0.6619\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2612 - val_loss: 0.6604\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2605 - val_loss: 0.6589\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2598 - val_loss: 0.6574\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2592 - val_loss: 0.6559\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2586 - val_loss: 0.6546\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2579 - val_loss: 0.6532\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2573 - val_loss: 0.6518\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2567 - val_loss: 0.6505\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2562 - val_loss: 0.6492\n",
      "In calc_results: 1775, 591, 592, sum = 2958\n",
      "In split_to_train_test: dataset_X.shape=(5587, 10, 65), dataset_y.shape=(5587, 65)\n",
      "Epoch 1/50\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.2229 - val_loss: 0.2399\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.2170 - val_loss: 0.2355\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.2127 - val_loss: 0.2321\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.2093 - val_loss: 0.2293\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.2064 - val_loss: 0.2271\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.2039 - val_loss: 0.2251\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.2017 - val_loss: 0.2235\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1997 - val_loss: 0.2221\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1980 - val_loss: 0.2208\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1965 - val_loss: 0.2196\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1951 - val_loss: 0.2185\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1939 - val_loss: 0.2175\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1927 - val_loss: 0.2166\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1916 - val_loss: 0.2157\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1906 - val_loss: 0.2149\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1897 - val_loss: 0.2141\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.1887 - val_loss: 0.2134\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1878 - val_loss: 0.2127\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1870 - val_loss: 0.2120\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1862 - val_loss: 0.2113\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1854 - val_loss: 0.2107\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1846 - val_loss: 0.2101\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1839 - val_loss: 0.2095\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1831 - val_loss: 0.2089\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1824 - val_loss: 0.2084\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1817 - val_loss: 0.2079\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1810 - val_loss: 0.2073\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1804 - val_loss: 0.2069\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1797 - val_loss: 0.2064\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1791 - val_loss: 0.2059\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1784 - val_loss: 0.2054\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1778 - val_loss: 0.2049\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.1772 - val_loss: 0.2045\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1766 - val_loss: 0.2040\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1760 - val_loss: 0.2036\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1754 - val_loss: 0.2031\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1748 - val_loss: 0.2027\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1742 - val_loss: 0.2023\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1737 - val_loss: 0.2019\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1731 - val_loss: 0.2014\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1726 - val_loss: 0.2010\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1721 - val_loss: 0.2006\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1716 - val_loss: 0.2002\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1710 - val_loss: 0.1998\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1705 - val_loss: 0.1995\n",
      "Epoch 46/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1701 - val_loss: 0.1991\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1696 - val_loss: 0.1987\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1691 - val_loss: 0.1984\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1687 - val_loss: 0.1980\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1682 - val_loss: 0.1977\n",
      "In calc_results: 3352, 1118, 1117, sum = 5587\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=2017, 2017\n",
      "IN Clustering.split_to_clusters: mask.sum()=42286, 42286\n",
      "IN Clustering.split_to_clusters: mask.sum()=2054, 2054\n",
      "IN Clustering.split_to_clusters: mask.sum()=2877, 2877\n",
      "IN Clustering.split_to_clusters: mask.sum()=5168, 5168\n",
      "In split_to_train_test: dataset_X.shape=(2017, 10, 65), dataset_y.shape=(2017, 65)\n",
      "Epoch 1/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.8106 - val_loss: 0.7187\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.8055 - val_loss: 0.7149\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.8011 - val_loss: 0.7115\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7970 - val_loss: 0.7084\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7932 - val_loss: 0.7055\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7896 - val_loss: 0.7028\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7863 - val_loss: 0.7002\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7832 - val_loss: 0.6979\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7803 - val_loss: 0.6956\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7776 - val_loss: 0.6935\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7750 - val_loss: 0.6915\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7725 - val_loss: 0.6895\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7701 - val_loss: 0.6877\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7679 - val_loss: 0.6859\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7657 - val_loss: 0.6842\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7636 - val_loss: 0.6826\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.7616 - val_loss: 0.6810\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7596 - val_loss: 0.6795\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.7577 - val_loss: 0.6781\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.7559 - val_loss: 0.6768\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.7541 - val_loss: 0.6755\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7524 - val_loss: 0.6742\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7507 - val_loss: 0.6731\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7491 - val_loss: 0.6720\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7476 - val_loss: 0.6709\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7461 - val_loss: 0.6698\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7447 - val_loss: 0.6689\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7433 - val_loss: 0.6679\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7420 - val_loss: 0.6670\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7407 - val_loss: 0.6661\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.7395 - val_loss: 0.6652\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7383 - val_loss: 0.6644\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7372 - val_loss: 0.6636\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7361 - val_loss: 0.6629\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7350 - val_loss: 0.6621\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7339 - val_loss: 0.6613\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7329 - val_loss: 0.6606\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.7319 - val_loss: 0.6599\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.7308 - val_loss: 0.6592\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.7299 - val_loss: 0.6586\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.7289 - val_loss: 0.6579\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.7279 - val_loss: 0.6572\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7270 - val_loss: 0.6565\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7261 - val_loss: 0.6559\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7252 - val_loss: 0.6553\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7243 - val_loss: 0.6547\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7234 - val_loss: 0.6540\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7225 - val_loss: 0.6534\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.7217 - val_loss: 0.6528\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.7208 - val_loss: 0.6522\n",
      "In calc_results: 1210, 404, 403, sum = 2017\n",
      "In split_to_train_test: dataset_X.shape=(42286, 10, 65), dataset_y.shape=(42286, 65)\n",
      "Epoch 1/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2616 - val_loss: 0.2424\n",
      "Epoch 2/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2471 - val_loss: 0.2358\n",
      "Epoch 3/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2411 - val_loss: 0.2324\n",
      "Epoch 4/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2375 - val_loss: 0.2301\n",
      "Epoch 5/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2349 - val_loss: 0.2283\n",
      "Epoch 6/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2327 - val_loss: 0.2267\n",
      "Epoch 7/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2308 - val_loss: 0.2252\n",
      "Epoch 8/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2290 - val_loss: 0.2238\n",
      "Epoch 9/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2273 - val_loss: 0.2225\n",
      "Epoch 10/50\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2256 - val_loss: 0.2212\n",
      "Epoch 11/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2240 - val_loss: 0.2200\n",
      "Epoch 12/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2225 - val_loss: 0.2190\n",
      "Epoch 13/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2211 - val_loss: 0.2180\n",
      "Epoch 14/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2197 - val_loss: 0.2171\n",
      "Epoch 15/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2184 - val_loss: 0.2163\n",
      "Epoch 16/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2173 - val_loss: 0.2156\n",
      "Epoch 17/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2163 - val_loss: 0.2150\n",
      "Epoch 18/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2155 - val_loss: 0.2145\n",
      "Epoch 19/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2148 - val_loss: 0.2140\n",
      "Epoch 20/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2142 - val_loss: 0.2136\n",
      "Epoch 21/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2136 - val_loss: 0.2133\n",
      "Epoch 22/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2131 - val_loss: 0.2130\n",
      "Epoch 23/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2127 - val_loss: 0.2127\n",
      "Epoch 24/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2123 - val_loss: 0.2125\n",
      "Epoch 25/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2119 - val_loss: 0.2123\n",
      "Epoch 26/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2115 - val_loss: 0.2120\n",
      "Epoch 27/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2112 - val_loss: 0.2119\n",
      "Epoch 28/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2109 - val_loss: 0.2116\n",
      "Epoch 29/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2106 - val_loss: 0.2114\n",
      "Epoch 30/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2103 - val_loss: 0.2113\n",
      "Epoch 31/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2101 - val_loss: 0.2111\n",
      "Epoch 32/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2098 - val_loss: 0.2109\n",
      "Epoch 33/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2096 - val_loss: 0.2109\n",
      "Epoch 34/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2094 - val_loss: 0.2107\n",
      "Epoch 35/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2092 - val_loss: 0.2105\n",
      "Epoch 36/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2090 - val_loss: 0.2105\n",
      "Epoch 37/50\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2088 - val_loss: 0.2103\n",
      "Epoch 38/50\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2086 - val_loss: 0.2102\n",
      "Epoch 39/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2084 - val_loss: 0.2102\n",
      "Epoch 40/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2082 - val_loss: 0.2100\n",
      "Epoch 41/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2081 - val_loss: 0.2099\n",
      "Epoch 42/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2079 - val_loss: 0.2098\n",
      "Epoch 43/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2077 - val_loss: 0.2098\n",
      "Epoch 44/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2076 - val_loss: 0.2096\n",
      "Epoch 45/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2074 - val_loss: 0.2096\n",
      "Epoch 46/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2073 - val_loss: 0.2094\n",
      "Epoch 47/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2072 - val_loss: 0.2094\n",
      "Epoch 48/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2070 - val_loss: 0.2094\n",
      "Epoch 49/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2069 - val_loss: 0.2092\n",
      "Epoch 50/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2068 - val_loss: 0.2091\n",
      "In calc_results: 25372, 8457, 8457, sum = 42286\n",
      "In split_to_train_test: dataset_X.shape=(2054, 10, 65), dataset_y.shape=(2054, 65)\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2558 - val_loss: 0.2416\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2516 - val_loss: 0.2397\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2481 - val_loss: 0.2380\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2450 - val_loss: 0.2365\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2424 - val_loss: 0.2350\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2401 - val_loss: 0.2337\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2380 - val_loss: 0.2326\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2361 - val_loss: 0.2314\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2344 - val_loss: 0.2304\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2328 - val_loss: 0.2295\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2313 - val_loss: 0.2286\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2299 - val_loss: 0.2278\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2287 - val_loss: 0.2270\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2275 - val_loss: 0.2263\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2263 - val_loss: 0.2256\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2253 - val_loss: 0.2250\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2242 - val_loss: 0.2244\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2233 - val_loss: 0.2239\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2223 - val_loss: 0.2233\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2214 - val_loss: 0.2228\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2206 - val_loss: 0.2223\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2198 - val_loss: 0.2218\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2190 - val_loss: 0.2213\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2183 - val_loss: 0.2208\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2175 - val_loss: 0.2204\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2168 - val_loss: 0.2200\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2162 - val_loss: 0.2196\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2155 - val_loss: 0.2192\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2149 - val_loss: 0.2188\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2143 - val_loss: 0.2185\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2137 - val_loss: 0.2181\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2131 - val_loss: 0.2177\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2126 - val_loss: 0.2174\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2120 - val_loss: 0.2171\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2115 - val_loss: 0.2168\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2110 - val_loss: 0.2164\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2105 - val_loss: 0.2161\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2101 - val_loss: 0.2158\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2096 - val_loss: 0.2155\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2091 - val_loss: 0.2153\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2087 - val_loss: 0.2149\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2082 - val_loss: 0.2147\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2078 - val_loss: 0.2144\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2074 - val_loss: 0.2141\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2069 - val_loss: 0.2138\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2065 - val_loss: 0.2136\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2061 - val_loss: 0.2133\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2057 - val_loss: 0.2131\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2053 - val_loss: 0.2128\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2049 - val_loss: 0.2126\n",
      "In calc_results: 1232, 411, 411, sum = 2054\n",
      "In split_to_train_test: dataset_X.shape=(2877, 10, 65), dataset_y.shape=(2877, 65)\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.3091 - val_loss: 0.6244\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.3021 - val_loss: 0.6201\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2964 - val_loss: 0.6162\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2917 - val_loss: 0.6125\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2875 - val_loss: 0.6091\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2838 - val_loss: 0.6058\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2804 - val_loss: 0.6025\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2773 - val_loss: 0.5996\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2744 - val_loss: 0.5967\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2717 - val_loss: 0.5938\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2693 - val_loss: 0.5912\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2670 - val_loss: 0.5887\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2649 - val_loss: 0.5861\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2628 - val_loss: 0.5837\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2610 - val_loss: 0.5814\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2593 - val_loss: 0.5791\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2576 - val_loss: 0.5770\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2561 - val_loss: 0.5748\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2547 - val_loss: 0.5727\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2533 - val_loss: 0.5708\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2520 - val_loss: 0.5689\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2508 - val_loss: 0.5671\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2496 - val_loss: 0.5652\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2485 - val_loss: 0.5635\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2474 - val_loss: 0.5618\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2463 - val_loss: 0.5601\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2453 - val_loss: 0.5586\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2443 - val_loss: 0.5570\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2434 - val_loss: 0.5555\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2425 - val_loss: 0.5540\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2416 - val_loss: 0.5525\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2408 - val_loss: 0.5511\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2400 - val_loss: 0.5497\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2392 - val_loss: 0.5484\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2385 - val_loss: 0.5471\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2377 - val_loss: 0.5458\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2371 - val_loss: 0.5446\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2364 - val_loss: 0.5434\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2357 - val_loss: 0.5422\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2351 - val_loss: 0.5411\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2345 - val_loss: 0.5400\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2339 - val_loss: 0.5389\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2333 - val_loss: 0.5378\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2328 - val_loss: 0.5368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2322 - val_loss: 0.5357\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2317 - val_loss: 0.5348\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2312 - val_loss: 0.5338\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2307 - val_loss: 0.5329\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2302 - val_loss: 0.5320\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2298 - val_loss: 0.5312\n",
      "In calc_results: 1726, 576, 575, sum = 2877\n",
      "In split_to_train_test: dataset_X.shape=(5168, 10, 65), dataset_y.shape=(5168, 65)\n",
      "Epoch 1/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.2268 - val_loss: 0.3276\n",
      "Epoch 2/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2220 - val_loss: 0.3236\n",
      "Epoch 3/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2184 - val_loss: 0.3205\n",
      "Epoch 4/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2155 - val_loss: 0.3179\n",
      "Epoch 5/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2131 - val_loss: 0.3158\n",
      "Epoch 6/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2111 - val_loss: 0.3139\n",
      "Epoch 7/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.2093 - val_loss: 0.3123\n",
      "Epoch 8/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2077 - val_loss: 0.3109\n",
      "Epoch 9/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2063 - val_loss: 0.3097\n",
      "Epoch 10/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2050 - val_loss: 0.3085\n",
      "Epoch 11/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2038 - val_loss: 0.3075\n",
      "Epoch 12/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2027 - val_loss: 0.3065\n",
      "Epoch 13/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2017 - val_loss: 0.3057\n",
      "Epoch 14/50\n",
      "49/49 [==============================] - 1s 31ms/step - loss: 0.2007 - val_loss: 0.3049\n",
      "Epoch 15/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.1997 - val_loss: 0.3042\n",
      "Epoch 16/50\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.1988 - val_loss: 0.3035\n",
      "Epoch 17/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1980 - val_loss: 0.3029\n",
      "Epoch 18/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1972 - val_loss: 0.3024\n",
      "Epoch 19/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1964 - val_loss: 0.3019\n",
      "Epoch 20/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1956 - val_loss: 0.3014\n",
      "Epoch 21/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1948 - val_loss: 0.3010\n",
      "Epoch 22/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.1941 - val_loss: 0.3006\n",
      "Epoch 23/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1934 - val_loss: 0.3002\n",
      "Epoch 24/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1927 - val_loss: 0.2998\n",
      "Epoch 25/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1920 - val_loss: 0.2995\n",
      "Epoch 26/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1913 - val_loss: 0.2992\n",
      "Epoch 27/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1906 - val_loss: 0.2989\n",
      "Epoch 28/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1900 - val_loss: 0.2986\n",
      "Epoch 29/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1893 - val_loss: 0.2984\n",
      "Epoch 30/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.1886 - val_loss: 0.2981\n",
      "Epoch 31/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1880 - val_loss: 0.2979\n",
      "Epoch 32/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1874 - val_loss: 0.2976\n",
      "Epoch 33/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1867 - val_loss: 0.2974\n",
      "Epoch 34/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.1861 - val_loss: 0.2972\n",
      "Epoch 35/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1855 - val_loss: 0.2969\n",
      "Epoch 36/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1849 - val_loss: 0.2968\n",
      "Epoch 37/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1843 - val_loss: 0.2966\n",
      "Epoch 38/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1837 - val_loss: 0.2964\n",
      "Epoch 39/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.1831 - val_loss: 0.2962\n",
      "Epoch 40/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.1825 - val_loss: 0.2961\n",
      "Epoch 41/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1820 - val_loss: 0.2959\n",
      "Epoch 42/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.1815 - val_loss: 0.2957\n",
      "Epoch 43/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.1809 - val_loss: 0.2956\n",
      "Epoch 44/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1804 - val_loss: 0.2954\n",
      "Epoch 45/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1799 - val_loss: 0.2953\n",
      "Epoch 46/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1794 - val_loss: 0.2952\n",
      "Epoch 47/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1789 - val_loss: 0.2950\n",
      "Epoch 48/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1785 - val_loss: 0.2949\n",
      "Epoch 49/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1780 - val_loss: 0.2947\n",
      "Epoch 50/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.1776 - val_loss: 0.2946\n",
      "In calc_results: 3101, 1033, 1034, sum = 5168\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=436, 436\n",
      "IN Clustering.split_to_clusters: mask.sum()=1381, 1381\n",
      "IN Clustering.split_to_clusters: mask.sum()=4375, 4375\n",
      "IN Clustering.split_to_clusters: mask.sum()=17353, 17353\n",
      "IN Clustering.split_to_clusters: mask.sum()=1883, 1883\n",
      "IN Clustering.split_to_clusters: mask.sum()=26552, 26552\n",
      "IN Clustering.split_to_clusters: mask.sum()=2422, 2422\n",
      "In split_to_train_test: dataset_X.shape=(436, 10, 65), dataset_y.shape=(436, 65)\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0783 - val_loss: 0.0820\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0769 - val_loss: 0.0804\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0756 - val_loss: 0.0788\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0743 - val_loss: 0.0774\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0731 - val_loss: 0.0760\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0721 - val_loss: 0.0748\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0710 - val_loss: 0.0736\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0701 - val_loss: 0.0725\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0692 - val_loss: 0.0715\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0683 - val_loss: 0.0706\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0675 - val_loss: 0.0697\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0667 - val_loss: 0.0688\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0660 - val_loss: 0.0680\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0653 - val_loss: 0.0672\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0646 - val_loss: 0.0665\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0639 - val_loss: 0.0658\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0633 - val_loss: 0.0651\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0627 - val_loss: 0.0645\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0621 - val_loss: 0.0639\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0616 - val_loss: 0.0633\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0610 - val_loss: 0.0627\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0605 - val_loss: 0.0621\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0599 - val_loss: 0.0616\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0594 - val_loss: 0.0611\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0589 - val_loss: 0.0606\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0585 - val_loss: 0.0601\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0580 - val_loss: 0.0597\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0576 - val_loss: 0.0593\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0571 - val_loss: 0.0588\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0567 - val_loss: 0.0584\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0563 - val_loss: 0.0579\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0559 - val_loss: 0.0575\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0555 - val_loss: 0.0570\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0551 - val_loss: 0.0566\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0547 - val_loss: 0.0562\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0543 - val_loss: 0.0558\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0540 - val_loss: 0.0555\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0536 - val_loss: 0.0551\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0533 - val_loss: 0.0548\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0529 - val_loss: 0.0544\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0526 - val_loss: 0.0541\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0523 - val_loss: 0.0538\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0520 - val_loss: 0.0535\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0517 - val_loss: 0.0532\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0514 - val_loss: 0.0528\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0511 - val_loss: 0.0525\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0508 - val_loss: 0.0522\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0505 - val_loss: 0.0520\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0502 - val_loss: 0.0517\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0499 - val_loss: 0.0515\n",
      "In calc_results: 262, 87, 87, sum = 436\n",
      "In split_to_train_test: dataset_X.shape=(1381, 10, 65), dataset_y.shape=(1381, 65)\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.9714 - val_loss: 0.6203\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9661 - val_loss: 0.6177\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9614 - val_loss: 0.6152\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.9569 - val_loss: 0.6129\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.9529 - val_loss: 0.6107\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9490 - val_loss: 0.6087\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.9453 - val_loss: 0.6068\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9417 - val_loss: 0.6050\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9385 - val_loss: 0.6032\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9354 - val_loss: 0.6015\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9324 - val_loss: 0.5999\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9296 - val_loss: 0.5984\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9269 - val_loss: 0.5969\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.9242 - val_loss: 0.5955\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9217 - val_loss: 0.5940\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9193 - val_loss: 0.5927\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.9170 - val_loss: 0.5913\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9147 - val_loss: 0.5900\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9125 - val_loss: 0.5888\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.9104 - val_loss: 0.5875\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9083 - val_loss: 0.5863\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.9063 - val_loss: 0.5851\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.9043 - val_loss: 0.5840\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.9024 - val_loss: 0.5829\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.9006 - val_loss: 0.5818\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.8988 - val_loss: 0.5807\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.8970 - val_loss: 0.5797\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.8953 - val_loss: 0.5787\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.8935 - val_loss: 0.5777\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.8918 - val_loss: 0.5768\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.8902 - val_loss: 0.5758\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.8886 - val_loss: 0.5749\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.8870 - val_loss: 0.5741\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.8854 - val_loss: 0.5732\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.8839 - val_loss: 0.5724\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.8824 - val_loss: 0.5716\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.8810 - val_loss: 0.5708\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.8796 - val_loss: 0.5701\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.8782 - val_loss: 0.5693\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.8768 - val_loss: 0.5686\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.8755 - val_loss: 0.5679\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.8742 - val_loss: 0.5672\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.8729 - val_loss: 0.5665\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.8717 - val_loss: 0.5659\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.8704 - val_loss: 0.5652\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.8692 - val_loss: 0.5646\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.8680 - val_loss: 0.5640\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.8668 - val_loss: 0.5634\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.8656 - val_loss: 0.5628\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.8645 - val_loss: 0.5622\n",
      "In calc_results: 829, 276, 276, sum = 1381\n",
      "In split_to_train_test: dataset_X.shape=(4375, 10, 65), dataset_y.shape=(4375, 65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2192 - val_loss: 0.3156\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.2147 - val_loss: 0.3126\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2113 - val_loss: 0.3102\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2087 - val_loss: 0.3082\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2065 - val_loss: 0.3066\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2047 - val_loss: 0.3051\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2030 - val_loss: 0.3038\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2015 - val_loss: 0.3026\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2002 - val_loss: 0.3015\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1989 - val_loss: 0.3004\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1977 - val_loss: 0.2995\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1967 - val_loss: 0.2986\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1956 - val_loss: 0.2978\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1947 - val_loss: 0.2970\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1938 - val_loss: 0.2963\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1931 - val_loss: 0.2957\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1923 - val_loss: 0.2951\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1916 - val_loss: 0.2946\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1910 - val_loss: 0.2941\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1903 - val_loss: 0.2936\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1897 - val_loss: 0.2932\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1891 - val_loss: 0.2927\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1885 - val_loss: 0.2923\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1879 - val_loss: 0.2919\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1873 - val_loss: 0.2915\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1868 - val_loss: 0.2912\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1862 - val_loss: 0.2908\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1857 - val_loss: 0.2905\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1852 - val_loss: 0.2901\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1846 - val_loss: 0.2898\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1841 - val_loss: 0.2895\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1836 - val_loss: 0.2892\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1831 - val_loss: 0.2889\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1826 - val_loss: 0.2886\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.1821 - val_loss: 0.2883\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.1817 - val_loss: 0.2881\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1812 - val_loss: 0.2878\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1807 - val_loss: 0.2876\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1803 - val_loss: 0.2873\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1798 - val_loss: 0.2871\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1793 - val_loss: 0.2868\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1789 - val_loss: 0.2866\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1785 - val_loss: 0.2864\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1780 - val_loss: 0.2862\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1776 - val_loss: 0.2860\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1772 - val_loss: 0.2858\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1767 - val_loss: 0.2856\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1763 - val_loss: 0.2854\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1759 - val_loss: 0.2853\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.1755 - val_loss: 0.2851\n",
      "In calc_results: 2625, 875, 875, sum = 4375\n",
      "In split_to_train_test: dataset_X.shape=(17353, 10, 65), dataset_y.shape=(17353, 65)\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2991 - val_loss: 0.2883\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2879 - val_loss: 0.2817\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 0.2813 - val_loss: 0.2776\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2770 - val_loss: 0.2747\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2738 - val_loss: 0.2727\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 0.2714 - val_loss: 0.2710\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2695 - val_loss: 0.2696\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2679 - val_loss: 0.2685\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2665 - val_loss: 0.2675\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2652 - val_loss: 0.2666\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2640 - val_loss: 0.2658\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2629 - val_loss: 0.2650\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2619 - val_loss: 0.2644\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2610 - val_loss: 0.2637\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2600 - val_loss: 0.2631\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2592 - val_loss: 0.2625\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2583 - val_loss: 0.2620\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2575 - val_loss: 0.2614\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2567 - val_loss: 0.2609\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2559 - val_loss: 0.2604\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2551 - val_loss: 0.2599\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2543 - val_loss: 0.2594\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2536 - val_loss: 0.2590\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2528 - val_loss: 0.2585\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2521 - val_loss: 0.2581\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 0.2514 - val_loss: 0.2577\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2507 - val_loss: 0.2572\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2500 - val_loss: 0.2568\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2493 - val_loss: 0.2565\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2486 - val_loss: 0.2561\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2479 - val_loss: 0.2558\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2473 - val_loss: 0.2555\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2466 - val_loss: 0.2552\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 0.2460 - val_loss: 0.2549\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2454 - val_loss: 0.2547\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2448 - val_loss: 0.2544\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 0.2442 - val_loss: 0.2542\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2437 - val_loss: 0.2540\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2432 - val_loss: 0.2538\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2427 - val_loss: 0.2536\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2423 - val_loss: 0.2534\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2418 - val_loss: 0.2532\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 0.2415 - val_loss: 0.2531\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2411 - val_loss: 0.2529\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2407 - val_loss: 0.2527\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2404 - val_loss: 0.2525\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2401 - val_loss: 0.2524\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2398 - val_loss: 0.2523\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 0.2395 - val_loss: 0.2521\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 0.2392 - val_loss: 0.2520\n",
      "In calc_results: 10412, 3470, 3471, sum = 17353\n",
      "In split_to_train_test: dataset_X.shape=(1883, 10, 65), dataset_y.shape=(1883, 65)\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2535 - val_loss: 0.2392\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2497 - val_loss: 0.2373\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2464 - val_loss: 0.2356\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2436 - val_loss: 0.2341\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.2411 - val_loss: 0.2327\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2388 - val_loss: 0.2313\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2367 - val_loss: 0.2301\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2349 - val_loss: 0.2290\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2332 - val_loss: 0.2279\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2316 - val_loss: 0.2269\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2302 - val_loss: 0.2260\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2288 - val_loss: 0.2252\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2276 - val_loss: 0.2244\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2264 - val_loss: 0.2237\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.2253 - val_loss: 0.2230\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2242 - val_loss: 0.2223\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.2232 - val_loss: 0.2217\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.2223 - val_loss: 0.2211\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2214 - val_loss: 0.2206\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2206 - val_loss: 0.2201\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2198 - val_loss: 0.2196\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2190 - val_loss: 0.2191\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2183 - val_loss: 0.2187\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2176 - val_loss: 0.2183\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2169 - val_loss: 0.2179\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2163 - val_loss: 0.2176\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2156 - val_loss: 0.2172\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2151 - val_loss: 0.2169\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2145 - val_loss: 0.2165\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2139 - val_loss: 0.2162\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2134 - val_loss: 0.2159\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2129 - val_loss: 0.2156\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2124 - val_loss: 0.2153\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2119 - val_loss: 0.2150\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2114 - val_loss: 0.2147\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2110 - val_loss: 0.2145\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2105 - val_loss: 0.2142\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2101 - val_loss: 0.2140\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2097 - val_loss: 0.2137\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2093 - val_loss: 0.2135\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2089 - val_loss: 0.2132\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2085 - val_loss: 0.2130\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2081 - val_loss: 0.2128\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2077 - val_loss: 0.2126\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2073 - val_loss: 0.2124\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2070 - val_loss: 0.2121\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2066 - val_loss: 0.2119\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2063 - val_loss: 0.2117\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2059 - val_loss: 0.2115\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2056 - val_loss: 0.2113\n",
      "In calc_results: 1130, 376, 377, sum = 1883\n",
      "In split_to_train_test: dataset_X.shape=(26552, 10, 65), dataset_y.shape=(26552, 65)\n",
      "Epoch 1/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2460 - val_loss: 0.2410\n",
      "Epoch 2/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2350 - val_loss: 0.2352\n",
      "Epoch 3/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2293 - val_loss: 0.2318\n",
      "Epoch 4/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2257 - val_loss: 0.2295\n",
      "Epoch 5/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.2232 - val_loss: 0.2277\n",
      "Epoch 6/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.2211 - val_loss: 0.2261\n",
      "Epoch 7/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2194 - val_loss: 0.2247\n",
      "Epoch 8/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2178 - val_loss: 0.2234\n",
      "Epoch 9/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2163 - val_loss: 0.2222\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2150 - val_loss: 0.2211\n",
      "Epoch 11/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2137 - val_loss: 0.2200\n",
      "Epoch 12/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2125 - val_loss: 0.2191\n",
      "Epoch 13/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2113 - val_loss: 0.2182\n",
      "Epoch 14/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.2102 - val_loss: 0.2173\n",
      "Epoch 15/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2092 - val_loss: 0.2165\n",
      "Epoch 16/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2082 - val_loss: 0.2158\n",
      "Epoch 17/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2073 - val_loss: 0.2151\n",
      "Epoch 18/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2064 - val_loss: 0.2144\n",
      "Epoch 19/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2056 - val_loss: 0.2139\n",
      "Epoch 20/50\n",
      "249/249 [==============================] - 8s 32ms/step - loss: 0.2048 - val_loss: 0.2132\n",
      "Epoch 21/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2040 - val_loss: 0.2127\n",
      "Epoch 22/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2033 - val_loss: 0.2122\n",
      "Epoch 23/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2027 - val_loss: 0.2117\n",
      "Epoch 24/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 0.2020 - val_loss: 0.2113\n",
      "Epoch 25/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2014 - val_loss: 0.2108\n",
      "Epoch 26/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.2009 - val_loss: 0.2104\n",
      "Epoch 27/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.2003 - val_loss: 0.2101\n",
      "Epoch 28/50\n",
      "249/249 [==============================] - 8s 30ms/step - loss: 0.1998 - val_loss: 0.2097\n",
      "Epoch 29/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1994 - val_loss: 0.2094\n",
      "Epoch 30/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.1990 - val_loss: 0.2091\n",
      "Epoch 31/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 0.1986 - val_loss: 0.2089\n",
      "Epoch 32/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1982 - val_loss: 0.2087\n",
      "Epoch 33/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1979 - val_loss: 0.2084\n",
      "Epoch 34/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 0.1976 - val_loss: 0.2082\n",
      "Epoch 35/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1973 - val_loss: 0.2081\n",
      "Epoch 36/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 0.1970 - val_loss: 0.2080\n",
      "Epoch 37/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1968 - val_loss: 0.2078\n",
      "Epoch 38/50\n",
      "249/249 [==============================] - 7s 28ms/step - loss: 0.1965 - val_loss: 0.2076\n",
      "Epoch 39/50\n",
      "249/249 [==============================] - 8s 31ms/step - loss: 0.1963 - val_loss: 0.2075\n",
      "Epoch 40/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1960 - val_loss: 0.2073\n",
      "Epoch 41/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1958 - val_loss: 0.2072\n",
      "Epoch 42/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1956 - val_loss: 0.2072\n",
      "Epoch 43/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1954 - val_loss: 0.2070\n",
      "Epoch 44/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.1952 - val_loss: 0.2070\n",
      "Epoch 45/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.1950 - val_loss: 0.2068\n",
      "Epoch 46/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1949 - val_loss: 0.2067\n",
      "Epoch 47/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1947 - val_loss: 0.2067\n",
      "Epoch 48/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1945 - val_loss: 0.2066\n",
      "Epoch 49/50\n",
      "249/249 [==============================] - 7s 29ms/step - loss: 0.1944 - val_loss: 0.2065\n",
      "Epoch 50/50\n",
      "249/249 [==============================] - 7s 30ms/step - loss: 0.1942 - val_loss: 0.2064\n",
      "In calc_results: 15931, 5311, 5310, sum = 26552\n",
      "In split_to_train_test: dataset_X.shape=(2422, 10, 65), dataset_y.shape=(2422, 65)\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.4130 - val_loss: 0.5165\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.4066 - val_loss: 0.5116\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.4009 - val_loss: 0.5074\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3958 - val_loss: 0.5034\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3912 - val_loss: 0.4999\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3871 - val_loss: 0.4966\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3833 - val_loss: 0.4937\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3797 - val_loss: 0.4908\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3764 - val_loss: 0.4882\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3733 - val_loss: 0.4856\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3704 - val_loss: 0.4833\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.3677 - val_loss: 0.4811\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.3651 - val_loss: 0.4789\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3627 - val_loss: 0.4769\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3604 - val_loss: 0.4750\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3582 - val_loss: 0.4732\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3561 - val_loss: 0.4715\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3542 - val_loss: 0.4698\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.3523 - val_loss: 0.4682\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3505 - val_loss: 0.4667\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3487 - val_loss: 0.4652\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.3471 - val_loss: 0.4638\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3455 - val_loss: 0.4624\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3440 - val_loss: 0.4610\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3425 - val_loss: 0.4597\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3411 - val_loss: 0.4584\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3397 - val_loss: 0.4572\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3384 - val_loss: 0.4560\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.3371 - val_loss: 0.4548\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3358 - val_loss: 0.4537\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3346 - val_loss: 0.4526\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3334 - val_loss: 0.4515\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3322 - val_loss: 0.4505\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.3310 - val_loss: 0.4495\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.3299 - val_loss: 0.4484\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3288 - val_loss: 0.4474\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3277 - val_loss: 0.4464\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3266 - val_loss: 0.4454\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.3256 - val_loss: 0.4445\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3246 - val_loss: 0.4435\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.3236 - val_loss: 0.4425\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.3226 - val_loss: 0.4416\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.3216 - val_loss: 0.4406\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3206 - val_loss: 0.4397\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.3197 - val_loss: 0.4389\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3189 - val_loss: 0.4380\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3180 - val_loss: 0.4371\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.3172 - val_loss: 0.4363\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3163 - val_loss: 0.4355\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3156 - val_loss: 0.4348\n",
      "In calc_results: 1453, 485, 484, sum = 2422\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=5610, 5610\n",
      "IN Clustering.split_to_clusters: mask.sum()=45837, 45837\n",
      "IN Clustering.split_to_clusters: mask.sum()=2955, 2955\n",
      "In split_to_train_test: dataset_X.shape=(5610, 10, 65), dataset_y.shape=(5610, 65)\n",
      "Epoch 1/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.2210 - val_loss: 0.2375\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.2146 - val_loss: 0.2333\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.2101 - val_loss: 0.2301\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.2067 - val_loss: 0.2276\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.2040 - val_loss: 0.2255\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.2017 - val_loss: 0.2238\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1997 - val_loss: 0.2223\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1981 - val_loss: 0.2211\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1966 - val_loss: 0.2200\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1953 - val_loss: 0.2190\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1941 - val_loss: 0.2181\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1930 - val_loss: 0.2173\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1920 - val_loss: 0.2164\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1910 - val_loss: 0.2157\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1901 - val_loss: 0.2150\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1892 - val_loss: 0.2143\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1883 - val_loss: 0.2136\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1875 - val_loss: 0.2130\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1867 - val_loss: 0.2124\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1860 - val_loss: 0.2118\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.1852 - val_loss: 0.2112\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1845 - val_loss: 0.2106\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1837 - val_loss: 0.2101\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1830 - val_loss: 0.2095\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.1823 - val_loss: 0.2090\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1816 - val_loss: 0.2085\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1810 - val_loss: 0.2079\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1803 - val_loss: 0.2074\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1796 - val_loss: 0.2069\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1789 - val_loss: 0.2064\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1783 - val_loss: 0.2059\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.1776 - val_loss: 0.2054\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1770 - val_loss: 0.2049\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1764 - val_loss: 0.2044\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1757 - val_loss: 0.2040\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1751 - val_loss: 0.2035\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1745 - val_loss: 0.2031\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1740 - val_loss: 0.2026\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1734 - val_loss: 0.2022\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1728 - val_loss: 0.2018\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1723 - val_loss: 0.2014\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1717 - val_loss: 0.2010\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1712 - val_loss: 0.2005\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1707 - val_loss: 0.2002\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1702 - val_loss: 0.1998\n",
      "Epoch 46/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1697 - val_loss: 0.1994\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1692 - val_loss: 0.1991\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1687 - val_loss: 0.1987\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1682 - val_loss: 0.1984\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1678 - val_loss: 0.1981\n",
      "In calc_results: 3366, 1122, 1122, sum = 5610\n",
      "In split_to_train_test: dataset_X.shape=(45837, 10, 65), dataset_y.shape=(45837, 65)\n",
      "Epoch 1/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2846 - val_loss: 0.2712\n",
      "Epoch 2/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2705 - val_loss: 0.2644\n",
      "Epoch 3/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2645 - val_loss: 0.2609\n",
      "Epoch 4/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2609 - val_loss: 0.2584\n",
      "Epoch 5/50\n",
      "430/430 [==============================] - 12s 28ms/step - loss: 0.2582 - val_loss: 0.2564\n",
      "Epoch 6/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2560 - val_loss: 0.2546\n",
      "Epoch 7/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2541 - val_loss: 0.2530\n",
      "Epoch 8/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2523 - val_loss: 0.2516\n",
      "Epoch 9/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2506 - val_loss: 0.2502\n",
      "Epoch 10/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2490 - val_loss: 0.2490\n",
      "Epoch 11/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2475 - val_loss: 0.2479\n",
      "Epoch 12/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2460 - val_loss: 0.2469\n",
      "Epoch 13/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2447 - val_loss: 0.2459\n",
      "Epoch 14/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2433 - val_loss: 0.2450\n",
      "Epoch 15/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2421 - val_loss: 0.2443\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2410 - val_loss: 0.2435\n",
      "Epoch 17/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2400 - val_loss: 0.2429\n",
      "Epoch 18/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2391 - val_loss: 0.2424\n",
      "Epoch 19/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2384 - val_loss: 0.2420\n",
      "Epoch 20/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2378 - val_loss: 0.2417\n",
      "Epoch 21/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2372 - val_loss: 0.2413\n",
      "Epoch 22/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2367 - val_loss: 0.2410\n",
      "Epoch 23/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2362 - val_loss: 0.2407\n",
      "Epoch 24/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2358 - val_loss: 0.2404\n",
      "Epoch 25/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2354 - val_loss: 0.2402\n",
      "Epoch 26/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2350 - val_loss: 0.2399\n",
      "Epoch 27/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2346 - val_loss: 0.2398\n",
      "Epoch 28/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2343 - val_loss: 0.2396\n",
      "Epoch 29/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2340 - val_loss: 0.2393\n",
      "Epoch 30/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2337 - val_loss: 0.2392\n",
      "Epoch 31/50\n",
      "430/430 [==============================] - 12s 28ms/step - loss: 0.2334 - val_loss: 0.2390\n",
      "Epoch 32/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2331 - val_loss: 0.2388\n",
      "Epoch 33/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2329 - val_loss: 0.2387\n",
      "Epoch 34/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2326 - val_loss: 0.2384\n",
      "Epoch 35/50\n",
      "430/430 [==============================] - 14s 32ms/step - loss: 0.2324 - val_loss: 0.2383\n",
      "Epoch 36/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2322 - val_loss: 0.2383\n",
      "Epoch 37/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2319 - val_loss: 0.2381\n",
      "Epoch 38/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2317 - val_loss: 0.2379\n",
      "Epoch 39/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2315 - val_loss: 0.2379\n",
      "Epoch 40/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2313 - val_loss: 0.2377\n",
      "Epoch 41/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2311 - val_loss: 0.2376\n",
      "Epoch 42/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2309 - val_loss: 0.2374\n",
      "Epoch 43/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2307 - val_loss: 0.2374\n",
      "Epoch 44/50\n",
      "430/430 [==============================] - 14s 32ms/step - loss: 0.2306 - val_loss: 0.2373\n",
      "Epoch 45/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2304 - val_loss: 0.2372\n",
      "Epoch 46/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2302 - val_loss: 0.2371\n",
      "Epoch 47/50\n",
      "430/430 [==============================] - 13s 31ms/step - loss: 0.2300 - val_loss: 0.2370\n",
      "Epoch 48/50\n",
      "430/430 [==============================] - 13s 29ms/step - loss: 0.2299 - val_loss: 0.2369\n",
      "Epoch 49/50\n",
      "430/430 [==============================] - 12s 29ms/step - loss: 0.2297 - val_loss: 0.2368\n",
      "Epoch 50/50\n",
      "430/430 [==============================] - 13s 30ms/step - loss: 0.2296 - val_loss: 0.2367\n",
      "In calc_results: 27502, 9168, 9167, sum = 45837\n",
      "In split_to_train_test: dataset_X.shape=(2955, 10, 65), dataset_y.shape=(2955, 65)\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3296 - val_loss: 0.7255\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3227 - val_loss: 0.7193\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3171 - val_loss: 0.7138\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3124 - val_loss: 0.7088\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3083 - val_loss: 0.7043\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3046 - val_loss: 0.7001\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3012 - val_loss: 0.6959\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.2982 - val_loss: 0.6921\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2954 - val_loss: 0.6885\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2928 - val_loss: 0.6851\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2905 - val_loss: 0.6820\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2882 - val_loss: 0.6790\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2861 - val_loss: 0.6762\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2841 - val_loss: 0.6734\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2822 - val_loss: 0.6708\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2804 - val_loss: 0.6682\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2787 - val_loss: 0.6657\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2771 - val_loss: 0.6633\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2755 - val_loss: 0.6610\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2740 - val_loss: 0.6588\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2726 - val_loss: 0.6566\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2712 - val_loss: 0.6545\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2699 - val_loss: 0.6525\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.2687 - val_loss: 0.6505\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2675 - val_loss: 0.6487\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2664 - val_loss: 0.6467\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2653 - val_loss: 0.6450\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2643 - val_loss: 0.6431\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2633 - val_loss: 0.6414\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2624 - val_loss: 0.6397\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2615 - val_loss: 0.6382\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2606 - val_loss: 0.6365\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2597 - val_loss: 0.6350\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2589 - val_loss: 0.6335\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2581 - val_loss: 0.6321\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2574 - val_loss: 0.6306\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2566 - val_loss: 0.6293\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2559 - val_loss: 0.6279\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2552 - val_loss: 0.6265\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2545 - val_loss: 0.6253\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2538 - val_loss: 0.6240\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2532 - val_loss: 0.6226\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2525 - val_loss: 0.6214\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2519 - val_loss: 0.6202\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2513 - val_loss: 0.6190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.2508 - val_loss: 0.6178\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2502 - val_loss: 0.6166\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.2497 - val_loss: 0.6155\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2491 - val_loss: 0.6143\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2486 - val_loss: 0.6132\n",
      "In calc_results: 1773, 591, 591, sum = 2955\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=5151, 5151\n",
      "IN Clustering.split_to_clusters: mask.sum()=2870, 2870\n",
      "IN Clustering.split_to_clusters: mask.sum()=2040, 2040\n",
      "IN Clustering.split_to_clusters: mask.sum()=2074, 2074\n",
      "IN Clustering.split_to_clusters: mask.sum()=42267, 42267\n",
      "In split_to_train_test: dataset_X.shape=(5151, 10, 65), dataset_y.shape=(5151, 65)\n",
      "Epoch 1/50\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.2264 - val_loss: 0.3302\n",
      "Epoch 2/50\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.2218 - val_loss: 0.3264\n",
      "Epoch 3/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2184 - val_loss: 0.3235\n",
      "Epoch 4/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2156 - val_loss: 0.3211\n",
      "Epoch 5/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2133 - val_loss: 0.3190\n",
      "Epoch 6/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2114 - val_loss: 0.3172\n",
      "Epoch 7/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2097 - val_loss: 0.3157\n",
      "Epoch 8/50\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.2081 - val_loss: 0.3143\n",
      "Epoch 9/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2068 - val_loss: 0.3131\n",
      "Epoch 10/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.2056 - val_loss: 0.3120\n",
      "Epoch 11/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2044 - val_loss: 0.3110\n",
      "Epoch 12/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2033 - val_loss: 0.3101\n",
      "Epoch 13/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2023 - val_loss: 0.3093\n",
      "Epoch 14/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2014 - val_loss: 0.3085\n",
      "Epoch 15/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.2005 - val_loss: 0.3078\n",
      "Epoch 16/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1996 - val_loss: 0.3072\n",
      "Epoch 17/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1988 - val_loss: 0.3066\n",
      "Epoch 18/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1980 - val_loss: 0.3060\n",
      "Epoch 19/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1972 - val_loss: 0.3055\n",
      "Epoch 20/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1964 - val_loss: 0.3050\n",
      "Epoch 21/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1957 - val_loss: 0.3046\n",
      "Epoch 22/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1950 - val_loss: 0.3042\n",
      "Epoch 23/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1942 - val_loss: 0.3039\n",
      "Epoch 24/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1935 - val_loss: 0.3035\n",
      "Epoch 25/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1928 - val_loss: 0.3032\n",
      "Epoch 26/50\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.1922 - val_loss: 0.3029\n",
      "Epoch 27/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1915 - val_loss: 0.3027\n",
      "Epoch 28/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1908 - val_loss: 0.3024\n",
      "Epoch 29/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1902 - val_loss: 0.3021\n",
      "Epoch 30/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1895 - val_loss: 0.3019\n",
      "Epoch 31/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1889 - val_loss: 0.3017\n",
      "Epoch 32/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1882 - val_loss: 0.3015\n",
      "Epoch 33/50\n",
      "49/49 [==============================] - 2s 31ms/step - loss: 0.1876 - val_loss: 0.3013\n",
      "Epoch 34/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1870 - val_loss: 0.3011\n",
      "Epoch 35/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1864 - val_loss: 0.3010\n",
      "Epoch 36/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1858 - val_loss: 0.3008\n",
      "Epoch 37/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1852 - val_loss: 0.3006\n",
      "Epoch 38/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1847 - val_loss: 0.3004\n",
      "Epoch 39/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1841 - val_loss: 0.3003\n",
      "Epoch 40/50\n",
      "49/49 [==============================] - 1s 30ms/step - loss: 0.1836 - val_loss: 0.3002\n",
      "Epoch 41/50\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 0.1830 - val_loss: 0.3000\n",
      "Epoch 42/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1825 - val_loss: 0.2999\n",
      "Epoch 43/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1820 - val_loss: 0.2998\n",
      "Epoch 44/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1815 - val_loss: 0.2996\n",
      "Epoch 45/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1811 - val_loss: 0.2995\n",
      "Epoch 46/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1806 - val_loss: 0.2994\n",
      "Epoch 47/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1801 - val_loss: 0.2993\n",
      "Epoch 48/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1797 - val_loss: 0.2992\n",
      "Epoch 49/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1792 - val_loss: 0.2991\n",
      "Epoch 50/50\n",
      "49/49 [==============================] - 1s 29ms/step - loss: 0.1788 - val_loss: 0.2989\n",
      "In calc_results: 3091, 1030, 1030, sum = 5151\n",
      "In split_to_train_test: dataset_X.shape=(2870, 10, 65), dataset_y.shape=(2870, 65)\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.3091 - val_loss: 0.5984\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.3008 - val_loss: 0.5922\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2940 - val_loss: 0.5865\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2882 - val_loss: 0.5814\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2832 - val_loss: 0.5770\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2789 - val_loss: 0.5728\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2751 - val_loss: 0.5691\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2718 - val_loss: 0.5655\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2687 - val_loss: 0.5623\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2659 - val_loss: 0.5593\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2634 - val_loss: 0.5564\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2610 - val_loss: 0.5538\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2588 - val_loss: 0.5512\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2567 - val_loss: 0.5487\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2548 - val_loss: 0.5464\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2530 - val_loss: 0.5440\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2512 - val_loss: 0.5418\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2496 - val_loss: 0.5396\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2480 - val_loss: 0.5375\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2466 - val_loss: 0.5355\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2452 - val_loss: 0.5334\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2439 - val_loss: 0.5315\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2426 - val_loss: 0.5297\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2415 - val_loss: 0.5279\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2404 - val_loss: 0.5262\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2393 - val_loss: 0.5245\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2383 - val_loss: 0.5229\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2373 - val_loss: 0.5212\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2364 - val_loss: 0.5197\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2355 - val_loss: 0.5182\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2347 - val_loss: 0.5168\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2339 - val_loss: 0.5154\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2331 - val_loss: 0.5141\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2324 - val_loss: 0.5126\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2316 - val_loss: 0.5114\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2309 - val_loss: 0.5100\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2303 - val_loss: 0.5087\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2296 - val_loss: 0.5074\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2290 - val_loss: 0.5062\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2284 - val_loss: 0.5050\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2277 - val_loss: 0.5038\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2272 - val_loss: 0.5026\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2266 - val_loss: 0.5015\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2260 - val_loss: 0.5003\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2254 - val_loss: 0.4991\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2249 - val_loss: 0.4980\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2243 - val_loss: 0.4970\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2238 - val_loss: 0.4960\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2233 - val_loss: 0.4949\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2228 - val_loss: 0.4938\n",
      "In calc_results: 1722, 574, 574, sum = 2870\n",
      "In split_to_train_test: dataset_X.shape=(2040, 10, 65), dataset_y.shape=(2040, 65)\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7891 - val_loss: 0.7094\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7839 - val_loss: 0.7056\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7795 - val_loss: 0.7021\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7754 - val_loss: 0.6991\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7717 - val_loss: 0.6962\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7682 - val_loss: 0.6936\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7650 - val_loss: 0.6913\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7621 - val_loss: 0.6890\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7592 - val_loss: 0.6869\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7566 - val_loss: 0.6849\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7540 - val_loss: 0.6830\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7517 - val_loss: 0.6812\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7494 - val_loss: 0.6794\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7473 - val_loss: 0.6778\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.7452 - val_loss: 0.6762\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7432 - val_loss: 0.6745\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7412 - val_loss: 0.6730\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.7394 - val_loss: 0.6714\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7376 - val_loss: 0.6699\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7359 - val_loss: 0.6686\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7342 - val_loss: 0.6673\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7326 - val_loss: 0.6660\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7311 - val_loss: 0.6648\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7296 - val_loss: 0.6636\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7281 - val_loss: 0.6624\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7267 - val_loss: 0.6613\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7254 - val_loss: 0.6603\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7241 - val_loss: 0.6593\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7228 - val_loss: 0.6583\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7216 - val_loss: 0.6574\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7205 - val_loss: 0.6565\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7193 - val_loss: 0.6556\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7182 - val_loss: 0.6547\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7170 - val_loss: 0.6539\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7159 - val_loss: 0.6530\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7149 - val_loss: 0.6522\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.7139 - val_loss: 0.6515\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.7128 - val_loss: 0.6507\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.7118 - val_loss: 0.6500\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7109 - val_loss: 0.6493\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7099 - val_loss: 0.6486\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7089 - val_loss: 0.6479\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7080 - val_loss: 0.6472\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.7071 - val_loss: 0.6466\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7063 - val_loss: 0.6460\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7055 - val_loss: 0.6453\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.7046 - val_loss: 0.6447\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.7038 - val_loss: 0.6441\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7029 - val_loss: 0.6435\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.7021 - val_loss: 0.6429\n",
      "In calc_results: 1224, 408, 408, sum = 2040\n",
      "In split_to_train_test: dataset_X.shape=(2074, 10, 65), dataset_y.shape=(2074, 65)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2493 - val_loss: 0.2422\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2454 - val_loss: 0.2401\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2420 - val_loss: 0.2383\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2390 - val_loss: 0.2366\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2365 - val_loss: 0.2351\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2342 - val_loss: 0.2337\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2322 - val_loss: 0.2325\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2303 - val_loss: 0.2313\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2286 - val_loss: 0.2303\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2271 - val_loss: 0.2293\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2256 - val_loss: 0.2284\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2243 - val_loss: 0.2277\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2231 - val_loss: 0.2269\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2220 - val_loss: 0.2262\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2209 - val_loss: 0.2256\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2199 - val_loss: 0.2250\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2190 - val_loss: 0.2244\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2181 - val_loss: 0.2239\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2172 - val_loss: 0.2233\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2165 - val_loss: 0.2229\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2157 - val_loss: 0.2224\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2150 - val_loss: 0.2220\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2143 - val_loss: 0.2215\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2136 - val_loss: 0.2211\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2130 - val_loss: 0.2207\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2124 - val_loss: 0.2204\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2118 - val_loss: 0.2200\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2112 - val_loss: 0.2196\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2107 - val_loss: 0.2193\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2101 - val_loss: 0.2189\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2096 - val_loss: 0.2186\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2091 - val_loss: 0.2183\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2086 - val_loss: 0.2180\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2081 - val_loss: 0.2177\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2076 - val_loss: 0.2173\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2071 - val_loss: 0.2170\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2067 - val_loss: 0.2168\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2063 - val_loss: 0.2165\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.2058 - val_loss: 0.2162\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2054 - val_loss: 0.2159\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2050 - val_loss: 0.2156\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2045 - val_loss: 0.2153\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2042 - val_loss: 0.2150\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2037 - val_loss: 0.2147\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2033 - val_loss: 0.2145\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2029 - val_loss: 0.2142\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.2025 - val_loss: 0.2139\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.2022 - val_loss: 0.2137\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.2018 - val_loss: 0.2135\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.2014 - val_loss: 0.2132\n",
      "In calc_results: 1244, 415, 415, sum = 2074\n",
      "In split_to_train_test: dataset_X.shape=(42267, 10, 65), dataset_y.shape=(42267, 65)\n",
      "Epoch 1/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2614 - val_loss: 0.2421\n",
      "Epoch 2/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2484 - val_loss: 0.2362\n",
      "Epoch 3/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2427 - val_loss: 0.2329\n",
      "Epoch 4/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2392 - val_loss: 0.2306\n",
      "Epoch 5/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2365 - val_loss: 0.2286\n",
      "Epoch 6/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2343 - val_loss: 0.2269\n",
      "Epoch 7/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2323 - val_loss: 0.2253\n",
      "Epoch 8/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2304 - val_loss: 0.2238\n",
      "Epoch 9/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2285 - val_loss: 0.2225\n",
      "Epoch 10/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2268 - val_loss: 0.2212\n",
      "Epoch 11/50\n",
      "397/397 [==============================] - 11s 28ms/step - loss: 0.2252 - val_loss: 0.2201\n",
      "Epoch 12/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2237 - val_loss: 0.2191\n",
      "Epoch 13/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2223 - val_loss: 0.2182\n",
      "Epoch 14/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2210 - val_loss: 0.2174\n",
      "Epoch 15/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2199 - val_loss: 0.2168\n",
      "Epoch 16/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2190 - val_loss: 0.2163\n",
      "Epoch 17/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2182 - val_loss: 0.2159\n",
      "Epoch 18/50\n",
      "397/397 [==============================] - 11s 29ms/step - loss: 0.2175 - val_loss: 0.2154\n",
      "Epoch 19/50\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2170 - val_loss: 0.2151\n",
      "Epoch 20/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2164 - val_loss: 0.2147\n",
      "Epoch 21/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2159 - val_loss: 0.2145\n",
      "Epoch 22/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2155 - val_loss: 0.2142\n",
      "Epoch 23/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2151 - val_loss: 0.2139\n",
      "Epoch 24/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2147 - val_loss: 0.2137\n",
      "Epoch 25/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2143 - val_loss: 0.2135\n",
      "Epoch 26/50\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2140 - val_loss: 0.2132\n",
      "Epoch 27/50\n",
      "397/397 [==============================] - 12s 29ms/step - loss: 0.2136 - val_loss: 0.2130\n",
      "Epoch 28/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2133 - val_loss: 0.2129\n",
      "Epoch 29/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2130 - val_loss: 0.2128\n",
      "Epoch 30/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2128 - val_loss: 0.2126\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2125 - val_loss: 0.2125\n",
      "Epoch 32/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2123 - val_loss: 0.2123\n",
      "Epoch 33/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2120 - val_loss: 0.2122\n",
      "Epoch 34/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2118 - val_loss: 0.2121\n",
      "Epoch 35/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2116 - val_loss: 0.2119\n",
      "Epoch 36/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2114 - val_loss: 0.2119\n",
      "Epoch 37/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2112 - val_loss: 0.2117\n",
      "Epoch 38/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2110 - val_loss: 0.2115\n",
      "Epoch 39/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2108 - val_loss: 0.2115\n",
      "Epoch 40/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2107 - val_loss: 0.2115\n",
      "Epoch 41/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2105 - val_loss: 0.2113\n",
      "Epoch 42/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2103 - val_loss: 0.2113\n",
      "Epoch 43/50\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2102 - val_loss: 0.2112\n",
      "Epoch 44/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2100 - val_loss: 0.2111\n",
      "Epoch 45/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2099 - val_loss: 0.2109\n",
      "Epoch 46/50\n",
      "397/397 [==============================] - 13s 32ms/step - loss: 0.2097 - val_loss: 0.2108\n",
      "Epoch 47/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2096 - val_loss: 0.2109\n",
      "Epoch 48/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2094 - val_loss: 0.2107\n",
      "Epoch 49/50\n",
      "397/397 [==============================] - 12s 31ms/step - loss: 0.2093 - val_loss: 0.2105\n",
      "Epoch 50/50\n",
      "397/397 [==============================] - 12s 30ms/step - loss: 0.2092 - val_loss: 0.2105\n",
      "In calc_results: 25360, 8454, 8453, sum = 42267\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=2866, 2866\n",
      "IN Clustering.split_to_clusters: mask.sum()=1821, 1821\n",
      "IN Clustering.split_to_clusters: mask.sum()=15161, 15161\n",
      "IN Clustering.split_to_clusters: mask.sum()=23797, 23797\n",
      "IN Clustering.split_to_clusters: mask.sum()=1213, 1213\n",
      "IN Clustering.split_to_clusters: mask.sum()=4060, 4060\n",
      "IN Clustering.split_to_clusters: mask.sum()=5484, 5484\n",
      "In split_to_train_test: dataset_X.shape=(2866, 10, 65), dataset_y.shape=(2866, 65)\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.3030 - val_loss: 0.5871\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2955 - val_loss: 0.5812\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2893 - val_loss: 0.5760\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2841 - val_loss: 0.5712\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2795 - val_loss: 0.5669\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2755 - val_loss: 0.5631\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2719 - val_loss: 0.5597\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2688 - val_loss: 0.5565\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2658 - val_loss: 0.5535\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2632 - val_loss: 0.5506\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2608 - val_loss: 0.5480\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2585 - val_loss: 0.5457\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 0.2564 - val_loss: 0.5433\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2544 - val_loss: 0.5412\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2526 - val_loss: 0.5390\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2508 - val_loss: 0.5370\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2492 - val_loss: 0.5349\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2477 - val_loss: 0.5330\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2462 - val_loss: 0.5311\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2449 - val_loss: 0.5293\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2436 - val_loss: 0.5275\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2424 - val_loss: 0.5257\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2412 - val_loss: 0.5241\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2402 - val_loss: 0.5225\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2391 - val_loss: 0.5211\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2381 - val_loss: 0.5195\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2372 - val_loss: 0.5181\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2362 - val_loss: 0.5166\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2353 - val_loss: 0.5152\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.2345 - val_loss: 0.5138\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2337 - val_loss: 0.5125\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2328 - val_loss: 0.5112\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2321 - val_loss: 0.5100\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2313 - val_loss: 0.5087\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2306 - val_loss: 0.5074\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2299 - val_loss: 0.5062\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.2292 - val_loss: 0.5051\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.2285 - val_loss: 0.5039\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2279 - val_loss: 0.5027\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2272 - val_loss: 0.5016\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2266 - val_loss: 0.5006\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2260 - val_loss: 0.4994\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2254 - val_loss: 0.4984\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2248 - val_loss: 0.4973\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2243 - val_loss: 0.4963\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2237 - val_loss: 0.4953\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2232 - val_loss: 0.4943\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2227 - val_loss: 0.4933\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2222 - val_loss: 0.4924\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2217 - val_loss: 0.4915\n",
      "In calc_results: 1720, 573, 573, sum = 2866\n",
      "In split_to_train_test: dataset_X.shape=(1821, 10, 65), dataset_y.shape=(1821, 65)\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.2546 - val_loss: 0.2383\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2504 - val_loss: 0.2365\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2469 - val_loss: 0.2350\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2440 - val_loss: 0.2336\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2416 - val_loss: 0.2325\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2393 - val_loss: 0.2315\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2373 - val_loss: 0.2305\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2355 - val_loss: 0.2296\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2339 - val_loss: 0.2288\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2324 - val_loss: 0.2281\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2310 - val_loss: 0.2274\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2298 - val_loss: 0.2269\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.2286 - val_loss: 0.2263\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2275 - val_loss: 0.2258\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2265 - val_loss: 0.2253\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2255 - val_loss: 0.2248\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.2246 - val_loss: 0.2243\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2237 - val_loss: 0.2239\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2229 - val_loss: 0.2235\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2221 - val_loss: 0.2230\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2213 - val_loss: 0.2226\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2206 - val_loss: 0.2222\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2199 - val_loss: 0.2219\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2192 - val_loss: 0.2215\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2186 - val_loss: 0.2211\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2180 - val_loss: 0.2208\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.2174 - val_loss: 0.2204\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2168 - val_loss: 0.2201\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2163 - val_loss: 0.2198\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.2158 - val_loss: 0.2194\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2152 - val_loss: 0.2191\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2147 - val_loss: 0.2188\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2143 - val_loss: 0.2185\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2138 - val_loss: 0.2183\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2133 - val_loss: 0.2180\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2128 - val_loss: 0.2177\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2124 - val_loss: 0.2175\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2120 - val_loss: 0.2172\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2115 - val_loss: 0.2169\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2111 - val_loss: 0.2167\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2107 - val_loss: 0.2164\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.2103 - val_loss: 0.2162\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2099 - val_loss: 0.2160\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2095 - val_loss: 0.2157\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2091 - val_loss: 0.2155\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2088 - val_loss: 0.2153\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2084 - val_loss: 0.2151\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2080 - val_loss: 0.2148\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.2077 - val_loss: 0.2146\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.2073 - val_loss: 0.2144\n",
      "In calc_results: 1093, 364, 364, sum = 1821\n",
      "In split_to_train_test: dataset_X.shape=(15161, 10, 65), dataset_y.shape=(15161, 65)\n",
      "Epoch 1/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2481 - val_loss: 0.2642\n",
      "Epoch 2/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2388 - val_loss: 0.2582\n",
      "Epoch 3/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2332 - val_loss: 0.2543\n",
      "Epoch 4/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2294 - val_loss: 0.2515\n",
      "Epoch 5/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2266 - val_loss: 0.2494\n",
      "Epoch 6/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2245 - val_loss: 0.2477\n",
      "Epoch 7/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2227 - val_loss: 0.2464\n",
      "Epoch 8/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2212 - val_loss: 0.2452\n",
      "Epoch 9/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2199 - val_loss: 0.2442\n",
      "Epoch 10/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2188 - val_loss: 0.2433\n",
      "Epoch 11/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2178 - val_loss: 0.2424\n",
      "Epoch 12/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2168 - val_loss: 0.2417\n",
      "Epoch 13/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2160 - val_loss: 0.2410\n",
      "Epoch 14/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2152 - val_loss: 0.2403\n",
      "Epoch 15/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2144 - val_loss: 0.2397\n",
      "Epoch 16/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2136 - val_loss: 0.2391\n",
      "Epoch 17/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2129 - val_loss: 0.2385\n",
      "Epoch 18/50\n",
      "143/143 [==============================] - 4s 31ms/step - loss: 0.2122 - val_loss: 0.2379\n",
      "Epoch 19/50\n",
      "143/143 [==============================] - 4s 31ms/step - loss: 0.2116 - val_loss: 0.2374\n",
      "Epoch 20/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2109 - val_loss: 0.2368\n",
      "Epoch 21/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2103 - val_loss: 0.2363\n",
      "Epoch 22/50\n",
      "143/143 [==============================] - 4s 31ms/step - loss: 0.2097 - val_loss: 0.2358\n",
      "Epoch 23/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2091 - val_loss: 0.2353\n",
      "Epoch 24/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2085 - val_loss: 0.2349\n",
      "Epoch 25/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2079 - val_loss: 0.2344\n",
      "Epoch 26/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2074 - val_loss: 0.2340\n",
      "Epoch 27/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2069 - val_loss: 0.2336\n",
      "Epoch 28/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2064 - val_loss: 0.2332\n",
      "Epoch 29/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2059 - val_loss: 0.2328\n",
      "Epoch 30/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2054 - val_loss: 0.2324\n",
      "Epoch 31/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2049 - val_loss: 0.2321\n",
      "Epoch 32/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2045 - val_loss: 0.2317\n",
      "Epoch 33/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2041 - val_loss: 0.2314\n",
      "Epoch 34/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2037 - val_loss: 0.2311\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2033 - val_loss: 0.2309\n",
      "Epoch 36/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2029 - val_loss: 0.2305\n",
      "Epoch 37/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2025 - val_loss: 0.2303\n",
      "Epoch 38/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2022 - val_loss: 0.2300\n",
      "Epoch 39/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2018 - val_loss: 0.2298\n",
      "Epoch 40/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2015 - val_loss: 0.2295\n",
      "Epoch 41/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.2011 - val_loss: 0.2293\n",
      "Epoch 42/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2008 - val_loss: 0.2291\n",
      "Epoch 43/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2005 - val_loss: 0.2289\n",
      "Epoch 44/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.2002 - val_loss: 0.2286\n",
      "Epoch 45/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.1999 - val_loss: 0.2284\n",
      "Epoch 46/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.1996 - val_loss: 0.2282\n",
      "Epoch 47/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.1994 - val_loss: 0.2280\n",
      "Epoch 48/50\n",
      "143/143 [==============================] - 4s 30ms/step - loss: 0.1991 - val_loss: 0.2278\n",
      "Epoch 49/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.1988 - val_loss: 0.2277\n",
      "Epoch 50/50\n",
      "143/143 [==============================] - 4s 29ms/step - loss: 0.1986 - val_loss: 0.2275\n",
      "In calc_results: 9097, 3032, 3032, sum = 15161\n",
      "In split_to_train_test: dataset_X.shape=(23797, 10, 65), dataset_y.shape=(23797, 65)\n",
      "Epoch 1/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2593 - val_loss: 0.2470\n",
      "Epoch 2/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2487 - val_loss: 0.2415\n",
      "Epoch 3/50\n",
      "224/224 [==============================] - 6s 29ms/step - loss: 0.2432 - val_loss: 0.2382\n",
      "Epoch 4/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2397 - val_loss: 0.2359\n",
      "Epoch 5/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2371 - val_loss: 0.2342\n",
      "Epoch 6/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2351 - val_loss: 0.2328\n",
      "Epoch 7/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2334 - val_loss: 0.2315\n",
      "Epoch 8/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2319 - val_loss: 0.2304\n",
      "Epoch 9/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2305 - val_loss: 0.2293\n",
      "Epoch 10/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2292 - val_loss: 0.2283\n",
      "Epoch 11/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2279 - val_loss: 0.2274\n",
      "Epoch 12/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2267 - val_loss: 0.2264\n",
      "Epoch 13/50\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.2255 - val_loss: 0.2255\n",
      "Epoch 14/50\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.2243 - val_loss: 0.2247\n",
      "Epoch 15/50\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.2232 - val_loss: 0.2238\n",
      "Epoch 16/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2220 - val_loss: 0.2230\n",
      "Epoch 17/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2208 - val_loss: 0.2223\n",
      "Epoch 18/50\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.2197 - val_loss: 0.2216\n",
      "Epoch 19/50\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.2186 - val_loss: 0.2210\n",
      "Epoch 20/50\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.2176 - val_loss: 0.2204\n",
      "Epoch 21/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2166 - val_loss: 0.2199\n",
      "Epoch 22/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2156 - val_loss: 0.2194\n",
      "Epoch 23/50\n",
      "224/224 [==============================] - 7s 32ms/step - loss: 0.2147 - val_loss: 0.2190\n",
      "Epoch 24/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2138 - val_loss: 0.2185\n",
      "Epoch 25/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2129 - val_loss: 0.2181\n",
      "Epoch 26/50\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.2122 - val_loss: 0.2177\n",
      "Epoch 27/50\n",
      "224/224 [==============================] - 6s 29ms/step - loss: 0.2115 - val_loss: 0.2172\n",
      "Epoch 28/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2109 - val_loss: 0.2170\n",
      "Epoch 29/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2103 - val_loss: 0.2166\n",
      "Epoch 30/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2099 - val_loss: 0.2163\n",
      "Epoch 31/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2094 - val_loss: 0.2160\n",
      "Epoch 32/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2090 - val_loss: 0.2157\n",
      "Epoch 33/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2087 - val_loss: 0.2155\n",
      "Epoch 34/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2083 - val_loss: 0.2153\n",
      "Epoch 35/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2080 - val_loss: 0.2150\n",
      "Epoch 36/50\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.2077 - val_loss: 0.2149\n",
      "Epoch 37/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2074 - val_loss: 0.2147\n",
      "Epoch 38/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2072 - val_loss: 0.2145\n",
      "Epoch 39/50\n",
      "224/224 [==============================] - 7s 29ms/step - loss: 0.2069 - val_loss: 0.2144\n",
      "Epoch 40/50\n",
      "224/224 [==============================] - 6s 29ms/step - loss: 0.2067 - val_loss: 0.2142\n",
      "Epoch 41/50\n",
      "224/224 [==============================] - 6s 28ms/step - loss: 0.2064 - val_loss: 0.2141\n",
      "Epoch 42/50\n",
      "224/224 [==============================] - 6s 28ms/step - loss: 0.2062 - val_loss: 0.2139\n",
      "Epoch 43/50\n",
      "224/224 [==============================] - 6s 28ms/step - loss: 0.2060 - val_loss: 0.2138\n",
      "Epoch 44/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2058 - val_loss: 0.2136\n",
      "Epoch 45/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2056 - val_loss: 0.2135\n",
      "Epoch 46/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2054 - val_loss: 0.2134\n",
      "Epoch 47/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2052 - val_loss: 0.2133\n",
      "Epoch 48/50\n",
      "224/224 [==============================] - 7s 31ms/step - loss: 0.2051 - val_loss: 0.2132\n",
      "Epoch 49/50\n",
      "224/224 [==============================] - 7s 30ms/step - loss: 0.2049 - val_loss: 0.2131\n",
      "Epoch 50/50\n",
      "224/224 [==============================] - 6s 29ms/step - loss: 0.2047 - val_loss: 0.2130\n",
      "In calc_results: 14278, 4760, 4759, sum = 23797\n",
      "In split_to_train_test: dataset_X.shape=(1213, 10, 65), dataset_y.shape=(1213, 65)\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.0074 - val_loss: 0.4664\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0022 - val_loss: 0.4640\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9974 - val_loss: 0.4618\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9930 - val_loss: 0.4597\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9889 - val_loss: 0.4577\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.9850 - val_loss: 0.4559\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9814 - val_loss: 0.4542\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9780 - val_loss: 0.4526\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.9747 - val_loss: 0.4510\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.9717 - val_loss: 0.4495\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.9688 - val_loss: 0.4481\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.9661 - val_loss: 0.4467\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9635 - val_loss: 0.4453\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9610 - val_loss: 0.4441\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.9586 - val_loss: 0.4428\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.9563 - val_loss: 0.4416\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9541 - val_loss: 0.4404\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9520 - val_loss: 0.4393\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9499 - val_loss: 0.4382\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.9479 - val_loss: 0.4371\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9460 - val_loss: 0.4361\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9441 - val_loss: 0.4351\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.9423 - val_loss: 0.4342\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9405 - val_loss: 0.4332\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9387 - val_loss: 0.4323\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9371 - val_loss: 0.4314\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9354 - val_loss: 0.4306\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9338 - val_loss: 0.4298\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9323 - val_loss: 0.4290\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9307 - val_loss: 0.4282\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9292 - val_loss: 0.4274\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9277 - val_loss: 0.4267\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9262 - val_loss: 0.4260\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9247 - val_loss: 0.4253\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9233 - val_loss: 0.4246\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9219 - val_loss: 0.4240\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9205 - val_loss: 0.4233\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9192 - val_loss: 0.4227\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9178 - val_loss: 0.4221\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9165 - val_loss: 0.4215\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9152 - val_loss: 0.4209\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9139 - val_loss: 0.4204\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9127 - val_loss: 0.4199\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9115 - val_loss: 0.4193\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9103 - val_loss: 0.4188\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.9091 - val_loss: 0.4184\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9079 - val_loss: 0.4179\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.9068 - val_loss: 0.4174\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.9057 - val_loss: 0.4169\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9046 - val_loss: 0.4164\n",
      "In calc_results: 728, 242, 243, sum = 1213\n",
      "In split_to_train_test: dataset_X.shape=(4060, 10, 65), dataset_y.shape=(4060, 65)\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2124 - val_loss: 0.3042\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.2082 - val_loss: 0.3014\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.2050 - val_loss: 0.2991\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.2024 - val_loss: 0.2972\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.2002 - val_loss: 0.2955\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1982 - val_loss: 0.2940\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1965 - val_loss: 0.2927\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1950 - val_loss: 0.2915\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1936 - val_loss: 0.2905\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1924 - val_loss: 0.2895\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1913 - val_loss: 0.2886\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1903 - val_loss: 0.2878\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1894 - val_loss: 0.2871\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1885 - val_loss: 0.2864\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1876 - val_loss: 0.2857\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1868 - val_loss: 0.2851\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1861 - val_loss: 0.2844\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1853 - val_loss: 0.2839\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 1s 34ms/step - loss: 0.1846 - val_loss: 0.2834\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1840 - val_loss: 0.2829\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.1833 - val_loss: 0.2824\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.1827 - val_loss: 0.2820\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1820 - val_loss: 0.2815\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1814 - val_loss: 0.2811\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1808 - val_loss: 0.2807\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1801 - val_loss: 0.2803\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1796 - val_loss: 0.2799\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1790 - val_loss: 0.2795\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1784 - val_loss: 0.2792\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1778 - val_loss: 0.2788\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1772 - val_loss: 0.2785\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1766 - val_loss: 0.2781\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1760 - val_loss: 0.2778\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1755 - val_loss: 0.2774\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1749 - val_loss: 0.2771\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1743 - val_loss: 0.2768\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1737 - val_loss: 0.2764\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1732 - val_loss: 0.2762\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1726 - val_loss: 0.2759\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1721 - val_loss: 0.2756\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1715 - val_loss: 0.2753\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1710 - val_loss: 0.2750\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1704 - val_loss: 0.2747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1699 - val_loss: 0.2744\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1694 - val_loss: 0.2742\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1689 - val_loss: 0.2739\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 1s 31ms/step - loss: 0.1684 - val_loss: 0.2736\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 1s 29ms/step - loss: 0.1679 - val_loss: 0.2734\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1674 - val_loss: 0.2732\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 1s 30ms/step - loss: 0.1670 - val_loss: 0.2729\n",
      "In calc_results: 2436, 812, 812, sum = 4060\n",
      "In split_to_train_test: dataset_X.shape=(5484, 10, 65), dataset_y.shape=(5484, 65)\n",
      "Epoch 1/50\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.3498 - val_loss: 0.4150\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 2s 34ms/step - loss: 0.3437 - val_loss: 0.4103\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3392 - val_loss: 0.4068\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3356 - val_loss: 0.4039\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3327 - val_loss: 0.4014\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.3302 - val_loss: 0.3994\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.3280 - val_loss: 0.3975\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.3260 - val_loss: 0.3959\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.3242 - val_loss: 0.3944\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.3227 - val_loss: 0.3930\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 2s 36ms/step - loss: 0.3212 - val_loss: 0.3918\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 2s 33ms/step - loss: 0.3199 - val_loss: 0.3907\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3187 - val_loss: 0.3896\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3177 - val_loss: 0.3887\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3166 - val_loss: 0.3879\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.3157 - val_loss: 0.3871\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3148 - val_loss: 0.3863\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3140 - val_loss: 0.3856\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3133 - val_loss: 0.3850\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3125 - val_loss: 0.3844\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3119 - val_loss: 0.3839\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3112 - val_loss: 0.3834\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3106 - val_loss: 0.3829\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3100 - val_loss: 0.3825\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3094 - val_loss: 0.3820\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.3089 - val_loss: 0.3816\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3084 - val_loss: 0.3812\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3079 - val_loss: 0.3808\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.3074 - val_loss: 0.3805\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3069 - val_loss: 0.3801\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3064 - val_loss: 0.3798\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.3059 - val_loss: 0.3795\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3055 - val_loss: 0.3792\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.3051 - val_loss: 0.3789\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3046 - val_loss: 0.3786\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3042 - val_loss: 0.3783\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3038 - val_loss: 0.3780\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3034 - val_loss: 0.3778\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3030 - val_loss: 0.3775\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 2s 31ms/step - loss: 0.3026 - val_loss: 0.3773\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.3022 - val_loss: 0.3770\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3018 - val_loss: 0.3768\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3015 - val_loss: 0.3766\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 2s 32ms/step - loss: 0.3011 - val_loss: 0.3763\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3007 - val_loss: 0.3761\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.3004 - val_loss: 0.3760\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.3000 - val_loss: 0.3758\n",
      "Epoch 48/50\n",
      "52/52 [==============================] - 2s 30ms/step - loss: 0.2997 - val_loss: 0.3756\n",
      "Epoch 49/50\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.2993 - val_loss: 0.3754\n",
      "Epoch 50/50\n",
      "52/52 [==============================] - 2s 29ms/step - loss: 0.2990 - val_loss: 0.3752\n",
      "In calc_results: 3290, 1097, 1097, sum = 5484\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=44884, 44884\n",
      "IN Clustering.split_to_clusters: mask.sum()=2459, 2459\n",
      "IN Clustering.split_to_clusters: mask.sum()=7059, 7059\n",
      "In split_to_train_test: dataset_X.shape=(44884, 10, 65), dataset_y.shape=(44884, 65)\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2855 - val_loss: 0.2732\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2712 - val_loss: 0.2667\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2651 - val_loss: 0.2632\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2615 - val_loss: 0.2608\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2589 - val_loss: 0.2589\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2567 - val_loss: 0.2573\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2548 - val_loss: 0.2558\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 14s 33ms/step - loss: 0.2531 - val_loss: 0.2545\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2515 - val_loss: 0.2533\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2499 - val_loss: 0.2522\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2485 - val_loss: 0.2511\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2472 - val_loss: 0.2502\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2459 - val_loss: 0.2493\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 12s 30ms/step - loss: 0.2448 - val_loss: 0.2485\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2437 - val_loss: 0.2478\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2427 - val_loss: 0.2472\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 13s 32ms/step - loss: 0.2418 - val_loss: 0.2466\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2409 - val_loss: 0.2461\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2401 - val_loss: 0.2457\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2394 - val_loss: 0.2453\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2388 - val_loss: 0.2449\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2382 - val_loss: 0.2446\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2376 - val_loss: 0.2443\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2371 - val_loss: 0.2441\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2367 - val_loss: 0.2438\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 14s 32ms/step - loss: 0.2363 - val_loss: 0.2435\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2359 - val_loss: 0.2433\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 14s 34ms/step - loss: 0.2356 - val_loss: 0.2431\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2352 - val_loss: 0.2430\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2349 - val_loss: 0.2427\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2346 - val_loss: 0.2426\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2344 - val_loss: 0.2425\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2341 - val_loss: 0.2423\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2338 - val_loss: 0.2422\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2336 - val_loss: 0.2420\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 12s 30ms/step - loss: 0.2334 - val_loss: 0.2419\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2331 - val_loss: 0.2418\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2329 - val_loss: 0.2416\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2327 - val_loss: 0.2416\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2325 - val_loss: 0.2414\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2323 - val_loss: 0.2413\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2322 - val_loss: 0.2412\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2320 - val_loss: 0.2411\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2318 - val_loss: 0.2410\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2316 - val_loss: 0.2409\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2314 - val_loss: 0.2408\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 13s 30ms/step - loss: 0.2313 - val_loss: 0.2407\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2311 - val_loss: 0.2406\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 13s 31ms/step - loss: 0.2310 - val_loss: 0.2405\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 12s 29ms/step - loss: 0.2308 - val_loss: 0.2404\n",
      "In calc_results: 26930, 8977, 8977, sum = 44884\n",
      "In split_to_train_test: dataset_X.shape=(2459, 10, 65), dataset_y.shape=(2459, 65)\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.4497 - val_loss: 0.5815\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.4426 - val_loss: 0.5772\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.4366 - val_loss: 0.5733\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4316 - val_loss: 0.5699\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.4271 - val_loss: 0.5668\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.4230 - val_loss: 0.5639\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.4193 - val_loss: 0.5613\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.4159 - val_loss: 0.5587\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.4126 - val_loss: 0.5560\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.4096 - val_loss: 0.5536\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.4069 - val_loss: 0.5515\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4043 - val_loss: 0.5494\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4019 - val_loss: 0.5475\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3996 - val_loss: 0.5456\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3975 - val_loss: 0.5437\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.3954 - val_loss: 0.5421\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.3935 - val_loss: 0.5404\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3917 - val_loss: 0.5389\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3899 - val_loss: 0.5373\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3883 - val_loss: 0.5357\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3866 - val_loss: 0.5343\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3851 - val_loss: 0.5328\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3835 - val_loss: 0.5314\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3821 - val_loss: 0.5301\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.3807 - val_loss: 0.5288\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3793 - val_loss: 0.5276\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3780 - val_loss: 0.5263\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3767 - val_loss: 0.5251\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3754 - val_loss: 0.5238\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3742 - val_loss: 0.5226\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3730 - val_loss: 0.5213\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3718 - val_loss: 0.5202\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3706 - val_loss: 0.5191\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3695 - val_loss: 0.5180\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3684 - val_loss: 0.5170\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3673 - val_loss: 0.5159\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3662 - val_loss: 0.5148\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3651 - val_loss: 0.5138\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.3640 - val_loss: 0.5128\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3630 - val_loss: 0.5118\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3620 - val_loss: 0.5108\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3610 - val_loss: 0.5098\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3601 - val_loss: 0.5089\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3591 - val_loss: 0.5079\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3582 - val_loss: 0.5070\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3573 - val_loss: 0.5061\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3564 - val_loss: 0.5052\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3555 - val_loss: 0.5043\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3546 - val_loss: 0.5035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3538 - val_loss: 0.5027\n",
      "In calc_results: 1475, 492, 492, sum = 2459\n",
      "In split_to_train_test: dataset_X.shape=(7059, 10, 65), dataset_y.shape=(7059, 65)\n",
      "Epoch 1/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.2250 - val_loss: 0.2945\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.2182 - val_loss: 0.2901\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.2135 - val_loss: 0.2868\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.2099 - val_loss: 0.2842\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.2070 - val_loss: 0.2821\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.2046 - val_loss: 0.2803\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.2026 - val_loss: 0.2788\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.2008 - val_loss: 0.2775\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 2s 31ms/step - loss: 0.1992 - val_loss: 0.2763\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1977 - val_loss: 0.2753\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 2s 31ms/step - loss: 0.1964 - val_loss: 0.2743\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 0.1952 - val_loss: 0.2734\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 2s 31ms/step - loss: 0.1940 - val_loss: 0.2726\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 2s 31ms/step - loss: 0.1930 - val_loss: 0.2719\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1919 - val_loss: 0.2711\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 2s 31ms/step - loss: 0.1909 - val_loss: 0.2705\n",
      "Epoch 17/50\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 0.1900 - val_loss: 0.2698\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 0.1891 - val_loss: 0.2692\n",
      "Epoch 19/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1881 - val_loss: 0.2687\n",
      "Epoch 20/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1873 - val_loss: 0.2682\n",
      "Epoch 21/50\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 0.1864 - val_loss: 0.2677\n",
      "Epoch 22/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1855 - val_loss: 0.2671\n",
      "Epoch 23/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1847 - val_loss: 0.2667\n",
      "Epoch 24/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1838 - val_loss: 0.2663\n",
      "Epoch 25/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1830 - val_loss: 0.2658\n",
      "Epoch 26/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1822 - val_loss: 0.2654\n",
      "Epoch 27/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1814 - val_loss: 0.2650\n",
      "Epoch 28/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1806 - val_loss: 0.2646\n",
      "Epoch 29/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1799 - val_loss: 0.2643\n",
      "Epoch 30/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1791 - val_loss: 0.2639\n",
      "Epoch 31/50\n",
      "67/67 [==============================] - 2s 31ms/step - loss: 0.1783 - val_loss: 0.2635\n",
      "Epoch 32/50\n",
      "67/67 [==============================] - 2s 32ms/step - loss: 0.1776 - val_loss: 0.2632\n",
      "Epoch 33/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1769 - val_loss: 0.2628\n",
      "Epoch 34/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1762 - val_loss: 0.2625\n",
      "Epoch 35/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1756 - val_loss: 0.2622\n",
      "Epoch 36/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1749 - val_loss: 0.2618\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1743 - val_loss: 0.2615\n",
      "Epoch 38/50\n",
      "67/67 [==============================] - 2s 33ms/step - loss: 0.1736 - val_loss: 0.2612\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 2s 34ms/step - loss: 0.1730 - val_loss: 0.2609\n",
      "Epoch 40/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1724 - val_loss: 0.2606\n",
      "Epoch 41/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1719 - val_loss: 0.2603\n",
      "Epoch 42/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1713 - val_loss: 0.2600\n",
      "Epoch 43/50\n",
      "67/67 [==============================] - 2s 31ms/step - loss: 0.1708 - val_loss: 0.2597\n",
      "Epoch 44/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1702 - val_loss: 0.2594\n",
      "Epoch 45/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1697 - val_loss: 0.2591\n",
      "Epoch 46/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1692 - val_loss: 0.2588\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 2s 31ms/step - loss: 0.1687 - val_loss: 0.2586\n",
      "Epoch 48/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1682 - val_loss: 0.2583\n",
      "Epoch 49/50\n",
      "67/67 [==============================] - 2s 30ms/step - loss: 0.1678 - val_loss: 0.2580\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 2s 29ms/step - loss: 0.1673 - val_loss: 0.2578\n",
      "In calc_results: 4235, 1412, 1412, sum = 7059\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=1604, 1604\n",
      "IN Clustering.split_to_clusters: mask.sum()=43280, 43280\n",
      "IN Clustering.split_to_clusters: mask.sum()=2002, 2002\n",
      "IN Clustering.split_to_clusters: mask.sum()=2459, 2459\n",
      "IN Clustering.split_to_clusters: mask.sum()=5057, 5057\n",
      "In split_to_train_test: dataset_X.shape=(1604, 10, 65), dataset_y.shape=(1604, 65)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.6280 - val_loss: 0.8044\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.6228 - val_loss: 0.7995\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6185 - val_loss: 0.7952\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6147 - val_loss: 0.7915\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6114 - val_loss: 0.7881\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6083 - val_loss: 0.7848\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.6055 - val_loss: 0.7820\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6029 - val_loss: 0.7794\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.6005 - val_loss: 0.7769\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.5984 - val_loss: 0.7746\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5964 - val_loss: 0.7726\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5946 - val_loss: 0.7706\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5929 - val_loss: 0.7687\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5912 - val_loss: 0.7669\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5896 - val_loss: 0.7653\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5881 - val_loss: 0.7637\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5867 - val_loss: 0.7621\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5852 - val_loss: 0.7605\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.5838 - val_loss: 0.7590\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5825 - val_loss: 0.7575\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5812 - val_loss: 0.7562\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5799 - val_loss: 0.7549\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5787 - val_loss: 0.7537\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5775 - val_loss: 0.7525\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5764 - val_loss: 0.7512\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5753 - val_loss: 0.7501\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5742 - val_loss: 0.7490\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5731 - val_loss: 0.7479\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.5720 - val_loss: 0.7468\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.5709 - val_loss: 0.7456\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5698 - val_loss: 0.7445\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5688 - val_loss: 0.7435\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.5678 - val_loss: 0.7425\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.5668 - val_loss: 0.7415\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5658 - val_loss: 0.7404\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5648 - val_loss: 0.7395\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5639 - val_loss: 0.7385\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.5629 - val_loss: 0.7376\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5620 - val_loss: 0.7367\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5611 - val_loss: 0.7358\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5603 - val_loss: 0.7350\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5594 - val_loss: 0.7341\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5585 - val_loss: 0.7332\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5578 - val_loss: 0.7324\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.5570 - val_loss: 0.7316\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.5562 - val_loss: 0.7307\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.5554 - val_loss: 0.7299\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5547 - val_loss: 0.7291\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5539 - val_loss: 0.7283\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5532 - val_loss: 0.7276\n",
      "In calc_results: 962, 321, 321, sum = 1604\n",
      "In split_to_train_test: dataset_X.shape=(43280, 10, 65), dataset_y.shape=(43280, 65)\n",
      "Epoch 1/50\n",
      "406/406 [==============================] - 13s 33ms/step - loss: 0.2666 - val_loss: 0.2470\n",
      "Epoch 2/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2525 - val_loss: 0.2405\n",
      "Epoch 3/50\n",
      "406/406 [==============================] - 13s 32ms/step - loss: 0.2467 - val_loss: 0.2371\n",
      "Epoch 4/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2432 - val_loss: 0.2347\n",
      "Epoch 5/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2405 - val_loss: 0.2328\n",
      "Epoch 6/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2382 - val_loss: 0.2310\n",
      "Epoch 7/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2361 - val_loss: 0.2294\n",
      "Epoch 8/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2342 - val_loss: 0.2278\n",
      "Epoch 9/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2323 - val_loss: 0.2263\n",
      "Epoch 10/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2305 - val_loss: 0.2249\n",
      "Epoch 11/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2287 - val_loss: 0.2237\n",
      "Epoch 12/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2269 - val_loss: 0.2225\n",
      "Epoch 13/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2253 - val_loss: 0.2215\n",
      "Epoch 14/50\n",
      "406/406 [==============================] - 13s 31ms/step - loss: 0.2239 - val_loss: 0.2207\n",
      "Epoch 15/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2227 - val_loss: 0.2201\n",
      "Epoch 16/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2218 - val_loss: 0.2195\n",
      "Epoch 17/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2210 - val_loss: 0.2190\n",
      "Epoch 18/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2203 - val_loss: 0.2185\n",
      "Epoch 19/50\n",
      "406/406 [==============================] - 13s 32ms/step - loss: 0.2197 - val_loss: 0.2182\n",
      "Epoch 20/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2192 - val_loss: 0.2179\n",
      "Epoch 21/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2187 - val_loss: 0.2176\n",
      "Epoch 22/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2182 - val_loss: 0.2172\n",
      "Epoch 23/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2178 - val_loss: 0.2171\n",
      "Epoch 24/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2175 - val_loss: 0.2167\n",
      "Epoch 25/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2171 - val_loss: 0.2165\n",
      "Epoch 26/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2168 - val_loss: 0.2164\n",
      "Epoch 27/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2165 - val_loss: 0.2161\n",
      "Epoch 28/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2162 - val_loss: 0.2159\n",
      "Epoch 29/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2159 - val_loss: 0.2158\n",
      "Epoch 30/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2156 - val_loss: 0.2157\n",
      "Epoch 31/50\n",
      "406/406 [==============================] - 13s 31ms/step - loss: 0.2154 - val_loss: 0.2154\n",
      "Epoch 32/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2151 - val_loss: 0.2152\n",
      "Epoch 33/50\n",
      "406/406 [==============================] - 13s 32ms/step - loss: 0.2149 - val_loss: 0.2151\n",
      "Epoch 34/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2147 - val_loss: 0.2150\n",
      "Epoch 35/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2145 - val_loss: 0.2148\n",
      "Epoch 36/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2143 - val_loss: 0.2146\n",
      "Epoch 37/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2141 - val_loss: 0.2145\n",
      "Epoch 38/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2139 - val_loss: 0.2144\n",
      "Epoch 39/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2137 - val_loss: 0.2143\n",
      "Epoch 40/50\n",
      "406/406 [==============================] - 13s 31ms/step - loss: 0.2135 - val_loss: 0.2143\n",
      "Epoch 41/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2134 - val_loss: 0.2142\n",
      "Epoch 42/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2132 - val_loss: 0.2141\n",
      "Epoch 43/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2131 - val_loss: 0.2140\n",
      "Epoch 44/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2129 - val_loss: 0.2139\n",
      "Epoch 45/50\n",
      "406/406 [==============================] - 12s 31ms/step - loss: 0.2128 - val_loss: 0.2137\n",
      "Epoch 46/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2126 - val_loss: 0.2137\n",
      "Epoch 47/50\n",
      "406/406 [==============================] - 12s 30ms/step - loss: 0.2125 - val_loss: 0.2136\n",
      "Epoch 48/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2123 - val_loss: 0.2135\n",
      "Epoch 49/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2122 - val_loss: 0.2134\n",
      "Epoch 50/50\n",
      "406/406 [==============================] - 12s 29ms/step - loss: 0.2121 - val_loss: 0.2135\n",
      "In calc_results: 25968, 8656, 8656, sum = 43280\n",
      "In split_to_train_test: dataset_X.shape=(2002, 10, 65), dataset_y.shape=(2002, 65)\n",
      "Epoch 1/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2553 - val_loss: 0.2608\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2511 - val_loss: 0.2583\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2475 - val_loss: 0.2560\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 38ms/step - loss: 0.2445 - val_loss: 0.2540\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 0.2418 - val_loss: 0.2522\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.2395 - val_loss: 0.2505\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2374 - val_loss: 0.2491\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2355 - val_loss: 0.2477\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2338 - val_loss: 0.2465\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.2322 - val_loss: 0.2454\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 0.2307 - val_loss: 0.2443\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2293 - val_loss: 0.2433\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2280 - val_loss: 0.2424\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 0.2267 - val_loss: 0.2415\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2255 - val_loss: 0.2407\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2244 - val_loss: 0.2400\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2234 - val_loss: 0.2393\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2224 - val_loss: 0.2387\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2215 - val_loss: 0.2381\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2206 - val_loss: 0.2375\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2197 - val_loss: 0.2369\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2189 - val_loss: 0.2364\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2181 - val_loss: 0.2359\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2174 - val_loss: 0.2354\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2167 - val_loss: 0.2349\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2161 - val_loss: 0.2344\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2154 - val_loss: 0.2339\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2148 - val_loss: 0.2335\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2142 - val_loss: 0.2331\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.2136 - val_loss: 0.2327\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2131 - val_loss: 0.2323\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2125 - val_loss: 0.2319\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2120 - val_loss: 0.2315\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2115 - val_loss: 0.2311\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2110 - val_loss: 0.2307\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2105 - val_loss: 0.2303\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2101 - val_loss: 0.2300\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2096 - val_loss: 0.2296\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2092 - val_loss: 0.2293\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2087 - val_loss: 0.2289\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2083 - val_loss: 0.2286\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2079 - val_loss: 0.2283\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2075 - val_loss: 0.2279\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2071 - val_loss: 0.2276\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2066 - val_loss: 0.2273\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2062 - val_loss: 0.2270\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2059 - val_loss: 0.2267\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2055 - val_loss: 0.2263\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2051 - val_loss: 0.2260\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2047 - val_loss: 0.2257\n",
      "In calc_results: 1201, 401, 400, sum = 2002\n",
      "In split_to_train_test: dataset_X.shape=(2459, 10, 65), dataset_y.shape=(2459, 65)\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4503 - val_loss: 0.5864\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.4428 - val_loss: 0.5816\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4365 - val_loss: 0.5774\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4311 - val_loss: 0.5737\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4262 - val_loss: 0.5703\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4218 - val_loss: 0.5670\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4179 - val_loss: 0.5640\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4143 - val_loss: 0.5612\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4109 - val_loss: 0.5586\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4078 - val_loss: 0.5562\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4049 - val_loss: 0.5538\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4022 - val_loss: 0.5515\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3996 - val_loss: 0.5493\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3971 - val_loss: 0.5472\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3949 - val_loss: 0.5451\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3926 - val_loss: 0.5432\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3906 - val_loss: 0.5413\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3885 - val_loss: 0.5395\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3866 - val_loss: 0.5377\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3847 - val_loss: 0.5360\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3830 - val_loss: 0.5344\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3812 - val_loss: 0.5328\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3796 - val_loss: 0.5313\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3780 - val_loss: 0.5298\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3765 - val_loss: 0.5284\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3751 - val_loss: 0.5271\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3737 - val_loss: 0.5257\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3723 - val_loss: 0.5244\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3710 - val_loss: 0.5231\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3696 - val_loss: 0.5219\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3684 - val_loss: 0.5207\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3672 - val_loss: 0.5195\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3660 - val_loss: 0.5184\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3649 - val_loss: 0.5173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3638 - val_loss: 0.5162\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3627 - val_loss: 0.5151\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3617 - val_loss: 0.5141\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3607 - val_loss: 0.5131\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3597 - val_loss: 0.5120\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3587 - val_loss: 0.5111\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3578 - val_loss: 0.5100\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3569 - val_loss: 0.5090\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3560 - val_loss: 0.5081\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3551 - val_loss: 0.5071\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3543 - val_loss: 0.5061\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3534 - val_loss: 0.5051\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3526 - val_loss: 0.5042\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3518 - val_loss: 0.5033\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3510 - val_loss: 0.5023\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3503 - val_loss: 0.5014\n",
      "In calc_results: 1475, 492, 492, sum = 2459\n",
      "In split_to_train_test: dataset_X.shape=(5057, 10, 65), dataset_y.shape=(5057, 65)\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.2178 - val_loss: 0.3311\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.2135 - val_loss: 0.3271\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.2103 - val_loss: 0.3239\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 2s 34ms/step - loss: 0.2077 - val_loss: 0.3212\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.2055 - val_loss: 0.3190\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.2036 - val_loss: 0.3170\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.2019 - val_loss: 0.3154\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.2005 - val_loss: 0.3139\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1991 - val_loss: 0.3126\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1979 - val_loss: 0.3115\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1968 - val_loss: 0.3105\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1958 - val_loss: 0.3096\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1948 - val_loss: 0.3088\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1939 - val_loss: 0.3081\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1931 - val_loss: 0.3074\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1922 - val_loss: 0.3068\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1914 - val_loss: 0.3063\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1906 - val_loss: 0.3058\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.1899 - val_loss: 0.3054\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1891 - val_loss: 0.3049\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1884 - val_loss: 0.3046\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1877 - val_loss: 0.3042\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1870 - val_loss: 0.3039\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1863 - val_loss: 0.3036\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1856 - val_loss: 0.3033\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1849 - val_loss: 0.3031\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 2s 35ms/step - loss: 0.1843 - val_loss: 0.3029\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.1836 - val_loss: 0.3026\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1829 - val_loss: 0.3025\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1823 - val_loss: 0.3023\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1816 - val_loss: 0.3021\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1809 - val_loss: 0.3020\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1803 - val_loss: 0.3019\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1796 - val_loss: 0.3017\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1790 - val_loss: 0.3016\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1783 - val_loss: 0.3015\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1777 - val_loss: 0.3014\n",
      "Epoch 38/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1771 - val_loss: 0.3013\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1765 - val_loss: 0.3012\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1759 - val_loss: 0.3011\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1753 - val_loss: 0.3011\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.1748 - val_loss: 0.3009\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 2s 35ms/step - loss: 0.1742 - val_loss: 0.3008\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1737 - val_loss: 0.3007\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1732 - val_loss: 0.3006\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1727 - val_loss: 0.3005\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1722 - val_loss: 0.3004\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1717 - val_loss: 0.3003\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1713 - val_loss: 0.3002\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.1708 - val_loss: 0.3000\n",
      "In calc_results: 3034, 1012, 1011, sum = 5057\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=39461, 39461\n",
      "IN Clustering.split_to_clusters: mask.sum()=5057, 5057\n",
      "IN Clustering.split_to_clusters: mask.sum()=2002, 2002\n",
      "IN Clustering.split_to_clusters: mask.sum()=2459, 2459\n",
      "IN Clustering.split_to_clusters: mask.sum()=1168, 1168\n",
      "IN Clustering.split_to_clusters: mask.sum()=436, 436\n",
      "IN Clustering.split_to_clusters: mask.sum()=3819, 3819\n",
      "In split_to_train_test: dataset_X.shape=(39461, 10, 65), dataset_y.shape=(39461, 65)\n",
      "Epoch 1/50\n",
      "370/370 [==============================] - 11s 31ms/step - loss: 0.2546 - val_loss: 0.2354\n",
      "Epoch 2/50\n",
      "370/370 [==============================] - 11s 31ms/step - loss: 0.2407 - val_loss: 0.2291\n",
      "Epoch 3/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2348 - val_loss: 0.2258\n",
      "Epoch 4/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2312 - val_loss: 0.2234\n",
      "Epoch 5/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2286 - val_loss: 0.2215\n",
      "Epoch 6/50\n",
      "370/370 [==============================] - 12s 33ms/step - loss: 0.2264 - val_loss: 0.2197\n",
      "Epoch 7/50\n",
      "370/370 [==============================] - 11s 31ms/step - loss: 0.2243 - val_loss: 0.2181\n",
      "Epoch 8/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2224 - val_loss: 0.2167\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2206 - val_loss: 0.2152\n",
      "Epoch 10/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2188 - val_loss: 0.2139\n",
      "Epoch 11/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2171 - val_loss: 0.2128\n",
      "Epoch 12/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2155 - val_loss: 0.2117\n",
      "Epoch 13/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2140 - val_loss: 0.2107\n",
      "Epoch 14/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2126 - val_loss: 0.2098\n",
      "Epoch 15/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2114 - val_loss: 0.2090\n",
      "Epoch 16/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2103 - val_loss: 0.2083\n",
      "Epoch 17/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2094 - val_loss: 0.2077\n",
      "Epoch 18/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2086 - val_loss: 0.2073\n",
      "Epoch 19/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2079 - val_loss: 0.2068\n",
      "Epoch 20/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2073 - val_loss: 0.2063\n",
      "Epoch 21/50\n",
      "370/370 [==============================] - 12s 31ms/step - loss: 0.2068 - val_loss: 0.2061\n",
      "Epoch 22/50\n",
      "370/370 [==============================] - 12s 32ms/step - loss: 0.2063 - val_loss: 0.2058\n",
      "Epoch 23/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2059 - val_loss: 0.2056\n",
      "Epoch 24/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2055 - val_loss: 0.2053\n",
      "Epoch 25/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2052 - val_loss: 0.2051\n",
      "Epoch 26/50\n",
      "370/370 [==============================] - 12s 32ms/step - loss: 0.2048 - val_loss: 0.2049\n",
      "Epoch 27/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2045 - val_loss: 0.2047\n",
      "Epoch 28/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2042 - val_loss: 0.2046\n",
      "Epoch 29/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2039 - val_loss: 0.2044\n",
      "Epoch 30/50\n",
      "370/370 [==============================] - 11s 31ms/step - loss: 0.2037 - val_loss: 0.2042\n",
      "Epoch 31/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2034 - val_loss: 0.2040\n",
      "Epoch 32/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2032 - val_loss: 0.2039\n",
      "Epoch 33/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2030 - val_loss: 0.2038\n",
      "Epoch 34/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2028 - val_loss: 0.2036\n",
      "Epoch 35/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2026 - val_loss: 0.2036\n",
      "Epoch 36/50\n",
      "370/370 [==============================] - 12s 31ms/step - loss: 0.2024 - val_loss: 0.2035\n",
      "Epoch 37/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2022 - val_loss: 0.2033\n",
      "Epoch 38/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2020 - val_loss: 0.2032\n",
      "Epoch 39/50\n",
      "370/370 [==============================] - 12s 31ms/step - loss: 0.2018 - val_loss: 0.2031\n",
      "Epoch 40/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2017 - val_loss: 0.2031\n",
      "Epoch 41/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2015 - val_loss: 0.2030\n",
      "Epoch 42/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2014 - val_loss: 0.2030\n",
      "Epoch 43/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2012 - val_loss: 0.2028\n",
      "Epoch 44/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2011 - val_loss: 0.2028\n",
      "Epoch 45/50\n",
      "370/370 [==============================] - 11s 30ms/step - loss: 0.2009 - val_loss: 0.2027\n",
      "Epoch 46/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2008 - val_loss: 0.2027\n",
      "Epoch 47/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2007 - val_loss: 0.2025\n",
      "Epoch 48/50\n",
      "370/370 [==============================] - 12s 32ms/step - loss: 0.2005 - val_loss: 0.2025\n",
      "Epoch 49/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2004 - val_loss: 0.2024\n",
      "Epoch 50/50\n",
      "370/370 [==============================] - 11s 29ms/step - loss: 0.2003 - val_loss: 0.2023\n",
      "In calc_results: 23677, 7892, 7892, sum = 39461\n",
      "In split_to_train_test: dataset_X.shape=(5057, 10, 65), dataset_y.shape=(5057, 65)\n",
      "Epoch 1/50\n",
      "48/48 [==============================] - 2s 36ms/step - loss: 0.2179 - val_loss: 0.3293\n",
      "Epoch 2/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.2135 - val_loss: 0.3253\n",
      "Epoch 3/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.2102 - val_loss: 0.3223\n",
      "Epoch 4/50\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.2074 - val_loss: 0.3198\n",
      "Epoch 5/50\n",
      "48/48 [==============================] - 2s 34ms/step - loss: 0.2052 - val_loss: 0.3177\n",
      "Epoch 6/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.2032 - val_loss: 0.3159\n",
      "Epoch 7/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.2015 - val_loss: 0.3145\n",
      "Epoch 8/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.2000 - val_loss: 0.3132\n",
      "Epoch 9/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1987 - val_loss: 0.3120\n",
      "Epoch 10/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1974 - val_loss: 0.3111\n",
      "Epoch 11/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1963 - val_loss: 0.3102\n",
      "Epoch 12/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1953 - val_loss: 0.3094\n",
      "Epoch 13/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1943 - val_loss: 0.3087\n",
      "Epoch 14/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1934 - val_loss: 0.3080\n",
      "Epoch 15/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1925 - val_loss: 0.3074\n",
      "Epoch 16/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1916 - val_loss: 0.3069\n",
      "Epoch 17/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1908 - val_loss: 0.3064\n",
      "Epoch 18/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1900 - val_loss: 0.3059\n",
      "Epoch 19/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1892 - val_loss: 0.3054\n",
      "Epoch 20/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1884 - val_loss: 0.3050\n",
      "Epoch 21/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1877 - val_loss: 0.3046\n",
      "Epoch 22/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1869 - val_loss: 0.3042\n",
      "Epoch 23/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1862 - val_loss: 0.3039\n",
      "Epoch 24/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1854 - val_loss: 0.3036\n",
      "Epoch 25/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1847 - val_loss: 0.3033\n",
      "Epoch 26/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1840 - val_loss: 0.3031\n",
      "Epoch 27/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1833 - val_loss: 0.3028\n",
      "Epoch 28/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1827 - val_loss: 0.3026\n",
      "Epoch 29/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1820 - val_loss: 0.3024\n",
      "Epoch 30/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1813 - val_loss: 0.3022\n",
      "Epoch 31/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1807 - val_loss: 0.3020\n",
      "Epoch 32/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1801 - val_loss: 0.3018\n",
      "Epoch 33/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1795 - val_loss: 0.3016\n",
      "Epoch 34/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1789 - val_loss: 0.3015\n",
      "Epoch 35/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1783 - val_loss: 0.3013\n",
      "Epoch 36/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1777 - val_loss: 0.3011\n",
      "Epoch 37/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1771 - val_loss: 0.3010\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1766 - val_loss: 0.3009\n",
      "Epoch 39/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1760 - val_loss: 0.3007\n",
      "Epoch 40/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1755 - val_loss: 0.3006\n",
      "Epoch 41/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1750 - val_loss: 0.3005\n",
      "Epoch 42/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1744 - val_loss: 0.3003\n",
      "Epoch 43/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1739 - val_loss: 0.3002\n",
      "Epoch 44/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1734 - val_loss: 0.3000\n",
      "Epoch 45/50\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.1730 - val_loss: 0.3000\n",
      "Epoch 46/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1725 - val_loss: 0.2998\n",
      "Epoch 47/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1721 - val_loss: 0.2997\n",
      "Epoch 48/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1716 - val_loss: 0.2996\n",
      "Epoch 49/50\n",
      "48/48 [==============================] - 1s 29ms/step - loss: 0.1712 - val_loss: 0.2994\n",
      "Epoch 50/50\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.1707 - val_loss: 0.2993\n",
      "In calc_results: 3034, 1012, 1011, sum = 5057\n",
      "In split_to_train_test: dataset_X.shape=(2002, 10, 65), dataset_y.shape=(2002, 65)\n",
      "Epoch 1/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2491 - val_loss: 0.2539\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2454 - val_loss: 0.2518\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2423 - val_loss: 0.2499\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2397 - val_loss: 0.2481\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2375 - val_loss: 0.2465\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2355 - val_loss: 0.2450\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2336 - val_loss: 0.2437\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2320 - val_loss: 0.2424\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2305 - val_loss: 0.2413\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2291 - val_loss: 0.2402\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.2278 - val_loss: 0.2392\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2266 - val_loss: 0.2384\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2255 - val_loss: 0.2376\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2244 - val_loss: 0.2368\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2234 - val_loss: 0.2361\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 0.2224 - val_loss: 0.2354\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.2216 - val_loss: 0.2348\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2207 - val_loss: 0.2342\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.2199 - val_loss: 0.2336\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2191 - val_loss: 0.2331\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2183 - val_loss: 0.2326\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2176 - val_loss: 0.2321\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2169 - val_loss: 0.2317\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2162 - val_loss: 0.2312\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2155 - val_loss: 0.2308\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2149 - val_loss: 0.2304\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2143 - val_loss: 0.2300\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2137 - val_loss: 0.2296\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2132 - val_loss: 0.2293\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2126 - val_loss: 0.2289\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2121 - val_loss: 0.2286\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.2115 - val_loss: 0.2282\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2111 - val_loss: 0.2279\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2106 - val_loss: 0.2276\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2101 - val_loss: 0.2273\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2096 - val_loss: 0.2270\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2092 - val_loss: 0.2267\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2087 - val_loss: 0.2264\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2083 - val_loss: 0.2261\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2079 - val_loss: 0.2258\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2075 - val_loss: 0.2255\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2071 - val_loss: 0.2253\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2067 - val_loss: 0.2250\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 0.2063 - val_loss: 0.2247\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 0.2059 - val_loss: 0.2244\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.2055 - val_loss: 0.2242\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.2051 - val_loss: 0.2239\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.2048 - val_loss: 0.2236\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 0.2044 - val_loss: 0.2234\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 0.2040 - val_loss: 0.2232\n",
      "In calc_results: 1201, 401, 400, sum = 2002\n",
      "In split_to_train_test: dataset_X.shape=(2459, 10, 65), dataset_y.shape=(2459, 65)\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.4483 - val_loss: 0.5848\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.4417 - val_loss: 0.5803\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4360 - val_loss: 0.5763\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.4310 - val_loss: 0.5726\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4266 - val_loss: 0.5694\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.4226 - val_loss: 0.5663\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.4190 - val_loss: 0.5635\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.4156 - val_loss: 0.5607\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.4125 - val_loss: 0.5581\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4096 - val_loss: 0.5557\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4069 - val_loss: 0.5533\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4044 - val_loss: 0.5512\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.4020 - val_loss: 0.5491\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3997 - val_loss: 0.5471\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3975 - val_loss: 0.5452\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3954 - val_loss: 0.5434\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3933 - val_loss: 0.5416\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3914 - val_loss: 0.5399\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3895 - val_loss: 0.5383\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.3877 - val_loss: 0.5366\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3859 - val_loss: 0.5350\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3842 - val_loss: 0.5336\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3826 - val_loss: 0.5321\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3810 - val_loss: 0.5306\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3794 - val_loss: 0.5291\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3779 - val_loss: 0.5278\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3765 - val_loss: 0.5263\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3750 - val_loss: 0.5250\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3736 - val_loss: 0.5238\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3723 - val_loss: 0.5226\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3710 - val_loss: 0.5214\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3698 - val_loss: 0.5201\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3686 - val_loss: 0.5190\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3674 - val_loss: 0.5178\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3663 - val_loss: 0.5167\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3651 - val_loss: 0.5157\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3640 - val_loss: 0.5145\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3630 - val_loss: 0.5135\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3620 - val_loss: 0.5125\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3610 - val_loss: 0.5114\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3600 - val_loss: 0.5104\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3590 - val_loss: 0.5094\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3581 - val_loss: 0.5084\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3572 - val_loss: 0.5075\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3564 - val_loss: 0.5065\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3555 - val_loss: 0.5055\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3546 - val_loss: 0.5046\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3539 - val_loss: 0.5037\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3530 - val_loss: 0.5029\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3523 - val_loss: 0.5020\n",
      "In calc_results: 1475, 492, 492, sum = 2459\n",
      "In split_to_train_test: dataset_X.shape=(1168, 10, 65), dataset_y.shape=(1168, 65)\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 1.0548 - val_loss: 0.5052\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 1.0494 - val_loss: 0.5027\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0445 - val_loss: 0.5004\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0399 - val_loss: 0.4982\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 1.0355 - val_loss: 0.4962\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 1.0315 - val_loss: 0.4943\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 1.0279 - val_loss: 0.4925\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 1.0244 - val_loss: 0.4908\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 1.0211 - val_loss: 0.4892\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 1.0181 - val_loss: 0.4876\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 1.0151 - val_loss: 0.4862\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0123 - val_loss: 0.4848\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0097 - val_loss: 0.4835\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0072 - val_loss: 0.4822\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0047 - val_loss: 0.4810\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 1.0024 - val_loss: 0.4798\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 1.0001 - val_loss: 0.4787\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9979 - val_loss: 0.4776\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9957 - val_loss: 0.4765\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9936 - val_loss: 0.4755\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.9916 - val_loss: 0.4745\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.9896 - val_loss: 0.4735\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9876 - val_loss: 0.4726\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.9857 - val_loss: 0.4716\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9838 - val_loss: 0.4707\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9820 - val_loss: 0.4698\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9803 - val_loss: 0.4689\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9786 - val_loss: 0.4681\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9769 - val_loss: 0.4672\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9753 - val_loss: 0.4664\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9737 - val_loss: 0.4656\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9721 - val_loss: 0.4648\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.9706 - val_loss: 0.4640\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.9691 - val_loss: 0.4633\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9676 - val_loss: 0.4626\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.9661 - val_loss: 0.4618\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9647 - val_loss: 0.4611\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9633 - val_loss: 0.4604\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9618 - val_loss: 0.4597\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9604 - val_loss: 0.4590\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9590 - val_loss: 0.4584\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9577 - val_loss: 0.4577\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9563 - val_loss: 0.4571\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9549 - val_loss: 0.4564\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9536 - val_loss: 0.4558\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9523 - val_loss: 0.4552\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9510 - val_loss: 0.4546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9497 - val_loss: 0.4540\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.9484 - val_loss: 0.4534\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.9472 - val_loss: 0.4529\n",
      "In calc_results: 701, 233, 234, sum = 1168\n",
      "In split_to_train_test: dataset_X.shape=(436, 10, 65), dataset_y.shape=(436, 65)\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.1142 - val_loss: 0.0933\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.1125 - val_loss: 0.0912\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.1110 - val_loss: 0.0891\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.1094 - val_loss: 0.0871\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.1080 - val_loss: 0.0852\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.1065 - val_loss: 0.0833\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.1052 - val_loss: 0.0816\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.1039 - val_loss: 0.0801\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.1027 - val_loss: 0.0786\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.1016 - val_loss: 0.0772\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.1005 - val_loss: 0.0759\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0995 - val_loss: 0.0747\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0985 - val_loss: 0.0735\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0976 - val_loss: 0.0724\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0967 - val_loss: 0.0714\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0959 - val_loss: 0.0704\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0951 - val_loss: 0.0695\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0944 - val_loss: 0.0686\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0937 - val_loss: 0.0677\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0930 - val_loss: 0.0669\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0923 - val_loss: 0.0662\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0917 - val_loss: 0.0654\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0911 - val_loss: 0.0647\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0905 - val_loss: 0.0640\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0899 - val_loss: 0.0633\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0894 - val_loss: 0.0626\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0888 - val_loss: 0.0620\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0883 - val_loss: 0.0614\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0879 - val_loss: 0.0608\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0874 - val_loss: 0.0603\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0869 - val_loss: 0.0598\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0865 - val_loss: 0.0594\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0861 - val_loss: 0.0589\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0857 - val_loss: 0.0584\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0852 - val_loss: 0.0579\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0848 - val_loss: 0.0574\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0845 - val_loss: 0.0570\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0841 - val_loss: 0.0565\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0837 - val_loss: 0.0561\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0834 - val_loss: 0.0557\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0830 - val_loss: 0.0554\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0827 - val_loss: 0.0550\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0823 - val_loss: 0.0546\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0820 - val_loss: 0.0543\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0817 - val_loss: 0.0540\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0814 - val_loss: 0.0536\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0811 - val_loss: 0.0534\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0808 - val_loss: 0.0530\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0805 - val_loss: 0.0527\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0802 - val_loss: 0.0524\n",
      "In calc_results: 262, 87, 87, sum = 436\n",
      "In split_to_train_test: dataset_X.shape=(3819, 10, 65), dataset_y.shape=(3819, 65)\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.3054 - val_loss: 0.4209\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.3012 - val_loss: 0.4175\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.2978 - val_loss: 0.4146\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.2950 - val_loss: 0.4121\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.2926 - val_loss: 0.4099\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.2904 - val_loss: 0.4080\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.2885 - val_loss: 0.4063\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.2869 - val_loss: 0.4047\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.2854 - val_loss: 0.4034\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.2840 - val_loss: 0.4021\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.2828 - val_loss: 0.4009\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.2816 - val_loss: 0.3998\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.2806 - val_loss: 0.3988\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.2796 - val_loss: 0.3979\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2788 - val_loss: 0.3970\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2779 - val_loss: 0.3963\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2772 - val_loss: 0.3955\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2764 - val_loss: 0.3948\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.2757 - val_loss: 0.3941\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2751 - val_loss: 0.3935\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2745 - val_loss: 0.3929\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2739 - val_loss: 0.3923\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2734 - val_loss: 0.3918\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2728 - val_loss: 0.3913\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2723 - val_loss: 0.3909\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2718 - val_loss: 0.3904\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.2714 - val_loss: 0.3900\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2709 - val_loss: 0.3895\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.2705 - val_loss: 0.3891\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.2700 - val_loss: 0.3887\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.2696 - val_loss: 0.3883\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.2692 - val_loss: 0.3880\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2688 - val_loss: 0.3876\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2685 - val_loss: 0.3873\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 1s 35ms/step - loss: 0.2681 - val_loss: 0.3870\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.2677 - val_loss: 0.3867\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2674 - val_loss: 0.3864\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2670 - val_loss: 0.3861\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2667 - val_loss: 0.3858\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2663 - val_loss: 0.3855\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2660 - val_loss: 0.3853\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2657 - val_loss: 0.3850\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2654 - val_loss: 0.3848\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2650 - val_loss: 0.3846\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 1s 34ms/step - loss: 0.2647 - val_loss: 0.3843\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2644 - val_loss: 0.3841\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2641 - val_loss: 0.3839\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.2638 - val_loss: 0.3837\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2636 - val_loss: 0.3835\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.2633 - val_loss: 0.3833\n",
      "In calc_results: 2291, 764, 764, sum = 3819\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=44647, 44647\n",
      "IN Clustering.split_to_clusters: mask.sum()=2469, 2469\n",
      "IN Clustering.split_to_clusters: mask.sum()=7286, 7286\n",
      "In split_to_train_test: dataset_X.shape=(44647, 10, 65), dataset_y.shape=(44647, 65)\n",
      "Epoch 1/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2841 - val_loss: 0.2721\n",
      "Epoch 2/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2710 - val_loss: 0.2657\n",
      "Epoch 3/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2653 - val_loss: 0.2623\n",
      "Epoch 4/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2617 - val_loss: 0.2599\n",
      "Epoch 5/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2590 - val_loss: 0.2581\n",
      "Epoch 6/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2569 - val_loss: 0.2564\n",
      "Epoch 7/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2550 - val_loss: 0.2550\n",
      "Epoch 8/50\n",
      "419/419 [==============================] - 13s 30ms/step - loss: 0.2533 - val_loss: 0.2537\n",
      "Epoch 9/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2517 - val_loss: 0.2525\n",
      "Epoch 10/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2502 - val_loss: 0.2514\n",
      "Epoch 11/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2487 - val_loss: 0.2503\n",
      "Epoch 12/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2473 - val_loss: 0.2493\n",
      "Epoch 13/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2460 - val_loss: 0.2485\n",
      "Epoch 14/50\n",
      "419/419 [==============================] - 13s 30ms/step - loss: 0.2447 - val_loss: 0.2477\n",
      "Epoch 15/50\n",
      "419/419 [==============================] - 13s 30ms/step - loss: 0.2435 - val_loss: 0.2469\n",
      "Epoch 16/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2424 - val_loss: 0.2462\n",
      "Epoch 17/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2413 - val_loss: 0.2455\n",
      "Epoch 18/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2404 - val_loss: 0.2449\n",
      "Epoch 19/50\n",
      "419/419 [==============================] - 13s 30ms/step - loss: 0.2396 - val_loss: 0.2444\n",
      "Epoch 20/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2389 - val_loss: 0.2440\n",
      "Epoch 21/50\n",
      "419/419 [==============================] - 13s 30ms/step - loss: 0.2383 - val_loss: 0.2437\n",
      "Epoch 22/50\n",
      "419/419 [==============================] - 12s 30ms/step - loss: 0.2377 - val_loss: 0.2433\n",
      "Epoch 23/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2372 - val_loss: 0.2430\n",
      "Epoch 24/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2368 - val_loss: 0.2428\n",
      "Epoch 25/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2364 - val_loss: 0.2424\n",
      "Epoch 26/50\n",
      "419/419 [==============================] - 12s 30ms/step - loss: 0.2360 - val_loss: 0.2422\n",
      "Epoch 27/50\n",
      "419/419 [==============================] - 12s 30ms/step - loss: 0.2357 - val_loss: 0.2420\n",
      "Epoch 28/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2353 - val_loss: 0.2418\n",
      "Epoch 29/50\n",
      "419/419 [==============================] - 12s 30ms/step - loss: 0.2350 - val_loss: 0.2416\n",
      "Epoch 30/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2347 - val_loss: 0.2414\n",
      "Epoch 31/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2345 - val_loss: 0.2413\n",
      "Epoch 32/50\n",
      "419/419 [==============================] - 13s 30ms/step - loss: 0.2342 - val_loss: 0.2411\n",
      "Epoch 33/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2340 - val_loss: 0.2409\n",
      "Epoch 34/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2337 - val_loss: 0.2408\n",
      "Epoch 35/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2335 - val_loss: 0.2406\n",
      "Epoch 36/50\n",
      "419/419 [==============================] - 13s 30ms/step - loss: 0.2333 - val_loss: 0.2404\n",
      "Epoch 37/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2331 - val_loss: 0.2404\n",
      "Epoch 38/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2329 - val_loss: 0.2403\n",
      "Epoch 39/50\n",
      "419/419 [==============================] - 12s 29ms/step - loss: 0.2327 - val_loss: 0.2401\n",
      "Epoch 40/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2325 - val_loss: 0.2400\n",
      "Epoch 41/50\n",
      "419/419 [==============================] - 13s 30ms/step - loss: 0.2323 - val_loss: 0.2400\n",
      "Epoch 42/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2322 - val_loss: 0.2399\n",
      "Epoch 43/50\n",
      "419/419 [==============================] - 12s 30ms/step - loss: 0.2320 - val_loss: 0.2397\n",
      "Epoch 44/50\n",
      "419/419 [==============================] - 12s 30ms/step - loss: 0.2318 - val_loss: 0.2396\n",
      "Epoch 45/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2317 - val_loss: 0.2396\n",
      "Epoch 46/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2315 - val_loss: 0.2394\n",
      "Epoch 47/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2314 - val_loss: 0.2394\n",
      "Epoch 48/50\n",
      "419/419 [==============================] - 12s 30ms/step - loss: 0.2312 - val_loss: 0.2392\n",
      "Epoch 49/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2311 - val_loss: 0.2392\n",
      "Epoch 50/50\n",
      "419/419 [==============================] - 13s 31ms/step - loss: 0.2309 - val_loss: 0.2392\n",
      "In calc_results: 26788, 8930, 8929, sum = 44647\n",
      "In split_to_train_test: dataset_X.shape=(2469, 10, 65), dataset_y.shape=(2469, 65)\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4190 - val_loss: 0.5950\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4117 - val_loss: 0.5902\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4055 - val_loss: 0.5859\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.4000 - val_loss: 0.5820\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.3950 - val_loss: 0.5784\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3906 - val_loss: 0.5751\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3865 - val_loss: 0.5720\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3827 - val_loss: 0.5691\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3793 - val_loss: 0.5663\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3760 - val_loss: 0.5637\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3729 - val_loss: 0.5612\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3700 - val_loss: 0.5587\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3673 - val_loss: 0.5565\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3647 - val_loss: 0.5543\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3623 - val_loss: 0.5523\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3600 - val_loss: 0.5503\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3577 - val_loss: 0.5484\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3556 - val_loss: 0.5465\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3536 - val_loss: 0.5447\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3516 - val_loss: 0.5429\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3497 - val_loss: 0.5412\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3479 - val_loss: 0.5395\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3462 - val_loss: 0.5379\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3446 - val_loss: 0.5363\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3430 - val_loss: 0.5348\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3414 - val_loss: 0.5333\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3400 - val_loss: 0.5318\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3385 - val_loss: 0.5303\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3371 - val_loss: 0.5288\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3357 - val_loss: 0.5275\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3344 - val_loss: 0.5262\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3331 - val_loss: 0.5248\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3319 - val_loss: 0.5236\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.3307 - val_loss: 0.5223\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3296 - val_loss: 0.5211\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3284 - val_loss: 0.5199\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3273 - val_loss: 0.5188\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3263 - val_loss: 0.5177\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3252 - val_loss: 0.5167\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3242 - val_loss: 0.5156\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3233 - val_loss: 0.5146\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3223 - val_loss: 0.5136\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3214 - val_loss: 0.5126\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3205 - val_loss: 0.5117\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3196 - val_loss: 0.5106\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3187 - val_loss: 0.5097\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3179 - val_loss: 0.5087\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3171 - val_loss: 0.5079\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3163 - val_loss: 0.5070\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3155 - val_loss: 0.5061\n",
      "In calc_results: 1481, 494, 494, sum = 2469\n",
      "In split_to_train_test: dataset_X.shape=(7286, 10, 65), dataset_y.shape=(7286, 65)\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.2276 - val_loss: 0.3028\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.2206 - val_loss: 0.2983\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.2157 - val_loss: 0.2949\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2119 - val_loss: 0.2923\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.2089 - val_loss: 0.2901\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.2063 - val_loss: 0.2882\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.2041 - val_loss: 0.2866\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.2021 - val_loss: 0.2851\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.2003 - val_loss: 0.2838\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1988 - val_loss: 0.2826\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.1973 - val_loss: 0.2816\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1960 - val_loss: 0.2807\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1948 - val_loss: 0.2799\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1936 - val_loss: 0.2791\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1926 - val_loss: 0.2784\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1915 - val_loss: 0.2777\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1905 - val_loss: 0.2771\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1895 - val_loss: 0.2765\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2760\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.1876 - val_loss: 0.2755\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.1867 - val_loss: 0.2750\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.1858 - val_loss: 0.2745\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1848 - val_loss: 0.2741\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.1839 - val_loss: 0.2736\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.1830 - val_loss: 0.2732\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.1822 - val_loss: 0.2729\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1813 - val_loss: 0.2725\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.1805 - val_loss: 0.2721\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1797 - val_loss: 0.2718\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 2s 34ms/step - loss: 0.1789 - val_loss: 0.2715\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.1781 - val_loss: 0.2711\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1774 - val_loss: 0.2708\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1767 - val_loss: 0.2705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 0.1760 - val_loss: 0.2702\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.1753 - val_loss: 0.2699\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.1746 - val_loss: 0.2696\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1740 - val_loss: 0.2694\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1734 - val_loss: 0.2691\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1728 - val_loss: 0.2688\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1722 - val_loss: 0.2686\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1716 - val_loss: 0.2684\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1711 - val_loss: 0.2681\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1705 - val_loss: 0.2679\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1700 - val_loss: 0.2676\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.1695 - val_loss: 0.2674\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.1690 - val_loss: 0.2671\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.1686 - val_loss: 0.2669\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1681 - val_loss: 0.2667\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.1677 - val_loss: 0.2665\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.1672 - val_loss: 0.2663\n",
      "In calc_results: 4372, 1457, 1457, sum = 7286\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=1517, 1517\n",
      "IN Clustering.split_to_clusters: mask.sum()=43130, 43130\n",
      "IN Clustering.split_to_clusters: mask.sum()=5655, 5655\n",
      "IN Clustering.split_to_clusters: mask.sum()=2469, 2469\n",
      "IN Clustering.split_to_clusters: mask.sum()=1631, 1631\n",
      "In split_to_train_test: dataset_X.shape=(1517, 10, 65), dataset_y.shape=(1517, 65)\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5926 - val_loss: 0.6458\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5881 - val_loss: 0.6425\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5843 - val_loss: 0.6394\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5809 - val_loss: 0.6367\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5777 - val_loss: 0.6342\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5749 - val_loss: 0.6320\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5722 - val_loss: 0.6299\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5698 - val_loss: 0.6279\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5675 - val_loss: 0.6260\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5653 - val_loss: 0.6242\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5633 - val_loss: 0.6225\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5614 - val_loss: 0.6209\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5596 - val_loss: 0.6193\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5579 - val_loss: 0.6178\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5563 - val_loss: 0.6163\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5547 - val_loss: 0.6149\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5532 - val_loss: 0.6136\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5518 - val_loss: 0.6123\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5504 - val_loss: 0.6110\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5491 - val_loss: 0.6098\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5478 - val_loss: 0.6086\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5466 - val_loss: 0.6074\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5454 - val_loss: 0.6063\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5442 - val_loss: 0.6052\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5430 - val_loss: 0.6041\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5420 - val_loss: 0.6031\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5409 - val_loss: 0.6020\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5398 - val_loss: 0.6010\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.5388 - val_loss: 0.6000\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5378 - val_loss: 0.5991\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5368 - val_loss: 0.5981\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5359 - val_loss: 0.5971\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.5349 - val_loss: 0.5962\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5340 - val_loss: 0.5954\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5331 - val_loss: 0.5945\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5322 - val_loss: 0.5937\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5314 - val_loss: 0.5929\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5306 - val_loss: 0.5921\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5298 - val_loss: 0.5912\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.5289 - val_loss: 0.5905\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.5282 - val_loss: 0.5898\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5274 - val_loss: 0.5890\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.5267 - val_loss: 0.5883\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5259 - val_loss: 0.5876\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5252 - val_loss: 0.5868\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.5245 - val_loss: 0.5861\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5238 - val_loss: 0.5854\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5232 - val_loss: 0.5847\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5225 - val_loss: 0.5839\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5218 - val_loss: 0.5832\n",
      "In calc_results: 910, 304, 303, sum = 1517\n",
      "In split_to_train_test: dataset_X.shape=(43130, 10, 65), dataset_y.shape=(43130, 65)\n",
      "Epoch 1/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2696 - val_loss: 0.2531\n",
      "Epoch 2/50\n",
      "405/405 [==============================] - 13s 31ms/step - loss: 0.2555 - val_loss: 0.2467\n",
      "Epoch 3/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2496 - val_loss: 0.2432\n",
      "Epoch 4/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2461 - val_loss: 0.2408\n",
      "Epoch 5/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2434 - val_loss: 0.2388\n",
      "Epoch 6/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2412 - val_loss: 0.2372\n",
      "Epoch 7/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2392 - val_loss: 0.2357\n",
      "Epoch 8/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2374 - val_loss: 0.2342\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 13s 31ms/step - loss: 0.2357 - val_loss: 0.2330\n",
      "Epoch 10/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2340 - val_loss: 0.2318\n",
      "Epoch 11/50\n",
      "405/405 [==============================] - 13s 31ms/step - loss: 0.2325 - val_loss: 0.2307\n",
      "Epoch 12/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2310 - val_loss: 0.2297\n",
      "Epoch 13/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2296 - val_loss: 0.2288\n",
      "Epoch 14/50\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.2283 - val_loss: 0.2279\n",
      "Epoch 15/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2271 - val_loss: 0.2272\n",
      "Epoch 16/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2260 - val_loss: 0.2265\n",
      "Epoch 17/50\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.2251 - val_loss: 0.2260\n",
      "Epoch 18/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2243 - val_loss: 0.2254\n",
      "Epoch 19/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2236 - val_loss: 0.2250\n",
      "Epoch 20/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2230 - val_loss: 0.2247\n",
      "Epoch 21/50\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.2225 - val_loss: 0.2243\n",
      "Epoch 22/50\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.2220 - val_loss: 0.2240\n",
      "Epoch 23/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2216 - val_loss: 0.2238\n",
      "Epoch 24/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2211 - val_loss: 0.2235\n",
      "Epoch 25/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2208 - val_loss: 0.2233\n",
      "Epoch 26/50\n",
      "405/405 [==============================] - 12s 31ms/step - loss: 0.2204 - val_loss: 0.2230\n",
      "Epoch 27/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2201 - val_loss: 0.2228\n",
      "Epoch 28/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2198 - val_loss: 0.2227\n",
      "Epoch 29/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2195 - val_loss: 0.2225\n",
      "Epoch 30/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2192 - val_loss: 0.2224\n",
      "Epoch 31/50\n",
      "405/405 [==============================] - 13s 32ms/step - loss: 0.2190 - val_loss: 0.2222\n",
      "Epoch 32/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2187 - val_loss: 0.2221\n",
      "Epoch 33/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2185 - val_loss: 0.2219\n",
      "Epoch 34/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2182 - val_loss: 0.2218\n",
      "Epoch 35/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2180 - val_loss: 0.2217\n",
      "Epoch 36/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2178 - val_loss: 0.2215\n",
      "Epoch 37/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2176 - val_loss: 0.2214\n",
      "Epoch 38/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2174 - val_loss: 0.2214\n",
      "Epoch 39/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2172 - val_loss: 0.2213\n",
      "Epoch 40/50\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.2170 - val_loss: 0.2211\n",
      "Epoch 41/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2169 - val_loss: 0.2210\n",
      "Epoch 42/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2167 - val_loss: 0.2209\n",
      "Epoch 43/50\n",
      "405/405 [==============================] - 12s 31ms/step - loss: 0.2165 - val_loss: 0.2209\n",
      "Epoch 44/50\n",
      "405/405 [==============================] - 13s 31ms/step - loss: 0.2163 - val_loss: 0.2207\n",
      "Epoch 45/50\n",
      "405/405 [==============================] - 13s 31ms/step - loss: 0.2162 - val_loss: 0.2207\n",
      "Epoch 46/50\n",
      "405/405 [==============================] - 13s 31ms/step - loss: 0.2160 - val_loss: 0.2206\n",
      "Epoch 47/50\n",
      "405/405 [==============================] - 12s 31ms/step - loss: 0.2159 - val_loss: 0.2205\n",
      "Epoch 48/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2158 - val_loss: 0.2204\n",
      "Epoch 49/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2156 - val_loss: 0.2203\n",
      "Epoch 50/50\n",
      "405/405 [==============================] - 12s 29ms/step - loss: 0.2155 - val_loss: 0.2203\n",
      "In calc_results: 25878, 8626, 8626, sum = 43130\n",
      "In split_to_train_test: dataset_X.shape=(5655, 10, 65), dataset_y.shape=(5655, 65)\n",
      "Epoch 1/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.2217 - val_loss: 0.3317\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2173 - val_loss: 0.3281\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2142 - val_loss: 0.3252\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2116 - val_loss: 0.3228\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.2094 - val_loss: 0.3206\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.2074 - val_loss: 0.3188\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 0.2056 - val_loss: 0.3171\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2040 - val_loss: 0.3156\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2025 - val_loss: 0.3143\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.2011 - val_loss: 0.3132\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1998 - val_loss: 0.3122\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1987 - val_loss: 0.3112\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1976 - val_loss: 0.3103\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1966 - val_loss: 0.3096\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1956 - val_loss: 0.3089\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1947 - val_loss: 0.3082\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1939 - val_loss: 0.3077\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 0.1931 - val_loss: 0.3073\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.1923 - val_loss: 0.3068\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 0.1916 - val_loss: 0.3064\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1908 - val_loss: 0.3060\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1902 - val_loss: 0.3057\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1895 - val_loss: 0.3053\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1888 - val_loss: 0.3050\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1882 - val_loss: 0.3047\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1875 - val_loss: 0.3045\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1869 - val_loss: 0.3042\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1863 - val_loss: 0.3040\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 2s 35ms/step - loss: 0.1856 - val_loss: 0.3037\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 2s 32ms/step - loss: 0.1851 - val_loss: 0.3034\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1845 - val_loss: 0.3032\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1839 - val_loss: 0.3030\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1833 - val_loss: 0.3029\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1828 - val_loss: 0.3027\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1822 - val_loss: 0.3025\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1817 - val_loss: 0.3023\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 0.1811 - val_loss: 0.3022\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1806 - val_loss: 0.3020\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1801 - val_loss: 0.3019\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1796 - val_loss: 0.3017\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1791 - val_loss: 0.3016\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1786 - val_loss: 0.3014\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1781 - val_loss: 0.3013\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 0.1777 - val_loss: 0.3011\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1772 - val_loss: 0.3009\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1768 - val_loss: 0.3008\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1763 - val_loss: 0.3006\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1759 - val_loss: 0.3005\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1755 - val_loss: 0.3003\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1751 - val_loss: 0.3001\n",
      "In calc_results: 3393, 1131, 1131, sum = 5655\n",
      "In split_to_train_test: dataset_X.shape=(2469, 10, 65), dataset_y.shape=(2469, 65)\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.4124 - val_loss: 0.5934\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.4053 - val_loss: 0.5885\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3992 - val_loss: 0.5841\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3939 - val_loss: 0.5802\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3891 - val_loss: 0.5767\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3849 - val_loss: 0.5734\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3810 - val_loss: 0.5704\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3775 - val_loss: 0.5676\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3742 - val_loss: 0.5650\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3711 - val_loss: 0.5626\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3682 - val_loss: 0.5602\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3654 - val_loss: 0.5580\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3628 - val_loss: 0.5557\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3602 - val_loss: 0.5534\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3578 - val_loss: 0.5513\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3556 - val_loss: 0.5493\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3534 - val_loss: 0.5473\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3513 - val_loss: 0.5453\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3493 - val_loss: 0.5435\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3474 - val_loss: 0.5417\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3455 - val_loss: 0.5400\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3437 - val_loss: 0.5383\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3420 - val_loss: 0.5367\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3404 - val_loss: 0.5350\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3389 - val_loss: 0.5336\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3374 - val_loss: 0.5321\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3359 - val_loss: 0.5306\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3346 - val_loss: 0.5293\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3333 - val_loss: 0.5279\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3320 - val_loss: 0.5266\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3308 - val_loss: 0.5253\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3296 - val_loss: 0.5241\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3285 - val_loss: 0.5228\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3274 - val_loss: 0.5216\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.3263 - val_loss: 0.5204\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3253 - val_loss: 0.5193\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3243 - val_loss: 0.5181\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3233 - val_loss: 0.5170\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3223 - val_loss: 0.5159\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3214 - val_loss: 0.5149\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3205 - val_loss: 0.5138\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3196 - val_loss: 0.5127\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3188 - val_loss: 0.5118\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3180 - val_loss: 0.5108\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3172 - val_loss: 0.5098\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3164 - val_loss: 0.5088\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3156 - val_loss: 0.5078\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3148 - val_loss: 0.5068\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3141 - val_loss: 0.5059\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3134 - val_loss: 0.5050\n",
      "In calc_results: 1481, 494, 494, sum = 2469\n",
      "In split_to_train_test: dataset_X.shape=(1631, 10, 65), dataset_y.shape=(1631, 65)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.2562 - val_loss: 0.2637\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.2529 - val_loss: 0.2618\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2500 - val_loss: 0.2602\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2475 - val_loss: 0.2587\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2451 - val_loss: 0.2573\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2430 - val_loss: 0.2561\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2411 - val_loss: 0.2549\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2392 - val_loss: 0.2538\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2375 - val_loss: 0.2528\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2358 - val_loss: 0.2519\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2343 - val_loss: 0.2509\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2328 - val_loss: 0.2501\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.2314 - val_loss: 0.2493\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2301 - val_loss: 0.2486\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2288 - val_loss: 0.2479\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2277 - val_loss: 0.2472\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2265 - val_loss: 0.2466\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2254 - val_loss: 0.2460\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2244 - val_loss: 0.2454\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2235 - val_loss: 0.2449\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2225 - val_loss: 0.2444\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2216 - val_loss: 0.2439\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2208 - val_loss: 0.2434\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2200 - val_loss: 0.2429\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2192 - val_loss: 0.2425\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2185 - val_loss: 0.2421\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2178 - val_loss: 0.2416\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2171 - val_loss: 0.2413\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2165 - val_loss: 0.2409\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2159 - val_loss: 0.2405\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2153 - val_loss: 0.2402\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.2148 - val_loss: 0.2398\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.2142 - val_loss: 0.2394\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2137 - val_loss: 0.2391\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2132 - val_loss: 0.2388\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.2127 - val_loss: 0.2385\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.2123 - val_loss: 0.2382\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2118 - val_loss: 0.2379\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.2114 - val_loss: 0.2376\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2109 - val_loss: 0.2373\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2105 - val_loss: 0.2370\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2101 - val_loss: 0.2367\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2097 - val_loss: 0.2364\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2093 - val_loss: 0.2362\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2089 - val_loss: 0.2359\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2086 - val_loss: 0.2356\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.2082 - val_loss: 0.2354\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2078 - val_loss: 0.2351\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.2074 - val_loss: 0.2349\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.2071 - val_loss: 0.2346\n",
      "In calc_results: 979, 326, 326, sum = 1631\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=39175, 39175\n",
      "IN Clustering.split_to_clusters: mask.sum()=2469, 2469\n",
      "IN Clustering.split_to_clusters: mask.sum()=5655, 5655\n",
      "IN Clustering.split_to_clusters: mask.sum()=1085, 1085\n",
      "IN Clustering.split_to_clusters: mask.sum()=1631, 1631\n",
      "IN Clustering.split_to_clusters: mask.sum()=432, 432\n",
      "IN Clustering.split_to_clusters: mask.sum()=3955, 3955\n",
      "In split_to_train_test: dataset_X.shape=(39175, 10, 65), dataset_y.shape=(39175, 65)\n",
      "Epoch 1/50\n",
      "368/368 [==============================] - 12s 33ms/step - loss: 0.2531 - val_loss: 0.2364\n",
      "Epoch 2/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2400 - val_loss: 0.2305\n",
      "Epoch 3/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2343 - val_loss: 0.2272\n",
      "Epoch 4/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2308 - val_loss: 0.2249\n",
      "Epoch 5/50\n",
      "368/368 [==============================] - 11s 31ms/step - loss: 0.2282 - val_loss: 0.2231\n",
      "Epoch 6/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2261 - val_loss: 0.2214\n",
      "Epoch 7/50\n",
      "368/368 [==============================] - 11s 31ms/step - loss: 0.2241 - val_loss: 0.2199\n",
      "Epoch 8/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2223 - val_loss: 0.2185\n",
      "Epoch 9/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2206 - val_loss: 0.2173\n",
      "Epoch 10/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2190 - val_loss: 0.2161\n",
      "Epoch 11/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2175 - val_loss: 0.2150\n",
      "Epoch 12/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2161 - val_loss: 0.2142\n",
      "Epoch 13/50\n",
      "368/368 [==============================] - 12s 31ms/step - loss: 0.2149 - val_loss: 0.2133\n",
      "Epoch 14/50\n",
      "368/368 [==============================] - 11s 31ms/step - loss: 0.2137 - val_loss: 0.2126\n",
      "Epoch 15/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2126 - val_loss: 0.2119\n",
      "Epoch 16/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2116 - val_loss: 0.2113\n",
      "Epoch 17/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2107 - val_loss: 0.2106\n",
      "Epoch 18/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2098 - val_loss: 0.2101\n",
      "Epoch 19/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2090 - val_loss: 0.2096\n",
      "Epoch 20/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2083 - val_loss: 0.2092\n",
      "Epoch 21/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2077 - val_loss: 0.2088\n",
      "Epoch 22/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2072 - val_loss: 0.2085\n",
      "Epoch 23/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2067 - val_loss: 0.2082\n",
      "Epoch 24/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2062 - val_loss: 0.2078\n",
      "Epoch 25/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2058 - val_loss: 0.2076\n",
      "Epoch 26/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2054 - val_loss: 0.2074\n",
      "Epoch 27/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2051 - val_loss: 0.2072\n",
      "Epoch 28/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2048 - val_loss: 0.2070\n",
      "Epoch 29/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2045 - val_loss: 0.2068\n",
      "Epoch 30/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2042 - val_loss: 0.2066\n",
      "Epoch 31/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2040 - val_loss: 0.2065\n",
      "Epoch 32/50\n",
      "368/368 [==============================] - 11s 31ms/step - loss: 0.2037 - val_loss: 0.2064\n",
      "Epoch 33/50\n",
      "368/368 [==============================] - 12s 31ms/step - loss: 0.2035 - val_loss: 0.2062\n",
      "Epoch 34/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2033 - val_loss: 0.2061\n",
      "Epoch 35/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2030 - val_loss: 0.2060\n",
      "Epoch 36/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2029 - val_loss: 0.2058\n",
      "Epoch 37/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2027 - val_loss: 0.2057\n",
      "Epoch 38/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2025 - val_loss: 0.2056\n",
      "Epoch 39/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2023 - val_loss: 0.2055\n",
      "Epoch 40/50\n",
      "368/368 [==============================] - 12s 31ms/step - loss: 0.2021 - val_loss: 0.2055\n",
      "Epoch 41/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2020 - val_loss: 0.2054\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2018 - val_loss: 0.2053\n",
      "Epoch 43/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2017 - val_loss: 0.2052\n",
      "Epoch 44/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2015 - val_loss: 0.2052\n",
      "Epoch 45/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2014 - val_loss: 0.2050\n",
      "Epoch 46/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2013 - val_loss: 0.2050\n",
      "Epoch 47/50\n",
      "368/368 [==============================] - 11s 29ms/step - loss: 0.2011 - val_loss: 0.2049\n",
      "Epoch 48/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2010 - val_loss: 0.2049\n",
      "Epoch 49/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2009 - val_loss: 0.2048\n",
      "Epoch 50/50\n",
      "368/368 [==============================] - 11s 30ms/step - loss: 0.2008 - val_loss: 0.2047\n",
      "In calc_results: 23505, 7835, 7835, sum = 39175\n",
      "In split_to_train_test: dataset_X.shape=(2469, 10, 65), dataset_y.shape=(2469, 65)\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4145 - val_loss: 0.5939\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4071 - val_loss: 0.5895\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4010 - val_loss: 0.5854\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3957 - val_loss: 0.5816\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3911 - val_loss: 0.5782\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3869 - val_loss: 0.5748\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3830 - val_loss: 0.5717\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3794 - val_loss: 0.5689\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3761 - val_loss: 0.5661\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3729 - val_loss: 0.5633\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3700 - val_loss: 0.5607\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3671 - val_loss: 0.5582\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3645 - val_loss: 0.5560\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3619 - val_loss: 0.5539\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3595 - val_loss: 0.5517\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3573 - val_loss: 0.5496\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3551 - val_loss: 0.5476\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3530 - val_loss: 0.5457\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3510 - val_loss: 0.5438\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3490 - val_loss: 0.5419\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3471 - val_loss: 0.5400\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3454 - val_loss: 0.5382\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3436 - val_loss: 0.5366\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3419 - val_loss: 0.5349\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.3403 - val_loss: 0.5333\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3387 - val_loss: 0.5317\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3371 - val_loss: 0.5301\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3357 - val_loss: 0.5285\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3342 - val_loss: 0.5270\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3329 - val_loss: 0.5257\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3315 - val_loss: 0.5243\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3303 - val_loss: 0.5230\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3290 - val_loss: 0.5217\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3278 - val_loss: 0.5205\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3267 - val_loss: 0.5192\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3255 - val_loss: 0.5180\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3245 - val_loss: 0.5168\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3234 - val_loss: 0.5157\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3224 - val_loss: 0.5146\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3214 - val_loss: 0.5135\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3204 - val_loss: 0.5124\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3195 - val_loss: 0.5114\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3186 - val_loss: 0.5104\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3177 - val_loss: 0.5093\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3169 - val_loss: 0.5083\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3161 - val_loss: 0.5073\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3152 - val_loss: 0.5064\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.3145 - val_loss: 0.5055\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3137 - val_loss: 0.5046\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.3130 - val_loss: 0.5038\n",
      "In calc_results: 1481, 494, 494, sum = 2469\n",
      "In split_to_train_test: dataset_X.shape=(5655, 10, 65), dataset_y.shape=(5655, 65)\n",
      "Epoch 1/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2236 - val_loss: 0.3330\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2184 - val_loss: 0.3287\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2148 - val_loss: 0.3254\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2119 - val_loss: 0.3226\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2095 - val_loss: 0.3203\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.2074 - val_loss: 0.3183\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 2s 32ms/step - loss: 0.2056 - val_loss: 0.3165\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 0.2040 - val_loss: 0.3151\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 0.2026 - val_loss: 0.3138\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.2014 - val_loss: 0.3128\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2003 - val_loss: 0.3117\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1992 - val_loss: 0.3109\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1983 - val_loss: 0.3101\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1973 - val_loss: 0.3093\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1965 - val_loss: 0.3086\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1957 - val_loss: 0.3080\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1949 - val_loss: 0.3074\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1941 - val_loss: 0.3069\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 2s 34ms/step - loss: 0.1934 - val_loss: 0.3064\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1927 - val_loss: 0.3059\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1919 - val_loss: 0.3055\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1912 - val_loss: 0.3051\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1906 - val_loss: 0.3047\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1900 - val_loss: 0.3044\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1894 - val_loss: 0.3042\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1888 - val_loss: 0.3039\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1882 - val_loss: 0.3037\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1876 - val_loss: 0.3034\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1871 - val_loss: 0.3032\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1865 - val_loss: 0.3030\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1860 - val_loss: 0.3028\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1855 - val_loss: 0.3026\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1849 - val_loss: 0.3024\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 0.1844 - val_loss: 0.3022\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1838 - val_loss: 0.3021\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1833 - val_loss: 0.3019\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1828 - val_loss: 0.3017\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1823 - val_loss: 0.3015\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 2s 32ms/step - loss: 0.1818 - val_loss: 0.3013\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 2s 32ms/step - loss: 0.1813 - val_loss: 0.3012\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1808 - val_loss: 0.3012\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1803 - val_loss: 0.3011\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1798 - val_loss: 0.3010\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1793 - val_loss: 0.3009\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1789 - val_loss: 0.3007\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1784 - val_loss: 0.3006\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1779 - val_loss: 0.3005\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1775 - val_loss: 0.3003\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1770 - val_loss: 0.3003\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1766 - val_loss: 0.3001\n",
      "In calc_results: 3393, 1131, 1131, sum = 5655\n",
      "In split_to_train_test: dataset_X.shape=(1085, 10, 65), dataset_y.shape=(1085, 65)\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9932 - val_loss: 0.4541\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9878 - val_loss: 0.4511\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9831 - val_loss: 0.4483\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.9787 - val_loss: 0.4457\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9747 - val_loss: 0.4433\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.9709 - val_loss: 0.4410\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.9674 - val_loss: 0.4389\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9641 - val_loss: 0.4369\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9610 - val_loss: 0.4350\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9580 - val_loss: 0.4332\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.9553 - val_loss: 0.4316\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.9526 - val_loss: 0.4300\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9501 - val_loss: 0.4285\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.9477 - val_loss: 0.4271\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9453 - val_loss: 0.4257\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9431 - val_loss: 0.4244\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9410 - val_loss: 0.4231\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9389 - val_loss: 0.4219\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9369 - val_loss: 0.4208\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.9349 - val_loss: 0.4197\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9330 - val_loss: 0.4186\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9311 - val_loss: 0.4176\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9293 - val_loss: 0.4166\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9276 - val_loss: 0.4156\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9259 - val_loss: 0.4146\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9242 - val_loss: 0.4137\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9225 - val_loss: 0.4127\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9209 - val_loss: 0.4118\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9193 - val_loss: 0.4110\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9177 - val_loss: 0.4101\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9162 - val_loss: 0.4093\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9147 - val_loss: 0.4085\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9132 - val_loss: 0.4077\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9118 - val_loss: 0.4070\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9103 - val_loss: 0.4063\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9090 - val_loss: 0.4055\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9076 - val_loss: 0.4048\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9063 - val_loss: 0.4042\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9050 - val_loss: 0.4035\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9038 - val_loss: 0.4028\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9026 - val_loss: 0.4021\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9013 - val_loss: 0.4015\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.9002 - val_loss: 0.4009\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.8991 - val_loss: 0.4002\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.8979 - val_loss: 0.3997\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.8968 - val_loss: 0.3991\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.8958 - val_loss: 0.3985\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.8947 - val_loss: 0.3980\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.8936 - val_loss: 0.3974\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.8926 - val_loss: 0.3969\n",
      "In calc_results: 651, 217, 217, sum = 1085\n",
      "In split_to_train_test: dataset_X.shape=(1631, 10, 65), dataset_y.shape=(1631, 65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.2548 - val_loss: 0.2642\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.2513 - val_loss: 0.2625\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2483 - val_loss: 0.2609\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.2456 - val_loss: 0.2595\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2433 - val_loss: 0.2582\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2412 - val_loss: 0.2571\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2394 - val_loss: 0.2560\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2377 - val_loss: 0.2551\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2361 - val_loss: 0.2541\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2346 - val_loss: 0.2533\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2332 - val_loss: 0.2525\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2318 - val_loss: 0.2517\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.2306 - val_loss: 0.2510\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2294 - val_loss: 0.2503\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2283 - val_loss: 0.2497\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2272 - val_loss: 0.2491\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2262 - val_loss: 0.2485\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2253 - val_loss: 0.2480\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2244 - val_loss: 0.2474\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2235 - val_loss: 0.2469\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2226 - val_loss: 0.2464\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2219 - val_loss: 0.2460\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.2211 - val_loss: 0.2456\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2204 - val_loss: 0.2451\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2196 - val_loss: 0.2447\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2190 - val_loss: 0.2443\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2183 - val_loss: 0.2440\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2177 - val_loss: 0.2436\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2171 - val_loss: 0.2433\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.2165 - val_loss: 0.2429\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2159 - val_loss: 0.2426\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2154 - val_loss: 0.2423\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2148 - val_loss: 0.2419\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2143 - val_loss: 0.2417\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2138 - val_loss: 0.2414\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2133 - val_loss: 0.2411\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.2129 - val_loss: 0.2408\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2124 - val_loss: 0.2405\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2120 - val_loss: 0.2403\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2115 - val_loss: 0.2400\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.2111 - val_loss: 0.2397\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2107 - val_loss: 0.2395\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2103 - val_loss: 0.2393\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2099 - val_loss: 0.2390\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2095 - val_loss: 0.2388\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2092 - val_loss: 0.2385\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2088 - val_loss: 0.2383\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2084 - val_loss: 0.2381\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2081 - val_loss: 0.2378\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2077 - val_loss: 0.2376\n",
      "In calc_results: 979, 326, 326, sum = 1631\n",
      "In split_to_train_test: dataset_X.shape=(432, 10, 65), dataset_y.shape=(432, 65)\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0850 - val_loss: 0.0943\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0831 - val_loss: 0.0920\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0814 - val_loss: 0.0899\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0798 - val_loss: 0.0879\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0783 - val_loss: 0.0862\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0770 - val_loss: 0.0846\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0758 - val_loss: 0.0830\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0746 - val_loss: 0.0815\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0735 - val_loss: 0.0800\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0723 - val_loss: 0.0787\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0713 - val_loss: 0.0773\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0703 - val_loss: 0.0760\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0693 - val_loss: 0.0749\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0684 - val_loss: 0.0737\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0675 - val_loss: 0.0725\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0666 - val_loss: 0.0715\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0658 - val_loss: 0.0704\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0650 - val_loss: 0.0695\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0643 - val_loss: 0.0685\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0635 - val_loss: 0.0676\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0628 - val_loss: 0.0667\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0621 - val_loss: 0.0658\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0615 - val_loss: 0.0650\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0609 - val_loss: 0.0643\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0603 - val_loss: 0.0636\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0597 - val_loss: 0.0630\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0592 - val_loss: 0.0624\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0587 - val_loss: 0.0618\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0582 - val_loss: 0.0611\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0577 - val_loss: 0.0606\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0572 - val_loss: 0.0600\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0567 - val_loss: 0.0595\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0563 - val_loss: 0.0590\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0559 - val_loss: 0.0586\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0554 - val_loss: 0.0582\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0550 - val_loss: 0.0577\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0546 - val_loss: 0.0572\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0542 - val_loss: 0.0568\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0539 - val_loss: 0.0563\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0535 - val_loss: 0.0559\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0531 - val_loss: 0.0555\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0528 - val_loss: 0.0550\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0524 - val_loss: 0.0547\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0521 - val_loss: 0.0544\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0518 - val_loss: 0.0541\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0515 - val_loss: 0.0537\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0512 - val_loss: 0.0534\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0508 - val_loss: 0.0531\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0505 - val_loss: 0.0527\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0503 - val_loss: 0.0524\n",
      "In calc_results: 259, 87, 86, sum = 432\n",
      "In split_to_train_test: dataset_X.shape=(3955, 10, 65), dataset_y.shape=(3955, 65)\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.3194 - val_loss: 0.4864\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.3152 - val_loss: 0.4825\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3117 - val_loss: 0.4792\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.3089 - val_loss: 0.4766\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.3065 - val_loss: 0.4742\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3043 - val_loss: 0.4721\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.3024 - val_loss: 0.4703\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3006 - val_loss: 0.4686\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2990 - val_loss: 0.4671\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2975 - val_loss: 0.4657\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2962 - val_loss: 0.4644\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2950 - val_loss: 0.4632\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2938 - val_loss: 0.4621\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2928 - val_loss: 0.4611\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2918 - val_loss: 0.4601\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2909 - val_loss: 0.4592\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2901 - val_loss: 0.4584\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2893 - val_loss: 0.4577\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2885 - val_loss: 0.4570\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.2879 - val_loss: 0.4564\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.2872 - val_loss: 0.4557\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.2866 - val_loss: 0.4552\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.2860 - val_loss: 0.4546\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.2854 - val_loss: 0.4541\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.2849 - val_loss: 0.4536\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.2844 - val_loss: 0.4531\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.2839 - val_loss: 0.4527\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2834 - val_loss: 0.4523\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2829 - val_loss: 0.4519\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2825 - val_loss: 0.4515\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2820 - val_loss: 0.4512\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2816 - val_loss: 0.4508\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2812 - val_loss: 0.4505\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2808 - val_loss: 0.4502\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2805 - val_loss: 0.4499\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2801 - val_loss: 0.4495\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2797 - val_loss: 0.4493\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2794 - val_loss: 0.4490\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2790 - val_loss: 0.4487\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2787 - val_loss: 0.4485\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2784 - val_loss: 0.4482\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.2780 - val_loss: 0.4480\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.2777 - val_loss: 0.4478\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.2774 - val_loss: 0.4476\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.2771 - val_loss: 0.4474\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.2768 - val_loss: 0.4472\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.2765 - val_loss: 0.4470\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.2762 - val_loss: 0.4468\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.2759 - val_loss: 0.4466\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.2756 - val_loss: 0.4464\n",
      "In calc_results: 2373, 791, 791, sum = 3955\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=3988, 3988\n",
      "IN Clustering.split_to_clusters: mask.sum()=5667, 5667\n",
      "IN Clustering.split_to_clusters: mask.sum()=44747, 44747\n",
      "In split_to_train_test: dataset_X.shape=(3988, 10, 65), dataset_y.shape=(3988, 65)\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.4791 - val_loss: 0.6870\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.4695 - val_loss: 0.6793\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.4620 - val_loss: 0.6727\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4556 - val_loss: 0.6671\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4500 - val_loss: 0.6619\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4452 - val_loss: 0.6574\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.4408 - val_loss: 0.6532\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4368 - val_loss: 0.6493\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 31ms/step - loss: 0.4333 - val_loss: 0.6458\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.4300 - val_loss: 0.6426\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 1s 36ms/step - loss: 0.4269 - val_loss: 0.6396\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.4241 - val_loss: 0.6367\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.4214 - val_loss: 0.6341\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.4189 - val_loss: 0.6317\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.4166 - val_loss: 0.6292\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4143 - val_loss: 0.6271\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.4122 - val_loss: 0.6250\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.4101 - val_loss: 0.6230\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.4082 - val_loss: 0.6210\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.4063 - val_loss: 0.6191\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4046 - val_loss: 0.6173\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4028 - val_loss: 0.6157\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.4012 - val_loss: 0.6140\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3996 - val_loss: 0.6125\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3981 - val_loss: 0.6110\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3966 - val_loss: 0.6095\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3952 - val_loss: 0.6082\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3938 - val_loss: 0.6069\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3924 - val_loss: 0.6056\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3911 - val_loss: 0.6044\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3899 - val_loss: 0.6032\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3886 - val_loss: 0.6021\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3875 - val_loss: 0.6011\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.3863 - val_loss: 0.6000\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.3852 - val_loss: 0.5989\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.3841 - val_loss: 0.5980\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.3830 - val_loss: 0.5971\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3820 - val_loss: 0.5961\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3810 - val_loss: 0.5952\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.3800 - val_loss: 0.5943\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.3790 - val_loss: 0.5934\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.3781 - val_loss: 0.5925\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.3772 - val_loss: 0.5917\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.3763 - val_loss: 0.5909\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.3754 - val_loss: 0.5901\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 1s 33ms/step - loss: 0.3745 - val_loss: 0.5892\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.3737 - val_loss: 0.5885\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.3729 - val_loss: 0.5877\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.3720 - val_loss: 0.5870\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 0.3712 - val_loss: 0.5863\n",
      "In calc_results: 2393, 797, 798, sum = 3988\n",
      "In split_to_train_test: dataset_X.shape=(5667, 10, 65), dataset_y.shape=(5667, 65)\n",
      "Epoch 1/50\n",
      "54/54 [==============================] - 2s 32ms/step - loss: 0.2239 - val_loss: 0.2353\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 2s 33ms/step - loss: 0.2176 - val_loss: 0.2310\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.2130 - val_loss: 0.2276\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.2095 - val_loss: 0.2250\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.2067 - val_loss: 0.2228\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.2043 - val_loss: 0.2210\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.2022 - val_loss: 0.2195\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.2005 - val_loss: 0.2181\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1989 - val_loss: 0.2169\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1974 - val_loss: 0.2158\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1961 - val_loss: 0.2148\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1949 - val_loss: 0.2139\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1938 - val_loss: 0.2130\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1927 - val_loss: 0.2122\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1917 - val_loss: 0.2114\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1907 - val_loss: 0.2107\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1898 - val_loss: 0.2100\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1889 - val_loss: 0.2093\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1880 - val_loss: 0.2086\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 2s 32ms/step - loss: 0.1872 - val_loss: 0.2080\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1864 - val_loss: 0.2073\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1856 - val_loss: 0.2068\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1848 - val_loss: 0.2061\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1840 - val_loss: 0.2056\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1832 - val_loss: 0.2050\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1825 - val_loss: 0.2045\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1818 - val_loss: 0.2039\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1811 - val_loss: 0.2034\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1804 - val_loss: 0.2028\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1797 - val_loss: 0.2023\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1790 - val_loss: 0.2018\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1783 - val_loss: 0.2012\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1776 - val_loss: 0.2007\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1770 - val_loss: 0.2002\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1763 - val_loss: 0.1997\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1757 - val_loss: 0.1993\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1751 - val_loss: 0.1988\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1745 - val_loss: 0.1983\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1739 - val_loss: 0.1979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1733 - val_loss: 0.1975\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1727 - val_loss: 0.1971\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1722 - val_loss: 0.1966\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1716 - val_loss: 0.1962\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1711 - val_loss: 0.1959\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1706 - val_loss: 0.1955\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1701 - val_loss: 0.1951\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1696 - val_loss: 0.1947\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.1691 - val_loss: 0.1944\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 2s 31ms/step - loss: 0.1687 - val_loss: 0.1940\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 2s 29ms/step - loss: 0.1682 - val_loss: 0.1937\n",
      "In calc_results: 3400, 1134, 1133, sum = 5667\n",
      "In split_to_train_test: dataset_X.shape=(44747, 10, 65), dataset_y.shape=(44747, 65)\n",
      "Epoch 1/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2722 - val_loss: 0.2574\n",
      "Epoch 2/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2579 - val_loss: 0.2503\n",
      "Epoch 3/50\n",
      "420/420 [==============================] - 14s 32ms/step - loss: 0.2518 - val_loss: 0.2467\n",
      "Epoch 4/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2482 - val_loss: 0.2443\n",
      "Epoch 5/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2456 - val_loss: 0.2423\n",
      "Epoch 6/50\n",
      "420/420 [==============================] - 12s 30ms/step - loss: 0.2433 - val_loss: 0.2406\n",
      "Epoch 7/50\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.2413 - val_loss: 0.2390\n",
      "Epoch 8/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2394 - val_loss: 0.2376\n",
      "Epoch 9/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2377 - val_loss: 0.2362\n",
      "Epoch 10/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2360 - val_loss: 0.2351\n",
      "Epoch 11/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2345 - val_loss: 0.2339\n",
      "Epoch 12/50\n",
      "420/420 [==============================] - 13s 32ms/step - loss: 0.2330 - val_loss: 0.2329\n",
      "Epoch 13/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2316 - val_loss: 0.2320\n",
      "Epoch 14/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2303 - val_loss: 0.2311\n",
      "Epoch 15/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2290 - val_loss: 0.2303\n",
      "Epoch 16/50\n",
      "420/420 [==============================] - 12s 30ms/step - loss: 0.2280 - val_loss: 0.2297\n",
      "Epoch 17/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2271 - val_loss: 0.2291\n",
      "Epoch 18/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2263 - val_loss: 0.2286\n",
      "Epoch 19/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2257 - val_loss: 0.2283\n",
      "Epoch 20/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2251 - val_loss: 0.2279\n",
      "Epoch 21/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2245 - val_loss: 0.2275\n",
      "Epoch 22/50\n",
      "420/420 [==============================] - 12s 30ms/step - loss: 0.2240 - val_loss: 0.2272\n",
      "Epoch 23/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2236 - val_loss: 0.2270\n",
      "Epoch 24/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2232 - val_loss: 0.2267\n",
      "Epoch 25/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2228 - val_loss: 0.2265\n",
      "Epoch 26/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2224 - val_loss: 0.2263\n",
      "Epoch 27/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2221 - val_loss: 0.2261\n",
      "Epoch 28/50\n",
      "420/420 [==============================] - 12s 30ms/step - loss: 0.2218 - val_loss: 0.2259\n",
      "Epoch 29/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2215 - val_loss: 0.2256\n",
      "Epoch 30/50\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.2212 - val_loss: 0.2256\n",
      "Epoch 31/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2210 - val_loss: 0.2254\n",
      "Epoch 32/50\n",
      "420/420 [==============================] - 12s 30ms/step - loss: 0.2207 - val_loss: 0.2253\n",
      "Epoch 33/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2205 - val_loss: 0.2252\n",
      "Epoch 34/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2203 - val_loss: 0.2250\n",
      "Epoch 35/50\n",
      "420/420 [==============================] - 12s 30ms/step - loss: 0.2201 - val_loss: 0.2248\n",
      "Epoch 36/50\n",
      "420/420 [==============================] - 12s 30ms/step - loss: 0.2199 - val_loss: 0.2248\n",
      "Epoch 37/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2197 - val_loss: 0.2247\n",
      "Epoch 38/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2195 - val_loss: 0.2245\n",
      "Epoch 39/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2193 - val_loss: 0.2245\n",
      "Epoch 40/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2191 - val_loss: 0.2243\n",
      "Epoch 41/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2189 - val_loss: 0.2242\n",
      "Epoch 42/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2188 - val_loss: 0.2242\n",
      "Epoch 43/50\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.2186 - val_loss: 0.2242\n",
      "Epoch 44/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2185 - val_loss: 0.2240\n",
      "Epoch 45/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2183 - val_loss: 0.2239\n",
      "Epoch 46/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2182 - val_loss: 0.2239\n",
      "Epoch 47/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2180 - val_loss: 0.2238\n",
      "Epoch 48/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2179 - val_loss: 0.2238\n",
      "Epoch 49/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2178 - val_loss: 0.2237\n",
      "Epoch 50/50\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.2176 - val_loss: 0.2236\n",
      "In calc_results: 26848, 8950, 8949, sum = 44747\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=44747, 44747\n",
      "IN Clustering.split_to_clusters: mask.sum()=1611, 1611\n",
      "IN Clustering.split_to_clusters: mask.sum()=2497, 2497\n",
      "IN Clustering.split_to_clusters: mask.sum()=2377, 2377\n",
      "IN Clustering.split_to_clusters: mask.sum()=3170, 3170\n",
      "In split_to_train_test: dataset_X.shape=(44747, 10, 65), dataset_y.shape=(44747, 65)\n",
      "Epoch 1/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2718 - val_loss: 0.2569\n",
      "Epoch 2/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2576 - val_loss: 0.2503\n",
      "Epoch 3/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2516 - val_loss: 0.2469\n",
      "Epoch 4/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2480 - val_loss: 0.2444\n",
      "Epoch 5/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2453 - val_loss: 0.2424\n",
      "Epoch 6/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2430 - val_loss: 0.2406\n",
      "Epoch 7/50\n",
      "420/420 [==============================] - 13s 32ms/step - loss: 0.2409 - val_loss: 0.2390\n",
      "Epoch 8/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2390 - val_loss: 0.2375\n",
      "Epoch 9/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2372 - val_loss: 0.2361\n",
      "Epoch 10/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2354 - val_loss: 0.2348\n",
      "Epoch 11/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2338 - val_loss: 0.2337\n",
      "Epoch 12/50\n",
      "420/420 [==============================] - 12s 30ms/step - loss: 0.2322 - val_loss: 0.2326\n",
      "Epoch 13/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2307 - val_loss: 0.2317\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2294 - val_loss: 0.2308\n",
      "Epoch 15/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2282 - val_loss: 0.2300\n",
      "Epoch 16/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2273 - val_loss: 0.2294\n",
      "Epoch 17/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2265 - val_loss: 0.2290\n",
      "Epoch 18/50\n",
      "420/420 [==============================] - 14s 32ms/step - loss: 0.2258 - val_loss: 0.2285\n",
      "Epoch 19/50\n",
      "420/420 [==============================] - 12s 28ms/step - loss: 0.2252 - val_loss: 0.2282\n",
      "Epoch 20/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2247 - val_loss: 0.2277\n",
      "Epoch 21/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2242 - val_loss: 0.2274\n",
      "Epoch 22/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2237 - val_loss: 0.2272\n",
      "Epoch 23/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2233 - val_loss: 0.2269\n",
      "Epoch 24/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2230 - val_loss: 0.2267\n",
      "Epoch 25/50\n",
      "420/420 [==============================] - 13s 32ms/step - loss: 0.2226 - val_loss: 0.2265\n",
      "Epoch 26/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2223 - val_loss: 0.2263\n",
      "Epoch 27/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2220 - val_loss: 0.2261\n",
      "Epoch 28/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2217 - val_loss: 0.2260\n",
      "Epoch 29/50\n",
      "420/420 [==============================] - 12s 30ms/step - loss: 0.2214 - val_loss: 0.2258\n",
      "Epoch 30/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2212 - val_loss: 0.2256\n",
      "Epoch 31/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2209 - val_loss: 0.2256\n",
      "Epoch 32/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2207 - val_loss: 0.2254\n",
      "Epoch 33/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2205 - val_loss: 0.2252\n",
      "Epoch 34/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2202 - val_loss: 0.2251\n",
      "Epoch 35/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2200 - val_loss: 0.2250\n",
      "Epoch 36/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2198 - val_loss: 0.2249\n",
      "Epoch 37/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2196 - val_loss: 0.2248\n",
      "Epoch 38/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2195 - val_loss: 0.2247\n",
      "Epoch 39/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2193 - val_loss: 0.2246\n",
      "Epoch 40/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2191 - val_loss: 0.2246\n",
      "Epoch 41/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2189 - val_loss: 0.2243\n",
      "Epoch 42/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2188 - val_loss: 0.2243\n",
      "Epoch 43/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2186 - val_loss: 0.2242\n",
      "Epoch 44/50\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.2185 - val_loss: 0.2242\n",
      "Epoch 45/50\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.2183 - val_loss: 0.2241\n",
      "Epoch 46/50\n",
      "420/420 [==============================] - 13s 31ms/step - loss: 0.2182 - val_loss: 0.2239\n",
      "Epoch 47/50\n",
      "420/420 [==============================] - 13s 30ms/step - loss: 0.2180 - val_loss: 0.2239\n",
      "Epoch 48/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2179 - val_loss: 0.2238\n",
      "Epoch 49/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2177 - val_loss: 0.2237\n",
      "Epoch 50/50\n",
      "420/420 [==============================] - 12s 29ms/step - loss: 0.2176 - val_loss: 0.2237\n",
      "In calc_results: 26848, 8950, 8949, sum = 44747\n",
      "In split_to_train_test: dataset_X.shape=(1611, 10, 65), dataset_y.shape=(1611, 65)\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.6217 - val_loss: 0.7580\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6167 - val_loss: 0.7542\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6123 - val_loss: 0.7509\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.6084 - val_loss: 0.7477\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6047 - val_loss: 0.7450\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.6015 - val_loss: 0.7426\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5984 - val_loss: 0.7403\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.5956 - val_loss: 0.7381\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5930 - val_loss: 0.7360\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.5906 - val_loss: 0.7341\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.5884 - val_loss: 0.7323\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5863 - val_loss: 0.7306\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5843 - val_loss: 0.7289\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5824 - val_loss: 0.7272\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.5806 - val_loss: 0.7256\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.5789 - val_loss: 0.7242\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.5773 - val_loss: 0.7228\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5757 - val_loss: 0.7215\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5742 - val_loss: 0.7203\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5728 - val_loss: 0.7190\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.5713 - val_loss: 0.7179\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5699 - val_loss: 0.7167\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.5686 - val_loss: 0.7156\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.5673 - val_loss: 0.7145\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5661 - val_loss: 0.7133\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5648 - val_loss: 0.7123\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5636 - val_loss: 0.7113\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5625 - val_loss: 0.7103\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5614 - val_loss: 0.7093\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5603 - val_loss: 0.7084\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5592 - val_loss: 0.7075\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5581 - val_loss: 0.7065\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5571 - val_loss: 0.7056\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5560 - val_loss: 0.7047\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5550 - val_loss: 0.7038\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5540 - val_loss: 0.7029\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5530 - val_loss: 0.7021\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.5521 - val_loss: 0.7012\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5511 - val_loss: 0.7004\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.5502 - val_loss: 0.6995\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.5493 - val_loss: 0.6986\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5484 - val_loss: 0.6978\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5474 - val_loss: 0.6970\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5466 - val_loss: 0.6962\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.5457 - val_loss: 0.6954\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.5448 - val_loss: 0.6946\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.5439 - val_loss: 0.6938\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5430 - val_loss: 0.6929\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.5422 - val_loss: 0.6922\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.5414 - val_loss: 0.6915\n",
      "In calc_results: 967, 322, 322, sum = 1611\n",
      "In split_to_train_test: dataset_X.shape=(2497, 10, 65), dataset_y.shape=(2497, 65)\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2429 - val_loss: 0.2337\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2391 - val_loss: 0.2310\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2359 - val_loss: 0.2287\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2331 - val_loss: 0.2267\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.2307 - val_loss: 0.2250\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2285 - val_loss: 0.2234\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.2265 - val_loss: 0.2220\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.2247 - val_loss: 0.2207\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2231 - val_loss: 0.2195\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2215 - val_loss: 0.2184\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2201 - val_loss: 0.2175\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2187 - val_loss: 0.2166\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2175 - val_loss: 0.2158\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2163 - val_loss: 0.2150\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.2152 - val_loss: 0.2143\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.2141 - val_loss: 0.2137\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.2131 - val_loss: 0.2131\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.2122 - val_loss: 0.2126\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2113 - val_loss: 0.2120\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.2105 - val_loss: 0.2115\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2097 - val_loss: 0.2110\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.2090 - val_loss: 0.2106\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2082 - val_loss: 0.2102\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2076 - val_loss: 0.2097\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2069 - val_loss: 0.2093\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.2063 - val_loss: 0.2090\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2057 - val_loss: 0.2086\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2052 - val_loss: 0.2082\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.2046 - val_loss: 0.2078\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2041 - val_loss: 0.2074\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.2035 - val_loss: 0.2071\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2030 - val_loss: 0.2068\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2025 - val_loss: 0.2064\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2020 - val_loss: 0.2061\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2016 - val_loss: 0.2058\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2011 - val_loss: 0.2055\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2006 - val_loss: 0.2052\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2002 - val_loss: 0.2049\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1998 - val_loss: 0.2046\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1993 - val_loss: 0.2043\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.1989 - val_loss: 0.2040\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1985 - val_loss: 0.2037\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1980 - val_loss: 0.2034\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.1976 - val_loss: 0.2032\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.1972 - val_loss: 0.2029\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1968 - val_loss: 0.2026\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.1964 - val_loss: 0.2023\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1960 - val_loss: 0.2021\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.1957 - val_loss: 0.2018\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1953 - val_loss: 0.2015\n",
      "In calc_results: 1498, 500, 499, sum = 2497\n",
      "In split_to_train_test: dataset_X.shape=(2377, 10, 65), dataset_y.shape=(2377, 65)\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.3884 - val_loss: 0.4501\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3817 - val_loss: 0.4457\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3761 - val_loss: 0.4420\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3711 - val_loss: 0.4386\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3666 - val_loss: 0.4356\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3626 - val_loss: 0.4327\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.3588 - val_loss: 0.4300\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.3553 - val_loss: 0.4275\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3521 - val_loss: 0.4251\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.3490 - val_loss: 0.4229\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.3461 - val_loss: 0.4208\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3434 - val_loss: 0.4188\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3408 - val_loss: 0.4168\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3383 - val_loss: 0.4149\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3360 - val_loss: 0.4131\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3337 - val_loss: 0.4113\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3315 - val_loss: 0.4095\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.3294 - val_loss: 0.4079\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3274 - val_loss: 0.4063\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3255 - val_loss: 0.4047\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3237 - val_loss: 0.4033\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3219 - val_loss: 0.4019\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3202 - val_loss: 0.4006\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.3186 - val_loss: 0.3993\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3170 - val_loss: 0.3981\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 29ms/step - loss: 0.3156 - val_loss: 0.3969\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3142 - val_loss: 0.3958\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3128 - val_loss: 0.3947\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3115 - val_loss: 0.3936\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3103 - val_loss: 0.3927\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3091 - val_loss: 0.3917\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3080 - val_loss: 0.3907\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3069 - val_loss: 0.3898\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3059 - val_loss: 0.3890\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.3049 - val_loss: 0.3881\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3039 - val_loss: 0.3873\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3030 - val_loss: 0.3863\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3021 - val_loss: 0.3855\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.3012 - val_loss: 0.3847\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.3003 - val_loss: 0.3840\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.2995 - val_loss: 0.3833\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2987 - val_loss: 0.3825\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2979 - val_loss: 0.3818\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2971 - val_loss: 0.3811\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2964 - val_loss: 0.3804\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2957 - val_loss: 0.3797\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2950 - val_loss: 0.3791\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2943 - val_loss: 0.3785\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2937 - val_loss: 0.3779\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.2930 - val_loss: 0.3772\n",
      "In calc_results: 1426, 476, 475, sum = 2377\n",
      "In split_to_train_test: dataset_X.shape=(3170, 10, 65), dataset_y.shape=(3170, 65)\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.2116 - val_loss: 0.2968\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.2078 - val_loss: 0.2944\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.2048 - val_loss: 0.2923\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.2023 - val_loss: 0.2905\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.2001 - val_loss: 0.2889\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.1982 - val_loss: 0.2874\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1966 - val_loss: 0.2861\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1951 - val_loss: 0.2850\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1937 - val_loss: 0.2840\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1925 - val_loss: 0.2830\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1914 - val_loss: 0.2821\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1904 - val_loss: 0.2813\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1894 - val_loss: 0.2806\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1885 - val_loss: 0.2798\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.1876 - val_loss: 0.2791\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.1868 - val_loss: 0.2785\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.1860 - val_loss: 0.2779\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1853 - val_loss: 0.2773\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1846 - val_loss: 0.2767\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1839 - val_loss: 0.2762\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1833 - val_loss: 0.2756\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.1826 - val_loss: 0.2751\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1820 - val_loss: 0.2746\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1814 - val_loss: 0.2741\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1808 - val_loss: 0.2737\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1802 - val_loss: 0.2732\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.1796 - val_loss: 0.2728\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1791 - val_loss: 0.2724\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1785 - val_loss: 0.2720\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1780 - val_loss: 0.2715\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1774 - val_loss: 0.2712\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1769 - val_loss: 0.2708\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1764 - val_loss: 0.2704\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.1759 - val_loss: 0.2700\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1753 - val_loss: 0.2696\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1748 - val_loss: 0.2693\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.1743 - val_loss: 0.2689\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1738 - val_loss: 0.2686\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.1733 - val_loss: 0.2682\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1728 - val_loss: 0.2678\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1723 - val_loss: 0.2675\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.1718 - val_loss: 0.2672\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1713 - val_loss: 0.2668\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1709 - val_loss: 0.2665\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1704 - val_loss: 0.2662\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1699 - val_loss: 0.2659\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1694 - val_loss: 0.2656\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1690 - val_loss: 0.2653\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1685 - val_loss: 0.2651\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.1681 - val_loss: 0.2648\n",
      "In calc_results: 1902, 634, 634, sum = 3170\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(54402, 1, 11, 65), labels.shape=(54402,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=40139, 40139\n",
      "IN Clustering.split_to_clusters: mask.sum()=1167, 1167\n",
      "IN Clustering.split_to_clusters: mask.sum()=2497, 2497\n",
      "IN Clustering.split_to_clusters: mask.sum()=2377, 2377\n",
      "IN Clustering.split_to_clusters: mask.sum()=3170, 3170\n",
      "IN Clustering.split_to_clusters: mask.sum()=4608, 4608\n",
      "IN Clustering.split_to_clusters: mask.sum()=444, 444\n",
      "In split_to_train_test: dataset_X.shape=(40139, 10, 65), dataset_y.shape=(40139, 65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "377/377 [==============================] - 12s 31ms/step - loss: 0.2528 - val_loss: 0.2380\n",
      "Epoch 2/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2399 - val_loss: 0.2321\n",
      "Epoch 3/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2343 - val_loss: 0.2288\n",
      "Epoch 4/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2307 - val_loss: 0.2264\n",
      "Epoch 5/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2279 - val_loss: 0.2244\n",
      "Epoch 6/50\n",
      "377/377 [==============================] - 12s 32ms/step - loss: 0.2256 - val_loss: 0.2227\n",
      "Epoch 7/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2236 - val_loss: 0.2211\n",
      "Epoch 8/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2217 - val_loss: 0.2196\n",
      "Epoch 9/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2200 - val_loss: 0.2183\n",
      "Epoch 10/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2183 - val_loss: 0.2172\n",
      "Epoch 11/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2168 - val_loss: 0.2162\n",
      "Epoch 12/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2154 - val_loss: 0.2152\n",
      "Epoch 13/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2142 - val_loss: 0.2143\n",
      "Epoch 14/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2129 - val_loss: 0.2136\n",
      "Epoch 15/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2118 - val_loss: 0.2128\n",
      "Epoch 16/50\n",
      "377/377 [==============================] - 11s 28ms/step - loss: 0.2108 - val_loss: 0.2121\n",
      "Epoch 17/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2098 - val_loss: 0.2115\n",
      "Epoch 18/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2090 - val_loss: 0.2110\n",
      "Epoch 19/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2082 - val_loss: 0.2105\n",
      "Epoch 20/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2076 - val_loss: 0.2100\n",
      "Epoch 21/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2070 - val_loss: 0.2097\n",
      "Epoch 22/50\n",
      "377/377 [==============================] - 12s 31ms/step - loss: 0.2065 - val_loss: 0.2094\n",
      "Epoch 23/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2061 - val_loss: 0.2090\n",
      "Epoch 24/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2057 - val_loss: 0.2088\n",
      "Epoch 25/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2053 - val_loss: 0.2084\n",
      "Epoch 26/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2050 - val_loss: 0.2083\n",
      "Epoch 27/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2047 - val_loss: 0.2081\n",
      "Epoch 28/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2044 - val_loss: 0.2079\n",
      "Epoch 29/50\n",
      "377/377 [==============================] - 11s 28ms/step - loss: 0.2041 - val_loss: 0.2076\n",
      "Epoch 30/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2038 - val_loss: 0.2075\n",
      "Epoch 31/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2036 - val_loss: 0.2073\n",
      "Epoch 32/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2034 - val_loss: 0.2072\n",
      "Epoch 33/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2031 - val_loss: 0.2070\n",
      "Epoch 34/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2029 - val_loss: 0.2069\n",
      "Epoch 35/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2027 - val_loss: 0.2068\n",
      "Epoch 36/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2025 - val_loss: 0.2067\n",
      "Epoch 37/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2023 - val_loss: 0.2065\n",
      "Epoch 38/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2021 - val_loss: 0.2065\n",
      "Epoch 39/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2020 - val_loss: 0.2064\n",
      "Epoch 40/50\n",
      "377/377 [==============================] - 12s 31ms/step - loss: 0.2018 - val_loss: 0.2062\n",
      "Epoch 41/50\n",
      "377/377 [==============================] - 11s 29ms/step - loss: 0.2017 - val_loss: 0.2061\n",
      "Epoch 42/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2015 - val_loss: 0.2060\n",
      "Epoch 43/50\n",
      "377/377 [==============================] - 12s 30ms/step - loss: 0.2013 - val_loss: 0.2059\n",
      "Epoch 44/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2012 - val_loss: 0.2058\n",
      "Epoch 45/50\n",
      "377/377 [==============================] - 13s 34ms/step - loss: 0.2010 - val_loss: 0.2057\n",
      "Epoch 46/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2009 - val_loss: 0.2056\n",
      "Epoch 47/50\n",
      "377/377 [==============================] - 12s 31ms/step - loss: 0.2008 - val_loss: 0.2056\n",
      "Epoch 48/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2007 - val_loss: 0.2055\n",
      "Epoch 49/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2005 - val_loss: 0.2055\n",
      "Epoch 50/50\n",
      "377/377 [==============================] - 11s 30ms/step - loss: 0.2004 - val_loss: 0.2054\n",
      "In calc_results: 24083, 8028, 8028, sum = 40139\n",
      "In split_to_train_test: dataset_X.shape=(1167, 10, 65), dataset_y.shape=(1167, 65)\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 1.0370 - val_loss: 0.4439\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 1.0313 - val_loss: 0.4413\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0261 - val_loss: 0.4389\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0211 - val_loss: 0.4367\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 1.0165 - val_loss: 0.4346\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0121 - val_loss: 0.4327\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 1.0081 - val_loss: 0.4308\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 1.0043 - val_loss: 0.4290\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 1.0008 - val_loss: 0.4273\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9975 - val_loss: 0.4257\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9943 - val_loss: 0.4242\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9913 - val_loss: 0.4228\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9885 - val_loss: 0.4214\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9858 - val_loss: 0.4201\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9832 - val_loss: 0.4188\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9806 - val_loss: 0.4176\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9782 - val_loss: 0.4164\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.9758 - val_loss: 0.4152\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.9735 - val_loss: 0.4141\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.9713 - val_loss: 0.4130\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.9691 - val_loss: 0.4119\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.9670 - val_loss: 0.4108\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.9650 - val_loss: 0.4098\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.9630 - val_loss: 0.4088\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9611 - val_loss: 0.4078\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9592 - val_loss: 0.4068\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9573 - val_loss: 0.4059\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9555 - val_loss: 0.4049\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9537 - val_loss: 0.4040\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9520 - val_loss: 0.4031\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9502 - val_loss: 0.4022\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9485 - val_loss: 0.4014\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9468 - val_loss: 0.4005\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9451 - val_loss: 0.3997\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9435 - val_loss: 0.3989\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9419 - val_loss: 0.3981\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9403 - val_loss: 0.3973\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9387 - val_loss: 0.3966\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9371 - val_loss: 0.3958\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9356 - val_loss: 0.3952\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9341 - val_loss: 0.3945\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9326 - val_loss: 0.3938\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9311 - val_loss: 0.3932\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9296 - val_loss: 0.3926\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9282 - val_loss: 0.3921\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9268 - val_loss: 0.3915\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9255 - val_loss: 0.3909\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.9241 - val_loss: 0.3904\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9228 - val_loss: 0.3899\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 0.9215 - val_loss: 0.3893\n",
      "In calc_results: 700, 234, 233, sum = 1167\n",
      "In split_to_train_test: dataset_X.shape=(2497, 10, 65), dataset_y.shape=(2497, 65)\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2414 - val_loss: 0.2314\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2376 - val_loss: 0.2295\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2344 - val_loss: 0.2278\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2317 - val_loss: 0.2262\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2293 - val_loss: 0.2247\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2271 - val_loss: 0.2234\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2252 - val_loss: 0.2222\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2235 - val_loss: 0.2211\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.2219 - val_loss: 0.2201\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.2204 - val_loss: 0.2192\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2191 - val_loss: 0.2183\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2178 - val_loss: 0.2175\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2167 - val_loss: 0.2167\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2156 - val_loss: 0.2160\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2146 - val_loss: 0.2153\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2136 - val_loss: 0.2147\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2127 - val_loss: 0.2141\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2119 - val_loss: 0.2135\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2111 - val_loss: 0.2130\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2103 - val_loss: 0.2125\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2096 - val_loss: 0.2120\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2089 - val_loss: 0.2115\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2082 - val_loss: 0.2110\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2076 - val_loss: 0.2106\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2070 - val_loss: 0.2102\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.2064 - val_loss: 0.2098\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.2058 - val_loss: 0.2094\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2053 - val_loss: 0.2090\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2048 - val_loss: 0.2086\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2042 - val_loss: 0.2083\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2037 - val_loss: 0.2079\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2032 - val_loss: 0.2076\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2027 - val_loss: 0.2073\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2023 - val_loss: 0.2070\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2018 - val_loss: 0.2066\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2013 - val_loss: 0.2063\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2009 - val_loss: 0.2060\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2004 - val_loss: 0.2057\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.2000 - val_loss: 0.2054\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1996 - val_loss: 0.2051\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1991 - val_loss: 0.2048\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1987 - val_loss: 0.2045\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1983 - val_loss: 0.2043\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1979 - val_loss: 0.2040\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1975 - val_loss: 0.2037\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1971 - val_loss: 0.2035\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1967 - val_loss: 0.2032\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1963 - val_loss: 0.2029\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1959 - val_loss: 0.2027\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1955 - val_loss: 0.2024\n",
      "In calc_results: 1498, 500, 499, sum = 2497\n",
      "In split_to_train_test: dataset_X.shape=(2377, 10, 65), dataset_y.shape=(2377, 65)\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3908 - val_loss: 0.4491\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3837 - val_loss: 0.4450\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3778 - val_loss: 0.4412\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.3725 - val_loss: 0.4378\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3678 - val_loss: 0.4346\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.3635 - val_loss: 0.4316\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.3595 - val_loss: 0.4288\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.3559 - val_loss: 0.4262\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 37ms/step - loss: 0.3525 - val_loss: 0.4238\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3494 - val_loss: 0.4214\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3465 - val_loss: 0.4192\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3438 - val_loss: 0.4171\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3412 - val_loss: 0.4152\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3388 - val_loss: 0.4132\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3365 - val_loss: 0.4114\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3344 - val_loss: 0.4096\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3323 - val_loss: 0.4080\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3303 - val_loss: 0.4064\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3284 - val_loss: 0.4049\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3266 - val_loss: 0.4034\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3249 - val_loss: 0.4021\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3233 - val_loss: 0.4008\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3217 - val_loss: 0.3995\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3202 - val_loss: 0.3982\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3188 - val_loss: 0.3970\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3174 - val_loss: 0.3958\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3160 - val_loss: 0.3947\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3147 - val_loss: 0.3936\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3135 - val_loss: 0.3925\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.3122 - val_loss: 0.3915\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3110 - val_loss: 0.3905\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3099 - val_loss: 0.3895\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3088 - val_loss: 0.3885\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.3077 - val_loss: 0.3876\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3067 - val_loss: 0.3867\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.3057 - val_loss: 0.3859\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3047 - val_loss: 0.3851\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3038 - val_loss: 0.3843\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3029 - val_loss: 0.3835\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.3020 - val_loss: 0.3827\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.3011 - val_loss: 0.3820\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.3002 - val_loss: 0.3813\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.2994 - val_loss: 0.3806\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.2986 - val_loss: 0.3799\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 36ms/step - loss: 0.2978 - val_loss: 0.3792\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2971 - val_loss: 0.3786\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2963 - val_loss: 0.3780\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2956 - val_loss: 0.3774\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.2949 - val_loss: 0.3768\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.2942 - val_loss: 0.3762\n",
      "In calc_results: 1426, 476, 475, sum = 2377\n",
      "In split_to_train_test: dataset_X.shape=(3170, 10, 65), dataset_y.shape=(3170, 65)\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.2098 - val_loss: 0.2955\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.2066 - val_loss: 0.2933\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.2039 - val_loss: 0.2913\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.2016 - val_loss: 0.2897\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1996 - val_loss: 0.2882\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1978 - val_loss: 0.2869\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1962 - val_loss: 0.2858\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1948 - val_loss: 0.2847\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1935 - val_loss: 0.2838\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1923 - val_loss: 0.2830\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1912 - val_loss: 0.2822\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1902 - val_loss: 0.2815\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.1892 - val_loss: 0.2808\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1883 - val_loss: 0.2802\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.1875 - val_loss: 0.2796\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.1867 - val_loss: 0.2790\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.1860 - val_loss: 0.2785\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.1853 - val_loss: 0.2780\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.1846 - val_loss: 0.2775\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1839 - val_loss: 0.2770\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1833 - val_loss: 0.2765\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1827 - val_loss: 0.2761\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1821 - val_loss: 0.2757\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1815 - val_loss: 0.2752\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1810 - val_loss: 0.2748\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1804 - val_loss: 0.2744\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1799 - val_loss: 0.2740\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1794 - val_loss: 0.2736\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1788 - val_loss: 0.2732\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1783 - val_loss: 0.2729\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1778 - val_loss: 0.2725\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1773 - val_loss: 0.2722\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1768 - val_loss: 0.2718\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1763 - val_loss: 0.2714\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1758 - val_loss: 0.2711\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1753 - val_loss: 0.2708\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1749 - val_loss: 0.2705\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1744 - val_loss: 0.2701\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1739 - val_loss: 0.2698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1734 - val_loss: 0.2695\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1730 - val_loss: 0.2692\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.1725 - val_loss: 0.2689\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.1721 - val_loss: 0.2686\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1716 - val_loss: 0.2683\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1711 - val_loss: 0.2680\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1707 - val_loss: 0.2677\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1702 - val_loss: 0.2674\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.1698 - val_loss: 0.2671\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.1694 - val_loss: 0.2668\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1689 - val_loss: 0.2666\n",
      "In calc_results: 1902, 634, 634, sum = 3170\n",
      "In split_to_train_test: dataset_X.shape=(4608, 10, 65), dataset_y.shape=(4608, 65)\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - 2s 35ms/step - loss: 0.3190 - val_loss: 0.5019\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.3139 - val_loss: 0.4975\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.3100 - val_loss: 0.4941\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.3068 - val_loss: 0.4912\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 1s 34ms/step - loss: 0.3041 - val_loss: 0.4888\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.3018 - val_loss: 0.4867\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.2997 - val_loss: 0.4848\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2979 - val_loss: 0.4831\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2962 - val_loss: 0.4816\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2947 - val_loss: 0.4802\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2933 - val_loss: 0.4790\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2921 - val_loss: 0.4779\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.2910 - val_loss: 0.4768\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2899 - val_loss: 0.4759\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2890 - val_loss: 0.4751\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2881 - val_loss: 0.4743\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.2872 - val_loss: 0.4735\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2865 - val_loss: 0.4728\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2858 - val_loss: 0.4722\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2851 - val_loss: 0.4716\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2844 - val_loss: 0.4709\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.2838 - val_loss: 0.4704\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.2832 - val_loss: 0.4698\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2826 - val_loss: 0.4693\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2821 - val_loss: 0.4688\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2816 - val_loss: 0.4684\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.2811 - val_loss: 0.4679\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.2806 - val_loss: 0.4675\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2801 - val_loss: 0.4671\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.2796 - val_loss: 0.4668\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - 2s 36ms/step - loss: 0.2792 - val_loss: 0.4664\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - 2s 34ms/step - loss: 0.2788 - val_loss: 0.4661\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - 2s 35ms/step - loss: 0.2783 - val_loss: 0.4657\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2779 - val_loss: 0.4654\n",
      "Epoch 35/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2775 - val_loss: 0.4651\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2771 - val_loss: 0.4648\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2767 - val_loss: 0.4645\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.2764 - val_loss: 0.4642\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2760 - val_loss: 0.4639\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2756 - val_loss: 0.4637\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2753 - val_loss: 0.4634\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2749 - val_loss: 0.4632\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2746 - val_loss: 0.4629\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2742 - val_loss: 0.4627\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2739 - val_loss: 0.4625\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2736 - val_loss: 0.4623\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2733 - val_loss: 0.4620\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2729 - val_loss: 0.4618\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2726 - val_loss: 0.4616\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2723 - val_loss: 0.4614\n",
      "In calc_results: 2765, 921, 922, sum = 4608\n",
      "In split_to_train_test: dataset_X.shape=(444, 10, 65), dataset_y.shape=(444, 65)\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.1096 - val_loss: 0.0816\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.1080 - val_loss: 0.0798\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.1064 - val_loss: 0.0780\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.1049 - val_loss: 0.0763\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.1035 - val_loss: 0.0747\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.1021 - val_loss: 0.0732\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.1008 - val_loss: 0.0718\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0995 - val_loss: 0.0705\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0983 - val_loss: 0.0692\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0972 - val_loss: 0.0680\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0961 - val_loss: 0.0669\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0950 - val_loss: 0.0659\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0940 - val_loss: 0.0650\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0931 - val_loss: 0.0642\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0921 - val_loss: 0.0634\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0912 - val_loss: 0.0626\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0904 - val_loss: 0.0620\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0896 - val_loss: 0.0614\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0889 - val_loss: 0.0607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0882 - val_loss: 0.0601\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0875 - val_loss: 0.0595\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0868 - val_loss: 0.0590\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0862 - val_loss: 0.0584\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0856 - val_loss: 0.0579\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0850 - val_loss: 0.0573\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0845 - val_loss: 0.0568\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0839 - val_loss: 0.0563\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0834 - val_loss: 0.0558\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0829 - val_loss: 0.0554\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0824 - val_loss: 0.0549\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0820 - val_loss: 0.0544\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0815 - val_loss: 0.0540\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0811 - val_loss: 0.0536\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0806 - val_loss: 0.0532\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0802 - val_loss: 0.0528\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0798 - val_loss: 0.0524\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0794 - val_loss: 0.0520\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0790 - val_loss: 0.0516\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0786 - val_loss: 0.0513\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0782 - val_loss: 0.0509\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0778 - val_loss: 0.0506\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0775 - val_loss: 0.0502\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0771 - val_loss: 0.0499\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0768 - val_loss: 0.0496\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0764 - val_loss: 0.0492\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0761 - val_loss: 0.0489\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0757 - val_loss: 0.0486\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0754 - val_loss: 0.0483\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0751 - val_loss: 0.0481\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0748 - val_loss: 0.0478\n",
      "In calc_results: 266, 89, 89, sum = 444\n"
     ]
    }
   ],
   "source": [
    "# models, results_training \n",
    "# forecasting_training_results = [Forecasting.apply_forecasting_training(dataset, cur_cluster_labels, W=10) for cur_cluster_labels in clusters_labels]\n",
    "# models = [x[0] for x in forecasting_training_results]\n",
    "# results_training = [x[1] for x in forecasting_training_results]\n",
    "# metrics = [x[2] for x in forecasting_training_results]\n",
    "\n",
    "forecasting_training_results = [Forecasting.apply_forecasting_training_simple_version(dataset_train, cur_cluster_labels, W=W) for cur_cluster_labels in clusters_labels]\n",
    "models = [x[0] for x in forecasting_training_results]\n",
    "results_training = [x[1] for x in forecasting_training_results]\n",
    "metrics_training = [x[2] for x in forecasting_training_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_training = results_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(models) == len(results_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = dataset.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results_training[0][:100, 8], label=\"true\")\n",
    "plt.plot(results_training[0][:100, Q+8], label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.title(\"Оригинальные значения\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# # full_results = np.concatenate((results_training, results_testing), axis=0)\n",
    "# # full_results = results_training\n",
    "# full_results = np.concatenate([results_training[:, :2*Q], results_training[:, 4*Q:]], axis=1)\n",
    "# with open(\"output_table_03-24.csv\", \"w\") as fout:\n",
    "#     writer = csv.writer(fout)\n",
    "#     writer.writerow([\"real \"+str(i) for i in range(Q)] + [\"predicted \" + str(i) for i in range(Q)] + [\"cluster_num\", \"mode\"])\n",
    "#     for i in range(full_results.shape[0]):\n",
    "#         writer.writerow(full_results[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52246408 0.81142087 0.72919793 0.9459502  0.56943107 0.91231344\n",
      " 2.05896235]\n",
      "[4.22260260e+01 5.27200977e+01 4.59942123e+01 2.26277702e+12\n",
      " 4.33432110e+01 4.78404195e+01 5.62114210e+01]\n"
     ]
    }
   ],
   "source": [
    "# print(\"weighted mae:\", [x[-1] for x in forecasting_training_results])\n",
    "print(np.mean([x['mae'] for x in metrics_training[2]], axis=1))\n",
    "print(np.mean([x['mase'] for x in metrics_training[2]], axis=1))\n",
    "# plt.plot([x['mae'] for x in metrics_training[0]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_sizes = [[np.sum(cur_clusters_labels == i) for i in range(len(np.unique(cur_clusters_labels)))] for cur_clusters_labels in clusters_labels]\n",
    "N_clusters = len(clusters_sizes)\n",
    "mae_on_max_cluster = np.array([metrics_training[i][np.argmax(clusters_sizes[i])]['mae'] for i in range(len(forecasting_training_results))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m maes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[metrics_training[i][c][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_clusters)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(metrics_training))])\n",
      "Cell \u001b[0;32mIn [98], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m maes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[metrics_training[i][c][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_clusters)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(metrics_training))])\n",
      "Cell \u001b[0;32mIn [98], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m maes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[43mmetrics_training\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_clusters)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(metrics_training))])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "maes = np.array([[metrics_training[i][c]['mae'] for c in range(N_clusters)] for i in range(len(metrics_training))])\n",
    "# weighted_mae = np.array([np.average(maes[i, :, :], weights=clusters_sizes[i], axis=0) for i in range(len(forecasting_training_results))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60331274, 0.55083819, 0.52246408, 0.60562334, 0.55334059,\n",
       "       0.53250796, 0.60643055, 0.55870269, 0.52963843, 0.60638499,\n",
       "       0.56860193, 0.53579372, 0.60497133, 0.57943249, 0.53553123,\n",
       "       0.58466161, 0.58433438, 0.54069749])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mae_on_max_cluster, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_clusters=3\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=387, 387\n",
      "IN Clustering.split_to_clusters: mask.sum()=13206, 13206\n",
      "13/13 [==============================] - 0s 6ms/step\n",
      "413/413 [==============================] - 2s 3ms/step\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=12980, 12980\n",
      "IN Clustering.split_to_clusters: mask.sum()=101, 101\n",
      "IN Clustering.split_to_clusters: mask.sum()=151, 151\n",
      "IN Clustering.split_to_clusters: mask.sum()=361, 361\n",
      "406/406 [==============================] - 1s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=6373, 6373\n",
      "IN Clustering.split_to_clusters: mask.sum()=11, 11\n",
      "IN Clustering.split_to_clusters: mask.sum()=358, 358\n",
      "IN Clustering.split_to_clusters: mask.sum()=6529, 6529\n",
      "IN Clustering.split_to_clusters: mask.sum()=207, 207\n",
      "IN Clustering.split_to_clusters: mask.sum()=115, 115\n",
      "200/200 [==============================] - 1s 3ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "205/205 [==============================] - 1s 3ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=13207, 13207\n",
      "IN Clustering.split_to_clusters: mask.sum()=386, 386\n",
      "413/413 [==============================] - 1s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=157, 157\n",
      "IN Clustering.split_to_clusters: mask.sum()=12977, 12977\n",
      "IN Clustering.split_to_clusters: mask.sum()=359, 359\n",
      "IN Clustering.split_to_clusters: mask.sum()=100, 100\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "406/406 [==============================] - 1s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=130, 130\n",
      "IN Clustering.split_to_clusters: mask.sum()=37, 37\n",
      "IN Clustering.split_to_clusters: mask.sum()=3494, 3494\n",
      "IN Clustering.split_to_clusters: mask.sum()=9577, 9577\n",
      "IN Clustering.split_to_clusters: mask.sum()=355, 355\n",
      "5/5 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "110/110 [==============================] - 1s 4ms/step\n",
      "300/300 [==============================] - 1s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=13208, 13208\n",
      "IN Clustering.split_to_clusters: mask.sum()=385, 385\n",
      "413/413 [==============================] - 1s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=98, 98\n",
      "IN Clustering.split_to_clusters: mask.sum()=358, 358\n",
      "IN Clustering.split_to_clusters: mask.sum()=162, 162\n",
      "IN Clustering.split_to_clusters: mask.sum()=12975, 12975\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "406/406 [==============================] - 2s 3ms/step\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=356, 356\n",
      "IN Clustering.split_to_clusters: mask.sum()=6409, 6409\n",
      "IN Clustering.split_to_clusters: mask.sum()=6496, 6496\n",
      "IN Clustering.split_to_clusters: mask.sum()=123, 123\n",
      "IN Clustering.split_to_clusters: mask.sum()=10, 10\n",
      "IN Clustering.split_to_clusters: mask.sum()=199, 199\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "201/201 [==============================] - 1s 3ms/step\n",
      "203/203 [==============================] - 1s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=13171, 13171\n",
      "IN Clustering.split_to_clusters: mask.sum()=367, 367\n",
      "IN Clustering.split_to_clusters: mask.sum()=55, 55\n",
      "412/412 [==============================] - 1s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=103, 103\n",
      "IN Clustering.split_to_clusters: mask.sum()=13068, 13068\n",
      "IN Clustering.split_to_clusters: mask.sum()=367, 367\n",
      "IN Clustering.split_to_clusters: mask.sum()=55, 55\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "409/409 [==============================] - 1s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=12911, 12911\n",
      "IN Clustering.split_to_clusters: mask.sum()=55, 55\n",
      "IN Clustering.split_to_clusters: mask.sum()=367, 367\n",
      "IN Clustering.split_to_clusters: mask.sum()=103, 103\n",
      "IN Clustering.split_to_clusters: mask.sum()=157, 157\n",
      "404/404 [==============================] - 2s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=13159, 13159\n",
      "IN Clustering.split_to_clusters: mask.sum()=375, 375\n",
      "IN Clustering.split_to_clusters: mask.sum()=59, 59\n",
      "412/412 [==============================] - 1s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=89, 89\n",
      "IN Clustering.split_to_clusters: mask.sum()=13070, 13070\n",
      "IN Clustering.split_to_clusters: mask.sum()=59, 59\n",
      "IN Clustering.split_to_clusters: mask.sum()=375, 375\n",
      "3/3 [==============================] - 2s 4ms/step\n",
      "409/409 [==============================] - 2s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=12901, 12901\n",
      "IN Clustering.split_to_clusters: mask.sum()=375, 375\n",
      "IN Clustering.split_to_clusters: mask.sum()=59, 59\n",
      "IN Clustering.split_to_clusters: mask.sum()=88, 88\n",
      "IN Clustering.split_to_clusters: mask.sum()=170, 170\n",
      "404/404 [==============================] - 1s 2ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "N_clusters=3\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=464, 464\n",
      "IN Clustering.split_to_clusters: mask.sum()=13129, 13129\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "411/411 [==============================] - 1s 3ms/step\n",
      "N_clusters=5\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=13129, 13129\n",
      "IN Clustering.split_to_clusters: mask.sum()=121, 121\n",
      "IN Clustering.split_to_clusters: mask.sum()=343, 343\n",
      "411/411 [==============================] - 1s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "N_clusters=7\n",
      "dataset_windows.shape=(13593, 1, 11, 65), labels.shape=(13593,)\n",
      "IN Clustering.split_to_clusters: mask.sum()=12935, 12935\n",
      "IN Clustering.split_to_clusters: mask.sum()=121, 121\n",
      "IN Clustering.split_to_clusters: mask.sum()=343, 343\n",
      "IN Clustering.split_to_clusters: mask.sum()=194, 194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/405 [==============================] - 1s 2ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results_testing = [Forecasting.predict_through_clusters(dataset_test, clustering_algorithms[i], models[i], W=W) for i in range(len(results_training))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results1 = [np.concatenate((\n",
    "                    results_training[i],\n",
    "                    np.concatenate((dataset_test[W:], results_testing[i]), axis=1)\n",
    "                    ),\n",
    "                    axis=0\n",
    "                ) for i in range(len(results_training))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp\n",
    "# full_results1 = results_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_metrics = [Forecasting.calc_metrics_for_full_results(x) for x in full_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 7, 3, 5, 7, 3, 5, 7, 3, 5, 7, 3, 5, 7, 3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "# global_metrics\n",
    "clusters_sizes = [np.array([np.sum(x[:, -2] == i) for i in range(len(np.unique(x[:, -2])))]) for x in full_results]\n",
    "N_clusters = [len(x) for x in clusters_sizes]\n",
    "print(N_clusters)\n",
    "# mae_on_max_cluster = np.array([global_metrics[i][np.argmax(clusters_sizes[i])]['mae'] for i in range(len(full_results))])\n",
    "# mae_mean = np.array([np.mean(global_metrics[i][np.argmax(clusters_sizes[i])]['mae']) for i in range(full_results)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes = np.array([global_metrics[i]['mae'] for i in range(len(forecasting_training_results))])\n",
    "mae_on_max_cluster = np.array([\n",
    "        Forecasting.calc_metrics_for_full_results(\n",
    "            full_results[i][full_results[i][:, -2] == np.argmax(clusters_sizes[i])]\n",
    "        )['mae'] \n",
    "    for i in range(len(full_results))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[3 5 7]\n",
      "  [3 5 7]\n",
      "  [3 5 7]]\n",
      "\n",
      " [[3 5 7]\n",
      "  [3 5 7]\n",
      "  [3 5 7]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(N_clusters).reshape(2, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02 , 0.033, 0.012, ..., 0.106, 0.632, 0.097],\n",
       "       [0.021, 0.035, 0.012, ..., 0.108, 0.636, 0.098],\n",
       "       [0.022, 0.036, 0.012, ..., 0.11 , 0.637, 0.099],\n",
       "       ...,\n",
       "       [0.02 , 0.033, 0.012, ..., 0.106, 0.631, 0.097],\n",
       "       [0.021, 0.034, 0.012, ..., 0.108, 0.634, 0.098],\n",
       "       [0.021, 0.035, 0.012, ..., 0.11 , 0.638, 0.099]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(maes1, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.712 0.643 0.598]\n",
      "  [0.72  0.722 0.609]\n",
      "  [0.721 0.658 0.634]]\n",
      "\n",
      " [[0.673 0.673 0.604]\n",
      "  [0.688 0.687 0.625]\n",
      "  [0.725 0.689 0.596]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.around(np.mean(mae_on_max_cluster, axis=1).reshape(2, 3, 3),decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.mean(mae_on_max_cluster1, axis=1), label=\"on max cluster\")\n",
    "plt.plot(np.mean(maes1, axis=1), label=\"global mae\")\n",
    "plt.legend()\n",
    "plt.title(\"Average mae\")\n",
    "plt.ylabel(\"mae\")\n",
    "plt.xlabel(\"Number of experiment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind1 = np.argmin(np.mean(mae_on_max_cluster, axis=1))\n",
    "ind1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Размеры кластеров')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(clusters_labels[ind1])\n",
    "plt.title(\"Размеры кластеров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.64468772985432"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(global_metrics[ind1]['mase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f44b1ecc1f0>]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([np.mean(x['mase']) for x in global_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 51.17009220465165)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2 = np.argmin([np.mean(x['mase']) for x in global_metrics])\n",
    "ind2, np.mean(global_metrics[ind2]['mase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование (старое)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#номер сохраняемого эксперимента\n",
    "IND = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# tmp = np.concatenate((dataset_test[W:], results_testing[0]), axis=1)\n",
    "# full_results = np.zeros((results_training.shape[0] + results_testing.shape[0], results_training))\n",
    "# full_results = np.concatenate((results_training[0], tmp), axis=0)\n",
    "# full_results = results_training\n",
    "# full_results = np.concatenate([results_training[:, :2*Q], results_training[:, 4*Q:]], axis=1)\n",
    "with open(\"output_table_04-06_for60_5.csv\", \"w\") as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    writer.writerow([\"real \"+str(i) for i in range(Q)] + [\"predicted \" + str(i) for i in range(Q)] + [\"cluster_num\", \"mode\"])\n",
    "    for i in range(full_results1[IND].shape[0]):\n",
    "        writer.writerow(full_results1[IND][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mae_on_max_cluster, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.mean([x[-1] for x in forecasting_training_results], axis=1), label=\"weighted MAE\")\n",
    "# plt.plot(np.mean(mae_on_max_cluster, axis=1), label=\"MAE on max cluster\")\n",
    "# plt.legend()\n",
    "# plt.title(\"MAE on different cluster algorithms\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_results1 = [Clustering.apply_clustering(dataset, cur_cluster_alg) for cur_cluster_alg in [Clustering.MeanShift_for_windows(W=W) for W in window_sizes_for_clustering]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_labels1 = [x[0] for x in clustering_results1]\n",
    "\n",
    "clusters_sizes1 = [[np.sum(cur_clusters_labels == i) for i in range(len(np.unique(cur_clusters_labels)))] for cur_clusters_labels in clusters_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clusters_labels1[-1])\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(np.mean(mae_on_max_cluster, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"dif\":True, \n",
    "              \"cluster_algs\":clustering_algorithms}\n",
    "# models, model_mae, results_training = Forecasting.try_parameters(parameters, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((5, 4))\n",
    "sc = Forecasting.MyStandardScaler()\n",
    "sc.fit(a)\n",
    "sc.transform(a)\n",
    "sc.mean, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for i, file_name in enumerate(list(os.listdir(\"scalers\"))):\n",
    "    os.unlink(\"scalers/\"+file_name)\n",
    "for i in range(len(models['scalers'])):\n",
    "    with open(\"scalers/\"+str(i)+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(models['scalers'][i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.unlink(\"clusters_model.pkl\")\n",
    "with open(\"clusters_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(models['clusters_model'], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "for i, file_name in enumerate(list(os.listdir(\"models\"))):\n",
    "    shutil.rmtree(\"models/\"+file_name)\n",
    "for i in range(len(models['models'])):\n",
    "    if not isinstance(models['models'][i], int):\n",
    "        models['models'][i].save(\"models/\"+str(i))\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "N_clusters = len(os.listdir('models'))\n",
    "assert(len(os.listdir('scalers')) == N_clusters)\n",
    "models = {'models':[], 'clusters_model':[], 'scalers':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "for file_name in os.listdir('models'):\n",
    "    models['models'].append(keras.models.load_model('models/'+file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir('scalers'):\n",
    "    with open('scalers/'+file_name, 'rb') as f:\n",
    "        models['scalers'].append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clusters_model.pkl', 'rb') as f:\n",
    "    models['clusters_model'] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_model = models[\"clusters_model\"]\n",
    "forecasting_models = models['models']\n",
    "scalers = models['scalers']\n",
    "assert(len(forecasting_models) == len(scalers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_clusters = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_windows = sliding_window_view(dataset_train, (window_size_clustering, dataset_train.shape[-1])) #(N, 1, W, Q)\n",
    "# new_shape = dataset_windows.shape\n",
    "# dataset_windows = dataset_windows.reshape(new_shape[0], new_shape[2] * new_shape[3])\n",
    "# cluster_nums = clusters_model.labels_\n",
    "# print(f\"{dataset.shape=}, {dataset_windows.shape=}, {cluster_nums.shape=}, {dataset.shape[0] - dataset_windows.shape[0]}\")\n",
    "# cluster_nums = np.pad(cluster_nums, (dataset.shape[0] - dataset_windows.shape[0], 0), mode='constant', constant_values=(cluster_nums[0])) #-1\n",
    "# print(f\"After pad: {dataset.shape=}, {cluster_nums.shape=}\")\n",
    "# # if window_size_clustering > window_size_forecasting:\n",
    "# #     cluster_num = np.pad(cluster_nums, (0, ), mode='constant', constant_values=(cluster_nums[-1]))\n",
    "# y_pred = np.zeros((dataset.shape[0] - window_size_forecasting, dataset.shape[-1]))\n",
    "# #only if dif then +1\n",
    "# dataset_windows = sliding_window_view(dataset, (window_size_forecasting + 1, dataset.shape[-1]))\n",
    "# cluster_nums = cluster_nums[window_size_forecasting:] #+1\n",
    "    \n",
    "# full_results = np.zeros((cluster_nums.shape[0], 2 * dataset_train.shape[-1] + 2)) # real_Q, Q, cluster_num, mask\n",
    "\n",
    "# for cluster_num in range(N_clusters):\n",
    "#     mask = (cluster_nums == cluster_num)\n",
    "#     if np.sum(mask) == 0:\n",
    "#         continue\n",
    "\n",
    "#     cur_windows = dataset_windows[mask, 0, ...] #(M, Wf, Q)\n",
    "#     scalers[cluster_num].save_first_elements(cur_windows)\n",
    "#     cur_windows = np.array(scalers[cluster_num].transform(cur_windows))\n",
    "#     cur_pred = np.array(prediction_models[cluster_num](cur_windows)) #(M, Q)\n",
    "#     cur_pred = scalers[cluster_num].inverse_transform(cur_pred)\n",
    "#     cur_pred = scalers[cluster_num].add_first_elements(cur_pred)\n",
    "#     y_pred[mask] = cur_pred\n",
    "#     Q = dataset.shape[-1]\n",
    "#     full_results[mask, Q:2 * Q] = cur_pred\n",
    "#     full_results[mask, 2 * Q] = cluster_num\n",
    "#     full_results[mask, 2 * Q + 1] = 3 #global test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_size_for_clustering = clusters_model.cluster_centers_.shape[-1] // dataset_test.shape[-1]\n",
    "window_size_for_clustering = window_sizes_for_clustering[0]\n",
    "y_pred, results_testing = Forecasting.predict_through_clusters(dataset_test, clusters_model, forecasting_models, scalers, window_size_clustering=window_size_for_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#лучшие параметры\n",
    "window_size_for_clustering, len(forecasting_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape, dataset.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{y_pred.shape=}, {dataset_test.shape=}\")\n",
    "y_true = dataset_test[-y_pred.shape[0]:]\n",
    "print(y_true.shape, results_testing[:, :dataset_train.shape[-1]].shape)\n",
    "results_testing[:, :dataset_train.shape[-1]] = y_true\n",
    "cur_mase = Forecasting.my_mase(y_true, y_pred, multioutput='raw_values')\n",
    "cur_mae = Forecasting.my_mae(y_true, y_pred, multioutput=\"raw_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = dataset_train.shape[-1]\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# full_results = np.concatenate((results_training, results_testing), axis=0)\n",
    "full_results = results_training\n",
    "with open(\"output_table_03-23.csv\", \"w\") as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    writer.writerow([\"real \"+str(i) for i in range(Q)] + [\"predicted \" + str(i) for i in range(Q)] + [\"cluster_num\", \"mode\"])\n",
    "    for i in range(full_results.shape[0]):\n",
    "        writer.writerow(full_results[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_mase, cur_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cur_mase <= np.percentile(cur_mase, 60)\n",
    "plt.plot(np.arange(cur_mase.shape[0])[mask], cur_mase[mask])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cur_mae <= np.percentile(cur_mae, 60)\n",
    "# plt.plot(np.arange(cur_mae.shape[0])[mask], cur_mae[mask])\n",
    "plt.plot(cur_mae[mask])\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.title(\"best MAE\")\n",
    "# plt.show()\n",
    "plt.savefig(\"best MAE.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"50% best MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_mape = mape(y_true, y_pred)\n",
    "plt.plot(cur_mape[cur_mape < np.percentile(cur_mape, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"50% best MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мелкое тестирование**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, Q = 1000, 10\n",
    "# test_array = (np.random.random((N * Q)) + np.sin(np.arange(N * Q) / 100)).reshape(N, Q)\n",
    "test_array = (np.sin(np.arange(N*Q)/100) * 5).reshape(N, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 5\n",
    "sc = Forecasting.MyStandardScaler()\n",
    "clusters_X, clusters_labels = Clustering.split_to_clusters(test_array, np.zeros(test_array.shape[0]), W=W + 2)\n",
    "test_array_windows = clusters_X[0]\n",
    "X_true, y_true = Forecasting.split_X_y(test_array_windows)\n",
    "prepared_array = sc.fit_transform(test_array_windows)\n",
    "prepared_X, prepared_y = Forecasting.split_X_y(prepared_array)\n",
    "y_changed = sc.inverse_transform(prepared_y)\n",
    "# array_changed = sc.inverse_transform(prepared_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_true[:100, 0], label=\"true\")\n",
    "plt.plot(prepared_y[:100, 0], label=\"transformed\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(y_true - y_changed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.zeros(N)\n",
    "# test_labels[test_array[:, 0] <= np.percentile(test_array, 50)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, test_results, _ = Forecasting.apply_forecasting_training_simple_version(test_array, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = test_array.shape[-1]\n",
    "plt.plot(test_results[:40, 0], label=\"true\")\n",
    "plt.plot(test_results[:40, Q], label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"output_table_03-22.csv\", \"w\") as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    writer.writerow([\"real \"+str(i) for i in range(Q)] + [\"predicted \" + str(i) for i in range(Q)] + [\"cluster_num\", \"mode\"])\n",
    "    for i in range(test_results.shape[0]):\n",
    "        writer.writerow(test_results[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anna",
   "language": "python",
   "name": "anna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
