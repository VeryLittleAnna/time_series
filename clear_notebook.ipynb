{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSet2.csv\", sep=\";\")#, parse_dates=['Timestamp']) #, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "df = data.groupby(data.index // K).mean() #усреднение\n",
    "df_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError, MeanAbsolutePercentageError\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mase = MeanAbsoluteScaledError(multioutput='raw_values')\n",
    "mase_uni = MeanAbsoluteScaledError(multioutput='uniform_average')\n",
    "mape = MeanAbsolutePercentageError(multioutput='raw_values')\n",
    "# mae = MeanAbsoluteError()\n",
    "\n",
    "\n",
    "#if ‘raw_values’, returns a full set of errors in case of multioutput input. If ‘uniform_average’, errors of all outputs are averaged with uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes_for_clustering = [1, 3, 5, 10]\n",
    "Ns_clusters = [2, 5, 7, 9, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns_clusters = [7]\n",
    "window_sizes_for_clustering = [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 67)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_np[:, :]\n",
    "# dataset = np.concatenate((dataset[:, :8], dataset[:, 9:]), axis=1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=2, 2, 21, (24, 67)\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 2.5459 - val_loss: 2.5625\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5408 - val_loss: 2.5571\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.5359 - val_loss: 2.5516\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.5310 - val_loss: 2.5459\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.5263 - val_loss: 2.5402\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.5217 - val_loss: 2.5346\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.5173 - val_loss: 2.5291\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5130 - val_loss: 2.5237\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5088 - val_loss: 2.5184\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5050 - val_loss: 2.5134\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.5012 - val_loss: 2.5088\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4975 - val_loss: 2.5043\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4938 - val_loss: 2.4999\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4901 - val_loss: 2.4958\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4864 - val_loss: 2.4918\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4827 - val_loss: 2.4878\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.4791 - val_loss: 2.4840\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4755 - val_loss: 2.4802\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4719 - val_loss: 2.4764\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4682 - val_loss: 2.4727\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.4646 - val_loss: 2.4690\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4610 - val_loss: 2.4653\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4573 - val_loss: 2.4616\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4536 - val_loss: 2.4578\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.4499 - val_loss: 2.4541\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4461 - val_loss: 2.4504\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4423 - val_loss: 2.4467\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4385 - val_loss: 2.4429\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4347 - val_loss: 2.4391\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.4308 - val_loss: 2.4354\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4268 - val_loss: 2.4316\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4228 - val_loss: 2.4277\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4188 - val_loss: 2.4239\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4148 - val_loss: 2.4200\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4107 - val_loss: 2.4161\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.4066 - val_loss: 2.4121\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.4024 - val_loss: 2.4080\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3981 - val_loss: 2.4039\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3938 - val_loss: 2.3997\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3894 - val_loss: 2.3954\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 465053987699.31793, my average MASE = 465053987699.31793\n",
      "Cluster 0, 465053987699.31793\n",
      "Before prediction: train_X.shape=(18359, 10, 67), train_y.shape=(18359, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.5283 - val_loss: 0.5190\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2848 - val_loss: 0.4396\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2150 - val_loss: 0.3804\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1720 - val_loss: 0.3387\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.1442 - val_loss: 0.3085\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.1262 - val_loss: 0.2868\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1133 - val_loss: 0.2681\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1031 - val_loss: 0.2523\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0948 - val_loss: 0.2398\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0877 - val_loss: 0.2291\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0820 - val_loss: 0.2212\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.0771 - val_loss: 0.2147\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.0730 - val_loss: 0.2084\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0693 - val_loss: 0.2030\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0661 - val_loss: 0.1974\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0633 - val_loss: 0.1926\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0607 - val_loss: 0.1872\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0583 - val_loss: 0.1826\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0561 - val_loss: 0.1785\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0541 - val_loss: 0.1751\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0522 - val_loss: 0.1715\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0506 - val_loss: 0.1682\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0491 - val_loss: 0.1653\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0478 - val_loss: 0.1624\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0466 - val_loss: 0.1593\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0455 - val_loss: 0.1571\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0445 - val_loss: 0.1546\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0436 - val_loss: 0.1517\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0427 - val_loss: 0.1496\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0419 - val_loss: 0.1470\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0411 - val_loss: 0.1449\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0404 - val_loss: 0.1427\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0397 - val_loss: 0.1402\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0391 - val_loss: 0.1389\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0384 - val_loss: 0.1369\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0378 - val_loss: 0.1345\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0373 - val_loss: 0.1326\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0367 - val_loss: 0.1311\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0362 - val_loss: 0.1298\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0357 - val_loss: 0.1279\n",
      "192/192 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 512807664.71274936, my average MASE = 512807664.71274936\n",
      "Cluster 1, 512807664.71274936\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=5, 5, 91, (65, 67)\n",
      "Before prediction: train_X.shape=(33, 10, 67), train_y.shape=(33, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2708 - val_loss: 1.2045\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2671 - val_loss: 1.2019\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2634 - val_loss: 1.1993\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2597 - val_loss: 1.1968\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2560 - val_loss: 1.1942\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2523 - val_loss: 1.1918\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2486 - val_loss: 1.1894\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2450 - val_loss: 1.1871\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2413 - val_loss: 1.1848\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2376 - val_loss: 1.1826\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2340 - val_loss: 1.1803\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2304 - val_loss: 1.1780\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2267 - val_loss: 1.1758\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2231 - val_loss: 1.1736\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2196 - val_loss: 1.1714\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2161 - val_loss: 1.1692\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2127 - val_loss: 1.1671\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2092 - val_loss: 1.1649\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2058 - val_loss: 1.1628\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2024 - val_loss: 1.1607\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1989 - val_loss: 1.1587\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1955 - val_loss: 1.1566\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1921 - val_loss: 1.1546\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1886 - val_loss: 1.1526\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1852 - val_loss: 1.1507\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1818 - val_loss: 1.1487\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1783 - val_loss: 1.1467\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1748 - val_loss: 1.1447\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1714 - val_loss: 1.1428\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1680 - val_loss: 1.1408\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1645 - val_loss: 1.1388\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1611 - val_loss: 1.1369\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1577 - val_loss: 1.1349\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1542 - val_loss: 1.1330\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1508 - val_loss: 1.1310\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1475 - val_loss: 1.1291\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1442 - val_loss: 1.1272\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1409 - val_loss: 1.1252\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1376 - val_loss: 1.1233\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1344 - val_loss: 1.1213\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 568043604964.5398, my average MASE = 568043604964.5398\n",
      "Cluster 0, 568043604964.5398\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.3115 - val_loss: 1.2084\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.2951 - val_loss: 1.1944\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.2791 - val_loss: 1.1809\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.2635 - val_loss: 1.1677\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2482 - val_loss: 1.1550\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.2333 - val_loss: 1.1427\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.2190 - val_loss: 1.1309\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2053 - val_loss: 1.1196\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.1922 - val_loss: 1.1086\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.1797 - val_loss: 1.0978\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.1675 - val_loss: 1.0872\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.1557 - val_loss: 1.0769\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.1443 - val_loss: 1.0667\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.1332 - val_loss: 1.0567\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.1224 - val_loss: 1.0467\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.1118 - val_loss: 1.0371\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.1014 - val_loss: 1.0279\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.0911 - val_loss: 1.0187\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.0810 - val_loss: 1.0095\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.0710 - val_loss: 1.0002\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.0611 - val_loss: 0.9908\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.0513 - val_loss: 0.9817\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.0416 - val_loss: 0.9726\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.0322 - val_loss: 0.9639\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.0230 - val_loss: 0.9555\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.0139 - val_loss: 0.9472\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.0049 - val_loss: 0.9389\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.9960 - val_loss: 0.9307\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9873 - val_loss: 0.9227\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.9788 - val_loss: 0.9148\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9705 - val_loss: 0.9072\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.9622 - val_loss: 0.8998\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.9540 - val_loss: 0.8926\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.9456 - val_loss: 0.8853\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.9373 - val_loss: 0.8780\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9289 - val_loss: 0.8707\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.9204 - val_loss: 0.8635\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.9117 - val_loss: 0.8563\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.9030 - val_loss: 0.8490\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.8942 - val_loss: 0.8416\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 59096593859.47234, my average MASE = 59096593859.47234\n",
      "Cluster 1, 59096593859.47234\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.5370 - val_loss: 0.5056\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.4818 - val_loss: 0.4726\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4318 - val_loss: 0.4392\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.3858 - val_loss: 0.4091\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.3435 - val_loss: 0.3803\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.3071 - val_loss: 0.3561\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2771 - val_loss: 0.3345\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.2507 - val_loss: 0.3120\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.2265 - val_loss: 0.2965\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.2058 - val_loss: 0.2878\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1869 - val_loss: 0.2796\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1700 - val_loss: 0.2722\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1559 - val_loss: 0.2654\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1444 - val_loss: 0.2577\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1343 - val_loss: 0.2527\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1263 - val_loss: 0.2502\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1200 - val_loss: 0.2465\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1144 - val_loss: 0.2436\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1094 - val_loss: 0.2407\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1053 - val_loss: 0.2384\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1021 - val_loss: 0.2357\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0994 - val_loss: 0.2336\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0973 - val_loss: 0.2319\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0953 - val_loss: 0.2305\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.2299\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0921 - val_loss: 0.2290\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0907 - val_loss: 0.2287\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0895 - val_loss: 0.2284\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0882 - val_loss: 0.2282\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0871 - val_loss: 0.2279\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0861 - val_loss: 0.2280\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0851 - val_loss: 0.2279\n",
      "Epoch 32: early stopping\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 446650662815.4875, my average MASE = 446650662815.4875\n",
      "Cluster 2, 446650662815.4875\n",
      "Before prediction: train_X.shape=(2219, 10, 67), train_y.shape=(2219, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.5170 - val_loss: 0.4604\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4674 - val_loss: 0.4487\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4234 - val_loss: 0.4377\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3806 - val_loss: 0.4270\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3439 - val_loss: 0.4180\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3154 - val_loss: 0.4095\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.2918 - val_loss: 0.4018\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.2710 - val_loss: 0.3942\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.2524 - val_loss: 0.3870\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.2356 - val_loss: 0.3801\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.2210 - val_loss: 0.3741\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.2077 - val_loss: 0.3684\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.1956 - val_loss: 0.3628\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.1848 - val_loss: 0.3574\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.1755 - val_loss: 0.3523\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1675 - val_loss: 0.3470\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.1601 - val_loss: 0.3414\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.1532 - val_loss: 0.3359\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.1468 - val_loss: 0.3305\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.1410 - val_loss: 0.3251\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.1360 - val_loss: 0.3201\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.1314 - val_loss: 0.3159\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.1271 - val_loss: 0.3116\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.1232 - val_loss: 0.3081\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.1195 - val_loss: 0.3046\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.1160 - val_loss: 0.3011\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.1126 - val_loss: 0.2977\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.1095 - val_loss: 0.2946\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.1065 - val_loss: 0.2915\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.1036 - val_loss: 0.2887\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.1009 - val_loss: 0.2859\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.0984 - val_loss: 0.2840\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0961 - val_loss: 0.2810\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.0939 - val_loss: 0.2791\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.0919 - val_loss: 0.2772\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.0900 - val_loss: 0.2752\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.0883 - val_loss: 0.2731\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.0866 - val_loss: 0.2714\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0850 - val_loss: 0.2697\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.0834 - val_loss: 0.2683\n",
      "24/24 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 75606485.68781136, my average MASE = 75606485.68781136\n",
      "Cluster 3, 75606485.68781136\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=7, 7, 325, (1, 67)\n",
      "Before prediction: train_X.shape=(60, 10, 67), train_y.shape=(60, 67), test_X.shape=(20, 10, 67), test_y.shape=(20, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7377 - val_loss: 0.6867\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7335 - val_loss: 0.6833\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7295 - val_loss: 0.6800\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7255 - val_loss: 0.6767\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7216 - val_loss: 0.6735\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7178 - val_loss: 0.6703\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7141 - val_loss: 0.6672\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7104 - val_loss: 0.6641\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7067 - val_loss: 0.6610\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7031 - val_loss: 0.6580\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6996 - val_loss: 0.6550\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6961 - val_loss: 0.6521\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6927 - val_loss: 0.6492\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6892 - val_loss: 0.6463\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6859 - val_loss: 0.6435\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6826 - val_loss: 0.6407\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6793 - val_loss: 0.6380\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6760 - val_loss: 0.6352\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6728 - val_loss: 0.6325\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6696 - val_loss: 0.6299\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6664 - val_loss: 0.6272\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6633 - val_loss: 0.6245\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6602 - val_loss: 0.6219\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6571 - val_loss: 0.6192\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6541 - val_loss: 0.6165\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6511 - val_loss: 0.6138\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6481 - val_loss: 0.6112\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6451 - val_loss: 0.6085\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6421 - val_loss: 0.6058\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6392 - val_loss: 0.6031\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6363 - val_loss: 0.6004\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6334 - val_loss: 0.5977\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6305 - val_loss: 0.5950\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6277 - val_loss: 0.5923\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6249 - val_loss: 0.5897\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6221 - val_loss: 0.5870\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6194 - val_loss: 0.5844\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6166 - val_loss: 0.5818\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6139 - val_loss: 0.5792\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6112 - val_loss: 0.5767\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(20, 67), test_y.shape=(20, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 189444995209.35107, my average MASE = 189444995209.35107\n",
      "Cluster 0, 189444995209.35107\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 4.1706 - val_loss: 4.2312\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1683 - val_loss: 4.2297\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.1661 - val_loss: 4.2281\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.1639 - val_loss: 4.2266\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.1617 - val_loss: 4.2251\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.1595 - val_loss: 4.2235\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.1572 - val_loss: 4.2219\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.1550 - val_loss: 4.2203\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.1527 - val_loss: 4.2187\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.1505 - val_loss: 4.2170\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.1483 - val_loss: 4.2153\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.1461 - val_loss: 4.2136\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4.1439 - val_loss: 4.2118\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.1418 - val_loss: 4.2099\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1396 - val_loss: 4.2081\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.1373 - val_loss: 4.2061\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.1351 - val_loss: 4.2042\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.1328 - val_loss: 4.2022\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.1305 - val_loss: 4.2001\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.1282 - val_loss: 4.1980\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.1258 - val_loss: 4.1959\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.1234 - val_loss: 4.1937\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 4.1210 - val_loss: 4.1915\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.1186 - val_loss: 4.1892\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.1162 - val_loss: 4.1869\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.1139 - val_loss: 4.1846\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.1116 - val_loss: 4.1822\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.1093 - val_loss: 4.1799\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.1071 - val_loss: 4.1777\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.1048 - val_loss: 4.1755\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.1025 - val_loss: 4.1732\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.1002 - val_loss: 4.1709\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.0979 - val_loss: 4.1686\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0955 - val_loss: 4.1662\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 4.0931 - val_loss: 4.1638\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.0907 - val_loss: 4.1613\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.0884 - val_loss: 4.1589\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.0861 - val_loss: 4.1565\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.0838 - val_loss: 4.1540\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.0814 - val_loss: 4.1516\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 227.40923402913126, my average MASE = 227.40923402913126\n",
      "Cluster 1, 227.40923402913126\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3130 - val_loss: 1.3020\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3085 - val_loss: 1.2976\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3040 - val_loss: 1.2932\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2995 - val_loss: 1.2887\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2950 - val_loss: 1.2842\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2905 - val_loss: 1.2797\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2861 - val_loss: 1.2752\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2817 - val_loss: 1.2706\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2773 - val_loss: 1.2661\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2732 - val_loss: 1.2619\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2693 - val_loss: 1.2579\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2654 - val_loss: 1.2538\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2615 - val_loss: 1.2498\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2576 - val_loss: 1.2457\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2537 - val_loss: 1.2418\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2498 - val_loss: 1.2378\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2458 - val_loss: 1.2338\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2419 - val_loss: 1.2298\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2379 - val_loss: 1.2258\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2340 - val_loss: 1.2219\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2300 - val_loss: 1.2179\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2260 - val_loss: 1.2140\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2221 - val_loss: 1.2100\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2181 - val_loss: 1.2063\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2141 - val_loss: 1.2026\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2102 - val_loss: 1.1989\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2065 - val_loss: 1.1953\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2029 - val_loss: 1.1918\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1994 - val_loss: 1.1884\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1958 - val_loss: 1.1850\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1922 - val_loss: 1.1816\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1886 - val_loss: 1.1780\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1850 - val_loss: 1.1745\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1813 - val_loss: 1.1709\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1776 - val_loss: 1.1673\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1738 - val_loss: 1.1636\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1700 - val_loss: 1.1599\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1662 - val_loss: 1.1562\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1624 - val_loss: 1.1524\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1586 - val_loss: 1.1486\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 591912443876.7551, my average MASE = 591912443876.7551\n",
      "Cluster 2, 591912443876.7551\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.8560 - val_loss: 0.8122\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8480 - val_loss: 0.8048\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8402 - val_loss: 0.7976\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.8325 - val_loss: 0.7903\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.8250 - val_loss: 0.7832\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.8177 - val_loss: 0.7760\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8105 - val_loss: 0.7690\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8035 - val_loss: 0.7621\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7966 - val_loss: 0.7553\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7898 - val_loss: 0.7487\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7831 - val_loss: 0.7423\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7767 - val_loss: 0.7359\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7704 - val_loss: 0.7297\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7643 - val_loss: 0.7236\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7583 - val_loss: 0.7176\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7526 - val_loss: 0.7118\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7470 - val_loss: 0.7062\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7415 - val_loss: 0.7008\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7362 - val_loss: 0.6955\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7311 - val_loss: 0.6904\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7259 - val_loss: 0.6852\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7209 - val_loss: 0.6802\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7159 - val_loss: 0.6752\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7110 - val_loss: 0.6703\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7061 - val_loss: 0.6654\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7012 - val_loss: 0.6605\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6964 - val_loss: 0.6557\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6916 - val_loss: 0.6509\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6868 - val_loss: 0.6461\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6821 - val_loss: 0.6412\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6773 - val_loss: 0.6363\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6726 - val_loss: 0.6314\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6679 - val_loss: 0.6265\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6632 - val_loss: 0.6217\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6585 - val_loss: 0.6171\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6539 - val_loss: 0.6125\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6494 - val_loss: 0.6081\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6449 - val_loss: 0.6036\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6404 - val_loss: 0.5993\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6358 - val_loss: 0.5949\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 56459763061.7193, my average MASE = 56459763061.7193\n",
      "Cluster 3, 56459763061.7193\n",
      "Before prediction: train_X.shape=(178, 10, 67), train_y.shape=(178, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.5461 - val_loss: 0.4157\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5378 - val_loss: 0.4131\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5300 - val_loss: 0.4107\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5224 - val_loss: 0.4084\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5153 - val_loss: 0.4063\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5081 - val_loss: 0.4043\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5015 - val_loss: 0.4024\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4949 - val_loss: 0.4005\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4885 - val_loss: 0.3986\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4824 - val_loss: 0.3967\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4764 - val_loss: 0.3947\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4706 - val_loss: 0.3929\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4649 - val_loss: 0.3910\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4592 - val_loss: 0.3891\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4537 - val_loss: 0.3871\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4483 - val_loss: 0.3851\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4431 - val_loss: 0.3830\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4379 - val_loss: 0.3809\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4327 - val_loss: 0.3787\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4277 - val_loss: 0.3763\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4228 - val_loss: 0.3739\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4178 - val_loss: 0.3715\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4129 - val_loss: 0.3690\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4079 - val_loss: 0.3665\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4029 - val_loss: 0.3640\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3978 - val_loss: 0.3615\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3928 - val_loss: 0.3591\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3877 - val_loss: 0.3566\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3827 - val_loss: 0.3542\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3778 - val_loss: 0.3518\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3731 - val_loss: 0.3494\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3683 - val_loss: 0.3471\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3636 - val_loss: 0.3447\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3590 - val_loss: 0.3424\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3545 - val_loss: 0.3402\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3498 - val_loss: 0.3381\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3451 - val_loss: 0.3360\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3405 - val_loss: 0.3339\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3359 - val_loss: 0.3318\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3312 - val_loss: 0.3296\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 56265561427.910545, my average MASE = 56265561427.910545\n",
      "Cluster 4, 56265561427.910545\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.5407 - val_loss: 0.5536\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4895 - val_loss: 0.5098\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.4426 - val_loss: 0.4714\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3965 - val_loss: 0.4303\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3537 - val_loss: 0.3941\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3132 - val_loss: 0.3610\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.2760 - val_loss: 0.3263\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.2435 - val_loss: 0.3000\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.2191 - val_loss: 0.2872\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1979 - val_loss: 0.2768\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1796 - val_loss: 0.2674\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1655 - val_loss: 0.2618\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1547 - val_loss: 0.2584\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1460 - val_loss: 0.2568\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1389 - val_loss: 0.2562\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1325 - val_loss: 0.2556\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1267 - val_loss: 0.2547\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1215 - val_loss: 0.2546\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1171 - val_loss: 0.2550\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1133 - val_loss: 0.2552\n",
      "Epoch 20: early stopping\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 433035988746.0601, my average MASE = 433035988746.0601\n",
      "Cluster 5, 433035988746.0601\n",
      "Before prediction: train_X.shape=(78, 10, 67), train_y.shape=(78, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3094 - val_loss: 1.2614\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.3007 - val_loss: 1.2528\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.2920 - val_loss: 1.2444\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.2835 - val_loss: 1.2361\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.2750 - val_loss: 1.2280\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.2665 - val_loss: 1.2199\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.2581 - val_loss: 1.2119\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.2499 - val_loss: 1.2039\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.2416 - val_loss: 1.1959\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.2334 - val_loss: 1.1878\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.2252 - val_loss: 1.1797\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.2171 - val_loss: 1.1715\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.2090 - val_loss: 1.1632\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.2009 - val_loss: 1.1548\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 1.1927 - val_loss: 1.1464\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1846 - val_loss: 1.1380\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1764 - val_loss: 1.1296\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1683 - val_loss: 1.1212\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.1603 - val_loss: 1.1130\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.1524 - val_loss: 1.1049\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1445 - val_loss: 1.0969\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1367 - val_loss: 1.0889\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 1.1290 - val_loss: 1.0809\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.1213 - val_loss: 1.0728\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 1.1134 - val_loss: 1.0648\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 1.1056 - val_loss: 1.0568\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0977 - val_loss: 1.0490\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0900 - val_loss: 1.0413\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.0823 - val_loss: 1.0338\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0747 - val_loss: 1.0262\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0671 - val_loss: 1.0186\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0596 - val_loss: 1.0110\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0521 - val_loss: 1.0033\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0447 - val_loss: 0.9957\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0373 - val_loss: 0.9881\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0300 - val_loss: 0.9805\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0226 - val_loss: 0.9730\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0153 - val_loss: 0.9656\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0080 - val_loss: 0.9581\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.0007 - val_loss: 0.9506\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 60326617903.149284, my average MASE = 60326617903.149284\n",
      "Cluster 6, 60326617903.149284\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=9, 9, 317, (42, 67)\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8024 - val_loss: 0.8025\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7990 - val_loss: 0.7991\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7957 - val_loss: 0.7957\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7924 - val_loss: 0.7925\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7891 - val_loss: 0.7892\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7858 - val_loss: 0.7861\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7826 - val_loss: 0.7830\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7794 - val_loss: 0.7800\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7761 - val_loss: 0.7770\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7729 - val_loss: 0.7741\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7697 - val_loss: 0.7711\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7665 - val_loss: 0.7682\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7633 - val_loss: 0.7653\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7602 - val_loss: 0.7624\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7570 - val_loss: 0.7595\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7539 - val_loss: 0.7567\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7507 - val_loss: 0.7540\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7476 - val_loss: 0.7513\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7447 - val_loss: 0.7488\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7418 - val_loss: 0.7462\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7390 - val_loss: 0.7437\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7362 - val_loss: 0.7411\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7334 - val_loss: 0.7384\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7306 - val_loss: 0.7358\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7278 - val_loss: 0.7331\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7251 - val_loss: 0.7303\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7223 - val_loss: 0.7276\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7196 - val_loss: 0.7249\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7168 - val_loss: 0.7221\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7141 - val_loss: 0.7194\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7113 - val_loss: 0.7166\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7086 - val_loss: 0.7140\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7059 - val_loss: 0.7113\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7032 - val_loss: 0.7087\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7005 - val_loss: 0.7061\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6978 - val_loss: 0.7034\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6951 - val_loss: 0.7007\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6924 - val_loss: 0.6980\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6897 - val_loss: 0.6953\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6870 - val_loss: 0.6925\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 58994086118.48446, my average MASE = 58994086118.48446\n",
      "Cluster 0, 58994086118.48446\n",
      "Before prediction: train_X.shape=(16, 10, 67), train_y.shape=(16, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.5631 - val_loss: 1.5520\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5599 - val_loss: 1.5489\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5567 - val_loss: 1.5458\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5535 - val_loss: 1.5427\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5503 - val_loss: 1.5395\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5470 - val_loss: 1.5363\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5438 - val_loss: 1.5331\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5405 - val_loss: 1.5298\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5372 - val_loss: 1.5265\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5338 - val_loss: 1.5232\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5305 - val_loss: 1.5198\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5271 - val_loss: 1.5164\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5236 - val_loss: 1.5129\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5201 - val_loss: 1.5095\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5165 - val_loss: 1.5059\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5130 - val_loss: 1.5024\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5093 - val_loss: 1.4989\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5056 - val_loss: 1.4954\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5019 - val_loss: 1.4919\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4982 - val_loss: 1.4885\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4945 - val_loss: 1.4850\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4907 - val_loss: 1.4815\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4869 - val_loss: 1.4780\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4831 - val_loss: 1.4743\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4791 - val_loss: 1.4705\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4751 - val_loss: 1.4667\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4710 - val_loss: 1.4627\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4669 - val_loss: 1.4587\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4626 - val_loss: 1.4545\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4583 - val_loss: 1.4502\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4539 - val_loss: 1.4456\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4493 - val_loss: 1.4410\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4446 - val_loss: 1.4362\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4397 - val_loss: 1.4312\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4346 - val_loss: 1.4262\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4295 - val_loss: 1.4210\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4243 - val_loss: 1.4158\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4190 - val_loss: 1.4104\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4136 - val_loss: 1.4051\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4083 - val_loss: 1.3997\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 95688222465.7208, my average MASE = 95688222465.7208\n",
      "Cluster 1, 95688222465.7208\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8727 - val_loss: 0.8769\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8686 - val_loss: 0.8728\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8645 - val_loss: 0.8687\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8605 - val_loss: 0.8646\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8565 - val_loss: 0.8605\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8524 - val_loss: 0.8564\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8483 - val_loss: 0.8522\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8442 - val_loss: 0.8480\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8401 - val_loss: 0.8439\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8360 - val_loss: 0.8397\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8319 - val_loss: 0.8355\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8277 - val_loss: 0.8312\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8236 - val_loss: 0.8270\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8195 - val_loss: 0.8227\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8154 - val_loss: 0.8185\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8113 - val_loss: 0.8142\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8071 - val_loss: 0.8099\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8030 - val_loss: 0.8056\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7988 - val_loss: 0.8013\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7947 - val_loss: 0.7970\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7906 - val_loss: 0.7927\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7865 - val_loss: 0.7884\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7824 - val_loss: 0.7841\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7783 - val_loss: 0.7798\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7742 - val_loss: 0.7755\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7701 - val_loss: 0.7712\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7662 - val_loss: 0.7671\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7624 - val_loss: 0.7632\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7587 - val_loss: 0.7593\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7550 - val_loss: 0.7554\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7513 - val_loss: 0.7516\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7476 - val_loss: 0.7479\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7440 - val_loss: 0.7444\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7405 - val_loss: 0.7408\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7372 - val_loss: 0.7372\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7338 - val_loss: 0.7337\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7304 - val_loss: 0.7302\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7269 - val_loss: 0.7267\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7233 - val_loss: 0.7232\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7198 - val_loss: 0.7197\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 231.9024325290266, my average MASE = 231.9024325290266\n",
      "Cluster 3, 231.9024325290266\n",
      "Before prediction: train_X.shape=(33, 10, 67), train_y.shape=(33, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.5721 - val_loss: 1.4992\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5673 - val_loss: 1.4964\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5627 - val_loss: 1.4936\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5583 - val_loss: 1.4908\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5539 - val_loss: 1.4880\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5497 - val_loss: 1.4852\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5455 - val_loss: 1.4824\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5413 - val_loss: 1.4796\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5372 - val_loss: 1.4767\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5331 - val_loss: 1.4739\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5291 - val_loss: 1.4710\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5250 - val_loss: 1.4681\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5210 - val_loss: 1.4652\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5170 - val_loss: 1.4623\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5130 - val_loss: 1.4594\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5091 - val_loss: 1.4565\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5051 - val_loss: 1.4536\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5011 - val_loss: 1.4506\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4972 - val_loss: 1.4477\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4934 - val_loss: 1.4449\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4897 - val_loss: 1.4420\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4860 - val_loss: 1.4391\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4823 - val_loss: 1.4363\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4786 - val_loss: 1.4335\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4750 - val_loss: 1.4307\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4713 - val_loss: 1.4279\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4676 - val_loss: 1.4252\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4640 - val_loss: 1.4224\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4603 - val_loss: 1.4197\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4566 - val_loss: 1.4170\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4530 - val_loss: 1.4143\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4493 - val_loss: 1.4116\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4456 - val_loss: 1.4089\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4419 - val_loss: 1.4062\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4382 - val_loss: 1.4035\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4345 - val_loss: 1.4008\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4307 - val_loss: 1.3982\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.4269 - val_loss: 1.3955\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4231 - val_loss: 1.3928\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4193 - val_loss: 1.3902\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 599139293487.9497, my average MASE = 599139293487.9497\n",
      "Cluster 4, 599139293487.9497\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(4681, 10, 67), train_y.shape=(4681, 67), test_X.shape=(1560, 10, 67), test_y.shape=(1560, 67)\n",
      "Epoch 1/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.5482 - val_loss: 0.5254\n",
      "Epoch 2/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.4358 - val_loss: 0.4154\n",
      "Epoch 3/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.3380 - val_loss: 0.3114\n",
      "Epoch 4/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.2584 - val_loss: 0.2233\n",
      "Epoch 5/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.2035 - val_loss: 0.1758\n",
      "Epoch 6/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.1712 - val_loss: 0.1424\n",
      "Epoch 7/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.1507 - val_loss: 0.1217\n",
      "Epoch 8/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.1349 - val_loss: 0.1060\n",
      "Epoch 9/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.1216 - val_loss: 0.1006\n",
      "Epoch 10/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.1120 - val_loss: 0.0979\n",
      "Epoch 11/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.1045 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0982 - val_loss: 0.0899\n",
      "Epoch 13/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0923 - val_loss: 0.0866\n",
      "Epoch 14/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0874 - val_loss: 0.0830\n",
      "Epoch 15/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0833 - val_loss: 0.0798\n",
      "Epoch 16/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0796 - val_loss: 0.0778\n",
      "Epoch 17/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0766 - val_loss: 0.0781\n",
      "Epoch 18/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0743 - val_loss: 0.0759\n",
      "Epoch 19/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0726 - val_loss: 0.0752\n",
      "Epoch 20/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0712 - val_loss: 0.0733\n",
      "Epoch 21/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0699 - val_loss: 0.0721\n",
      "Epoch 22/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0688 - val_loss: 0.0705\n",
      "Epoch 23/40\n",
      "74/74 [==============================] - 2s 34ms/step - loss: 0.0677 - val_loss: 0.0699\n",
      "Epoch 24/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0667 - val_loss: 0.0690\n",
      "Epoch 25/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0657 - val_loss: 0.0684\n",
      "Epoch 26/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0648 - val_loss: 0.0678\n",
      "Epoch 27/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0638 - val_loss: 0.0658\n",
      "Epoch 28/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0630 - val_loss: 0.0654\n",
      "Epoch 29/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0622 - val_loss: 0.0643\n",
      "Epoch 30/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0614 - val_loss: 0.0639\n",
      "Epoch 31/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0608 - val_loss: 0.0637\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0602 - val_loss: 0.0632\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0596 - val_loss: 0.0628\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0590 - val_loss: 0.0636\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0584 - val_loss: 0.0624\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0578 - val_loss: 0.0629\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0572 - val_loss: 0.0623\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0566 - val_loss: 0.0630\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0560 - val_loss: 0.0632\n",
      "Epoch 39: early stopping\n",
      "49/49 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1560, 67), test_y.shape=(1560, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_423049/1036013534.py:65: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 10))\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 466627176094.015, my average MASE = 466627176094.015\n",
      "Cluster 6, 466627176094.015\n",
      "Before prediction: train_X.shape=(28, 10, 67), train_y.shape=(28, 67), test_X.shape=(9, 10, 67), test_y.shape=(9, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5282 - val_loss: 0.4903\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5246 - val_loss: 0.4871\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5210 - val_loss: 0.4839\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5173 - val_loss: 0.4806\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5137 - val_loss: 0.4774\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5101 - val_loss: 0.4742\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5065 - val_loss: 0.4711\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5029 - val_loss: 0.4679\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4993 - val_loss: 0.4648\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4958 - val_loss: 0.4616\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4922 - val_loss: 0.4585\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4887 - val_loss: 0.4553\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4851 - val_loss: 0.4522\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4816 - val_loss: 0.4491\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4781 - val_loss: 0.4460\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4747 - val_loss: 0.4429\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4713 - val_loss: 0.4398\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4680 - val_loss: 0.4368\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4647 - val_loss: 0.4339\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4614 - val_loss: 0.4310\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4582 - val_loss: 0.4281\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4549 - val_loss: 0.4254\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4516 - val_loss: 0.4227\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4484 - val_loss: 0.4200\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4452 - val_loss: 0.4174\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4420 - val_loss: 0.4149\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4389 - val_loss: 0.4124\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4357 - val_loss: 0.4099\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4326 - val_loss: 0.4074\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4296 - val_loss: 0.4048\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4265 - val_loss: 0.4023\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4235 - val_loss: 0.3998\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4205 - val_loss: 0.3973\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4175 - val_loss: 0.3947\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4145 - val_loss: 0.3921\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4115 - val_loss: 0.3896\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4085 - val_loss: 0.3870\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4056 - val_loss: 0.3844\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4026 - val_loss: 0.3817\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3995 - val_loss: 0.3791\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(9, 67), test_y.shape=(9, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 213260685802.90137, my average MASE = 213260685802.90137\n",
      "Cluster 7, 213260685802.90137\n",
      "Before prediction: train_X.shape=(14, 10, 67), train_y.shape=(14, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6389 - val_loss: 0.6557\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6343 - val_loss: 0.6511\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6298 - val_loss: 0.6466\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6253 - val_loss: 0.6420\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6208 - val_loss: 0.6376\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6163 - val_loss: 0.6331\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6118 - val_loss: 0.6287\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6075 - val_loss: 0.6245\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6034 - val_loss: 0.6205\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5995 - val_loss: 0.6167\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5959 - val_loss: 0.6130\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5925 - val_loss: 0.6094\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5891 - val_loss: 0.6058\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5857 - val_loss: 0.6024\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5824 - val_loss: 0.5990\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5791 - val_loss: 0.5956\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5758 - val_loss: 0.5923\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5725 - val_loss: 0.5889\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5693 - val_loss: 0.5856\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5660 - val_loss: 0.5823\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5628 - val_loss: 0.5790\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5596 - val_loss: 0.5757\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5564 - val_loss: 0.5725\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5533 - val_loss: 0.5692\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5501 - val_loss: 0.5660\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5469 - val_loss: 0.5628\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5437 - val_loss: 0.5597\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5406 - val_loss: 0.5567\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5376 - val_loss: 0.5538\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5345 - val_loss: 0.5508\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5315 - val_loss: 0.5478\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5285 - val_loss: 0.5448\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5255 - val_loss: 0.5419\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5226 - val_loss: 0.5389\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5196 - val_loss: 0.5360\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5166 - val_loss: 0.5330\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5136 - val_loss: 0.5300\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5106 - val_loss: 0.5270\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5076 - val_loss: 0.5240\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5046 - val_loss: 0.5210\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 211677469181.3413, my average MASE = 211677469181.3413\n",
      "Cluster 8, 211677469181.3413\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=11, 11, 417, (1, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.2049 - val_loss: 1.1895\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2008 - val_loss: 1.1857\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1968 - val_loss: 1.1820\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1928 - val_loss: 1.1783\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1888 - val_loss: 1.1746\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1849 - val_loss: 1.1709\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1810 - val_loss: 1.1673\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1772 - val_loss: 1.1637\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1736 - val_loss: 1.1602\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1701 - val_loss: 1.1568\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1668 - val_loss: 1.1535\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1635 - val_loss: 1.1503\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1603 - val_loss: 1.1471\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1571 - val_loss: 1.1440\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1539 - val_loss: 1.1409\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1508 - val_loss: 1.1377\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1475 - val_loss: 1.1345\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1443 - val_loss: 1.1313\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1411 - val_loss: 1.1281\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1378 - val_loss: 1.1249\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1345 - val_loss: 1.1216\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1312 - val_loss: 1.1183\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1279 - val_loss: 1.1151\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1246 - val_loss: 1.1118\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1212 - val_loss: 1.1085\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1179 - val_loss: 1.1052\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1145 - val_loss: 1.1019\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1111 - val_loss: 1.0986\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1078 - val_loss: 1.0953\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1044 - val_loss: 1.0919\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1012 - val_loss: 1.0886\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0979 - val_loss: 1.0853\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0946 - val_loss: 1.0819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0913 - val_loss: 1.0786\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0880 - val_loss: 1.0752\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0848 - val_loss: 1.0719\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0816 - val_loss: 1.0686\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0784 - val_loss: 1.0653\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0752 - val_loss: 1.0621\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0720 - val_loss: 1.0589\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 249016951157.64252, my average MASE = 249016951157.64252\n",
      "Cluster 0, 249016951157.64252\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.2380 - val_loss: 1.2236\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2332 - val_loss: 1.2191\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2284 - val_loss: 1.2147\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2237 - val_loss: 1.2102\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2190 - val_loss: 1.2057\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2143 - val_loss: 1.2013\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2096 - val_loss: 1.1968\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2050 - val_loss: 1.1924\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2005 - val_loss: 1.1880\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1960 - val_loss: 1.1837\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1915 - val_loss: 1.1794\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1870 - val_loss: 1.1751\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1825 - val_loss: 1.1707\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1780 - val_loss: 1.1664\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1734 - val_loss: 1.1622\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1689 - val_loss: 1.1580\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1643 - val_loss: 1.1538\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1598 - val_loss: 1.1495\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1552 - val_loss: 1.1452\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1506 - val_loss: 1.1409\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1462 - val_loss: 1.1365\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1417 - val_loss: 1.1320\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1372 - val_loss: 1.1276\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1326 - val_loss: 1.1231\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1281 - val_loss: 1.1185\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1235 - val_loss: 1.1139\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1188 - val_loss: 1.1093\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1142 - val_loss: 1.1046\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1095 - val_loss: 1.0999\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1048 - val_loss: 1.0952\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1002 - val_loss: 1.0905\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0955 - val_loss: 1.0857\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0908 - val_loss: 1.0809\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0861 - val_loss: 1.0762\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0814 - val_loss: 1.0714\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0767 - val_loss: 1.0666\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0720 - val_loss: 1.0618\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0673 - val_loss: 1.0571\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0626 - val_loss: 1.0526\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0580 - val_loss: 1.0480\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 579659746813.9388, my average MASE = 579659746813.9388\n",
      "Cluster 1, 579659746813.9388\n",
      "Before prediction: train_X.shape=(87, 10, 67), train_y.shape=(87, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.7327 - val_loss: 0.6929\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7250 - val_loss: 0.6877\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7172 - val_loss: 0.6825\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7095 - val_loss: 0.6773\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7020 - val_loss: 0.6723\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6947 - val_loss: 0.6673\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6878 - val_loss: 0.6624\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6810 - val_loss: 0.6575\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6742 - val_loss: 0.6528\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6675 - val_loss: 0.6480\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6608 - val_loss: 0.6434\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6541 - val_loss: 0.6387\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6475 - val_loss: 0.6342\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6410 - val_loss: 0.6297\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6347 - val_loss: 0.6253\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6286 - val_loss: 0.6210\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6225 - val_loss: 0.6167\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6165 - val_loss: 0.6125\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6105 - val_loss: 0.6082\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6046 - val_loss: 0.6039\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5986 - val_loss: 0.5995\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5928 - val_loss: 0.5952\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5869 - val_loss: 0.5908\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5811 - val_loss: 0.5865\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5754 - val_loss: 0.5821\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5697 - val_loss: 0.5778\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5640 - val_loss: 0.5736\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5583 - val_loss: 0.5695\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5528 - val_loss: 0.5654\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5472 - val_loss: 0.5613\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5418 - val_loss: 0.5574\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5364 - val_loss: 0.5535\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5311 - val_loss: 0.5496\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5257 - val_loss: 0.5457\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5204 - val_loss: 0.5419\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5151 - val_loss: 0.5380\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5098 - val_loss: 0.5342\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5045 - val_loss: 0.5304\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4991 - val_loss: 0.5266\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4937 - val_loss: 0.5226\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 33302150388.17988, my average MASE = 33302150388.17988\n",
      "Cluster 2, 33302150388.17988\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(9, 10, 67), train_y.shape=(9, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7418 - val_loss: 0.7240\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7370 - val_loss: 0.7192\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7322 - val_loss: 0.7145\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7275 - val_loss: 0.7100\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7230 - val_loss: 0.7056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7186 - val_loss: 0.7011\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7141 - val_loss: 0.6967\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7097 - val_loss: 0.6923\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7052 - val_loss: 0.6879\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7008 - val_loss: 0.6836\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6964 - val_loss: 0.6792\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6920 - val_loss: 0.6749\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6877 - val_loss: 0.6705\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6834 - val_loss: 0.6662\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6791 - val_loss: 0.6619\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6748 - val_loss: 0.6575\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6705 - val_loss: 0.6532\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6663 - val_loss: 0.6489\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6620 - val_loss: 0.6447\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6578 - val_loss: 0.6406\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6537 - val_loss: 0.6366\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6498 - val_loss: 0.6327\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6460 - val_loss: 0.6291\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6425 - val_loss: 0.6255\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6390 - val_loss: 0.6220\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6355 - val_loss: 0.6186\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6321 - val_loss: 0.6151\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6287 - val_loss: 0.6118\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6253 - val_loss: 0.6085\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6219 - val_loss: 0.6053\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6187 - val_loss: 0.6021\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6155 - val_loss: 0.5990\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6124 - val_loss: 0.5958\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6092 - val_loss: 0.5926\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6060 - val_loss: 0.5894\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6028 - val_loss: 0.5861\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5996 - val_loss: 0.5829\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5963 - val_loss: 0.5796\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5931 - val_loss: 0.5764\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5899 - val_loss: 0.5733\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 211986689858.47574, my average MASE = 211986689858.47574\n",
      "Cluster 4, 211986689858.47574\n",
      "Before prediction: train_X.shape=(85, 10, 67), train_y.shape=(85, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.8666 - val_loss: 0.8491\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8576 - val_loss: 0.8402\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8488 - val_loss: 0.8315\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8402 - val_loss: 0.8231\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8318 - val_loss: 0.8150\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8238 - val_loss: 0.8071\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.8159 - val_loss: 0.7995\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8081 - val_loss: 0.7921\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8004 - val_loss: 0.7849\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7927 - val_loss: 0.7778\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7850 - val_loss: 0.7708\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7773 - val_loss: 0.7640\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7697 - val_loss: 0.7574\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7622 - val_loss: 0.7509\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7547 - val_loss: 0.7446\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7474 - val_loss: 0.7383\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7402 - val_loss: 0.7320\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7331 - val_loss: 0.7256\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7259 - val_loss: 0.7191\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7187 - val_loss: 0.7126\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7115 - val_loss: 0.7059\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7042 - val_loss: 0.6992\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6968 - val_loss: 0.6925\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6894 - val_loss: 0.6858\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6819 - val_loss: 0.6793\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6746 - val_loss: 0.6728\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6671 - val_loss: 0.6663\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6596 - val_loss: 0.6598\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6522 - val_loss: 0.6534\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6447 - val_loss: 0.6472\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6373 - val_loss: 0.6410\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6298 - val_loss: 0.6348\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6223 - val_loss: 0.6288\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6149 - val_loss: 0.6227\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6077 - val_loss: 0.6166\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6006 - val_loss: 0.6106\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5937 - val_loss: 0.6046\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5870 - val_loss: 0.5987\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5806 - val_loss: 0.5929\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5743 - val_loss: 0.5871\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 59422226059.109474, my average MASE = 59422226059.109474\n",
      "Cluster 5, 59422226059.109474\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5504 - val_loss: 0.5199\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.4916 - val_loss: 0.4796\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.4370 - val_loss: 0.4436\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.3861 - val_loss: 0.4064\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.3400 - val_loss: 0.3694\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2988 - val_loss: 0.3373\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.2619 - val_loss: 0.3082\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.2317 - val_loss: 0.2855\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2078 - val_loss: 0.2724\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.1900 - val_loss: 0.2637\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1760 - val_loss: 0.2575\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.2545\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1532 - val_loss: 0.2528\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1453 - val_loss: 0.2524\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1392 - val_loss: 0.2511\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1341 - val_loss: 0.2497\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1297 - val_loss: 0.2482\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1258 - val_loss: 0.2473\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1223 - val_loss: 0.2457\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1191 - val_loss: 0.2449\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1163 - val_loss: 0.2433\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1136 - val_loss: 0.2426\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1110 - val_loss: 0.2411\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1086 - val_loss: 0.2406\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1063 - val_loss: 0.2393\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1041 - val_loss: 0.2385\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1020 - val_loss: 0.2376\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1001 - val_loss: 0.2365\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0983 - val_loss: 0.2357\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0969 - val_loss: 0.2349\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0957 - val_loss: 0.2344\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0948 - val_loss: 0.2330\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0939 - val_loss: 0.2324\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0931 - val_loss: 0.2316\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0922 - val_loss: 0.2308\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0914 - val_loss: 0.2299\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0907 - val_loss: 0.2291\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0899 - val_loss: 0.2287\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0891 - val_loss: 0.2280\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0884 - val_loss: 0.2271\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 442423531376.6017, my average MASE = 442423531376.6017\n",
      "Cluster 7, 442423531376.6017\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(9, 10, 67), train_y.shape=(9, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6851 - val_loss: 0.6840\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6815 - val_loss: 0.6805\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6778 - val_loss: 0.6770\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6742 - val_loss: 0.6735\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6705 - val_loss: 0.6700\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6669 - val_loss: 0.6665\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6633 - val_loss: 0.6630\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6597 - val_loss: 0.6596\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6561 - val_loss: 0.6561\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6525 - val_loss: 0.6526\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6489 - val_loss: 0.6492\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6453 - val_loss: 0.6458\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6418 - val_loss: 0.6424\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6383 - val_loss: 0.6391\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6348 - val_loss: 0.6358\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6314 - val_loss: 0.6326\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6280 - val_loss: 0.6293\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6246 - val_loss: 0.6261\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6212 - val_loss: 0.6229\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6178 - val_loss: 0.6197\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6144 - val_loss: 0.6165\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6111 - val_loss: 0.6134\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6079 - val_loss: 0.6104\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6047 - val_loss: 0.6074\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6015 - val_loss: 0.6044\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5983 - val_loss: 0.6014\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5951 - val_loss: 0.5983\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5919 - val_loss: 0.5953\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5888 - val_loss: 0.5923\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5858 - val_loss: 0.5893\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5827 - val_loss: 0.5863\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5798 - val_loss: 0.5834\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5769 - val_loss: 0.5805\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5740 - val_loss: 0.5777\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5711 - val_loss: 0.5749\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5681 - val_loss: 0.5721\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5651 - val_loss: 0.5693\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5622 - val_loss: 0.5666\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5593 - val_loss: 0.5639\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5566 - val_loss: 0.5613\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 57281660079.115486, my average MASE = 57281660079.115486\n",
      "Cluster 9, 57281660079.115486\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=2, 2, 17, (25, 67)\n",
      "Before prediction: train_X.shape=(9, 10, 67), train_y.shape=(9, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 2.5171 - val_loss: 2.4843\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.5129 - val_loss: 2.4804\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.5086 - val_loss: 2.4767\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.5046 - val_loss: 2.4731\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.5006 - val_loss: 2.4695\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4967 - val_loss: 2.4661\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4930 - val_loss: 2.4628\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4893 - val_loss: 2.4595\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.4857 - val_loss: 2.4562\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4822 - val_loss: 2.4529\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4787 - val_loss: 2.4496\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4752 - val_loss: 2.4463\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4718 - val_loss: 2.4430\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.4684 - val_loss: 2.4397\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.4650 - val_loss: 2.4364\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4616 - val_loss: 2.4331\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.4582 - val_loss: 2.4299\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4548 - val_loss: 2.4266\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4514 - val_loss: 2.4233\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.4480 - val_loss: 2.4201\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.4446 - val_loss: 2.4169\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4412 - val_loss: 2.4136\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4379 - val_loss: 2.4104\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.4346 - val_loss: 2.4072\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.4312 - val_loss: 2.4041\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.4279 - val_loss: 2.4011\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.4247 - val_loss: 2.3982\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4215 - val_loss: 2.3953\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4184 - val_loss: 2.3925\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4154 - val_loss: 2.3896\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4123 - val_loss: 2.3868\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.4093 - val_loss: 2.3840\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4064 - val_loss: 2.3812\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.4034 - val_loss: 2.3784\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4005 - val_loss: 2.3757\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3976 - val_loss: 2.3730\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3948 - val_loss: 2.3704\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 2.3921 - val_loss: 2.3680\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.3894 - val_loss: 2.3655\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.3867 - val_loss: 2.3631\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 474522499455.5884, my average MASE = 474522499455.5884\n",
      "Cluster 0, 474522499455.5884\n",
      "Before prediction: train_X.shape=(18360, 10, 67), train_y.shape=(18360, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.5469 - val_loss: 0.5468\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2910 - val_loss: 0.4696\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2180 - val_loss: 0.4180\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.1782 - val_loss: 0.3821\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1520 - val_loss: 0.3498\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.1326 - val_loss: 0.3222\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.1179 - val_loss: 0.3017\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.1065 - val_loss: 0.2833\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0974 - val_loss: 0.2674\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0902 - val_loss: 0.2542\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0845 - val_loss: 0.2436\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0798 - val_loss: 0.2335\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0757 - val_loss: 0.2249\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0720 - val_loss: 0.2171\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0687 - val_loss: 0.2091\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0657 - val_loss: 0.2023\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0629 - val_loss: 0.1964\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0604 - val_loss: 0.1906\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0581 - val_loss: 0.1854\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0560 - val_loss: 0.1807\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0541 - val_loss: 0.1768\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0523 - val_loss: 0.1731\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0507 - val_loss: 0.1688\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0492 - val_loss: 0.1660\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0478 - val_loss: 0.1625\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0465 - val_loss: 0.1601\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0453 - val_loss: 0.1576\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0442 - val_loss: 0.1549\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0432 - val_loss: 0.1525\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0422 - val_loss: 0.1508\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0414 - val_loss: 0.1494\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0406 - val_loss: 0.1472\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0398 - val_loss: 0.1456\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0391 - val_loss: 0.1440\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0384 - val_loss: 0.1417\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0377 - val_loss: 0.1405\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0371 - val_loss: 0.1387\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0365 - val_loss: 0.1369\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0359 - val_loss: 0.1352\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0354 - val_loss: 0.1341\n",
      "192/192 [==============================] - 2s 11ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 512758624.65144426, my average MASE = 512758624.65144426\n",
      "Cluster 1, 512758624.65144426\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=5, 5, 700, (270, 67)\n",
      "Before prediction: train_X.shape=(156, 10, 67), train_y.shape=(156, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.3471 - val_loss: 1.2442\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.3382 - val_loss: 1.2369\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.3297 - val_loss: 1.2298\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.3217 - val_loss: 1.2229\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.3140 - val_loss: 1.2162\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.3066 - val_loss: 1.2097\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.2992 - val_loss: 1.2032\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.2919 - val_loss: 1.1968\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2847 - val_loss: 1.1905\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.2774 - val_loss: 1.1841\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2703 - val_loss: 1.1778\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2631 - val_loss: 1.1715\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.2559 - val_loss: 1.1652\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.2487 - val_loss: 1.1587\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.2414 - val_loss: 1.1522\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2339 - val_loss: 1.1456\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.2264 - val_loss: 1.1388\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.2187 - val_loss: 1.1319\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.2109 - val_loss: 1.1246\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.2029 - val_loss: 1.1170\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.1947 - val_loss: 1.1091\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.1863 - val_loss: 1.1008\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.1778 - val_loss: 1.0920\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.1693 - val_loss: 1.0829\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.1606 - val_loss: 1.0738\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.1518 - val_loss: 1.0645\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.1428 - val_loss: 1.0551\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.1336 - val_loss: 1.0456\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.1242 - val_loss: 1.0359\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.1144 - val_loss: 1.0259\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.1045 - val_loss: 1.0158\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.0944 - val_loss: 1.0060\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.0840 - val_loss: 0.9965\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.0734 - val_loss: 0.9871\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.0627 - val_loss: 0.9775\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.0519 - val_loss: 0.9681\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.0413 - val_loss: 0.9593\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.0308 - val_loss: 0.9506\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.0204 - val_loss: 0.9419\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.0100 - val_loss: 0.9333\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 60859125455.72316, my average MASE = 60859125455.72316\n",
      "Cluster 0, 60859125455.72316\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3450 - val_loss: 1.3446\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3400 - val_loss: 1.3397\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3351 - val_loss: 1.3348\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3302 - val_loss: 1.3300\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3255 - val_loss: 1.3252\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3207 - val_loss: 1.3205\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3160 - val_loss: 1.3157\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3113 - val_loss: 1.3109\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3066 - val_loss: 1.3061\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3019 - val_loss: 1.3014\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2972 - val_loss: 1.2967\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2925 - val_loss: 1.2921\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2879 - val_loss: 1.2875\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2834 - val_loss: 1.2829\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2789 - val_loss: 1.2784\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2744 - val_loss: 1.2739\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2699 - val_loss: 1.2693\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2654 - val_loss: 1.2648\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2609 - val_loss: 1.2603\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2564 - val_loss: 1.2559\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2519 - val_loss: 1.2515\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2474 - val_loss: 1.2471\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2429 - val_loss: 1.2427\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2384 - val_loss: 1.2384\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2340 - val_loss: 1.2342\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2296 - val_loss: 1.2300\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2254 - val_loss: 1.2258\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2211 - val_loss: 1.2217\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2170 - val_loss: 1.2176\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2130 - val_loss: 1.2135\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2091 - val_loss: 1.2095\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2051 - val_loss: 1.2055\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2012 - val_loss: 1.2015\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1972 - val_loss: 1.1975\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1932 - val_loss: 1.1936\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1893 - val_loss: 1.1896\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1853 - val_loss: 1.1856\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1813 - val_loss: 1.1816\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1772 - val_loss: 1.1776\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1731 - val_loss: 1.1735\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 91192511709.21356, my average MASE = 91192511709.21356\n",
      "Cluster 1, 91192511709.21356\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.5046 - val_loss: 0.4274\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3657 - val_loss: 0.3171\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.2544 - val_loss: 0.2584\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.1861 - val_loss: 0.2540\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1473 - val_loss: 0.2708\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1233 - val_loss: 0.2763\n",
      "Epoch 6: early stopping\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 373882001998.0068, my average MASE = 373882001998.0068\n",
      "Cluster 2, 373882001998.0068\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5195 - val_loss: 1.4988\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5157 - val_loss: 1.4970\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5120 - val_loss: 1.4951\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5082 - val_loss: 1.4933\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5045 - val_loss: 1.4914\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5008 - val_loss: 1.4895\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4973 - val_loss: 1.4876\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4939 - val_loss: 1.4857\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4905 - val_loss: 1.4838\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4871 - val_loss: 1.4819\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4838 - val_loss: 1.4799\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4804 - val_loss: 1.4780\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4771 - val_loss: 1.4761\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4737 - val_loss: 1.4741\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4703 - val_loss: 1.4722\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4670 - val_loss: 1.4702\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4637 - val_loss: 1.4683\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4603 - val_loss: 1.4663\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4570 - val_loss: 1.4643\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4537 - val_loss: 1.4623\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4504 - val_loss: 1.4603\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4470 - val_loss: 1.4583\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4437 - val_loss: 1.4563\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4404 - val_loss: 1.4542\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4372 - val_loss: 1.4522\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4339 - val_loss: 1.4501\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4307 - val_loss: 1.4480\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4276 - val_loss: 1.4460\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4245 - val_loss: 1.4439\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4214 - val_loss: 1.4418\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.4184 - val_loss: 1.4396\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4154 - val_loss: 1.4375\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4125 - val_loss: 1.4354\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4095 - val_loss: 1.4332\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4065 - val_loss: 1.4311\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4036 - val_loss: 1.4289\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4006 - val_loss: 1.4267\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3976 - val_loss: 1.4244\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3947 - val_loss: 1.4222\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3917 - val_loss: 1.4199\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 600371399018.3632, my average MASE = 600371399018.3632\n",
      "Cluster 3, 600371399018.3632\n",
      "Before prediction: train_X.shape=(2220, 10, 67), train_y.shape=(2220, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5201 - val_loss: 0.4799\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4679 - val_loss: 0.4642\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4224 - val_loss: 0.4493\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3809 - val_loss: 0.4354\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3432 - val_loss: 0.4227\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3104 - val_loss: 0.4125\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.2826 - val_loss: 0.4024\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.2608 - val_loss: 0.3936\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.2437 - val_loss: 0.3864\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.2295 - val_loss: 0.3797\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.2172 - val_loss: 0.3734\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.2058 - val_loss: 0.3678\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.1954 - val_loss: 0.3627\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1857 - val_loss: 0.3579\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1765 - val_loss: 0.3535\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1679 - val_loss: 0.3487\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.1600 - val_loss: 0.3444\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1531 - val_loss: 0.3391\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1468 - val_loss: 0.3346\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1413 - val_loss: 0.3300\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1365 - val_loss: 0.3258\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1321 - val_loss: 0.3218\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.1282 - val_loss: 0.3181\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.1246 - val_loss: 0.3146\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1213 - val_loss: 0.3109\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.1184 - val_loss: 0.3075\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1156 - val_loss: 0.3041\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1131 - val_loss: 0.3010\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.1107 - val_loss: 0.2982\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1085 - val_loss: 0.2953\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1065 - val_loss: 0.2927\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.1045 - val_loss: 0.2902\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.1026 - val_loss: 0.2879\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.1007 - val_loss: 0.2854\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.0989 - val_loss: 0.2833\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.0971 - val_loss: 0.2810\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.0955 - val_loss: 0.2790\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.0938 - val_loss: 0.2771\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.0922 - val_loss: 0.2744\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.0906 - val_loss: 0.2719\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 75856024.38332567, my average MASE = 75856024.38332567\n",
      "Cluster 4, 75856024.38332567\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=7, 7, 44, (67, 67)\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.5201 - val_loss: 1.4489\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5164 - val_loss: 1.4466\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5127 - val_loss: 1.4443\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5090 - val_loss: 1.4420\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5053 - val_loss: 1.4397\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5015 - val_loss: 1.4375\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4977 - val_loss: 1.4353\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4939 - val_loss: 1.4331\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4900 - val_loss: 1.4310\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4862 - val_loss: 1.4288\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4823 - val_loss: 1.4266\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4783 - val_loss: 1.4244\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4743 - val_loss: 1.4222\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4703 - val_loss: 1.4200\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4663 - val_loss: 1.4178\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4622 - val_loss: 1.4155\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4582 - val_loss: 1.4133\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4541 - val_loss: 1.4111\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4500 - val_loss: 1.4089\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4458 - val_loss: 1.4067\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4417 - val_loss: 1.4044\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4376 - val_loss: 1.4022\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4334 - val_loss: 1.3999\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4293 - val_loss: 1.3977\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4251 - val_loss: 1.3954\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4209 - val_loss: 1.3931\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4167 - val_loss: 1.3908\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4125 - val_loss: 1.3884\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4082 - val_loss: 1.3861\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4040 - val_loss: 1.3837\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3998 - val_loss: 1.3814\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3955 - val_loss: 1.3790\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3913 - val_loss: 1.3766\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3871 - val_loss: 1.3743\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3828 - val_loss: 1.3719\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3786 - val_loss: 1.3694\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3744 - val_loss: 1.3669\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3702 - val_loss: 1.3644\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3661 - val_loss: 1.3618\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3620 - val_loss: 1.3592\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 603504948684.2297, my average MASE = 603504948684.2297\n",
      "Cluster 0, 603504948684.2297\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.5226 - val_loss: 0.4307\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3734 - val_loss: 0.3122\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.2632 - val_loss: 0.2522\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1995 - val_loss: 0.2433\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1617 - val_loss: 0.2584\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1391 - val_loss: 0.2660\n",
      "Epoch 6: early stopping\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 372351557264.3331, my average MASE = 372351557264.3331\n",
      "Cluster 1, 372351557264.3331\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5606 - val_loss: 0.4106\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5515 - val_loss: 0.4065\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5427 - val_loss: 0.4025\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5339 - val_loss: 0.3987\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5255 - val_loss: 0.3949\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5176 - val_loss: 0.3914\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5100 - val_loss: 0.3882\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5028 - val_loss: 0.3850\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4963 - val_loss: 0.3821\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4903 - val_loss: 0.3794\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4845 - val_loss: 0.3767\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4788 - val_loss: 0.3742\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4734 - val_loss: 0.3717\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4680 - val_loss: 0.3693\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4627 - val_loss: 0.3669\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4575 - val_loss: 0.3645\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4523 - val_loss: 0.3623\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4471 - val_loss: 0.3599\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4419 - val_loss: 0.3576\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4368 - val_loss: 0.3553\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4316 - val_loss: 0.3530\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4264 - val_loss: 0.3507\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4212 - val_loss: 0.3484\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4159 - val_loss: 0.3461\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4105 - val_loss: 0.3438\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4050 - val_loss: 0.3416\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3994 - val_loss: 0.3394\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3937 - val_loss: 0.3372\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3878 - val_loss: 0.3350\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3819 - val_loss: 0.3329\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3760 - val_loss: 0.3309\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3701 - val_loss: 0.3290\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3643 - val_loss: 0.3272\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3585 - val_loss: 0.3253\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3529 - val_loss: 0.3237\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3474 - val_loss: 0.3220\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3420 - val_loss: 0.3205\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3367 - val_loss: 0.3190\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3316 - val_loss: 0.3175\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3266 - val_loss: 0.3161\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 56470494190.30021, my average MASE = 56470494190.30021\n",
      "Cluster 2, 56470494190.30021\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(133, 10, 67), train_y.shape=(133, 67), test_X.shape=(44, 10, 67), test_y.shape=(44, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.2452 - val_loss: 1.1965\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.2314 - val_loss: 1.1837\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.2176 - val_loss: 1.1711\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.2036 - val_loss: 1.1586\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.1896 - val_loss: 1.1464\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.1756 - val_loss: 1.1342\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.1618 - val_loss: 1.1221\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.1481 - val_loss: 1.1102\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.1346 - val_loss: 1.0983\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.1215 - val_loss: 1.0867\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.1087 - val_loss: 1.0754\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.0962 - val_loss: 1.0644\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.0841 - val_loss: 1.0537\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.0724 - val_loss: 1.0434\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.0611 - val_loss: 1.0333\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.0501 - val_loss: 1.0234\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.0393 - val_loss: 1.0138\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.0287 - val_loss: 1.0043\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.0180 - val_loss: 0.9950\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.0076 - val_loss: 0.9859\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.9971 - val_loss: 0.9769\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.9867 - val_loss: 0.9680\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.9764 - val_loss: 0.9591\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.9661 - val_loss: 0.9503\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.9558 - val_loss: 0.9413\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.9454 - val_loss: 0.9322\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.9351 - val_loss: 0.9230\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.9247 - val_loss: 0.9136\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.9144 - val_loss: 0.9042\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.9042 - val_loss: 0.8949\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.8941 - val_loss: 0.8857\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8840 - val_loss: 0.8767\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8741 - val_loss: 0.8681\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.8648 - val_loss: 0.8600\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.8559 - val_loss: 0.8522\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8469 - val_loss: 0.8443\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.8381 - val_loss: 0.8364\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.8291 - val_loss: 0.8283\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.8203 - val_loss: 0.8201\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.8114 - val_loss: 0.8118\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(44, 67), test_y.shape=(44, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 94879674845.79556, my average MASE = 94879674845.79556\n",
      "Cluster 4, 94879674845.79556\n",
      "Before prediction: train_X.shape=(97, 10, 67), train_y.shape=(97, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.8277 - val_loss: 0.7831\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8202 - val_loss: 0.7766\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8128 - val_loss: 0.7701\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8055 - val_loss: 0.7637\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7982 - val_loss: 0.7573\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7910 - val_loss: 0.7510\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7840 - val_loss: 0.7448\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7770 - val_loss: 0.7386\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7700 - val_loss: 0.7325\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7631 - val_loss: 0.7264\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7563 - val_loss: 0.7204\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7496 - val_loss: 0.7145\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7429 - val_loss: 0.7085\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7363 - val_loss: 0.7026\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7298 - val_loss: 0.6967\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7233 - val_loss: 0.6909\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7170 - val_loss: 0.6851\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7108 - val_loss: 0.6793\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7049 - val_loss: 0.6737\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6991 - val_loss: 0.6681\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6935 - val_loss: 0.6625\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6880 - val_loss: 0.6571\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6826 - val_loss: 0.6518\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6773 - val_loss: 0.6466\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6721 - val_loss: 0.6413\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6669 - val_loss: 0.6362\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6618 - val_loss: 0.6311\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6568 - val_loss: 0.6261\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6518 - val_loss: 0.6212\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6469 - val_loss: 0.6164\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6420 - val_loss: 0.6118\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6372 - val_loss: 0.6072\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6325 - val_loss: 0.6026\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6279 - val_loss: 0.5982\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6233 - val_loss: 0.5939\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6187 - val_loss: 0.5896\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6141 - val_loss: 0.5853\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6096 - val_loss: 0.5811\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6051 - val_loss: 0.5768\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6006 - val_loss: 0.5726\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 56770575962.03453, my average MASE = 56770575962.03453\n",
      "Cluster 5, 56770575962.03453\n",
      "Before prediction: train_X.shape=(79, 10, 67), train_y.shape=(79, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.7052 - val_loss: 0.6636\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6953 - val_loss: 0.6570\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6855 - val_loss: 0.6506\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6760 - val_loss: 0.6445\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6669 - val_loss: 0.6385\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6582 - val_loss: 0.6327\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6496 - val_loss: 0.6270\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6413 - val_loss: 0.6213\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6330 - val_loss: 0.6156\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6249 - val_loss: 0.6098\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6170 - val_loss: 0.6040\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6093 - val_loss: 0.5982\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6017 - val_loss: 0.5924\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5941 - val_loss: 0.5865\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5866 - val_loss: 0.5806\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5791 - val_loss: 0.5747\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5716 - val_loss: 0.5687\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5641 - val_loss: 0.5627\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5565 - val_loss: 0.5568\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5490 - val_loss: 0.5509\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5415 - val_loss: 0.5452\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5340 - val_loss: 0.5394\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5264 - val_loss: 0.5337\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5189 - val_loss: 0.5279\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5115 - val_loss: 0.5221\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5041 - val_loss: 0.5161\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4968 - val_loss: 0.5102\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4897 - val_loss: 0.5043\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4827 - val_loss: 0.4986\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4760 - val_loss: 0.4930\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4694 - val_loss: 0.4878\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4630 - val_loss: 0.4830\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4568 - val_loss: 0.4783\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4507 - val_loss: 0.4739\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4447 - val_loss: 0.4697\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4388 - val_loss: 0.4657\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4330 - val_loss: 0.4618\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4273 - val_loss: 0.4578\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4218 - val_loss: 0.4538\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4164 - val_loss: 0.4498\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 189263407948.19165, my average MASE = 189263407948.19165\n",
      "Cluster 6, 189263407948.19165\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=9, 9, 166, (151, 67)\n",
      "Before prediction: train_X.shape=(85, 10, 67), train_y.shape=(85, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.7217 - val_loss: 0.6432\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7130 - val_loss: 0.6369\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7045 - val_loss: 0.6308\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6960 - val_loss: 0.6249\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6877 - val_loss: 0.6193\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6796 - val_loss: 0.6138\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6717 - val_loss: 0.6085\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6639 - val_loss: 0.6032\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6563 - val_loss: 0.5979\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6488 - val_loss: 0.5927\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6414 - val_loss: 0.5877\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6341 - val_loss: 0.5827\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6269 - val_loss: 0.5778\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6198 - val_loss: 0.5730\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6128 - val_loss: 0.5684\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6058 - val_loss: 0.5637\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5990 - val_loss: 0.5591\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5922 - val_loss: 0.5544\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5855 - val_loss: 0.5498\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5788 - val_loss: 0.5451\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5723 - val_loss: 0.5405\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5658 - val_loss: 0.5358\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5593 - val_loss: 0.5311\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5527 - val_loss: 0.5263\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5462 - val_loss: 0.5216\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5397 - val_loss: 0.5170\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5332 - val_loss: 0.5123\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5268 - val_loss: 0.5078\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5204 - val_loss: 0.5032\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5142 - val_loss: 0.4986\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5081 - val_loss: 0.4940\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5020 - val_loss: 0.4895\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4959 - val_loss: 0.4851\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4899 - val_loss: 0.4807\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4840 - val_loss: 0.4763\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4782 - val_loss: 0.4719\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4723 - val_loss: 0.4675\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4665 - val_loss: 0.4632\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4606 - val_loss: 0.4589\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4548 - val_loss: 0.4548\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 188216904192.57803, my average MASE = 188216904192.57803\n",
      "Cluster 0, 188216904192.57803\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(1564, 10, 67), train_y.shape=(1564, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.3996 - val_loss: 0.3983\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.3697 - val_loss: 0.3850\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.3461 - val_loss: 0.3721\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3257 - val_loss: 0.3606\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3068 - val_loss: 0.3517\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2889 - val_loss: 0.3438\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2723 - val_loss: 0.3362\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2573 - val_loss: 0.3290\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2442 - val_loss: 0.3229\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2329 - val_loss: 0.3171\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2232 - val_loss: 0.3115\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2146 - val_loss: 0.3055\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2066 - val_loss: 0.2997\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1989 - val_loss: 0.2943\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1916 - val_loss: 0.2888\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1847 - val_loss: 0.2839\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1783 - val_loss: 0.2786\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1723 - val_loss: 0.2741\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1666 - val_loss: 0.2692\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1612 - val_loss: 0.2651\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1561 - val_loss: 0.2604\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1512 - val_loss: 0.2560\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1463 - val_loss: 0.2517\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1416 - val_loss: 0.2479\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1372 - val_loss: 0.2441\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1331 - val_loss: 0.2406\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1293 - val_loss: 0.2376\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1257 - val_loss: 0.2344\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1223 - val_loss: 0.2310\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1191 - val_loss: 0.2282\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1161 - val_loss: 0.2258\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1132 - val_loss: 0.2237\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1105 - val_loss: 0.2220\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1078 - val_loss: 0.2204\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1053 - val_loss: 0.2185\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1028 - val_loss: 0.2168\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1004 - val_loss: 0.2154\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.0981 - val_loss: 0.2136\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.0958 - val_loss: 0.2124\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.0936 - val_loss: 0.2112\n",
      "17/17 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 613990151233.6454, my average MASE = 613990151233.6454\n",
      "Cluster 2, 613990151233.6454\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.5316 - val_loss: 0.5311\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.4777 - val_loss: 0.4938\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.4333 - val_loss: 0.4612\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.3927 - val_loss: 0.4307\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3536 - val_loss: 0.4007\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3154 - val_loss: 0.3738\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2808 - val_loss: 0.3506\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2501 - val_loss: 0.3296\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2239 - val_loss: 0.3092\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2029 - val_loss: 0.2930\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1876 - val_loss: 0.2824\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1748 - val_loss: 0.2735\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1630 - val_loss: 0.2653\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1529 - val_loss: 0.2606\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1443 - val_loss: 0.2582\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1372 - val_loss: 0.2584\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1319 - val_loss: 0.2577\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1273 - val_loss: 0.2572\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1234 - val_loss: 0.2569\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1197 - val_loss: 0.2565\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1163 - val_loss: 0.2563\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1130 - val_loss: 0.2562\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1099 - val_loss: 0.2564\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1069 - val_loss: 0.2564\n",
      "Epoch 24: early stopping\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 440535608307.6205, my average MASE = 440535608307.6205\n",
      "Cluster 4, 440535608307.6205\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.8493 - val_loss: 0.8105\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.8409 - val_loss: 0.8034\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.8325 - val_loss: 0.7963\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8242 - val_loss: 0.7893\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.8161 - val_loss: 0.7824\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.8080 - val_loss: 0.7754\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.8000 - val_loss: 0.7684\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.7922 - val_loss: 0.7615\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.7844 - val_loss: 0.7546\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7768 - val_loss: 0.7478\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7694 - val_loss: 0.7411\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7620 - val_loss: 0.7344\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7547 - val_loss: 0.7277\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7475 - val_loss: 0.7210\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7404 - val_loss: 0.7144\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7333 - val_loss: 0.7079\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7262 - val_loss: 0.7014\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7192 - val_loss: 0.6948\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7123 - val_loss: 0.6883\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7055 - val_loss: 0.6818\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6987 - val_loss: 0.6754\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6920 - val_loss: 0.6690\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6853 - val_loss: 0.6628\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6787 - val_loss: 0.6567\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6722 - val_loss: 0.6507\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6657 - val_loss: 0.6448\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6593 - val_loss: 0.6390\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6531 - val_loss: 0.6333\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6470 - val_loss: 0.6278\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6411 - val_loss: 0.6225\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6354 - val_loss: 0.6173\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6298 - val_loss: 0.6122\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6243 - val_loss: 0.6071\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6188 - val_loss: 0.6020\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6135 - val_loss: 0.5970\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6083 - val_loss: 0.5921\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6033 - val_loss: 0.5873\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5983 - val_loss: 0.5825\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5933 - val_loss: 0.5777\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5884 - val_loss: 0.5731\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 32218002313.13773, my average MASE = 32218002313.13773\n",
      "Cluster 5, 32218002313.13773\n",
      "Before prediction: train_X.shape=(174, 10, 67), train_y.shape=(174, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5868 - val_loss: 0.4350\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5785 - val_loss: 0.4307\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5703 - val_loss: 0.4264\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5624 - val_loss: 0.4222\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5547 - val_loss: 0.4181\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5473 - val_loss: 0.4140\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5400 - val_loss: 0.4098\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5329 - val_loss: 0.4058\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.5263 - val_loss: 0.4019\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5198 - val_loss: 0.3982\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5135 - val_loss: 0.3946\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5072 - val_loss: 0.3911\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5012 - val_loss: 0.3878\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4951 - val_loss: 0.3845\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4891 - val_loss: 0.3813\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4832 - val_loss: 0.3781\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.4773 - val_loss: 0.3748\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4715 - val_loss: 0.3716\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4658 - val_loss: 0.3683\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4601 - val_loss: 0.3651\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4544 - val_loss: 0.3619\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4489 - val_loss: 0.3588\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4433 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4378 - val_loss: 0.3528\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4323 - val_loss: 0.3499\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4268 - val_loss: 0.3469\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.4212 - val_loss: 0.3439\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4156 - val_loss: 0.3409\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.4098 - val_loss: 0.3378\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4041 - val_loss: 0.3348\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3982 - val_loss: 0.3318\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3922 - val_loss: 0.3289\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3862 - val_loss: 0.3260\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3803 - val_loss: 0.3232\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3744 - val_loss: 0.3203\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3686 - val_loss: 0.3174\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3628 - val_loss: 0.3145\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3572 - val_loss: 0.3117\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3516 - val_loss: 0.3090\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3461 - val_loss: 0.3064\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 59448861725.29094, my average MASE = 59448861725.29094\n",
      "Cluster 6, 59448861725.29094\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3494 - val_loss: 1.3159\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3450 - val_loss: 1.3114\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3405 - val_loss: 1.3068\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3360 - val_loss: 1.3023\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3314 - val_loss: 1.2977\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3268 - val_loss: 1.2930\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3222 - val_loss: 1.2884\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3176 - val_loss: 1.2837\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3129 - val_loss: 1.2790\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3082 - val_loss: 1.2742\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3035 - val_loss: 1.2695\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2988 - val_loss: 1.2647\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2940 - val_loss: 1.2598\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2892 - val_loss: 1.2550\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2843 - val_loss: 1.2501\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2794 - val_loss: 1.2452\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2746 - val_loss: 1.2402\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2698 - val_loss: 1.2353\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2651 - val_loss: 1.2306\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2604 - val_loss: 1.2259\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2557 - val_loss: 1.2211\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2510 - val_loss: 1.2163\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2462 - val_loss: 1.2115\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2414 - val_loss: 1.2066\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2365 - val_loss: 1.2017\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2316 - val_loss: 1.1968\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2267 - val_loss: 1.1919\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2220 - val_loss: 1.1875\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2173 - val_loss: 1.1830\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2126 - val_loss: 1.1784\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2080 - val_loss: 1.1738\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2033 - val_loss: 1.1691\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1986 - val_loss: 1.1643\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1938 - val_loss: 1.1595\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1890 - val_loss: 1.1547\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1841 - val_loss: 1.1498\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1792 - val_loss: 1.1448\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1743 - val_loss: 1.1398\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1693 - val_loss: 1.1348\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1642 - val_loss: 1.1298\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 230.71069628710254, my average MASE = 230.71069628710254\n",
      "Cluster 7, 230.71069628710254\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4860 - val_loss: 1.3869\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4814 - val_loss: 1.3846\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4768 - val_loss: 1.3824\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4722 - val_loss: 1.3802\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4677 - val_loss: 1.3780\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4632 - val_loss: 1.3759\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4588 - val_loss: 1.3737\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4543 - val_loss: 1.3715\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4500 - val_loss: 1.3693\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4457 - val_loss: 1.3671\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4414 - val_loss: 1.3649\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4371 - val_loss: 1.3626\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4329 - val_loss: 1.3604\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4287 - val_loss: 1.3581\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4246 - val_loss: 1.3559\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4205 - val_loss: 1.3536\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4164 - val_loss: 1.3514\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4123 - val_loss: 1.3491\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4083 - val_loss: 1.3468\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4044 - val_loss: 1.3446\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4005 - val_loss: 1.3423\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3966 - val_loss: 1.3400\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3928 - val_loss: 1.3377\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3890 - val_loss: 1.3355\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3853 - val_loss: 1.3333\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3816 - val_loss: 1.3311\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3781 - val_loss: 1.3289\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3745 - val_loss: 1.3267\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3711 - val_loss: 1.3246\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3677 - val_loss: 1.3224\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3643 - val_loss: 1.3203\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3610 - val_loss: 1.3181\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3576 - val_loss: 1.3160\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3543 - val_loss: 1.3139\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3510 - val_loss: 1.3117\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3477 - val_loss: 1.3096\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3444 - val_loss: 1.3075\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3412 - val_loss: 1.3054\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3379 - val_loss: 1.3033\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3347 - val_loss: 1.3013\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 591796592057.2554, my average MASE = 591796592057.2554\n",
      "Cluster 8, 591796592057.2554\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=11, 11, 1, (2617, 67)\n",
      "Before prediction: train_X.shape=(1564, 10, 67), train_y.shape=(1564, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.4273 - val_loss: 0.4056\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.3956 - val_loss: 0.3948\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3685 - val_loss: 0.3840\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3444 - val_loss: 0.3739\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.3221 - val_loss: 0.3646\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.3008 - val_loss: 0.3566\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2811 - val_loss: 0.3498\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2643 - val_loss: 0.3429\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2502 - val_loss: 0.3361\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2378 - val_loss: 0.3296\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2271 - val_loss: 0.3238\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2177 - val_loss: 0.3185\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2097 - val_loss: 0.3131\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2026 - val_loss: 0.3077\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1960 - val_loss: 0.3026\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1900 - val_loss: 0.2979\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2936\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1790 - val_loss: 0.2895\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1740 - val_loss: 0.2854\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1693 - val_loss: 0.2813\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1649 - val_loss: 0.2770\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1608 - val_loss: 0.2729\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1568 - val_loss: 0.2689\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1529 - val_loss: 0.2649\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1491 - val_loss: 0.2609\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1454 - val_loss: 0.2570\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1417 - val_loss: 0.2527\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1382 - val_loss: 0.2489\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1347 - val_loss: 0.2451\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1314 - val_loss: 0.2417\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1282 - val_loss: 0.2379\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1250 - val_loss: 0.2345\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1219 - val_loss: 0.2316\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1189 - val_loss: 0.2288\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1161 - val_loss: 0.2261\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1133 - val_loss: 0.2241\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1106 - val_loss: 0.2223\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1080 - val_loss: 0.2207\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1057 - val_loss: 0.2191\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1034 - val_loss: 0.2178\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 614113370241.7611, my average MASE = 614113370241.7611\n",
      "Cluster 0, 614113370241.7611\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.5177 - val_loss: 0.4854\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.4548 - val_loss: 0.4431\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.3989 - val_loss: 0.4025\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.3492 - val_loss: 0.3629\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.3083 - val_loss: 0.3352\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2757 - val_loss: 0.3156\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2483 - val_loss: 0.3015\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2294 - val_loss: 0.2924\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2151 - val_loss: 0.2833\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2025 - val_loss: 0.2765\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1908 - val_loss: 0.2706\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1789 - val_loss: 0.2635\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1668 - val_loss: 0.2581\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1555 - val_loss: 0.2545\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1454 - val_loss: 0.2513\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1367 - val_loss: 0.2486\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1295 - val_loss: 0.2460\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1238 - val_loss: 0.2447\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1194 - val_loss: 0.2431\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1159 - val_loss: 0.2420\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1129 - val_loss: 0.2409\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1100 - val_loss: 0.2401\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1075 - val_loss: 0.2392\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1050 - val_loss: 0.2378\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1027 - val_loss: 0.2372\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1005 - val_loss: 0.2366\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0986 - val_loss: 0.2353\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0968 - val_loss: 0.2345\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0955 - val_loss: 0.2334\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0944 - val_loss: 0.2324\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0933 - val_loss: 0.2318\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0923 - val_loss: 0.2310\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0914 - val_loss: 0.2303\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0904 - val_loss: 0.2299\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0895 - val_loss: 0.2299\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0887 - val_loss: 0.2295\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0878 - val_loss: 0.2289\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0870 - val_loss: 0.2290\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0862 - val_loss: 0.2287\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0854 - val_loss: 0.2285\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 451106412715.38513, my average MASE = 451106412715.38513\n",
      "Cluster 2, 451106412715.38513\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4108 - val_loss: 1.4003\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4064 - val_loss: 1.3959\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4021 - val_loss: 1.3915\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3977 - val_loss: 1.3871\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3934 - val_loss: 1.3827\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3891 - val_loss: 1.3784\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3849 - val_loss: 1.3742\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3807 - val_loss: 1.3701\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3766 - val_loss: 1.3660\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3726 - val_loss: 1.3620\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3685 - val_loss: 1.3581\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3645 - val_loss: 1.3541\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3606 - val_loss: 1.3502\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3566 - val_loss: 1.3463\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3526 - val_loss: 1.3424\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3486 - val_loss: 1.3386\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3446 - val_loss: 1.3348\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3406 - val_loss: 1.3310\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3366 - val_loss: 1.3274\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3327 - val_loss: 1.3238\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3288 - val_loss: 1.3202\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3250 - val_loss: 1.3167\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3212 - val_loss: 1.3133\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3175 - val_loss: 1.3100\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3138 - val_loss: 1.3066\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3101 - val_loss: 1.3032\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3065 - val_loss: 1.2998\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3029 - val_loss: 1.2963\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2993 - val_loss: 1.2927\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2957 - val_loss: 1.2890\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2921 - val_loss: 1.2853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2884 - val_loss: 1.2816\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.2848 - val_loss: 1.2780\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2812 - val_loss: 1.2745\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2776 - val_loss: 1.2710\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2741 - val_loss: 1.2676\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2706 - val_loss: 1.2644\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.2670 - val_loss: 1.2611\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2635 - val_loss: 1.2579\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2599 - val_loss: 1.2547\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 94727636073.10507, my average MASE = 94727636073.10507\n",
      "Cluster 3, 94727636073.10507\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7821 - val_loss: 0.7953\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7773 - val_loss: 0.7906\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7726 - val_loss: 0.7860\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7678 - val_loss: 0.7813\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7632 - val_loss: 0.7767\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7585 - val_loss: 0.7720\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7539 - val_loss: 0.7674\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7493 - val_loss: 0.7627\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7446 - val_loss: 0.7581\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7400 - val_loss: 0.7534\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7353 - val_loss: 0.7488\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7307 - val_loss: 0.7442\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7260 - val_loss: 0.7396\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7214 - val_loss: 0.7350\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7167 - val_loss: 0.7305\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7120 - val_loss: 0.7259\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7074 - val_loss: 0.7213\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7027 - val_loss: 0.7168\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6981 - val_loss: 0.7122\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6936 - val_loss: 0.7076\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6892 - val_loss: 0.7031\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6847 - val_loss: 0.6985\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6803 - val_loss: 0.6940\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6758 - val_loss: 0.6894\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6715 - val_loss: 0.6849\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6672 - val_loss: 0.6806\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6629 - val_loss: 0.6766\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6586 - val_loss: 0.6728\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6544 - val_loss: 0.6691\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6502 - val_loss: 0.6653\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6461 - val_loss: 0.6616\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6420 - val_loss: 0.6578\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6379 - val_loss: 0.6541\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6339 - val_loss: 0.6503\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6300 - val_loss: 0.6466\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6261 - val_loss: 0.6428\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6222 - val_loss: 0.6389\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6182 - val_loss: 0.6351\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6143 - val_loss: 0.6312\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6104 - val_loss: 0.6276\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 92681419742.12125, my average MASE = 92681419742.12125\n",
      "Cluster 4, 92681419742.12125\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0550 - val_loss: 1.0371\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0503 - val_loss: 1.0330\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0456 - val_loss: 1.0288\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.0408 - val_loss: 1.0248\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0361 - val_loss: 1.0207\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.0314 - val_loss: 1.0167\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0267 - val_loss: 1.0127\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0220 - val_loss: 1.0087\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.0173 - val_loss: 1.0046\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0127 - val_loss: 1.0006\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0081 - val_loss: 0.9965\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0036 - val_loss: 0.9924\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9990 - val_loss: 0.9882\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9945 - val_loss: 0.9841\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9900 - val_loss: 0.9799\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9856 - val_loss: 0.9757\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9811 - val_loss: 0.9715\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9767 - val_loss: 0.9672\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9723 - val_loss: 0.9629\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9679 - val_loss: 0.9586\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9635 - val_loss: 0.9543\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9592 - val_loss: 0.9499\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9548 - val_loss: 0.9455\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9505 - val_loss: 0.9411\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9461 - val_loss: 0.9367\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9419 - val_loss: 0.9322\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9378 - val_loss: 0.9278\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9337 - val_loss: 0.9234\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9297 - val_loss: 0.9192\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9258 - val_loss: 0.9152\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9218 - val_loss: 0.9115\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9179 - val_loss: 0.9080\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9141 - val_loss: 0.9045\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9102 - val_loss: 0.9010\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9064 - val_loss: 0.8975\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9026 - val_loss: 0.8939\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8989 - val_loss: 0.8903\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8951 - val_loss: 0.8868\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8915 - val_loss: 0.8832\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8878 - val_loss: 0.8796\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 62001413635.00812, my average MASE = 62001413635.00812\n",
      "Cluster 5, 62001413635.00812\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.4727 - val_loss: 1.4641\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4693 - val_loss: 1.4607\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4658 - val_loss: 1.4573\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4624 - val_loss: 1.4539\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4590 - val_loss: 1.4506\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4556 - val_loss: 1.4472\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4522 - val_loss: 1.4438\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4488 - val_loss: 1.4404\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4454 - val_loss: 1.4371\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4421 - val_loss: 1.4337\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4388 - val_loss: 1.4304\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4356 - val_loss: 1.4270\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4323 - val_loss: 1.4238\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4291 - val_loss: 1.4205\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4258 - val_loss: 1.4172\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4226 - val_loss: 1.4140\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4194 - val_loss: 1.4107\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4162 - val_loss: 1.4075\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4130 - val_loss: 1.4043\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4098 - val_loss: 1.4011\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4066 - val_loss: 1.3979\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4035 - val_loss: 1.3947\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4003 - val_loss: 1.3915\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3972 - val_loss: 1.3883\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3941 - val_loss: 1.3851\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3909 - val_loss: 1.3819\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3879 - val_loss: 1.3788\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3848 - val_loss: 1.3756\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3818 - val_loss: 1.3724\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3787 - val_loss: 1.3693\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3758 - val_loss: 1.3661\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3728 - val_loss: 1.3631\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3698 - val_loss: 1.3600\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3668 - val_loss: 1.3570\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3638 - val_loss: 1.3541\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3609 - val_loss: 1.3513\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3580 - val_loss: 1.3485\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3551 - val_loss: 1.3457\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3522 - val_loss: 1.3430\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3493 - val_loss: 1.3402\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 610011515221.5139, my average MASE = 610011515221.5139\n",
      "Cluster 6, 610011515221.5139\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.5424 - val_loss: 0.5130\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5330 - val_loss: 0.5048\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5239 - val_loss: 0.4969\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5150 - val_loss: 0.4899\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.5065 - val_loss: 0.4831\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4987 - val_loss: 0.4765\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4911 - val_loss: 0.4698\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4837 - val_loss: 0.4632\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4766 - val_loss: 0.4567\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4696 - val_loss: 0.4504\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4628 - val_loss: 0.4442\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4561 - val_loss: 0.4381\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4494 - val_loss: 0.4322\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4428 - val_loss: 0.4264\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4361 - val_loss: 0.4207\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4295 - val_loss: 0.4152\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4230 - val_loss: 0.4100\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4165 - val_loss: 0.4050\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4100 - val_loss: 0.4000\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4035 - val_loss: 0.3951\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3971 - val_loss: 0.3902\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3908 - val_loss: 0.3852\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3845 - val_loss: 0.3800\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3783 - val_loss: 0.3747\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3720 - val_loss: 0.3694\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3658 - val_loss: 0.3641\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3596 - val_loss: 0.3587\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3533 - val_loss: 0.3533\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3470 - val_loss: 0.3479\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3408 - val_loss: 0.3425\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3347 - val_loss: 0.3372\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3286 - val_loss: 0.3322\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3227 - val_loss: 0.3272\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3169 - val_loss: 0.3223\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3112 - val_loss: 0.3177\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3056 - val_loss: 0.3132\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3002 - val_loss: 0.3090\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2949 - val_loss: 0.3049\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2897 - val_loss: 0.3009\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2847 - val_loss: 0.2970\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 215556677838.2035, my average MASE = 215556677838.2035\n",
      "Cluster 7, 215556677838.2035\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.6583 - val_loss: 3.6945\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6554 - val_loss: 3.6916\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.6526 - val_loss: 3.6887\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.6498 - val_loss: 3.6859\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.6470 - val_loss: 3.6830\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.6442 - val_loss: 3.6801\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6414 - val_loss: 3.6773\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6386 - val_loss: 3.6744\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6359 - val_loss: 3.6715\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6331 - val_loss: 3.6687\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6303 - val_loss: 3.6659\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.6276 - val_loss: 3.6630\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.6248 - val_loss: 3.6602\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.6221 - val_loss: 3.6574\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.6193 - val_loss: 3.6546\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.6166 - val_loss: 3.6518\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.6139 - val_loss: 3.6490\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.6111 - val_loss: 3.6462\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.6084 - val_loss: 3.6435\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.6057 - val_loss: 3.6408\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.6030 - val_loss: 3.6380\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.6003 - val_loss: 3.6353\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5976 - val_loss: 3.6326\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.5950 - val_loss: 3.6298\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.5923 - val_loss: 3.6270\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.5896 - val_loss: 3.6242\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.5869 - val_loss: 3.6215\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5843 - val_loss: 3.6187\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.5816 - val_loss: 3.6159\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.5790 - val_loss: 3.6131\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.5763 - val_loss: 3.6105\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.5737 - val_loss: 3.6078\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.5710 - val_loss: 3.6052\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.5684 - val_loss: 3.6025\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.5658 - val_loss: 3.5999\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.5631 - val_loss: 3.5973\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.5605 - val_loss: 3.5946\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.5579 - val_loss: 3.5920\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.5552 - val_loss: 3.5894\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.5526 - val_loss: 3.5868\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 224.78184996552397, my average MASE = 224.78184996552397\n",
      "Cluster 8, 224.78184996552397\n",
      "Before prediction: train_X.shape=(14, 10, 67), train_y.shape=(14, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6007 - val_loss: 0.6147\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5973 - val_loss: 0.6114\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5939 - val_loss: 0.6081\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5905 - val_loss: 0.6049\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5873 - val_loss: 0.6018\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5841 - val_loss: 0.5987\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5810 - val_loss: 0.5957\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5779 - val_loss: 0.5927\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5747 - val_loss: 0.5896\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5715 - val_loss: 0.5866\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5684 - val_loss: 0.5835\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5652 - val_loss: 0.5805\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5620 - val_loss: 0.5775\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5588 - val_loss: 0.5744\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5556 - val_loss: 0.5714\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5525 - val_loss: 0.5684\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5493 - val_loss: 0.5653\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5462 - val_loss: 0.5622\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5431 - val_loss: 0.5591\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5400 - val_loss: 0.5560\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5368 - val_loss: 0.5528\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5337 - val_loss: 0.5497\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5306 - val_loss: 0.5465\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5274 - val_loss: 0.5434\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5242 - val_loss: 0.5402\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5210 - val_loss: 0.5370\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5177 - val_loss: 0.5338\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5144 - val_loss: 0.5305\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5112 - val_loss: 0.5273\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5078 - val_loss: 0.5239\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5045 - val_loss: 0.5206\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5011 - val_loss: 0.5172\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4977 - val_loss: 0.5138\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4942 - val_loss: 0.5103\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4908 - val_loss: 0.5068\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4873 - val_loss: 0.5032\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4838 - val_loss: 0.4996\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4803 - val_loss: 0.4959\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4767 - val_loss: 0.4921\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4731 - val_loss: 0.4883\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 212307263811.50735, my average MASE = 212307263811.50735\n",
      "Cluster 9, 212307263811.50735\n",
      "Before prediction: train_X.shape=(87, 10, 67), train_y.shape=(87, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.9164 - val_loss: 0.8942\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.9072 - val_loss: 0.8847\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8980 - val_loss: 0.8752\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8890 - val_loss: 0.8660\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8799 - val_loss: 0.8568\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8710 - val_loss: 0.8476\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8621 - val_loss: 0.8385\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8532 - val_loss: 0.8295\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8444 - val_loss: 0.8206\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.8357 - val_loss: 0.8119\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8269 - val_loss: 0.8033\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8182 - val_loss: 0.7950\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8096 - val_loss: 0.7869\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8009 - val_loss: 0.7792\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7923 - val_loss: 0.7715\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7838 - val_loss: 0.7639\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7754 - val_loss: 0.7564\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7670 - val_loss: 0.7489\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7587 - val_loss: 0.7415\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7504 - val_loss: 0.7341\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7424 - val_loss: 0.7269\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7346 - val_loss: 0.7197\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7269 - val_loss: 0.7127\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7192 - val_loss: 0.7060\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7116 - val_loss: 0.6996\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7040 - val_loss: 0.6933\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6966 - val_loss: 0.6872\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6893 - val_loss: 0.6813\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6821 - val_loss: 0.6753\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6749 - val_loss: 0.6693\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6677 - val_loss: 0.6632\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6606 - val_loss: 0.6569\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6534 - val_loss: 0.6505\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6462 - val_loss: 0.6441\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6391 - val_loss: 0.6375\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6319 - val_loss: 0.6309\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6247 - val_loss: 0.6243\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6176 - val_loss: 0.6175\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6104 - val_loss: 0.6107\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6032 - val_loss: 0.6037\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 59655038086.750046, my average MASE = 59655038086.750046\n",
      "Cluster 10, 59655038086.750046\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=2, 2, 17, (27, 67)\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.3620 - val_loss: 2.3089\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.3585 - val_loss: 2.3056\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.3551 - val_loss: 2.3023\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.3517 - val_loss: 2.2991\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3484 - val_loss: 2.2959\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.3450 - val_loss: 2.2927\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.3417 - val_loss: 2.2895\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.3383 - val_loss: 2.2864\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 2.3351 - val_loss: 2.2834\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.3318 - val_loss: 2.2805\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3286 - val_loss: 2.2775\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.3254 - val_loss: 2.2746\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.3222 - val_loss: 2.2718\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3190 - val_loss: 2.2688\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.3159 - val_loss: 2.2659\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.3128 - val_loss: 2.2629\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.3097 - val_loss: 2.2599\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.3065 - val_loss: 2.2570\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.3035 - val_loss: 2.2541\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.3005 - val_loss: 2.2513\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.2976 - val_loss: 2.2485\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.2946 - val_loss: 2.2457\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.2917 - val_loss: 2.2430\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 2.2888 - val_loss: 2.2403\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.2859 - val_loss: 2.2376\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.2830 - val_loss: 2.2348\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2801 - val_loss: 2.2321\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.2773 - val_loss: 2.2293\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.2744 - val_loss: 2.2265\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2715 - val_loss: 2.2237\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2686 - val_loss: 2.2208\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2656 - val_loss: 2.2179\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.2627 - val_loss: 2.2150\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2598 - val_loss: 2.2120\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.2569 - val_loss: 2.2091\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.2541 - val_loss: 2.2061\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.2513 - val_loss: 2.2031\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.2484 - val_loss: 2.2002\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 2.2456 - val_loss: 2.1973\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.2426 - val_loss: 2.1944\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 468876541132.8507, my average MASE = 468876541132.8507\n",
      "Cluster 0, 468876541132.8507\n",
      "Before prediction: train_X.shape=(18361, 10, 67), train_y.shape=(18361, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.5348 - val_loss: 0.5194\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2797 - val_loss: 0.4523\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2189 - val_loss: 0.4071\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1855 - val_loss: 0.3694\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1588 - val_loss: 0.3339\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1361 - val_loss: 0.3054\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.1195 - val_loss: 0.2861\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1078 - val_loss: 0.2697\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.0989 - val_loss: 0.2567\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0919 - val_loss: 0.2447\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0862 - val_loss: 0.2353\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0813 - val_loss: 0.2257\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0770 - val_loss: 0.2180\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0731 - val_loss: 0.2094\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0696 - val_loss: 0.2017\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0665 - val_loss: 0.1949\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0637 - val_loss: 0.1897\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0611 - val_loss: 0.1845\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0587 - val_loss: 0.1791\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0565 - val_loss: 0.1753\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0546 - val_loss: 0.1715\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0528 - val_loss: 0.1676\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0511 - val_loss: 0.1642\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0495 - val_loss: 0.1604\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0481 - val_loss: 0.1579\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0468 - val_loss: 0.1551\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0457 - val_loss: 0.1525\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0446 - val_loss: 0.1505\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0436 - val_loss: 0.1481\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0427 - val_loss: 0.1456\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0419 - val_loss: 0.1442\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0411 - val_loss: 0.1422\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0403 - val_loss: 0.1399\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0396 - val_loss: 0.1383\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0389 - val_loss: 0.1368\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0383 - val_loss: 0.1348\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0377 - val_loss: 0.1334\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0371 - val_loss: 0.1315\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0366 - val_loss: 0.1299\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0361 - val_loss: 0.1285\n",
      "192/192 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 512761445.09864753, my average MASE = 512761445.09864753\n",
      "Cluster 1, 512761445.09864753\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=5, 5, 127, (79, 67)\n",
      "Before prediction: train_X.shape=(41, 10, 67), train_y.shape=(41, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7975 - val_loss: 0.7162\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7928 - val_loss: 0.7120\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7881 - val_loss: 0.7078\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7834 - val_loss: 0.7036\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7787 - val_loss: 0.6993\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7740 - val_loss: 0.6950\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7692 - val_loss: 0.6908\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7644 - val_loss: 0.6865\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7596 - val_loss: 0.6823\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7548 - val_loss: 0.6782\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7500 - val_loss: 0.6740\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7452 - val_loss: 0.6700\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7404 - val_loss: 0.6659\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7355 - val_loss: 0.6618\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7306 - val_loss: 0.6578\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7257 - val_loss: 0.6537\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7208 - val_loss: 0.6496\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7158 - val_loss: 0.6455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7109 - val_loss: 0.6415\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7059 - val_loss: 0.6374\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7009 - val_loss: 0.6333\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6958 - val_loss: 0.6292\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6907 - val_loss: 0.6250\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6856 - val_loss: 0.6209\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6806 - val_loss: 0.6167\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6755 - val_loss: 0.6125\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6704 - val_loss: 0.6083\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6654 - val_loss: 0.6042\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6605 - val_loss: 0.6001\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6557 - val_loss: 0.5961\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6512 - val_loss: 0.5923\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6468 - val_loss: 0.5884\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6425 - val_loss: 0.5847\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6382 - val_loss: 0.5811\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6340 - val_loss: 0.5775\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6298 - val_loss: 0.5741\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6256 - val_loss: 0.5707\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6214 - val_loss: 0.5673\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6173 - val_loss: 0.5640\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6131 - val_loss: 0.5607\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 214501592829.1013, my average MASE = 214501592829.1013\n",
      "Cluster 0, 214501592829.1013\n",
      "Before prediction: train_X.shape=(25, 10, 67), train_y.shape=(25, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.5507 - val_loss: 1.5643\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5476 - val_loss: 1.5615\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5445 - val_loss: 1.5587\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5414 - val_loss: 1.5560\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5384 - val_loss: 1.5532\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5353 - val_loss: 1.5506\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5322 - val_loss: 1.5479\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5292 - val_loss: 1.5454\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5261 - val_loss: 1.5428\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5231 - val_loss: 1.5403\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5201 - val_loss: 1.5378\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5170 - val_loss: 1.5353\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5140 - val_loss: 1.5329\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5110 - val_loss: 1.5304\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5081 - val_loss: 1.5279\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5051 - val_loss: 1.5254\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5021 - val_loss: 1.5230\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4992 - val_loss: 1.5205\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4962 - val_loss: 1.5181\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4933 - val_loss: 1.5157\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4903 - val_loss: 1.5133\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4874 - val_loss: 1.5109\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4845 - val_loss: 1.5084\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4815 - val_loss: 1.5060\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4786 - val_loss: 1.5036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4756 - val_loss: 1.5011\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4727 - val_loss: 1.4987\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4698 - val_loss: 1.4963\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4669 - val_loss: 1.4938\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4639 - val_loss: 1.4914\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4610 - val_loss: 1.4889\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4581 - val_loss: 1.4864\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4551 - val_loss: 1.4839\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4522 - val_loss: 1.4814\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4492 - val_loss: 1.4788\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4462 - val_loss: 1.4763\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4432 - val_loss: 1.4738\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4403 - val_loss: 1.4712\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4373 - val_loss: 1.4687\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4343 - val_loss: 1.4663\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 67490029871.61379, my average MASE = 67490029871.61379\n",
      "Cluster 1, 67490029871.61379\n",
      "Before prediction: train_X.shape=(5956, 10, 67), train_y.shape=(5956, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.4884 - val_loss: 0.3987\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.3350 - val_loss: 0.2788\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.2376 - val_loss: 0.2393\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.1907 - val_loss: 0.2335\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.1609 - val_loss: 0.2446\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1397 - val_loss: 0.2605\n",
      "Epoch 6: early stopping\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 372878922661.9205, my average MASE = 372878922661.9205\n",
      "Cluster 2, 372878922661.9205\n",
      "Before prediction: train_X.shape=(187, 10, 67), train_y.shape=(187, 67), test_X.shape=(62, 10, 67), test_y.shape=(62, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.5089 - val_loss: 0.4112\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5004 - val_loss: 0.4072\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4923 - val_loss: 0.4034\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4847 - val_loss: 0.3996\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4775 - val_loss: 0.3959\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4706 - val_loss: 0.3925\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4640 - val_loss: 0.3891\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4578 - val_loss: 0.3859\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4517 - val_loss: 0.3828\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4460 - val_loss: 0.3800\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4403 - val_loss: 0.3772\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4348 - val_loss: 0.3745\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4293 - val_loss: 0.3720\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4239 - val_loss: 0.3695\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4186 - val_loss: 0.3670\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4133 - val_loss: 0.3646\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4081 - val_loss: 0.3622\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4030 - val_loss: 0.3598\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3979 - val_loss: 0.3574\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3929 - val_loss: 0.3550\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3880 - val_loss: 0.3527\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3831 - val_loss: 0.3504\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3784 - val_loss: 0.3482\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3737 - val_loss: 0.3459\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3691 - val_loss: 0.3438\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3646 - val_loss: 0.3417\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3600 - val_loss: 0.3396\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3554 - val_loss: 0.3374\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3510 - val_loss: 0.3352\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3466 - val_loss: 0.3330\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3422 - val_loss: 0.3308\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3378 - val_loss: 0.3285\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3335 - val_loss: 0.3263\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3291 - val_loss: 0.3241\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3247 - val_loss: 0.3219\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3202 - val_loss: 0.3198\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3158 - val_loss: 0.3177\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3113 - val_loss: 0.3156\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3067 - val_loss: 0.3137\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3021 - val_loss: 0.3117\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(62, 67), test_y.shape=(62, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 59775868722.90994, my average MASE = 59775868722.90994\n",
      "Cluster 3, 59775868722.90994\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.7178 - val_loss: 1.7657\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.7134 - val_loss: 1.7631\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7091 - val_loss: 1.7605\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7047 - val_loss: 1.7580\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.7004 - val_loss: 1.7556\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6961 - val_loss: 1.7532\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6919 - val_loss: 1.7508\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6877 - val_loss: 1.7486\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6836 - val_loss: 1.7463\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6795 - val_loss: 1.7441\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6754 - val_loss: 1.7420\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6715 - val_loss: 1.7399\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6677 - val_loss: 1.7380\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6640 - val_loss: 1.7360\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6603 - val_loss: 1.7341\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6566 - val_loss: 1.7321\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6530 - val_loss: 1.7302\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6493 - val_loss: 1.7282\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6457 - val_loss: 1.7262\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6420 - val_loss: 1.7242\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6384 - val_loss: 1.7222\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6347 - val_loss: 1.7201\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6311 - val_loss: 1.7180\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6275 - val_loss: 1.7159\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6239 - val_loss: 1.7137\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6203 - val_loss: 1.7116\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6167 - val_loss: 1.7093\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6132 - val_loss: 1.7071\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6096 - val_loss: 1.7048\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6062 - val_loss: 1.7025\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6027 - val_loss: 1.7001\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5993 - val_loss: 1.6977\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5959 - val_loss: 1.6953\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5925 - val_loss: 1.6928\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5891 - val_loss: 1.6902\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5857 - val_loss: 1.6877\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5824 - val_loss: 1.6852\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5791 - val_loss: 1.6826\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5757 - val_loss: 1.6801\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5724 - val_loss: 1.6775\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 579949417104.3091, my average MASE = 579949417104.3091\n",
      "Cluster 4, 579949417104.3091\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=7, 7, 55, (309, 67)\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5861 - val_loss: 0.4112\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5768 - val_loss: 0.4081\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5679 - val_loss: 0.4051\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5592 - val_loss: 0.4022\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5511 - val_loss: 0.3994\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5431 - val_loss: 0.3966\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5354 - val_loss: 0.3940\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5279 - val_loss: 0.3916\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5206 - val_loss: 0.3893\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5135 - val_loss: 0.3871\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5066 - val_loss: 0.3850\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4999 - val_loss: 0.3831\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4934 - val_loss: 0.3811\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4869 - val_loss: 0.3792\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4805 - val_loss: 0.3773\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4743 - val_loss: 0.3754\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4682 - val_loss: 0.3735\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4622 - val_loss: 0.3716\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4564 - val_loss: 0.3695\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4507 - val_loss: 0.3674\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4451 - val_loss: 0.3654\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4395 - val_loss: 0.3634\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4341 - val_loss: 0.3613\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4287 - val_loss: 0.3592\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4234 - val_loss: 0.3572\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4180 - val_loss: 0.3550\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4126 - val_loss: 0.3528\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4073 - val_loss: 0.3507\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4019 - val_loss: 0.3485\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3965 - val_loss: 0.3462\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3909 - val_loss: 0.3439\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3854 - val_loss: 0.3416\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3799 - val_loss: 0.3394\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3743 - val_loss: 0.3372\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3688 - val_loss: 0.3351\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3636 - val_loss: 0.3330\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3589 - val_loss: 0.3310\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3540 - val_loss: 0.3289\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3492 - val_loss: 0.3269\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3445 - val_loss: 0.3250\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 57807542967.69541, my average MASE = 57807542967.69541\n",
      "Cluster 0, 57807542967.69541\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.4702 - val_loss: 1.4433\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4658 - val_loss: 1.4409\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4615 - val_loss: 1.4386\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4572 - val_loss: 1.4363\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4529 - val_loss: 1.4341\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4487 - val_loss: 1.4318\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4445 - val_loss: 1.4296\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4404 - val_loss: 1.4274\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4363 - val_loss: 1.4252\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4323 - val_loss: 1.4230\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4284 - val_loss: 1.4208\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4245 - val_loss: 1.4185\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4207 - val_loss: 1.4163\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4170 - val_loss: 1.4140\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4132 - val_loss: 1.4118\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4095 - val_loss: 1.4095\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4059 - val_loss: 1.4073\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4022 - val_loss: 1.4050\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3986 - val_loss: 1.4028\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3950 - val_loss: 1.4005\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3914 - val_loss: 1.3983\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3878 - val_loss: 1.3961\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3842 - val_loss: 1.3940\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3806 - val_loss: 1.3918\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3770 - val_loss: 1.3897\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3734 - val_loss: 1.3876\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3698 - val_loss: 1.3855\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3662 - val_loss: 1.3834\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3626 - val_loss: 1.3813\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3591 - val_loss: 1.3792\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3555 - val_loss: 1.3772\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3519 - val_loss: 1.3751\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3483 - val_loss: 1.3730\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3447 - val_loss: 1.3709\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3412 - val_loss: 1.3687\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3376 - val_loss: 1.3665\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3340 - val_loss: 1.3643\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3305 - val_loss: 1.3620\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3269 - val_loss: 1.3596\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3233 - val_loss: 1.3572\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 593835391004.2117, my average MASE = 593835391004.2117\n",
      "Cluster 1, 593835391004.2117\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(151, 10, 67), train_y.shape=(151, 67), test_X.shape=(50, 10, 67), test_y.shape=(50, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.8076 - val_loss: 0.7430\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7960 - val_loss: 0.7329\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7844 - val_loss: 0.7230\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7729 - val_loss: 0.7133\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7615 - val_loss: 0.7039\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7502 - val_loss: 0.6946\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7392 - val_loss: 0.6855\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7285 - val_loss: 0.6768\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7181 - val_loss: 0.6683\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7081 - val_loss: 0.6600\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6983 - val_loss: 0.6519\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6888 - val_loss: 0.6440\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6796 - val_loss: 0.6362\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6707 - val_loss: 0.6286\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6622 - val_loss: 0.6212\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6538 - val_loss: 0.6139\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6457 - val_loss: 0.6067\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6378 - val_loss: 0.5995\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6300 - val_loss: 0.5923\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6224 - val_loss: 0.5851\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6149 - val_loss: 0.5780\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6075 - val_loss: 0.5709\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6003 - val_loss: 0.5640\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5931 - val_loss: 0.5571\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5861 - val_loss: 0.5505\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5791 - val_loss: 0.5440\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5720 - val_loss: 0.5376\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5650 - val_loss: 0.5313\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5581 - val_loss: 0.5251\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5512 - val_loss: 0.5192\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5444 - val_loss: 0.5134\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5376 - val_loss: 0.5079\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5309 - val_loss: 0.5026\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5243 - val_loss: 0.4973\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5177 - val_loss: 0.4920\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5111 - val_loss: 0.4867\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5046 - val_loss: 0.4813\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4980 - val_loss: 0.4757\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4914 - val_loss: 0.4700\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4849 - val_loss: 0.4644\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(50, 67), test_y.shape=(50, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 56100444379.39332, my average MASE = 56100444379.39332\n",
      "Cluster 3, 56100444379.39332\n",
      "Before prediction: train_X.shape=(80, 10, 67), train_y.shape=(80, 67), test_X.shape=(27, 10, 67), test_y.shape=(27, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.7280 - val_loss: 0.7211\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7195 - val_loss: 0.7139\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7111 - val_loss: 0.7069\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7030 - val_loss: 0.6999\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6951 - val_loss: 0.6930\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6872 - val_loss: 0.6862\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6794 - val_loss: 0.6796\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6719 - val_loss: 0.6730\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6644 - val_loss: 0.6664\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6571 - val_loss: 0.6600\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6498 - val_loss: 0.6537\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6427 - val_loss: 0.6474\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6356 - val_loss: 0.6412\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6287 - val_loss: 0.6352\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6219 - val_loss: 0.6292\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6153 - val_loss: 0.6235\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6088 - val_loss: 0.6178\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6025 - val_loss: 0.6123\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5962 - val_loss: 0.6069\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5901 - val_loss: 0.6016\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5840 - val_loss: 0.5963\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5780 - val_loss: 0.5911\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5721 - val_loss: 0.5860\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5662 - val_loss: 0.5809\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5604 - val_loss: 0.5758\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5546 - val_loss: 0.5708\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5488 - val_loss: 0.5657\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5429 - val_loss: 0.5607\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5371 - val_loss: 0.5556\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5312 - val_loss: 0.5505\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5255 - val_loss: 0.5453\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5199 - val_loss: 0.5401\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5142 - val_loss: 0.5348\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5086 - val_loss: 0.5295\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5029 - val_loss: 0.5242\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4972 - val_loss: 0.5190\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4916 - val_loss: 0.5137\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4859 - val_loss: 0.5084\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4804 - val_loss: 0.5032\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4748 - val_loss: 0.4981\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(27, 67), test_y.shape=(27, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 188481987790.98926, my average MASE = 188481987790.98926\n",
      "Cluster 4, 188481987790.98926\n",
      "Before prediction: train_X.shape=(5956, 10, 67), train_y.shape=(5956, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.5244 - val_loss: 0.4300\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.3702 - val_loss: 0.3145\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.2629 - val_loss: 0.2688\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1989 - val_loss: 0.2664\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.1581 - val_loss: 0.2776\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.1320 - val_loss: 0.2862\n",
      "Epoch 6: early stopping\n",
      "63/63 [==============================] - 1s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 381566481870.29803, my average MASE = 381566481870.29803\n",
      "Cluster 5, 381566481870.29803\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=9, 9, 39, (69, 67)\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4578 - val_loss: 1.4552\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4538 - val_loss: 1.4523\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4499 - val_loss: 1.4495\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4459 - val_loss: 1.4467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4420 - val_loss: 1.4439\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4380 - val_loss: 1.4411\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4341 - val_loss: 1.4382\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4301 - val_loss: 1.4354\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4262 - val_loss: 1.4325\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4222 - val_loss: 1.4296\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4183 - val_loss: 1.4267\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4143 - val_loss: 1.4237\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4103 - val_loss: 1.4207\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4063 - val_loss: 1.4177\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4024 - val_loss: 1.4147\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3984 - val_loss: 1.4117\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3944 - val_loss: 1.4086\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3904 - val_loss: 1.4056\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3864 - val_loss: 1.4025\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3823 - val_loss: 1.3994\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3783 - val_loss: 1.3962\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3743 - val_loss: 1.3931\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3702 - val_loss: 1.3900\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3661 - val_loss: 1.3868\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3620 - val_loss: 1.3837\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3579 - val_loss: 1.3805\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3538 - val_loss: 1.3773\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3497 - val_loss: 1.3741\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3456 - val_loss: 1.3709\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3414 - val_loss: 1.3678\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3373 - val_loss: 1.3646\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3332 - val_loss: 1.3614\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3290 - val_loss: 1.3582\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3249 - val_loss: 1.3551\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3208 - val_loss: 1.3519\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3167 - val_loss: 1.3488\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3126 - val_loss: 1.3456\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3085 - val_loss: 1.3425\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3045 - val_loss: 1.3394\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3005 - val_loss: 1.3363\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 610597210933.441, my average MASE = 610597210933.441\n",
      "Cluster 0, 610597210933.441\n",
      "Before prediction: train_X.shape=(121, 10, 67), train_y.shape=(121, 67), test_X.shape=(40, 10, 67), test_y.shape=(40, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0755 - val_loss: 0.7663\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.0656 - val_loss: 0.7627\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0558 - val_loss: 0.7593\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.0460 - val_loss: 0.7559\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 1.0364 - val_loss: 0.7527\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.0269 - val_loss: 0.7495\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0176 - val_loss: 0.7464\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.0083 - val_loss: 0.7434\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.9994 - val_loss: 0.7405\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.9906 - val_loss: 0.7376\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.9821 - val_loss: 0.7348\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.9738 - val_loss: 0.7320\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.9657 - val_loss: 0.7291\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.9577 - val_loss: 0.7262\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.9498 - val_loss: 0.7233\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9421 - val_loss: 0.7203\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.9343 - val_loss: 0.7173\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.9266 - val_loss: 0.7143\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.9190 - val_loss: 0.7113\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.9114 - val_loss: 0.7083\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.9038 - val_loss: 0.7052\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.8963 - val_loss: 0.7020\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8889 - val_loss: 0.6989\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8814 - val_loss: 0.6957\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.8740 - val_loss: 0.6925\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8666 - val_loss: 0.6893\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8592 - val_loss: 0.6861\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8518 - val_loss: 0.6830\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8444 - val_loss: 0.6798\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8370 - val_loss: 0.6767\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8298 - val_loss: 0.6738\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.8225 - val_loss: 0.6708\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8155 - val_loss: 0.6680\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8084 - val_loss: 0.6652\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8013 - val_loss: 0.6625\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7943 - val_loss: 0.6597\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7874 - val_loss: 0.6569\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7804 - val_loss: 0.6541\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7736 - val_loss: 0.6511\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7669 - val_loss: 0.6481\n",
      "2/2 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(40, 67), test_y.shape=(40, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 57102943493.415245, my average MASE = 57102943493.415245\n",
      "Cluster 1, 57102943493.415245\n",
      "Before prediction: train_X.shape=(151, 10, 67), train_y.shape=(151, 67), test_X.shape=(50, 10, 67), test_y.shape=(50, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7894 - val_loss: 0.7348\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7795 - val_loss: 0.7257\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7699 - val_loss: 0.7167\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7606 - val_loss: 0.7078\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7515 - val_loss: 0.6990\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7426 - val_loss: 0.6904\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7337 - val_loss: 0.6821\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7249 - val_loss: 0.6740\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7161 - val_loss: 0.6661\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7072 - val_loss: 0.6582\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6984 - val_loss: 0.6503\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6894 - val_loss: 0.6423\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6804 - val_loss: 0.6341\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6713 - val_loss: 0.6258\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6621 - val_loss: 0.6176\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6529 - val_loss: 0.6094\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6436 - val_loss: 0.6012\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6343 - val_loss: 0.5930\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6250 - val_loss: 0.5849\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6159 - val_loss: 0.5767\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6069 - val_loss: 0.5686\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5979 - val_loss: 0.5605\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5890 - val_loss: 0.5525\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5801 - val_loss: 0.5444\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5712 - val_loss: 0.5362\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5622 - val_loss: 0.5278\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5530 - val_loss: 0.5192\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5436 - val_loss: 0.5106\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5340 - val_loss: 0.5022\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5243 - val_loss: 0.4939\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5146 - val_loss: 0.4859\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5049 - val_loss: 0.4781\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4952 - val_loss: 0.4704\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4856 - val_loss: 0.4628\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4758 - val_loss: 0.4552\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4660 - val_loss: 0.4477\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4562 - val_loss: 0.4401\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4465 - val_loss: 0.4324\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4369 - val_loss: 0.4249\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4276 - val_loss: 0.4175\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(50, 67), test_y.shape=(50, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 57411282055.5864, my average MASE = 57411282055.5864\n",
      "Cluster 2, 57411282055.5864\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.6257 - val_loss: 1.6137\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6231 - val_loss: 1.6116\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6206 - val_loss: 1.6094\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6182 - val_loss: 1.6073\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6158 - val_loss: 1.6052\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6134 - val_loss: 1.6031\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6111 - val_loss: 1.6010\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6089 - val_loss: 1.5990\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6066 - val_loss: 1.5969\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6044 - val_loss: 1.5949\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6022 - val_loss: 1.5928\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6000 - val_loss: 1.5906\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5978 - val_loss: 1.5885\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5957 - val_loss: 1.5864\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5935 - val_loss: 1.5842\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5913 - val_loss: 1.5820\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5891 - val_loss: 1.5798\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5870 - val_loss: 1.5776\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5848 - val_loss: 1.5754\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5826 - val_loss: 1.5732\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5804 - val_loss: 1.5710\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5781 - val_loss: 1.5688\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5759 - val_loss: 1.5666\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5737 - val_loss: 1.5644\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5715 - val_loss: 1.5621\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5693 - val_loss: 1.5599\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5671 - val_loss: 1.5577\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5649 - val_loss: 1.5555\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5627 - val_loss: 1.5533\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5604 - val_loss: 1.5511\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5582 - val_loss: 1.5489\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5559 - val_loss: 1.5466\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5536 - val_loss: 1.5444\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5514 - val_loss: 1.5421\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5491 - val_loss: 1.5398\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5469 - val_loss: 1.5376\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5446 - val_loss: 1.5354\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.5424 - val_loss: 1.5332\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5403 - val_loss: 1.5310\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5381 - val_loss: 1.5289\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 98728297588.5253, my average MASE = 98728297588.5253\n",
      "Cluster 3, 98728297588.5253\n",
      "Before prediction: train_X.shape=(22, 10, 67), train_y.shape=(22, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.6377 - val_loss: 1.8239\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.6328 - val_loss: 1.8193\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6280 - val_loss: 1.8146\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.6232 - val_loss: 1.8098\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.6184 - val_loss: 1.8051\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6136 - val_loss: 1.8003\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6089 - val_loss: 1.7955\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6043 - val_loss: 1.7907\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.5997 - val_loss: 1.7859\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5952 - val_loss: 1.7811\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5908 - val_loss: 1.7763\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5864 - val_loss: 1.7715\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5820 - val_loss: 1.7668\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5776 - val_loss: 1.7620\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5733 - val_loss: 1.7572\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5690 - val_loss: 1.7525\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5648 - val_loss: 1.7478\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5605 - val_loss: 1.7430\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5564 - val_loss: 1.7383\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5522 - val_loss: 1.7335\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5481 - val_loss: 1.7288\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5439 - val_loss: 1.7240\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5398 - val_loss: 1.7193\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5357 - val_loss: 1.7146\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5316 - val_loss: 1.7099\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5275 - val_loss: 1.7052\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5234 - val_loss: 1.7005\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5193 - val_loss: 1.6959\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5152 - val_loss: 1.6913\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5111 - val_loss: 1.6867\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5070 - val_loss: 1.6822\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5029 - val_loss: 1.6777\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4988 - val_loss: 1.6734\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4947 - val_loss: 1.6692\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4905 - val_loss: 1.6650\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4864 - val_loss: 1.6610\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4822 - val_loss: 1.6570\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.4781 - val_loss: 1.6531\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4739 - val_loss: 1.6492\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4697 - val_loss: 1.6454\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 445424282686.5781, my average MASE = 445424282686.5781\n",
      "Cluster 4, 445424282686.5781\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7803 - val_loss: 0.7887\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7753 - val_loss: 0.7836\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7702 - val_loss: 0.7784\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7651 - val_loss: 0.7735\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7601 - val_loss: 0.7685\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7551 - val_loss: 0.7638\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7501 - val_loss: 0.7590\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7454 - val_loss: 0.7543\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7410 - val_loss: 0.7496\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7365 - val_loss: 0.7451\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7319 - val_loss: 0.7408\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7274 - val_loss: 0.7368\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7229 - val_loss: 0.7327\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7184 - val_loss: 0.7286\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7140 - val_loss: 0.7245\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7095 - val_loss: 0.7204\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7049 - val_loss: 0.7163\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7005 - val_loss: 0.7123\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6961 - val_loss: 0.7082\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6917 - val_loss: 0.7043\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6873 - val_loss: 0.7003\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6829 - val_loss: 0.6964\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6785 - val_loss: 0.6925\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6741 - val_loss: 0.6885\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6698 - val_loss: 0.6844\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6656 - val_loss: 0.6803\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6614 - val_loss: 0.6762\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6571 - val_loss: 0.6720\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6528 - val_loss: 0.6681\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6485 - val_loss: 0.6642\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6443 - val_loss: 0.6601\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6400 - val_loss: 0.6561\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6357 - val_loss: 0.6522\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6314 - val_loss: 0.6484\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6272 - val_loss: 0.6447\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6231 - val_loss: 0.6409\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6192 - val_loss: 0.6372\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6153 - val_loss: 0.6336\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6113 - val_loss: 0.6300\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6074 - val_loss: 0.6265\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 90441929831.64088, my average MASE = 90441929831.64088\n",
      "Cluster 6, 90441929831.64088\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7400 - val_loss: 0.7217\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7357 - val_loss: 0.7178\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7316 - val_loss: 0.7139\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7276 - val_loss: 0.7100\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7237 - val_loss: 0.7061\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7199 - val_loss: 0.7023\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7161 - val_loss: 0.6986\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7123 - val_loss: 0.6950\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7086 - val_loss: 0.6915\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7048 - val_loss: 0.6879\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7011 - val_loss: 0.6842\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6973 - val_loss: 0.6804\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6936 - val_loss: 0.6766\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6898 - val_loss: 0.6728\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6861 - val_loss: 0.6689\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6823 - val_loss: 0.6650\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6784 - val_loss: 0.6612\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6746 - val_loss: 0.6574\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6707 - val_loss: 0.6537\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6669 - val_loss: 0.6499\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6630 - val_loss: 0.6461\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6591 - val_loss: 0.6423\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6553 - val_loss: 0.6385\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6514 - val_loss: 0.6346\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6475 - val_loss: 0.6307\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6435 - val_loss: 0.6268\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6396 - val_loss: 0.6230\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6357 - val_loss: 0.6191\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6318 - val_loss: 0.6151\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6278 - val_loss: 0.6112\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6239 - val_loss: 0.6072\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6199 - val_loss: 0.6032\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6159 - val_loss: 0.5991\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6119 - val_loss: 0.5950\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6078 - val_loss: 0.5909\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6037 - val_loss: 0.5868\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5996 - val_loss: 0.5826\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5954 - val_loss: 0.5784\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5912 - val_loss: 0.5742\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5870 - val_loss: 0.5699\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 212978162013.04172, my average MASE = 212978162013.04172\n",
      "Cluster 7, 212978162013.04172\n",
      "Before prediction: train_X.shape=(5956, 10, 67), train_y.shape=(5956, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.4909 - val_loss: 0.4087\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.3630 - val_loss: 0.3165\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.2667 - val_loss: 0.2621\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.2046 - val_loss: 0.2502\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.1633 - val_loss: 0.2516\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1380 - val_loss: 0.2595\n",
      "Epoch 6: early stopping\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 369214614924.24725, my average MASE = 369214614924.24725\n",
      "Cluster 8, 369214614924.24725\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=11, 11, 39, (69, 67)\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.4850 - val_loss: 1.4114\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4809 - val_loss: 1.4087\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4768 - val_loss: 1.4060\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4727 - val_loss: 1.4033\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4687 - val_loss: 1.4006\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4647 - val_loss: 1.3979\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4608 - val_loss: 1.3952\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4569 - val_loss: 1.3925\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4530 - val_loss: 1.3898\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4491 - val_loss: 1.3872\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4453 - val_loss: 1.3845\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4415 - val_loss: 1.3819\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4377 - val_loss: 1.3793\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4340 - val_loss: 1.3767\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4303 - val_loss: 1.3742\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4266 - val_loss: 1.3716\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4230 - val_loss: 1.3691\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4193 - val_loss: 1.3666\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4156 - val_loss: 1.3641\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4120 - val_loss: 1.3617\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4083 - val_loss: 1.3593\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4046 - val_loss: 1.3571\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4008 - val_loss: 1.3548\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3971 - val_loss: 1.3526\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3934 - val_loss: 1.3504\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3897 - val_loss: 1.3483\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3860 - val_loss: 1.3462\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.3823 - val_loss: 1.3440\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3785 - val_loss: 1.3419\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3748 - val_loss: 1.3398\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3710 - val_loss: 1.3378\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3672 - val_loss: 1.3357\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3635 - val_loss: 1.3336\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3597 - val_loss: 1.3315\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3559 - val_loss: 1.3295\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3520 - val_loss: 1.3274\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3482 - val_loss: 1.3253\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3443 - val_loss: 1.3232\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3405 - val_loss: 1.3211\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3366 - val_loss: 1.3190\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 585953039154.5165, my average MASE = 585953039154.5165\n",
      "Cluster 0, 585953039154.5165\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7073 - val_loss: 0.7496\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7037 - val_loss: 0.7459\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7000 - val_loss: 0.7422\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6964 - val_loss: 0.7385\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6928 - val_loss: 0.7349\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6893 - val_loss: 0.7312\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6857 - val_loss: 0.7276\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6822 - val_loss: 0.7240\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6788 - val_loss: 0.7205\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6753 - val_loss: 0.7169\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6719 - val_loss: 0.7134\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6685 - val_loss: 0.7099\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6651 - val_loss: 0.7064\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6618 - val_loss: 0.7029\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6584 - val_loss: 0.6995\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6551 - val_loss: 0.6962\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6519 - val_loss: 0.6928\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6486 - val_loss: 0.6895\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6454 - val_loss: 0.6863\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6421 - val_loss: 0.6830\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6389 - val_loss: 0.6798\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6357 - val_loss: 0.6767\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6325 - val_loss: 0.6735\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6293 - val_loss: 0.6704\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6262 - val_loss: 0.6673\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6230 - val_loss: 0.6642\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6198 - val_loss: 0.6611\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6167 - val_loss: 0.6580\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6135 - val_loss: 0.6550\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6103 - val_loss: 0.6519\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6072 - val_loss: 0.6488\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6040 - val_loss: 0.6457\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6009 - val_loss: 0.6426\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5977 - val_loss: 0.6394\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5946 - val_loss: 0.6363\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5915 - val_loss: 0.6331\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5883 - val_loss: 0.6299\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5852 - val_loss: 0.6268\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5820 - val_loss: 0.6236\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5789 - val_loss: 0.6204\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 57308865890.66418, my average MASE = 57308865890.66418\n",
      "Cluster 1, 57308865890.66418\n",
      "Before prediction: train_X.shape=(62, 10, 67), train_y.shape=(62, 67), test_X.shape=(21, 10, 67), test_y.shape=(21, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9128 - val_loss: 0.8620\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9089 - val_loss: 0.8579\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9049 - val_loss: 0.8538\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9010 - val_loss: 0.8496\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8970 - val_loss: 0.8455\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8931 - val_loss: 0.8413\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8891 - val_loss: 0.8372\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8852 - val_loss: 0.8331\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8813 - val_loss: 0.8291\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8774 - val_loss: 0.8251\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8736 - val_loss: 0.8211\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8698 - val_loss: 0.8173\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8660 - val_loss: 0.8134\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8622 - val_loss: 0.8096\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8585 - val_loss: 0.8059\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8548 - val_loss: 0.8022\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8510 - val_loss: 0.7986\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8473 - val_loss: 0.7949\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8437 - val_loss: 0.7912\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8400 - val_loss: 0.7876\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8364 - val_loss: 0.7840\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8329 - val_loss: 0.7804\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8295 - val_loss: 0.7769\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8261 - val_loss: 0.7735\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8228 - val_loss: 0.7701\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8195 - val_loss: 0.7668\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8162 - val_loss: 0.7635\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8131 - val_loss: 0.7604\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8100 - val_loss: 0.7576\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8071 - val_loss: 0.7549\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8042 - val_loss: 0.7523\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8013 - val_loss: 0.7498\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7986 - val_loss: 0.7473\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7958 - val_loss: 0.7449\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7931 - val_loss: 0.7425\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7904 - val_loss: 0.7401\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7877 - val_loss: 0.7377\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7850 - val_loss: 0.7353\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7823 - val_loss: 0.7328\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7796 - val_loss: 0.7304\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(21, 67), test_y.shape=(21, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 106182787206.1948, my average MASE = 106182787206.1948\n",
      "Cluster 2, 106182787206.1948\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.5161 - val_loss: 1.4351\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5107 - val_loss: 1.4299\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5053 - val_loss: 1.4247\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4999 - val_loss: 1.4195\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4945 - val_loss: 1.4144\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4892 - val_loss: 1.4094\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4840 - val_loss: 1.4044\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4788 - val_loss: 1.3994\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4736 - val_loss: 1.3944\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4684 - val_loss: 1.3894\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4632 - val_loss: 1.3844\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4580 - val_loss: 1.3795\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4528 - val_loss: 1.3744\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4476 - val_loss: 1.3697\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4424 - val_loss: 1.3652\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4374 - val_loss: 1.3606\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4324 - val_loss: 1.3560\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4276 - val_loss: 1.3514\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4227 - val_loss: 1.3467\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4177 - val_loss: 1.3419\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4127 - val_loss: 1.3373\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4077 - val_loss: 1.3327\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4028 - val_loss: 1.3280\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3978 - val_loss: 1.3233\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3927 - val_loss: 1.3184\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3877 - val_loss: 1.3135\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3827 - val_loss: 1.3085\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3776 - val_loss: 1.3035\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3725 - val_loss: 1.2983\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3674 - val_loss: 1.2931\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3623 - val_loss: 1.2881\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3573 - val_loss: 1.2834\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3524 - val_loss: 1.2785\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3477 - val_loss: 1.2737\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3432 - val_loss: 1.2687\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3387 - val_loss: 1.2638\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3342 - val_loss: 1.2588\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3297 - val_loss: 1.2539\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3251 - val_loss: 1.2489\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3206 - val_loss: 1.2440\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 95986748052.71614, my average MASE = 95986748052.71614\n",
      "Cluster 3, 95986748052.71614\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.4059 - val_loss: 0.3890\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3758 - val_loss: 0.3749\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3507 - val_loss: 0.3614\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.3286 - val_loss: 0.3486\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.3087 - val_loss: 0.3383\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2901 - val_loss: 0.3296\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2718 - val_loss: 0.3223\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2547 - val_loss: 0.3156\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2391 - val_loss: 0.3092\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2257 - val_loss: 0.3042\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2140 - val_loss: 0.2994\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2037 - val_loss: 0.2945\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1947 - val_loss: 0.2898\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1865 - val_loss: 0.2851\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1791 - val_loss: 0.2806\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1721 - val_loss: 0.2759\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1657 - val_loss: 0.2714\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1600 - val_loss: 0.2666\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1547 - val_loss: 0.2621\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1500 - val_loss: 0.2575\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1457 - val_loss: 0.2531\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1417 - val_loss: 0.2488\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1380 - val_loss: 0.2446\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1343 - val_loss: 0.2410\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1309 - val_loss: 0.2371\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1276 - val_loss: 0.2334\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1243 - val_loss: 0.2301\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1212 - val_loss: 0.2270\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1180 - val_loss: 0.2241\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1150 - val_loss: 0.2214\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1120 - val_loss: 0.2193\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1091 - val_loss: 0.2169\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1063 - val_loss: 0.2148\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1035 - val_loss: 0.2129\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1009 - val_loss: 0.2109\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.0983 - val_loss: 0.2092\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0958 - val_loss: 0.2078\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.0935 - val_loss: 0.2065\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.0912 - val_loss: 0.2050\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.0891 - val_loss: 0.2038\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 481887034088.8586, my average MASE = 481887034088.8586\n",
      "Cluster 4, 481887034088.8586\n",
      "Before prediction: train_X.shape=(16, 10, 67), train_y.shape=(16, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6383 - val_loss: 0.6409\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6348 - val_loss: 0.6376\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6314 - val_loss: 0.6343\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6281 - val_loss: 0.6311\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6249 - val_loss: 0.6279\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6216 - val_loss: 0.6247\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6184 - val_loss: 0.6215\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6151 - val_loss: 0.6183\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6119 - val_loss: 0.6152\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6088 - val_loss: 0.6120\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6056 - val_loss: 0.6089\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6025 - val_loss: 0.6058\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5993 - val_loss: 0.6026\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5962 - val_loss: 0.5996\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5931 - val_loss: 0.5965\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5901 - val_loss: 0.5935\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5871 - val_loss: 0.5905\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5840 - val_loss: 0.5875\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5810 - val_loss: 0.5845\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5781 - val_loss: 0.5815\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5751 - val_loss: 0.5785\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5721 - val_loss: 0.5755\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5692 - val_loss: 0.5725\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5663 - val_loss: 0.5695\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5635 - val_loss: 0.5665\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5607 - val_loss: 0.5635\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5578 - val_loss: 0.5605\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5550 - val_loss: 0.5575\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5522 - val_loss: 0.5545\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5494 - val_loss: 0.5517\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5465 - val_loss: 0.5490\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5437 - val_loss: 0.5466\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5410 - val_loss: 0.5443\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5385 - val_loss: 0.5420\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5361 - val_loss: 0.5397\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5338 - val_loss: 0.5374\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5314 - val_loss: 0.5351\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5291 - val_loss: 0.5327\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5267 - val_loss: 0.5304\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5243 - val_loss: 0.5282\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 244758068621.99603, my average MASE = 244758068621.99603\n",
      "Cluster 5, 244758068621.99603\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.5035 - val_loss: 0.4892\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.4516 - val_loss: 0.4529\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.4061 - val_loss: 0.4221\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.3657 - val_loss: 0.3947\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.3289 - val_loss: 0.3685\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2946 - val_loss: 0.3416\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2667 - val_loss: 0.3192\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2446 - val_loss: 0.2987\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2237 - val_loss: 0.2799\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.2036 - val_loss: 0.2649\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1864 - val_loss: 0.2543\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1719 - val_loss: 0.2452\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1595 - val_loss: 0.2371\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1496 - val_loss: 0.2326\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1418 - val_loss: 0.2305\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1351 - val_loss: 0.2295\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1289 - val_loss: 0.2274\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1233 - val_loss: 0.2259\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1185 - val_loss: 0.2242\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1146 - val_loss: 0.2232\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1111 - val_loss: 0.2230\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1079 - val_loss: 0.2218\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1048 - val_loss: 0.2219\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1022 - val_loss: 0.2215\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1001 - val_loss: 0.2213\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0981 - val_loss: 0.2214\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0963 - val_loss: 0.2215\n",
      "Epoch 27: early stopping\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 428342176834.8368, my average MASE = 428342176834.8368\n",
      "Cluster 6, 428342176834.8368\n",
      "Before prediction: train_X.shape=(64, 10, 67), train_y.shape=(64, 67), test_X.shape=(21, 10, 67), test_y.shape=(21, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.8873 - val_loss: 0.8803\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8828 - val_loss: 0.8764\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8783 - val_loss: 0.8725\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8739 - val_loss: 0.8686\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8695 - val_loss: 0.8647\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8652 - val_loss: 0.8608\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8608 - val_loss: 0.8569\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8565 - val_loss: 0.8530\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8521 - val_loss: 0.8491\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8478 - val_loss: 0.8452\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8435 - val_loss: 0.8414\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8392 - val_loss: 0.8376\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8349 - val_loss: 0.8338\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8306 - val_loss: 0.8300\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8264 - val_loss: 0.8262\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8222 - val_loss: 0.8225\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8180 - val_loss: 0.8188\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8138 - val_loss: 0.8151\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8097 - val_loss: 0.8114\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8057 - val_loss: 0.8077\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8017 - val_loss: 0.8041\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7978 - val_loss: 0.8006\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7939 - val_loss: 0.7970\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7900 - val_loss: 0.7935\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7862 - val_loss: 0.7899\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7825 - val_loss: 0.7864\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7787 - val_loss: 0.7829\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7749 - val_loss: 0.7794\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7712 - val_loss: 0.7759\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7675 - val_loss: 0.7724\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7638 - val_loss: 0.7689\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7601 - val_loss: 0.7654\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7564 - val_loss: 0.7619\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7527 - val_loss: 0.7584\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7490 - val_loss: 0.7549\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7453 - val_loss: 0.7513\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7416 - val_loss: 0.7478\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7379 - val_loss: 0.7443\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7342 - val_loss: 0.7408\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7305 - val_loss: 0.7373\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(21, 67), test_y.shape=(21, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 59376244270.88399, my average MASE = 59376244270.88399\n",
      "Cluster 7, 59376244270.88399\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.3173 - val_loss: 1.3238\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3143 - val_loss: 1.3207\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3112 - val_loss: 1.3176\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3081 - val_loss: 1.3146\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3051 - val_loss: 1.3117\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3020 - val_loss: 1.3088\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2991 - val_loss: 1.3058\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2962 - val_loss: 1.3029\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2933 - val_loss: 1.3000\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2904 - val_loss: 1.2971\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2876 - val_loss: 1.2942\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2847 - val_loss: 1.2913\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2817 - val_loss: 1.2885\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2788 - val_loss: 1.2857\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2759 - val_loss: 1.2829\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2730 - val_loss: 1.2800\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2702 - val_loss: 1.2772\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2673 - val_loss: 1.2744\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2645 - val_loss: 1.2715\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2616 - val_loss: 1.2687\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2588 - val_loss: 1.2658\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2560 - val_loss: 1.2629\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2531 - val_loss: 1.2600\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2503 - val_loss: 1.2571\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2474 - val_loss: 1.2542\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2445 - val_loss: 1.2513\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2416 - val_loss: 1.2484\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2387 - val_loss: 1.2455\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2358 - val_loss: 1.2425\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2329 - val_loss: 1.2396\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2299 - val_loss: 1.2367\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2270 - val_loss: 1.2337\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2240 - val_loss: 1.2308\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2210 - val_loss: 1.2279\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2180 - val_loss: 1.2250\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2150 - val_loss: 1.2221\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2119 - val_loss: 1.2191\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2089 - val_loss: 1.2162\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2058 - val_loss: 1.2132\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.2027 - val_loss: 1.2102\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 222.80853873464983, my average MASE = 222.80853873464983\n",
      "Cluster 8, 222.80853873464983\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6511 - val_loss: 0.6503\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6465 - val_loss: 0.6462\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6420 - val_loss: 0.6421\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6376 - val_loss: 0.6379\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6332 - val_loss: 0.6337\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6287 - val_loss: 0.6294\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6243 - val_loss: 0.6251\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6200 - val_loss: 0.6208\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6158 - val_loss: 0.6165\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6116 - val_loss: 0.6124\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6075 - val_loss: 0.6083\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6034 - val_loss: 0.6043\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5993 - val_loss: 0.6004\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5952 - val_loss: 0.5965\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5911 - val_loss: 0.5925\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5871 - val_loss: 0.5886\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5830 - val_loss: 0.5847\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5790 - val_loss: 0.5807\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5751 - val_loss: 0.5769\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5712 - val_loss: 0.5730\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5674 - val_loss: 0.5691\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5634 - val_loss: 0.5651\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5595 - val_loss: 0.5611\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5556 - val_loss: 0.5571\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5517 - val_loss: 0.5531\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5478 - val_loss: 0.5491\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5438 - val_loss: 0.5451\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5399 - val_loss: 0.5410\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5360 - val_loss: 0.5372\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5322 - val_loss: 0.5334\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5285 - val_loss: 0.5302\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5252 - val_loss: 0.5269\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5219 - val_loss: 0.5238\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5186 - val_loss: 0.5206\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5153 - val_loss: 0.5174\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5120 - val_loss: 0.5142\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5087 - val_loss: 0.5109\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5055 - val_loss: 0.5077\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5022 - val_loss: 0.5048\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4992 - val_loss: 0.5021\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 245.61588242665698, my average MASE = 245.61588242665698\n",
      "Cluster 9, 245.61588242665698\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.8883 - val_loss: 0.8484\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.8808 - val_loss: 0.8408\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.8733 - val_loss: 0.8333\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8659 - val_loss: 0.8257\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8584 - val_loss: 0.8181\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8509 - val_loss: 0.8105\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.8434 - val_loss: 0.8028\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.8359 - val_loss: 0.7952\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8285 - val_loss: 0.7875\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8210 - val_loss: 0.7799\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.8136 - val_loss: 0.7723\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.8063 - val_loss: 0.7648\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7990 - val_loss: 0.7574\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7918 - val_loss: 0.7503\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7848 - val_loss: 0.7432\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7777 - val_loss: 0.7362\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7706 - val_loss: 0.7291\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7635 - val_loss: 0.7220\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7563 - val_loss: 0.7148\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7490 - val_loss: 0.7077\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7417 - val_loss: 0.7005\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.7343 - val_loss: 0.6934\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7269 - val_loss: 0.6863\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7195 - val_loss: 0.6793\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7120 - val_loss: 0.6721\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7048 - val_loss: 0.6650\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6976 - val_loss: 0.6580\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6905 - val_loss: 0.6511\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6834 - val_loss: 0.6444\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6764 - val_loss: 0.6378\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6695 - val_loss: 0.6315\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6625 - val_loss: 0.6252\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6556 - val_loss: 0.6190\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6489 - val_loss: 0.6128\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6422 - val_loss: 0.6069\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6357 - val_loss: 0.6010\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6293 - val_loss: 0.5952\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6229 - val_loss: 0.5894\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6167 - val_loss: 0.5836\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6104 - val_loss: 0.5779\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 32038978684.47234, my average MASE = 32038978684.47234\n",
      "Cluster 10, 32038978684.47234\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=2, 2, 13, (10045, 67)\n",
      "Before prediction: train_X.shape=(6021, 10, 67), train_y.shape=(6021, 67), test_X.shape=(2007, 10, 67), test_y.shape=(2007, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 34ms/step - loss: 0.5288 - val_loss: 0.4469\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.3797 - val_loss: 0.3514\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.2711 - val_loss: 0.2869\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.2048 - val_loss: 0.2710\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.1650 - val_loss: 0.2687\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.1379 - val_loss: 0.2684\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.1231 - val_loss: 0.2654\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.1135 - val_loss: 0.2462\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.1060 - val_loss: 0.2218\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0991 - val_loss: 0.1976\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0929 - val_loss: 0.1831\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0868 - val_loss: 0.1712\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0808 - val_loss: 0.1632\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0758 - val_loss: 0.1592\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0728 - val_loss: 0.1560\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0706 - val_loss: 0.1521\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0690 - val_loss: 0.1517\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0676 - val_loss: 0.1506\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0663 - val_loss: 0.1496\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0651 - val_loss: 0.1496\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0641 - val_loss: 0.1481\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0631 - val_loss: 0.1482\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0621 - val_loss: 0.1475\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0612 - val_loss: 0.1475\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0603 - val_loss: 0.1474\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0595 - val_loss: 0.1473\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0586 - val_loss: 0.1474\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0578 - val_loss: 0.1479\n",
      "Epoch 28: early stopping\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2007, 67), test_y.shape=(2007, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 135093603506.5839, my average MASE = 135093603506.5839\n",
      "Cluster 0, 135093603506.5839\n",
      "Before prediction: train_X.shape=(18364, 10, 67), train_y.shape=(18364, 67), test_X.shape=(6121, 10, 67), test_y.shape=(6121, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.5445 - val_loss: 0.5862\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2993 - val_loss: 0.5026\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2302 - val_loss: 0.4367\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1861 - val_loss: 0.3879\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1563 - val_loss: 0.3505\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1343 - val_loss: 0.3187\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1182 - val_loss: 0.2937\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1062 - val_loss: 0.2744\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0969 - val_loss: 0.2599\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0896 - val_loss: 0.2482\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0837 - val_loss: 0.2388\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0788 - val_loss: 0.2307\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0746 - val_loss: 0.2249\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0710 - val_loss: 0.2186\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0678 - val_loss: 0.2123\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0648 - val_loss: 0.2073\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0622 - val_loss: 0.2016\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0597 - val_loss: 0.1966\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0574 - val_loss: 0.1917\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0554 - val_loss: 0.1872\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.0536 - val_loss: 0.1830\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.0518 - val_loss: 0.1786\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0502 - val_loss: 0.1749\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.0487 - val_loss: 0.1713\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0472 - val_loss: 0.1677\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0458 - val_loss: 0.1645\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0445 - val_loss: 0.1619\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0433 - val_loss: 0.1588\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0422 - val_loss: 0.1559\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0413 - val_loss: 0.1531\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0404 - val_loss: 0.1500\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0396 - val_loss: 0.1487\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0389 - val_loss: 0.1456\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0381 - val_loss: 0.1432\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0375 - val_loss: 0.1415\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0368 - val_loss: 0.1404\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0362 - val_loss: 0.1388\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0357 - val_loss: 0.1372\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.0351 - val_loss: 0.1366\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.0346 - val_loss: 0.1352\n",
      "192/192 [==============================] - 2s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(6121, 67), test_y.shape=(6121, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 512815686.2159365, my average MASE = 512815686.2159365\n",
      "Cluster 1, 512815686.2159365\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=5, 5, 11, (9941, 67)\n",
      "Before prediction: train_X.shape=(5959, 10, 67), train_y.shape=(5959, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.5242 - val_loss: 0.4608\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.3798 - val_loss: 0.3486\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.2569 - val_loss: 0.2762\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.1962 - val_loss: 0.2520\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.1625 - val_loss: 0.2554\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.1370 - val_loss: 0.2649\n",
      "Epoch 6: early stopping\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 375595963203.1339, my average MASE = 375595963203.1339\n",
      "Cluster 0, 375595963203.1339\n",
      "Before prediction: train_X.shape=(162, 10, 67), train_y.shape=(162, 67), test_X.shape=(54, 10, 67), test_y.shape=(54, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 1.5100 - val_loss: 1.4140\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.5015 - val_loss: 1.4064\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.4931 - val_loss: 1.3988\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.4849 - val_loss: 1.3912\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 1.4767 - val_loss: 1.3835\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 1.4685 - val_loss: 1.3758\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.4605 - val_loss: 1.3681\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.4523 - val_loss: 1.3603\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.4443 - val_loss: 1.3525\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.4362 - val_loss: 1.3447\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.4283 - val_loss: 1.3368\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.4203 - val_loss: 1.3289\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.4123 - val_loss: 1.3210\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.4043 - val_loss: 1.3129\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.3962 - val_loss: 1.3047\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.3881 - val_loss: 1.2964\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.3798 - val_loss: 1.2881\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.3716 - val_loss: 1.2798\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.3634 - val_loss: 1.2716\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.3553 - val_loss: 1.2634\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.3472 - val_loss: 1.2552\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.3388 - val_loss: 1.2469\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.3301 - val_loss: 1.2385\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.3213 - val_loss: 1.2300\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.3122 - val_loss: 1.2214\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.3029 - val_loss: 1.2125\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.2933 - val_loss: 1.2034\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.2835 - val_loss: 1.1941\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.2733 - val_loss: 1.1845\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.2628 - val_loss: 1.1747\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.2520 - val_loss: 1.1646\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.2408 - val_loss: 1.1542\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 1.2293 - val_loss: 1.1435\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.2174 - val_loss: 1.1325\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.2053 - val_loss: 1.1211\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.1929 - val_loss: 1.1095\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.1803 - val_loss: 1.0974\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.1675 - val_loss: 1.0851\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.1549 - val_loss: 1.0731\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.1425 - val_loss: 1.0613\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(54, 67), test_y.shape=(54, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 60259221256.32995, my average MASE = 60259221256.32995\n",
      "Cluster 1, 60259221256.32995\n",
      "Before prediction: train_X.shape=(188, 10, 67), train_y.shape=(188, 67), test_X.shape=(63, 10, 67), test_y.shape=(63, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5443 - val_loss: 0.3901\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5355 - val_loss: 0.3871\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5271 - val_loss: 0.3842\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5190 - val_loss: 0.3814\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5114 - val_loss: 0.3786\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5040 - val_loss: 0.3760\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4967 - val_loss: 0.3734\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.3710\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4829 - val_loss: 0.3685\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4761 - val_loss: 0.3662\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4695 - val_loss: 0.3638\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4631 - val_loss: 0.3616\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4566 - val_loss: 0.3594\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4502 - val_loss: 0.3572\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4439 - val_loss: 0.3550\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.4379 - val_loss: 0.3529\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4319 - val_loss: 0.3508\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4259 - val_loss: 0.3488\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4200 - val_loss: 0.3466\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4141 - val_loss: 0.3445\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4083 - val_loss: 0.3424\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4025 - val_loss: 0.3403\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3969 - val_loss: 0.3382\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3913 - val_loss: 0.3361\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3857 - val_loss: 0.3340\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3802 - val_loss: 0.3319\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3746 - val_loss: 0.3298\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3690 - val_loss: 0.3280\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3634 - val_loss: 0.3261\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3580 - val_loss: 0.3244\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3525 - val_loss: 0.3227\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3472 - val_loss: 0.3212\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3417 - val_loss: 0.3197\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3363 - val_loss: 0.3182\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3310 - val_loss: 0.3168\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3258 - val_loss: 0.3155\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3205 - val_loss: 0.3140\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3151 - val_loss: 0.3125\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3099 - val_loss: 0.3111\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3045 - val_loss: 0.3095\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(63, 67), test_y.shape=(63, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 59264424051.31893, my average MASE = 59264424051.31893\n",
      "Cluster 2, 59264424051.31893\n",
      "Before prediction: train_X.shape=(43, 10, 67), train_y.shape=(43, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.6737 - val_loss: 1.7192\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6693 - val_loss: 1.7166\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6649 - val_loss: 1.7141\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6605 - val_loss: 1.7116\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6561 - val_loss: 1.7091\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6518 - val_loss: 1.7066\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6476 - val_loss: 1.7042\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.6433 - val_loss: 1.7017\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6391 - val_loss: 1.6993\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6349 - val_loss: 1.6968\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6308 - val_loss: 1.6945\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6268 - val_loss: 1.6921\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6227 - val_loss: 1.6898\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6188 - val_loss: 1.6875\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6149 - val_loss: 1.6851\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.6110 - val_loss: 1.6828\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6072 - val_loss: 1.6806\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6034 - val_loss: 1.6784\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5996 - val_loss: 1.6763\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5958 - val_loss: 1.6742\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5920 - val_loss: 1.6720\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5883 - val_loss: 1.6699\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5845 - val_loss: 1.6678\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5808 - val_loss: 1.6657\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5771 - val_loss: 1.6636\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5734 - val_loss: 1.6616\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5698 - val_loss: 1.6595\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5661 - val_loss: 1.6575\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5624 - val_loss: 1.6554\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5588 - val_loss: 1.6534\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5551 - val_loss: 1.6513\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5515 - val_loss: 1.6492\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5478 - val_loss: 1.6472\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5442 - val_loss: 1.6451\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.5406 - val_loss: 1.6431\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5370 - val_loss: 1.6412\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5334 - val_loss: 1.6392\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5299 - val_loss: 1.6373\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.5263 - val_loss: 1.6354\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5227 - val_loss: 1.6336\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 589375300745.4619, my average MASE = 589375300745.4619\n",
      "Cluster 3, 589375300745.4619\n",
      "Before prediction: train_X.shape=(44, 10, 67), train_y.shape=(44, 67), test_X.shape=(15, 10, 67), test_y.shape=(15, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7969 - val_loss: 0.7283\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7930 - val_loss: 0.7252\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7891 - val_loss: 0.7222\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7852 - val_loss: 0.7192\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7814 - val_loss: 0.7161\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7776 - val_loss: 0.7130\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7738 - val_loss: 0.7099\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7701 - val_loss: 0.7068\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7664 - val_loss: 0.7036\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7627 - val_loss: 0.7004\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7590 - val_loss: 0.6973\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7553 - val_loss: 0.6941\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7516 - val_loss: 0.6908\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7479 - val_loss: 0.6876\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7442 - val_loss: 0.6843\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7406 - val_loss: 0.6810\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7369 - val_loss: 0.6778\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7332 - val_loss: 0.6747\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7295 - val_loss: 0.6717\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7259 - val_loss: 0.6688\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7223 - val_loss: 0.6659\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7188 - val_loss: 0.6631\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7154 - val_loss: 0.6602\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7120 - val_loss: 0.6572\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7086 - val_loss: 0.6543\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7053 - val_loss: 0.6513\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7019 - val_loss: 0.6484\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6984 - val_loss: 0.6454\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6950 - val_loss: 0.6425\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6915 - val_loss: 0.6397\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6880 - val_loss: 0.6368\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6845 - val_loss: 0.6341\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6810 - val_loss: 0.6313\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6776 - val_loss: 0.6285\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6742 - val_loss: 0.6259\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6711 - val_loss: 0.6234\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6681 - val_loss: 0.6210\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6650 - val_loss: 0.6186\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6621 - val_loss: 0.6162\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6591 - val_loss: 0.6139\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(15, 67), test_y.shape=(15, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 180251152857.0116, my average MASE = 180251152857.0116\n",
      "Cluster 4, 180251152857.0116\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=7, 7, 432, (13, 67)\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(40, 10, 67), train_y.shape=(40, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.4248 - val_loss: 1.3996\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4210 - val_loss: 1.3971\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4172 - val_loss: 1.3945\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4134 - val_loss: 1.3919\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.4097 - val_loss: 1.3894\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4060 - val_loss: 1.3869\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4024 - val_loss: 1.3844\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3988 - val_loss: 1.3818\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3952 - val_loss: 1.3794\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3917 - val_loss: 1.3769\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3882 - val_loss: 1.3743\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3848 - val_loss: 1.3718\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3814 - val_loss: 1.3693\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3780 - val_loss: 1.3668\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3746 - val_loss: 1.3642\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3713 - val_loss: 1.3616\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3680 - val_loss: 1.3591\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3647 - val_loss: 1.3565\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3614 - val_loss: 1.3539\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3581 - val_loss: 1.3513\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3548 - val_loss: 1.3488\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3515 - val_loss: 1.3462\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3482 - val_loss: 1.3436\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3449 - val_loss: 1.3411\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3416 - val_loss: 1.3385\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3383 - val_loss: 1.3359\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3350 - val_loss: 1.3334\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3316 - val_loss: 1.3308\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3283 - val_loss: 1.3283\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3249 - val_loss: 1.3257\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3215 - val_loss: 1.3232\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3181 - val_loss: 1.3208\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3147 - val_loss: 1.3184\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3113 - val_loss: 1.3161\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3079 - val_loss: 1.3137\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3045 - val_loss: 1.3113\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3011 - val_loss: 1.3089\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2977 - val_loss: 1.3065\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2943 - val_loss: 1.3040\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2909 - val_loss: 1.3016\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 567371290273.5166, my average MASE = 567371290273.5166\n",
      "Cluster 1, 567371290273.5166\n",
      "Before prediction: train_X.shape=(152, 10, 67), train_y.shape=(152, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.8247 - val_loss: 0.7769\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.8141 - val_loss: 0.7672\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.8036 - val_loss: 0.7578\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7934 - val_loss: 0.7484\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7833 - val_loss: 0.7391\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7734 - val_loss: 0.7300\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7636 - val_loss: 0.7209\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7539 - val_loss: 0.7118\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7442 - val_loss: 0.7027\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7346 - val_loss: 0.6937\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7250 - val_loss: 0.6849\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7156 - val_loss: 0.6764\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7064 - val_loss: 0.6680\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6974 - val_loss: 0.6597\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6889 - val_loss: 0.6517\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6805 - val_loss: 0.6438\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6722 - val_loss: 0.6358\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6640 - val_loss: 0.6278\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6559 - val_loss: 0.6198\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6479 - val_loss: 0.6118\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6400 - val_loss: 0.6040\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6321 - val_loss: 0.5963\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6244 - val_loss: 0.5887\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6168 - val_loss: 0.5812\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6094 - val_loss: 0.5739\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6021 - val_loss: 0.5667\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5949 - val_loss: 0.5595\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5879 - val_loss: 0.5525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5810 - val_loss: 0.5456\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5741 - val_loss: 0.5389\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5672 - val_loss: 0.5323\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5602 - val_loss: 0.5255\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5532 - val_loss: 0.5188\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5460 - val_loss: 0.5121\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5388 - val_loss: 0.5052\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5315 - val_loss: 0.4983\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5242 - val_loss: 0.4915\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5167 - val_loss: 0.4847\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5092 - val_loss: 0.4780\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5017 - val_loss: 0.4715\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 58395359757.92362, my average MASE = 58395359757.92362\n",
      "Cluster 2, 58395359757.92362\n",
      "Before prediction: train_X.shape=(83, 10, 67), train_y.shape=(83, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6766 - val_loss: 0.6337\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6690 - val_loss: 0.6277\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6616 - val_loss: 0.6219\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6542 - val_loss: 0.6163\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6469 - val_loss: 0.6107\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6396 - val_loss: 0.6052\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6326 - val_loss: 0.5998\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6259 - val_loss: 0.5947\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6195 - val_loss: 0.5897\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6133 - val_loss: 0.5850\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6073 - val_loss: 0.5804\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6015 - val_loss: 0.5760\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5958 - val_loss: 0.5716\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5902 - val_loss: 0.5674\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5847 - val_loss: 0.5632\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5793 - val_loss: 0.5592\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5740 - val_loss: 0.5552\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5688 - val_loss: 0.5513\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5636 - val_loss: 0.5475\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5586 - val_loss: 0.5437\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5536 - val_loss: 0.5400\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5487 - val_loss: 0.5366\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5439 - val_loss: 0.5332\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5391 - val_loss: 0.5299\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5346 - val_loss: 0.5265\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5302 - val_loss: 0.5232\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5259 - val_loss: 0.5198\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5216 - val_loss: 0.5163\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5174 - val_loss: 0.5128\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5132 - val_loss: 0.5093\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5091 - val_loss: 0.5059\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5050 - val_loss: 0.5026\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5009 - val_loss: 0.4992\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4969 - val_loss: 0.4958\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4929 - val_loss: 0.4923\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4889 - val_loss: 0.4888\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4851 - val_loss: 0.4852\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4812 - val_loss: 0.4817\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4774 - val_loss: 0.4782\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4736 - val_loss: 0.4750\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 189826677290.27332, my average MASE = 189826677290.27332\n",
      "Cluster 3, 189826677290.27332\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.7426 - val_loss: 1.7822\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7409 - val_loss: 1.7804\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.7391 - val_loss: 1.7786\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7374 - val_loss: 1.7768\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.7356 - val_loss: 1.7749\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7339 - val_loss: 1.7730\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7321 - val_loss: 1.7711\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7302 - val_loss: 1.7691\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7284 - val_loss: 1.7670\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.7265 - val_loss: 1.7649\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.7245 - val_loss: 1.7627\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.7225 - val_loss: 1.7604\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.7204 - val_loss: 1.7581\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7183 - val_loss: 1.7557\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7162 - val_loss: 1.7533\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7139 - val_loss: 1.7508\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7117 - val_loss: 1.7488\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7095 - val_loss: 1.7469\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.7072 - val_loss: 1.7450\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.7050 - val_loss: 1.7431\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7028 - val_loss: 1.7413\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.7007 - val_loss: 1.7395\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6987 - val_loss: 1.7378\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6967 - val_loss: 1.7361\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6949 - val_loss: 1.7344\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6931 - val_loss: 1.7327\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6913 - val_loss: 1.7311\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6896 - val_loss: 1.7295\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6879 - val_loss: 1.7280\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6862 - val_loss: 1.7265\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6845 - val_loss: 1.7250\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.6829 - val_loss: 1.7235\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.6813 - val_loss: 1.7219\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6797 - val_loss: 1.7203\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6781 - val_loss: 1.7187\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.6765 - val_loss: 1.7171\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6749 - val_loss: 1.7155\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6733 - val_loss: 1.7139\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.6717 - val_loss: 1.7122\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.6700 - val_loss: 1.7106\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 224.1225578719105, my average MASE = 224.1225578719105\n",
      "Cluster 4, 224.1225578719105\n",
      "Before prediction: train_X.shape=(181, 10, 67), train_y.shape=(181, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5728 - val_loss: 0.4146\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5632 - val_loss: 0.4096\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5542 - val_loss: 0.4048\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5452 - val_loss: 0.4003\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5369 - val_loss: 0.3962\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5289 - val_loss: 0.3923\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5210 - val_loss: 0.3886\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5134 - val_loss: 0.3850\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5062 - val_loss: 0.3816\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4994 - val_loss: 0.3782\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4927 - val_loss: 0.3749\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4862 - val_loss: 0.3717\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4796 - val_loss: 0.3684\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4733 - val_loss: 0.3652\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4671 - val_loss: 0.3622\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4610 - val_loss: 0.3593\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4551 - val_loss: 0.3567\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4491 - val_loss: 0.3541\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4434 - val_loss: 0.3517\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4377 - val_loss: 0.3494\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4321 - val_loss: 0.3471\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4267 - val_loss: 0.3449\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4212 - val_loss: 0.3428\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4159 - val_loss: 0.3408\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4105 - val_loss: 0.3390\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4051 - val_loss: 0.3372\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3998 - val_loss: 0.3356\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3944 - val_loss: 0.3340\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3890 - val_loss: 0.3323\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3837 - val_loss: 0.3308\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3783 - val_loss: 0.3292\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3729 - val_loss: 0.3276\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3676 - val_loss: 0.3260\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3623 - val_loss: 0.3243\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3572 - val_loss: 0.3227\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3520 - val_loss: 0.3210\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3468 - val_loss: 0.3194\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3418 - val_loss: 0.3177\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3367 - val_loss: 0.3161\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3316 - val_loss: 0.3144\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 55975005045.727974, my average MASE = 55975005045.727974\n",
      "Cluster 5, 55975005045.727974\n",
      "Before prediction: train_X.shape=(5959, 10, 67), train_y.shape=(5959, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.4888 - val_loss: 0.3741\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.3526 - val_loss: 0.2884\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.2765 - val_loss: 0.2458\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.2303 - val_loss: 0.2382\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.1902 - val_loss: 0.2434\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.1577 - val_loss: 0.2597\n",
      "Epoch 6: early stopping\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 377104752463.9683, my average MASE = 377104752463.9683\n",
      "Cluster 6, 377104752463.9683\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=9, 9, 31, (75, 67)\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.4426 - val_loss: 1.4633\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4377 - val_loss: 1.4610\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4328 - val_loss: 1.4588\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4278 - val_loss: 1.4566\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4229 - val_loss: 1.4544\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4181 - val_loss: 1.4522\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4132 - val_loss: 1.4500\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4084 - val_loss: 1.4478\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4036 - val_loss: 1.4456\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3989 - val_loss: 1.4433\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3944 - val_loss: 1.4410\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3900 - val_loss: 1.4387\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3857 - val_loss: 1.4364\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3814 - val_loss: 1.4341\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3771 - val_loss: 1.4317\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3729 - val_loss: 1.4294\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3687 - val_loss: 1.4270\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3645 - val_loss: 1.4245\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3603 - val_loss: 1.4221\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3562 - val_loss: 1.4197\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3520 - val_loss: 1.4172\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3479 - val_loss: 1.4148\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3438 - val_loss: 1.4123\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3397 - val_loss: 1.4098\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3356 - val_loss: 1.4073\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3316 - val_loss: 1.4048\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3275 - val_loss: 1.4023\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3235 - val_loss: 1.3998\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3196 - val_loss: 1.3972\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.3156 - val_loss: 1.3947\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3116 - val_loss: 1.3921\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3077 - val_loss: 1.3895\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3038 - val_loss: 1.3869\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2999 - val_loss: 1.3843\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2961 - val_loss: 1.3817\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2922 - val_loss: 1.3791\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2885 - val_loss: 1.3764\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2847 - val_loss: 1.3737\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2810 - val_loss: 1.3710\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2772 - val_loss: 1.3683\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 581379883099.8748, my average MASE = 581379883099.8748\n",
      "Cluster 0, 581379883099.8748\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(18, 10, 67), train_y.shape=(18, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6174 - val_loss: 0.6379\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6127 - val_loss: 0.6335\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6081 - val_loss: 0.6291\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6035 - val_loss: 0.6248\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5991 - val_loss: 0.6206\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5947 - val_loss: 0.6166\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5905 - val_loss: 0.6126\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5863 - val_loss: 0.6086\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5822 - val_loss: 0.6045\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5781 - val_loss: 0.6005\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5741 - val_loss: 0.5965\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5700 - val_loss: 0.5925\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5659 - val_loss: 0.5887\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5618 - val_loss: 0.5849\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5579 - val_loss: 0.5811\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5540 - val_loss: 0.5772\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5501 - val_loss: 0.5734\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5463 - val_loss: 0.5695\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5425 - val_loss: 0.5658\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5388 - val_loss: 0.5620\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5352 - val_loss: 0.5583\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5316 - val_loss: 0.5547\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5280 - val_loss: 0.5511\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5245 - val_loss: 0.5476\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5210 - val_loss: 0.5441\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5174 - val_loss: 0.5405\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5139 - val_loss: 0.5370\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5103 - val_loss: 0.5334\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5068 - val_loss: 0.5299\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5033 - val_loss: 0.5263\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4998 - val_loss: 0.5228\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4963 - val_loss: 0.5193\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4928 - val_loss: 0.5157\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4893 - val_loss: 0.5121\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4858 - val_loss: 0.5086\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4822 - val_loss: 0.5051\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4787 - val_loss: 0.5015\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4751 - val_loss: 0.4980\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4716 - val_loss: 0.4945\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4681 - val_loss: 0.4910\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 213640072720.59335, my average MASE = 213640072720.59335\n",
      "Cluster 2, 213640072720.59335\n",
      "Before prediction: train_X.shape=(9, 10, 67), train_y.shape=(9, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8339 - val_loss: 0.8404\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8287 - val_loss: 0.8351\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8234 - val_loss: 0.8299\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8182 - val_loss: 0.8246\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8129 - val_loss: 0.8192\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8076 - val_loss: 0.8139\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8023 - val_loss: 0.8086\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7970 - val_loss: 0.8033\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7917 - val_loss: 0.7980\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7864 - val_loss: 0.7926\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7812 - val_loss: 0.7873\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7759 - val_loss: 0.7820\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7706 - val_loss: 0.7767\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7654 - val_loss: 0.7714\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7601 - val_loss: 0.7661\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7549 - val_loss: 0.7608\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7497 - val_loss: 0.7555\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7447 - val_loss: 0.7504\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7397 - val_loss: 0.7453\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7347 - val_loss: 0.7403\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7298 - val_loss: 0.7354\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7249 - val_loss: 0.7306\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7201 - val_loss: 0.7260\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7154 - val_loss: 0.7218\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7107 - val_loss: 0.7179\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7062 - val_loss: 0.7140\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7017 - val_loss: 0.7101\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6972 - val_loss: 0.7064\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6929 - val_loss: 0.7027\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6886 - val_loss: 0.6992\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6845 - val_loss: 0.6958\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6805 - val_loss: 0.6924\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6765 - val_loss: 0.6890\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6725 - val_loss: 0.6855\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6687 - val_loss: 0.6821\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6649 - val_loss: 0.6786\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6611 - val_loss: 0.6751\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6574 - val_loss: 0.6716\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6537 - val_loss: 0.6681\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6499 - val_loss: 0.6646\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 92223964757.14085, my average MASE = 92223964757.14085\n",
      "Cluster 3, 92223964757.14085\n",
      "Before prediction: train_X.shape=(5959, 10, 67), train_y.shape=(5959, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.5208 - val_loss: 0.4439\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.3919 - val_loss: 0.3549\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.2856 - val_loss: 0.2857\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.2083 - val_loss: 0.2710\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.1605 - val_loss: 0.2809\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.1317 - val_loss: 0.2839\n",
      "Epoch 6: early stopping\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 373741517566.62506, my average MASE = 373741517566.62506\n",
      "Cluster 4, 373741517566.62506\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.2511 - val_loss: 1.2791\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.2472 - val_loss: 1.2754\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2434 - val_loss: 1.2716\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2397 - val_loss: 1.2679\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2360 - val_loss: 1.2642\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2324 - val_loss: 1.2605\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2289 - val_loss: 1.2568\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2255 - val_loss: 1.2532\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2222 - val_loss: 1.2496\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2190 - val_loss: 1.2463\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2159 - val_loss: 1.2430\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2130 - val_loss: 1.2397\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2101 - val_loss: 1.2364\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2073 - val_loss: 1.2332\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2046 - val_loss: 1.2300\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.2019 - val_loss: 1.2270\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1992 - val_loss: 1.2240\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1966 - val_loss: 1.2210\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1940 - val_loss: 1.2181\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1914 - val_loss: 1.2153\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1888 - val_loss: 1.2125\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1863 - val_loss: 1.2097\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1837 - val_loss: 1.2069\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1812 - val_loss: 1.2042\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1787 - val_loss: 1.2014\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.1762 - val_loss: 1.1988\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1737 - val_loss: 1.1961\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1712 - val_loss: 1.1935\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1688 - val_loss: 1.1909\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1663 - val_loss: 1.1884\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1638 - val_loss: 1.1858\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1614 - val_loss: 1.1834\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1590 - val_loss: 1.1809\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1566 - val_loss: 1.1784\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1542 - val_loss: 1.1760\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1518 - val_loss: 1.1735\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1494 - val_loss: 1.1711\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1470 - val_loss: 1.1686\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1446 - val_loss: 1.1662\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1421 - val_loss: 1.1638\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 62635002147.580956, my average MASE = 62635002147.580956\n",
      "Cluster 5, 62635002147.580956\n",
      "Before prediction: train_X.shape=(91, 10, 67), train_y.shape=(91, 67), test_X.shape=(30, 10, 67), test_y.shape=(30, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.7872 - val_loss: 0.7437\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7801 - val_loss: 0.7372\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7732 - val_loss: 0.7310\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.7664 - val_loss: 0.7251\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7597 - val_loss: 0.7193\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7533 - val_loss: 0.7137\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7471 - val_loss: 0.7083\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7411 - val_loss: 0.7029\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7353 - val_loss: 0.6976\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7297 - val_loss: 0.6923\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7242 - val_loss: 0.6872\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7188 - val_loss: 0.6822\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7136 - val_loss: 0.6772\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7084 - val_loss: 0.6722\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7032 - val_loss: 0.6672\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6982 - val_loss: 0.6622\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6932 - val_loss: 0.6574\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6883 - val_loss: 0.6526\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6834 - val_loss: 0.6479\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6787 - val_loss: 0.6432\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6739 - val_loss: 0.6385\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6692 - val_loss: 0.6338\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6644 - val_loss: 0.6292\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6597 - val_loss: 0.6246\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6549 - val_loss: 0.6199\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6501 - val_loss: 0.6152\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6453 - val_loss: 0.6105\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6404 - val_loss: 0.6058\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6356 - val_loss: 0.6011\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6307 - val_loss: 0.5963\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6257 - val_loss: 0.5915\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6208 - val_loss: 0.5867\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6158 - val_loss: 0.5819\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6108 - val_loss: 0.5772\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6058 - val_loss: 0.5724\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6008 - val_loss: 0.5676\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5957 - val_loss: 0.5629\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5907 - val_loss: 0.5581\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5856 - val_loss: 0.5533\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5805 - val_loss: 0.5486\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(30, 67), test_y.shape=(30, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 57560691135.98538, my average MASE = 57560691135.98538\n",
      "Cluster 6, 57560691135.98538\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=11, 11, 23, (27, 67)\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5988 - val_loss: 0.5795\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5944 - val_loss: 0.5757\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5902 - val_loss: 0.5720\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5861 - val_loss: 0.5683\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5820 - val_loss: 0.5647\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5782 - val_loss: 0.5614\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5744 - val_loss: 0.5581\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5708 - val_loss: 0.5548\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5673 - val_loss: 0.5516\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5637 - val_loss: 0.5485\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5602 - val_loss: 0.5453\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5567 - val_loss: 0.5424\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5532 - val_loss: 0.5396\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5499 - val_loss: 0.5368\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5467 - val_loss: 0.5339\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5435 - val_loss: 0.5311\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5404 - val_loss: 0.5283\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5375 - val_loss: 0.5255\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5346 - val_loss: 0.5227\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5317 - val_loss: 0.5199\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5288 - val_loss: 0.5171\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5259 - val_loss: 0.5143\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5229 - val_loss: 0.5114\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5199 - val_loss: 0.5085\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5169 - val_loss: 0.5056\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5139 - val_loss: 0.5026\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5109 - val_loss: 0.4997\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5079 - val_loss: 0.4967\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5049 - val_loss: 0.4938\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5018 - val_loss: 0.4909\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4989 - val_loss: 0.4881\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4960 - val_loss: 0.4856\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4933 - val_loss: 0.4832\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4906 - val_loss: 0.4809\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4879 - val_loss: 0.4786\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4853 - val_loss: 0.4764\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4828 - val_loss: 0.4742\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4803 - val_loss: 0.4721\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4778 - val_loss: 0.4701\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4754 - val_loss: 0.4680\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 57010123172.36322, my average MASE = 57010123172.36322\n",
      "Cluster 0, 57010123172.36322\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4673 - val_loss: 1.5096\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4655 - val_loss: 1.5082\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4638 - val_loss: 1.5068\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4621 - val_loss: 1.5055\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4605 - val_loss: 1.5041\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4589 - val_loss: 1.5027\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4573 - val_loss: 1.5013\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4557 - val_loss: 1.4999\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4541 - val_loss: 1.4985\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4525 - val_loss: 1.4971\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4510 - val_loss: 1.4957\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4494 - val_loss: 1.4943\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4478 - val_loss: 1.4929\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4462 - val_loss: 1.4915\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4446 - val_loss: 1.4901\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4431 - val_loss: 1.4887\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4415 - val_loss: 1.4873\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4399 - val_loss: 1.4859\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4383 - val_loss: 1.4845\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4367 - val_loss: 1.4831\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4352 - val_loss: 1.4817\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4336 - val_loss: 1.4803\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4320 - val_loss: 1.4789\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4304 - val_loss: 1.4775\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4288 - val_loss: 1.4761\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4272 - val_loss: 1.4748\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4257 - val_loss: 1.4735\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4241 - val_loss: 1.4722\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4225 - val_loss: 1.4709\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4209 - val_loss: 1.4696\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4193 - val_loss: 1.4682\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4177 - val_loss: 1.4669\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.4161 - val_loss: 1.4656\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4145 - val_loss: 1.4642\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4128 - val_loss: 1.4629\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4112 - val_loss: 1.4616\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4096 - val_loss: 1.4603\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4080 - val_loss: 1.4590\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.4063 - val_loss: 1.4576\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.4047 - val_loss: 1.4563\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 229.11583805388037, my average MASE = 229.11583805388037\n",
      "Cluster 2, 229.11583805388037\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.5147 - val_loss: 0.5123\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4658 - val_loss: 0.4838\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.4204 - val_loss: 0.4480\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.3731 - val_loss: 0.4072\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.3267 - val_loss: 0.3727\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.2864 - val_loss: 0.3473\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.2521 - val_loss: 0.3267\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.2235 - val_loss: 0.3112\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.2019 - val_loss: 0.3000\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1839 - val_loss: 0.2922\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1681 - val_loss: 0.2858\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1552 - val_loss: 0.2800\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1444 - val_loss: 0.2780\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1357 - val_loss: 0.2781\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1290 - val_loss: 0.2779\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1240 - val_loss: 0.2772\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1199 - val_loss: 0.2767\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1164 - val_loss: 0.2761\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1132 - val_loss: 0.2756\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1102 - val_loss: 0.2753\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1074 - val_loss: 0.2749\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1048 - val_loss: 0.2735\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1023 - val_loss: 0.2732\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1002 - val_loss: 0.2728\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0984 - val_loss: 0.2719\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0967 - val_loss: 0.2714\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0951 - val_loss: 0.2710\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0936 - val_loss: 0.2697\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0921 - val_loss: 0.2689\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.2678\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0894 - val_loss: 0.2666\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0882 - val_loss: 0.2658\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0871 - val_loss: 0.2648\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0860 - val_loss: 0.2642\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0850 - val_loss: 0.2630\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0840 - val_loss: 0.2624\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0831 - val_loss: 0.2617\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.2610\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0814 - val_loss: 0.2605\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0805 - val_loss: 0.2600\n",
      "21/21 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 431497839720.64716, my average MASE = 431497839720.64716\n",
      "Cluster 4, 431497839720.64716\n",
      "Before prediction: train_X.shape=(91, 10, 67), train_y.shape=(91, 67), test_X.shape=(30, 10, 67), test_y.shape=(30, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.7982 - val_loss: 0.7455\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7895 - val_loss: 0.7373\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7809 - val_loss: 0.7292\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7723 - val_loss: 0.7211\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7638 - val_loss: 0.7130\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7553 - val_loss: 0.7049\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7467 - val_loss: 0.6967\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7381 - val_loss: 0.6885\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7296 - val_loss: 0.6803\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7210 - val_loss: 0.6720\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7123 - val_loss: 0.6637\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7036 - val_loss: 0.6554\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6948 - val_loss: 0.6474\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6862 - val_loss: 0.6395\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6777 - val_loss: 0.6317\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6693 - val_loss: 0.6241\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6610 - val_loss: 0.6165\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6530 - val_loss: 0.6091\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6451 - val_loss: 0.6018\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6373 - val_loss: 0.5945\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6298 - val_loss: 0.5871\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6223 - val_loss: 0.5800\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6150 - val_loss: 0.5732\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6077 - val_loss: 0.5665\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6005 - val_loss: 0.5600\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5934 - val_loss: 0.5535\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5865 - val_loss: 0.5471\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5796 - val_loss: 0.5407\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5727 - val_loss: 0.5343\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5659 - val_loss: 0.5278\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5591 - val_loss: 0.5214\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5523 - val_loss: 0.5149\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5454 - val_loss: 0.5085\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5387 - val_loss: 0.5022\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5320 - val_loss: 0.4959\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5254 - val_loss: 0.4897\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5188 - val_loss: 0.4836\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5122 - val_loss: 0.4775\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5057 - val_loss: 0.4716\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4993 - val_loss: 0.4657\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(30, 67), test_y.shape=(30, 67)\n",
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 59830897206.837685, my average MASE = 59830897206.837685\n",
      "Cluster 5, 59830897206.837685\n",
      "Before prediction: train_X.shape=(1568, 10, 67), train_y.shape=(1568, 67), test_X.shape=(523, 10, 67), test_y.shape=(523, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.3965 - val_loss: 0.3918\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.3690 - val_loss: 0.3776\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.3459 - val_loss: 0.3647\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.3245 - val_loss: 0.3532\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.3039 - val_loss: 0.3427\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2846 - val_loss: 0.3331\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2662 - val_loss: 0.3237\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2488 - val_loss: 0.3153\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2336 - val_loss: 0.3078\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2206 - val_loss: 0.3006\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2095 - val_loss: 0.2940\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2000 - val_loss: 0.2888\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1917 - val_loss: 0.2835\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1844 - val_loss: 0.2785\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1777 - val_loss: 0.2735\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1717 - val_loss: 0.2687\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1663 - val_loss: 0.2641\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1612 - val_loss: 0.2597\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1563 - val_loss: 0.2555\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1517 - val_loss: 0.2514\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1473 - val_loss: 0.2475\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1431 - val_loss: 0.2435\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1391 - val_loss: 0.2399\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1353 - val_loss: 0.2360\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1319 - val_loss: 0.2323\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1285 - val_loss: 0.2290\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1254 - val_loss: 0.2262\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1224 - val_loss: 0.2231\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1196 - val_loss: 0.2206\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1169 - val_loss: 0.2184\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1144 - val_loss: 0.2165\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1120 - val_loss: 0.2147\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1097 - val_loss: 0.2130\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1075 - val_loss: 0.2112\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1054 - val_loss: 0.2096\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1034 - val_loss: 0.2083\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1014 - val_loss: 0.2069\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.0995 - val_loss: 0.2055\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.0976 - val_loss: 0.2040\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.0957 - val_loss: 0.2032\n",
      "17/17 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(523, 67), test_y.shape=(523, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 482142742689.1522, my average MASE = 482142742689.1522\n",
      "Cluster 6, 482142742689.1522\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.2073 - val_loss: 1.2269\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.2046 - val_loss: 1.2241\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2018 - val_loss: 1.2213\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1991 - val_loss: 1.2185\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1963 - val_loss: 1.2157\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1936 - val_loss: 1.2129\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1908 - val_loss: 1.2101\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1881 - val_loss: 1.2073\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1854 - val_loss: 1.2046\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1826 - val_loss: 1.2019\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1800 - val_loss: 1.1992\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1774 - val_loss: 1.1965\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1748 - val_loss: 1.1938\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1721 - val_loss: 1.1912\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.1695 - val_loss: 1.1886\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.1669 - val_loss: 1.1860\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1643 - val_loss: 1.1834\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1617 - val_loss: 1.1808\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1590 - val_loss: 1.1782\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1564 - val_loss: 1.1756\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1538 - val_loss: 1.1730\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1512 - val_loss: 1.1703\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1485 - val_loss: 1.1677\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1459 - val_loss: 1.1650\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1432 - val_loss: 1.1624\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1405 - val_loss: 1.1597\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1379 - val_loss: 1.1571\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1352 - val_loss: 1.1544\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1325 - val_loss: 1.1519\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1298 - val_loss: 1.1493\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1270 - val_loss: 1.1467\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1243 - val_loss: 1.1442\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.1216 - val_loss: 1.1416\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1189 - val_loss: 1.1390\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1162 - val_loss: 1.1364\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1135 - val_loss: 1.1338\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.1108 - val_loss: 1.1312\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1081 - val_loss: 1.1287\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1053 - val_loss: 1.1262\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1026 - val_loss: 1.1236\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 60714422265.98051, my average MASE = 60714422265.98051\n",
      "Cluster 7, 60714422265.98051\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.4343 - val_loss: 1.3952\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4303 - val_loss: 1.3923\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4264 - val_loss: 1.3894\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4224 - val_loss: 1.3865\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4185 - val_loss: 1.3836\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.4145 - val_loss: 1.3808\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4106 - val_loss: 1.3779\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.4067 - val_loss: 1.3751\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4027 - val_loss: 1.3724\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3988 - val_loss: 1.3696\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3949 - val_loss: 1.3669\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3910 - val_loss: 1.3642\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3870 - val_loss: 1.3615\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3832 - val_loss: 1.3589\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3793 - val_loss: 1.3563\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3754 - val_loss: 1.3537\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3716 - val_loss: 1.3512\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3678 - val_loss: 1.3487\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3640 - val_loss: 1.3462\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3602 - val_loss: 1.3437\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3564 - val_loss: 1.3413\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3526 - val_loss: 1.3389\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3488 - val_loss: 1.3365\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3450 - val_loss: 1.3341\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3412 - val_loss: 1.3317\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3374 - val_loss: 1.3292\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.3335 - val_loss: 1.3268\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3297 - val_loss: 1.3244\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3258 - val_loss: 1.3220\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.3219 - val_loss: 1.3196\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.3181 - val_loss: 1.3172\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.3142 - val_loss: 1.3148\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3103 - val_loss: 1.3124\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.3064 - val_loss: 1.3100\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3025 - val_loss: 1.3078\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2986 - val_loss: 1.3055\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2946 - val_loss: 1.3033\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2907 - val_loss: 1.3010\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.2867 - val_loss: 1.2988\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2827 - val_loss: 1.2966\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 567436187132.1053, my average MASE = 567436187132.1053\n",
      "Cluster 8, 567436187132.1053\n",
      "Before prediction: train_X.shape=(41, 10, 67), train_y.shape=(41, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6347 - val_loss: 0.6623\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6307 - val_loss: 0.6583\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6267 - val_loss: 0.6544\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6228 - val_loss: 0.6506\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6189 - val_loss: 0.6468\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6150 - val_loss: 0.6430\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6112 - val_loss: 0.6393\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6076 - val_loss: 0.6357\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6040 - val_loss: 0.6321\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6005 - val_loss: 0.6286\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5972 - val_loss: 0.6251\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5939 - val_loss: 0.6218\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5906 - val_loss: 0.6185\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5875 - val_loss: 0.6154\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5844 - val_loss: 0.6122\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5813 - val_loss: 0.6092\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5783 - val_loss: 0.6062\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5754 - val_loss: 0.6032\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5724 - val_loss: 0.6002\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5695 - val_loss: 0.5972\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5666 - val_loss: 0.5942\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5637 - val_loss: 0.5912\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5608 - val_loss: 0.5882\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5580 - val_loss: 0.5853\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5551 - val_loss: 0.5824\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5522 - val_loss: 0.5795\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5494 - val_loss: 0.5768\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5465 - val_loss: 0.5741\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5437 - val_loss: 0.5714\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5409 - val_loss: 0.5688\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5381 - val_loss: 0.5662\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5354 - val_loss: 0.5637\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5327 - val_loss: 0.5612\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5300 - val_loss: 0.5588\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5274 - val_loss: 0.5564\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5248 - val_loss: 0.5540\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5222 - val_loss: 0.5516\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5196 - val_loss: 0.5492\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5171 - val_loss: 0.5467\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5146 - val_loss: 0.5443\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 59025933474.71495, my average MASE = 59025933474.71495\n",
      "Cluster 9, 59025933474.71495\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6306 - val_loss: 0.6258\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6264 - val_loss: 0.6216\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6223 - val_loss: 0.6174\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6182 - val_loss: 0.6133\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6142 - val_loss: 0.6092\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6102 - val_loss: 0.6053\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6065 - val_loss: 0.6016\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6029 - val_loss: 0.5979\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5993 - val_loss: 0.5942\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5957 - val_loss: 0.5906\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5921 - val_loss: 0.5870\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5885 - val_loss: 0.5833\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5850 - val_loss: 0.5796\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5814 - val_loss: 0.5760\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5777 - val_loss: 0.5723\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5741 - val_loss: 0.5685\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5704 - val_loss: 0.5648\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5668 - val_loss: 0.5610\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5630 - val_loss: 0.5573\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5593 - val_loss: 0.5535\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5555 - val_loss: 0.5498\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5518 - val_loss: 0.5459\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5480 - val_loss: 0.5421\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5442 - val_loss: 0.5382\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5404 - val_loss: 0.5344\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5365 - val_loss: 0.5305\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5327 - val_loss: 0.5266\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5287 - val_loss: 0.5226\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5248 - val_loss: 0.5186\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5207 - val_loss: 0.5148\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5169 - val_loss: 0.5112\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5132 - val_loss: 0.5076\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5095 - val_loss: 0.5040\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5057 - val_loss: 0.5004\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5020 - val_loss: 0.4967\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4983 - val_loss: 0.4930\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4947 - val_loss: 0.4893\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4910 - val_loss: 0.4856\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4872 - val_loss: 0.4817\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4833 - val_loss: 0.4778\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE in_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 4.51024016e+04 5.60659422e+04 1.31745323e+05 5.08796664e+04\n",
      " 1.95394004e-01 7.60255899e+01 2.03975436e+03 7.33535702e+03\n",
      " 5.69343080e+03 8.78201885e+03 0.00000000e+00 2.42473495e+04\n",
      " 2.81851185e+04 4.85350839e+04 2.39611854e+02 1.43533604e+05\n",
      " 5.09141883e+03 3.52736586e+02 5.73305552e+03 4.44261940e+02\n",
      " 7.61770148e+03 3.53377675e+02 6.96568799e+03 4.45270524e+04\n",
      " 1.20523353e+16 2.57916668e+04 2.05952330e+02 4.46476308e+16\n",
      " 1.53125790e+06 4.87301062e+16 1.30594357e+06 4.61054461e+16\n",
      " 1.48604913e+06 4.47131264e+16 1.53598891e+06 2.22982986e+15\n",
      " 4.70171907e+03 5.50548106e+03 8.62186551e+03 8.44892973e+03\n",
      " 6.18328585e+03 3.86890568e+03 2.59101186e+03 6.81091475e+03\n",
      " 1.05153019e+04 1.73460030e+05 3.75901838e+03 1.50532807e+05\n",
      " 5.66569604e+03 1.81859382e+04 1.72379575e+05 1.83564144e+05\n",
      " 5.78942275e+03 4.58009869e+03 8.81205790e+02 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 3.46518862e+03 2.24829021e+18], MASE out_sample = [2.94477266e+17 2.44723269e+17 2.34084995e+16 4.42348725e+17\n",
      " 8.55003561e+15 9.46048855e+16 2.08825302e+17 5.96107317e+16\n",
      " 3.00823880e+13 4.46019306e+02 4.02747145e+02 1.45711649e+16\n",
      " 1.39075485e+17 1.97407219e+03 0.00000000e+00 1.47731256e+03\n",
      " 1.82384683e+03 1.81771685e+03 3.89242255e+01 1.91154644e+04\n",
      " 5.54790857e+02 1.41070933e+02 5.08671440e+02 1.50340321e+02\n",
      " 4.83869115e+02 1.32574580e+02 3.67791520e+02 5.80072776e+02\n",
      " 9.06101493e+01 1.22943503e+05 3.76690855e+01 4.46476308e+16\n",
      " 2.37181338e+18 4.87301062e+16 8.10692346e+05 4.61054461e+16\n",
      " 2.30181475e+18 4.47131264e+16 2.37912219e+18 2.22982986e+15\n",
      " 3.30291896e+03 8.01331979e+03 6.33465558e+03 6.56721842e+03\n",
      " 7.60495365e+03 2.30537483e+03 2.27479313e+03 3.86895600e+03\n",
      " 7.66444661e+03 2.51641435e+05 6.32697036e+03 1.90567822e+05\n",
      " 9.73491798e+03 1.52981693e+04 2.09688200e+05 2.56785621e+05\n",
      " 3.14661996e+03 2.41077824e+03 1.93593424e+03 2.90168721e+17\n",
      " 3.39392720e+15 5.41738879e+15 2.48182942e+15 1.18048089e+16\n",
      " 1.03700358e+17 1.40028703e+02 2.24829021e+18]\n",
      "average MASE = 243439352298.85837, my average MASE = 243439352298.85837\n",
      "Cluster 10, 243439352298.85837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maes = defaultdict(lambda: [])\n",
    "mases = defaultdict(lambda: [])\n",
    "mapes = defaultdict(lambda: [])\n",
    "answers = {}\n",
    "bad_values = np.zeros(dataset.shape[1])\n",
    "\n",
    "dif=False\n",
    "\n",
    "for window_size in window_sizes_for_clustering:\n",
    "    for N_clusters in Ns_clusters:\n",
    "        dataset_windows, dataset_y = Forecasting.create_windows(dataset, window_size=window_size)\n",
    "        clusters_labels = Clustering.KMeans_for_windows(dataset_windows, W=window_size, N_clusters=N_clusters, max_iter=50)\n",
    "        print(f\"{clusters_labels.shape=}\")\n",
    "        datasets_clusters = Clustering.flatten_from_interceting_windows(dataset_windows, clusters_labels, W=window_size, \\\n",
    "                N_clusters=N_clusters)\n",
    "        # list of list of ndarrays [N_i, Q], dataset_clusters[cluster_num][i] - i-th part of dataset for cluster_num\n",
    "\n",
    "        print(f\"{N_clusters=}, {len(datasets_clusters)}, {len(datasets_clusters[0])}, {datasets_clusters[0][0].shape}\")\n",
    "        ###window_size for model\n",
    "        errors = [1] * N_clusters\n",
    "        for cluster_num in range(N_clusters):\n",
    "            sc = Forecasting.MyStandardScaler(dif=dif)\n",
    "            #datasets_clusters[cluster_num] - list of [N_i, Q] ndarrays\n",
    "            sc.fit(datasets_clusters[cluster_num])\n",
    "            prepared_data = sc.transform(datasets_clusters[cluster_num])\n",
    "            data_X, data_y = Forecasting.create_windows(prepared_data, window_size=10)\n",
    "            #data_X - list of [N_i-W, W, Q] ndarrays\n",
    "            train_X, train_y, valid_X, valid_y, test_X, test_y, ind = Forecasting.split_to_train_test(data_X, data_y, part_of_test=0.2, part_of_valid=0.2)\n",
    "            #ndarrays [N_i, W, Q] or [N_i, Q]\n",
    "            ind = np.array(ind) + window_size\n",
    "            print(f\"Before prediction: {train_X.shape=}, {train_y.shape=}, {test_X.shape=}, {test_y.shape=}\")\n",
    "            try:\n",
    "                assert(len(test_X.shape) == 3 and test_X.shape[0] > 0)\n",
    "                assert(len(valid_X.shape) == 3 and valid_X.shape[0] > 0)\n",
    "                assert(len(train_X.shape) == 3 and train_X.shape[0] > 0)\n",
    "            except AssertionError:\n",
    "                print(f\"FAIL - {test_X.shape=}, {valid_X.shape=}, {train_X.shape=}\")\n",
    "                errors[cluster_num] = np.Inf\n",
    "                continue\n",
    "            model, history = Forecasting.learn(train_X, train_y, valid_X=valid_X, valid_y=valid_y)\n",
    "            predicted = model.predict(test_X)\n",
    "            predicted_original = sc.inverse_transform(predicted)[0]\n",
    "            #inverse_trasform returns list of ndarrays \n",
    "            if dif:\n",
    "                #константа при дифференцировании\n",
    "                predicted_original = sc.add_first_element(predicted_original, ind)[0]\n",
    "            print(f\"{predicted_original.shape=}, {test_y.shape=}\")\n",
    "\n",
    "            #calc all metrics\n",
    "            cur_mae = mae(test_y, predicted_original, multioutput='raw_values')\n",
    "#             error_out = mase(test_y, predicted_original, y_train=test_y)\n",
    "#             error_in = mase(test_y, predicted_original, y_train=train_y)\n",
    "            # cur_mase = mase(test_y, predicted_original, y_train=test_y)\n",
    "            cur_mape = mape(test_y, predicted_original)\n",
    "            cur_mase = Forecasting.my_mase(test_y, predicted_original, multioutput='raw_values')\n",
    "            maes[(window_size, N_clusters)].append(cur_mae)\n",
    "#             mases[(window_size, N_clusters)].append((error_in, error_out))\n",
    "            mapes[(window_size, N_clusters)].append(cur_mape)\n",
    "#             errors[cluster_num] = mase_uni(test_y, predicted_original, y_train=test_y)\n",
    "            errors[cluster_num] = Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')\n",
    "            tmp_bad = cur_mase > np.percentile(cur_mase, 95)\n",
    "            bad_values += tmp_bad\n",
    "            cur_mase[tmp_bad] = -1\n",
    "            #show all metrics\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.suptitle(f\"K={N_clusters}, W={window_size}, C={cluster_num}\")\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(cur_mae, color=\"green\", label=\"library\")\n",
    "#             plt.plot(Forecasting.my_mae(test_y, predicted_original, multioutput='raw_values'), color=\"red\", label=\"custom\")\n",
    "            plt.title(\"MAE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "#             plt.plot(error_in, label=\"library, in\")\n",
    "#             plt.plot(error_out, label=\"library, out\")\n",
    "            plt.plot(cur_mase, label=\"custom, out\")\n",
    "            plt.title(\"MASE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(cur_mape)\n",
    "            plt.title(\"MAPE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f\"plots/Dataset2/K={N_clusters}  W={window_size} C={cluster_num}.png\")\n",
    "#             plt.show()\n",
    "            plt.clf()\n",
    "            # print(f\"{cur_mae=}, {cur_mase=}, {cur_mape=}\")\n",
    "            # my_mase = mase()\n",
    "            print(f\"MASE in_sample = {error_in}, MASE out_sample = {error_out}\")\n",
    "            print(f\"average MASE = {errors[cluster_num]}, my average MASE = {Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')}\")\n",
    "            print(f\"Cluster {cluster_num}, {errors[cluster_num]}\")\n",
    "        answers[(window_size, N_clusters)] = errors\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.suptitle(f\"K={N_clusters}, W={window_size}\")\n",
    "        plt.subplot(2, 2, 1)\n",
    "\n",
    "        plt.bar(np.arange(N_clusters), [np.sum(clusters_labels == i) for i in range(N_clusters)], color='blue')\n",
    "        plt.title(\"Размеры кластеров\")\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.bar(np.arange(N_clusters), [len(datasets_clusters[i]) for i in range(N_clusters)], color=\"green\")\n",
    "        plt.title(\"Количество непрерывных отрезков\")\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.bar(np.arange(N_clusters), errors, color=\"red\")\n",
    "        plt.title(\"MASE на тесте каждого из кластеров\")\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        plt.table(cellText= [[f\"{x:.2f}\"] for x in errors],\n",
    "                      rowLabels=list(range(N_clusters)),\n",
    "                      loc='center')\n",
    "#         plt.show()\n",
    "        plt.savefig(f\"plots/Dataset2/method1: {N_clusters=}  W={window_size}.png\")\n",
    "        #         plt.show()\n",
    "        plt.clf()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.bar(np.arange(bad_values.shape[0]), bad_values)\n",
    "plt.title(\"Количество раз, когда переменная имела максимум MASE\")\n",
    "plt.savefig(f\"plots/Dataset2/bad_values.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([ 2,  4,  7,  8, 11, 14, 18, 21, 23, 25, 28, 30, 33, 37, 39, 43, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 5)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33,\n",
      "       39, 48, 50, 53, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 28, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 33, 37, 39,\n",
      "       41, 43, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 9)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 30, 31, 33, 35, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 12, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 23, 25, 26, 28, 30, 39, 41, 42, 48,\n",
      "       51, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(3, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 13, 14, 15, 18, 21, 23, 25, 26, 28, 30, 33,\n",
      "       37, 39, 41, 42, 44, 48, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 5)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 26, 28, 30, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 7)\n",
      "     (array([ 2, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 35, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 9)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 23, 25, 28, 30, 31, 33, 35, 39,\n",
      "       41, 43, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(3, 11)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 37, 39, 44, 48,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 2)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 12, 14, 18, 21, 23, 25, 30, 31, 33, 37, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 5)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 31, 39, 60, 61,\n",
      "       62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(5, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 16, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 23, 25, 28, 30, 33, 35, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "(5, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 14, 15, 16, 18, 19, 21, 23, 25, 27, 28, 30,\n",
      "       39, 42, 44, 47, 48, 52, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 15, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35,\n",
      "       37, 39, 60, 61, 62, 63, 65]),)\n",
      "(5, 11)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 28, 30, 31, 33, 39,\n",
      "       41, 42, 49, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(10, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 11, 13, 14, 18, 21, 23, 25, 28, 30, 31, 33,\n",
      "       35, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 5)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 22, 23, 25, 28, 30, 31, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 7)\n",
      "     (array([ 2,  4,  8,  9, 14, 16, 18, 19, 30, 58, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "(10, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 23, 24, 25, 26, 28, 30, 31,\n",
      "       33, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(10, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 12, 14, 18, 21, 22, 23, 25, 28, 30, 39, 56, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in maes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in mases.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c[0] < 1)}, {np.where(val_c[1] < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([14, 18, 25, 30, 31, 33, 35, 37, 43]),)\n",
      "     (array([14, 30]),)\n",
      "(1, 5)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(1, 7)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 11, 14]),)\n",
      "     (array([14]),)\n",
      "(1, 9)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 4,  8, 14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14, 60, 61]),)\n",
      "(1, 11)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(3, 2)\n",
      "     (array([ 4, 14, 18, 30, 31, 33, 35, 37, 42, 62]),)\n",
      "     (array([14, 30]),)\n",
      "(3, 5)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(3, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61]),)\n",
      "(3, 9)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 28, 39, 62]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 19, 30]),)\n",
      "(3, 11)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 23, 28, 39, 62, 65]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "(5, 2)\n",
      "     (array([12, 14, 18, 30, 31, 33, 35, 37, 60, 62, 65]),)\n",
      "     (array([14, 30]),)\n",
      "(5, 5)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "(5, 7)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 9, 11, 14, 18, 19, 21, 23, 25, 30, 39, 42, 44, 47, 52, 60, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 11)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 21, 23, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "(10, 2)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "(10, 5)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 14]),)\n",
      "(10, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 11)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in mapes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anna",
   "language": "python",
   "name": "anna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
