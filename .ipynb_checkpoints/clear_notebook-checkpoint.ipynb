{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSet2.csv\", sep=\";\")#, parse_dates=['Timestamp']) #, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "df = data.groupby(data.index // K).mean() #усреднение\n",
    "df_np = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsoluteScaledError, MeanAbsolutePercentageError\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mase = MeanAbsoluteScaledError(multioutput='raw_values')\n",
    "mase_uni = MeanAbsoluteScaledError(multioutput='uniform_average')\n",
    "mape = MeanAbsolutePercentageError(multioutput='raw_values')\n",
    "# mae = MeanAbsoluteError()\n",
    "\n",
    "\n",
    "#if ‘raw_values’, returns a full set of errors in case of multioutput input. If ‘uniform_average’, errors of all outputs are averaged with uniform weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 67)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df_np[:, :]\n",
    "# dataset = np.concatenate((dataset[:, :8], dataset[:, 9:]), axis=1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**__Отбор признаков на минималках__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удаление константных\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(0.001)\n",
    "dataset1 = selector.fit_transform(dataset) \n",
    "dataset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 14}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(range(67)) - set(selector.get_feature_names_out(input_features=np.arange(dataset.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset[:, 14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(dataset[:, 8], color=\"green\")\n",
    "plt.plot(np.concatenate((dataset[:32714, 8], dataset[32717:, 8])))\n",
    "plt.title(\"consumption_09\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00292  0.00733  0.754974 1.658794 1.956544]\n",
      "[32714, 375379, 1, 1, 1]\n",
      "Изменение только в [[32713]\n",
      " [32714]\n",
      " [32715]\n",
      " [32716]]\n"
     ]
    }
   ],
   "source": [
    "values = np.unique(dataset[:, 8])\n",
    "print(values)\n",
    "print([len(np.argwhere(dataset[:, 8] == val)) for val in values])\n",
    "print(f\"Изменение только в {np.argwhere(dataset[1:, 8] - dataset[:-1, 8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Эти датчики пока выкинем из-за константности: ** \n",
    "\n",
    "8: consumption_09\n",
    "\n",
    "14 : consumption_07 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('consumption_07', 'consumption_09')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[15], columns[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fecaa525310>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataset[7])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import correlate\n",
    "# a = np.array([np.sin(x + 1) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 2) for x in range(10)])\n",
    "# c = correlate(a, b, mode=\"full\") #mode='same'\n",
    "# plt.plot(a, label=\"a\")\n",
    "# plt.plot(b, label=\"b\")\n",
    "# plt.plot(c, label=\"correlation\")\n",
    "# plt.legend()\n",
    "# c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "#еще не поняла до конца\n",
    "from sklearn.feature_selection import f_regression\n",
    "for i in range(1):\n",
    "    X = np.concatenate((dataset[:, :i], dataset[:, i + 1:]), axis=1)\n",
    "    y = dataset[:, i]\n",
    "    res = f_regression(X, y)\n",
    "    print(res[0].shape)\n",
    "    # plt.plot(res[0], label=\"f_statistics\")\n",
    "    # # plt.plot(res[1], label=\"p_values\")\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([np.sin(x) for x in range(10)])\n",
    "# b = np.array([np.sin(x + 1) + 1 for x in range(10)])\n",
    "# c = np.array([np.sin(x + 0.1) for x in range(10)])\n",
    "\n",
    "# f_regression(a[:, None], b), f_regression(a[:, None], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прогнозирование**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408096, 65)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset1\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "window_sizes_for_clustering = 10\n",
    "# X, y = dataset[:-window_sizes_for_clustering, ...], dataset[window_sizes_for_clustering:, ...]\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "n_split = round(0.2 * dataset.shape[0])\n",
    "dataset_train, dataset_test = dataset[:-n_split, ...], dataset[-n_split:, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((326477, 65), (81619, 65))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes_for_clustering = [5, 10, 15] #1, 3\n",
    "Ns_clusters = [7, 9, 11] #2, 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ns_clusters = [11]\n",
    "# window_sizes_for_clustering = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_windows.shape=(326472, 5, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=11, result_data[0].shape=(3245, 65)\n",
      "Before prediction: train_X.shape=(1941, 10, 65), train_y.shape=(1941, 65), test_X.shape=(647, 10, 65), test_y.shape=(647, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 16:37:48.545545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-09 16:37:48.548198: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "31/31 [==============================] - 2s 47ms/step - loss: 0.1169 - val_loss: 0.0939\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1116 - val_loss: 0.0921\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1073 - val_loss: 0.0909\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.1037 - val_loss: 0.0901\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1006 - val_loss: 0.0894\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0979 - val_loss: 0.0889\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0954 - val_loss: 0.0885\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0932 - val_loss: 0.0881\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0912 - val_loss: 0.0878\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0893 - val_loss: 0.0875\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0876 - val_loss: 0.0872\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0861 - val_loss: 0.0870\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0846 - val_loss: 0.0867\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0833 - val_loss: 0.0865\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0821 - val_loss: 0.0863\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0809 - val_loss: 0.0861\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0799 - val_loss: 0.0860\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0789 - val_loss: 0.0858\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0780 - val_loss: 0.0856\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0771 - val_loss: 0.0855\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0763 - val_loss: 0.0854\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0755 - val_loss: 0.0852\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0748 - val_loss: 0.0851\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0741 - val_loss: 0.0850\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0735 - val_loss: 0.0849\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0728 - val_loss: 0.0847\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0722 - val_loss: 0.0846\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0716 - val_loss: 0.0845\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.0711 - val_loss: 0.0844\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0706 - val_loss: 0.0843\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0701 - val_loss: 0.0842\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0696 - val_loss: 0.0841\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0692 - val_loss: 0.0840\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.0688 - val_loss: 0.0839\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0684 - val_loss: 0.0839\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0681 - val_loss: 0.0838\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0677 - val_loss: 0.0837\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0674 - val_loss: 0.0837\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0671 - val_loss: 0.0836\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0668 - val_loss: 0.0835\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=141, result_data[0].shape=(94, 65)\n",
      "Before prediction: train_X.shape=(50, 10, 65), train_y.shape=(50, 65), test_X.shape=(17, 10, 65), test_y.shape=(17, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4046 - val_loss: 0.3960\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4042 - val_loss: 0.3959\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4038 - val_loss: 0.3958\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4033 - val_loss: 0.3957\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4029 - val_loss: 0.3957\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4025 - val_loss: 0.3956\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4021 - val_loss: 0.3955\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4017 - val_loss: 0.3954\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4013 - val_loss: 0.3953\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4009 - val_loss: 0.3952\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4005 - val_loss: 0.3951\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4001 - val_loss: 0.3950\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3997 - val_loss: 0.3950\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3994 - val_loss: 0.3949\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3990 - val_loss: 0.3948\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3986 - val_loss: 0.3947\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3983 - val_loss: 0.3946\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3945\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3975 - val_loss: 0.3944\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3972 - val_loss: 0.3943\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3968 - val_loss: 0.3942\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3965 - val_loss: 0.3941\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3961 - val_loss: 0.3940\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3958 - val_loss: 0.3939\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3954 - val_loss: 0.3938\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3951 - val_loss: 0.3937\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3947 - val_loss: 0.3937\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3944 - val_loss: 0.3936\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3941 - val_loss: 0.3935\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3937 - val_loss: 0.3934\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3934 - val_loss: 0.3933\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3930 - val_loss: 0.3932\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3927 - val_loss: 0.3931\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3924 - val_loss: 0.3930\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3920 - val_loss: 0.3929\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3917 - val_loss: 0.3929\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3914 - val_loss: 0.3928\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3911 - val_loss: 0.3927\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3907 - val_loss: 0.3926\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3904 - val_loss: 0.3925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=52, result_data[0].shape=(316, 65)\n",
      "Before prediction: train_X.shape=(184, 10, 65), train_y.shape=(184, 65), test_X.shape=(61, 10, 65), test_y.shape=(61, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7052 - val_loss: 0.6419\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7037 - val_loss: 0.6410\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7023 - val_loss: 0.6401\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7010 - val_loss: 0.6393\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6996 - val_loss: 0.6385\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6984 - val_loss: 0.6376\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6971 - val_loss: 0.6368\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6959 - val_loss: 0.6360\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6947 - val_loss: 0.6352\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6936 - val_loss: 0.6344\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6924 - val_loss: 0.6337\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6913 - val_loss: 0.6330\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6902 - val_loss: 0.6322\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6891 - val_loss: 0.6315\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6881 - val_loss: 0.6308\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6870 - val_loss: 0.6301\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6860 - val_loss: 0.6294\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6850 - val_loss: 0.6287\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6840 - val_loss: 0.6281\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6830 - val_loss: 0.6274\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6820 - val_loss: 0.6268\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6810 - val_loss: 0.6261\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6801 - val_loss: 0.6255\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6791 - val_loss: 0.6249\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6782 - val_loss: 0.6243\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6773 - val_loss: 0.6237\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6764 - val_loss: 0.6231\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6754 - val_loss: 0.6225\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6746 - val_loss: 0.6220\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6737 - val_loss: 0.6214\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6728 - val_loss: 0.6208\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6719 - val_loss: 0.6202\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6711 - val_loss: 0.6197\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6703 - val_loss: 0.6191\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6694 - val_loss: 0.6185\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6686 - val_loss: 0.6180\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6677 - val_loss: 0.6174\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6669 - val_loss: 0.6168\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6661 - val_loss: 0.6163\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6652 - val_loss: 0.6157\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=369, result_data[0].shape=(267, 65)\n",
      "Before prediction: train_X.shape=(154, 10, 65), train_y.shape=(154, 65), test_X.shape=(51, 10, 65), test_y.shape=(51, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.5122 - val_loss: 0.4286\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5109 - val_loss: 0.4277\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5097 - val_loss: 0.4269\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5086 - val_loss: 0.4260\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5074 - val_loss: 0.4252\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5063 - val_loss: 0.4244\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5052 - val_loss: 0.4236\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5041 - val_loss: 0.4228\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5031 - val_loss: 0.4221\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5020 - val_loss: 0.4213\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.5010 - val_loss: 0.4206\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.5000 - val_loss: 0.4199\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.4990 - val_loss: 0.4192\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.4980 - val_loss: 0.4186\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4971 - val_loss: 0.4179\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4962 - val_loss: 0.4172\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.4952 - val_loss: 0.4166\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4943 - val_loss: 0.4159\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.4934 - val_loss: 0.4152\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4926 - val_loss: 0.4146\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4917 - val_loss: 0.4139\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.4908 - val_loss: 0.4133\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.4900 - val_loss: 0.4127\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4892 - val_loss: 0.4121\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4883 - val_loss: 0.4114\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4875 - val_loss: 0.4108\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4867 - val_loss: 0.4103\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4859 - val_loss: 0.4097\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4852 - val_loss: 0.4091\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4844 - val_loss: 0.4085\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4836 - val_loss: 0.4079\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4829 - val_loss: 0.4074\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4822 - val_loss: 0.4068\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4814 - val_loss: 0.4063\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4807 - val_loss: 0.4057\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4800 - val_loss: 0.4052\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4793 - val_loss: 0.4046\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4786 - val_loss: 0.4041\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4779 - val_loss: 0.4036\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4772 - val_loss: 0.4030\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=1, result_data[0].shape=(2618, 65)\n",
      "Before prediction: train_X.shape=(1565, 10, 65), train_y.shape=(1565, 65), test_X.shape=(522, 10, 65), test_y.shape=(522, 65)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2474 - val_loss: 0.2876\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2372 - val_loss: 0.2782\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2298 - val_loss: 0.2707\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.2238 - val_loss: 0.2645\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2188 - val_loss: 0.2591\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2143 - val_loss: 0.2543\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.2103 - val_loss: 0.2500\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2067 - val_loss: 0.2461\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2034 - val_loss: 0.2425\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.2004 - val_loss: 0.2391\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.1975 - val_loss: 0.2359\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1949 - val_loss: 0.2330\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1924 - val_loss: 0.2302\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1900 - val_loss: 0.2276\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1878 - val_loss: 0.2252\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1856 - val_loss: 0.2229\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.1837 - val_loss: 0.2207\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.1818 - val_loss: 0.2188\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1802 - val_loss: 0.2170\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1786 - val_loss: 0.2154\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1772 - val_loss: 0.2138\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1758 - val_loss: 0.2123\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1746 - val_loss: 0.2109\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1734 - val_loss: 0.2096\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.1723 - val_loss: 0.2084\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1712 - val_loss: 0.2072\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1702 - val_loss: 0.2061\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1693 - val_loss: 0.2049\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1683 - val_loss: 0.2039\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1675 - val_loss: 0.2029\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1666 - val_loss: 0.2019\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.1658 - val_loss: 0.2010\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1651 - val_loss: 0.2001\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1643 - val_loss: 0.1993\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1636 - val_loss: 0.1985\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1629 - val_loss: 0.1977\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1623 - val_loss: 0.1969\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.1617 - val_loss: 0.1962\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1611 - val_loss: 0.1955\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1605 - val_loss: 0.1948\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=424, result_data[0].shape=(9, 65)\n",
      "Before prediction: train_X.shape=(23, 10, 65), train_y.shape=(23, 65), test_X.shape=(8, 10, 65), test_y.shape=(8, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4543 - val_loss: 0.4172\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4538 - val_loss: 0.4171\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4533 - val_loss: 0.4170\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4527 - val_loss: 0.4169\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4522 - val_loss: 0.4169\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4517 - val_loss: 0.4168\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4512 - val_loss: 0.4167\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4507 - val_loss: 0.4166\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4502 - val_loss: 0.4165\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4497 - val_loss: 0.4165\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4492 - val_loss: 0.4164\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4487 - val_loss: 0.4163\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4482 - val_loss: 0.4162\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4477 - val_loss: 0.4162\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4472 - val_loss: 0.4161\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4467 - val_loss: 0.4160\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4463 - val_loss: 0.4160\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4458 - val_loss: 0.4159\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4454 - val_loss: 0.4158\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4449 - val_loss: 0.4157\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4445 - val_loss: 0.4157\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4440 - val_loss: 0.4156\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4436 - val_loss: 0.4155\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4431 - val_loss: 0.4154\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4427 - val_loss: 0.4154\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4422 - val_loss: 0.4153\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4418 - val_loss: 0.4152\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4414 - val_loss: 0.4152\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4409 - val_loss: 0.4151\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4405 - val_loss: 0.4150\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4401 - val_loss: 0.4150\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4397 - val_loss: 0.4149\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4392 - val_loss: 0.4149\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4388 - val_loss: 0.4148\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4384 - val_loss: 0.4147\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4380 - val_loss: 0.4147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4375 - val_loss: 0.4146\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4371 - val_loss: 0.4146\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4367 - val_loss: 0.4145\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4363 - val_loss: 0.4145\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=40, result_data[0].shape=(69, 65)\n",
      "Before prediction: train_X.shape=(35, 10, 65), train_y.shape=(35, 65), test_X.shape=(12, 10, 65), test_y.shape=(12, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5766 - val_loss: 0.4863\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5746 - val_loss: 0.4851\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5726 - val_loss: 0.4838\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5707 - val_loss: 0.4827\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5687 - val_loss: 0.4815\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5668 - val_loss: 0.4803\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5650 - val_loss: 0.4792\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5631 - val_loss: 0.4781\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5613 - val_loss: 0.4770\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5594 - val_loss: 0.4759\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5577 - val_loss: 0.4748\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5559 - val_loss: 0.4738\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5541 - val_loss: 0.4727\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5524 - val_loss: 0.4717\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5507 - val_loss: 0.4707\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5490 - val_loss: 0.4697\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5474 - val_loss: 0.4687\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5457 - val_loss: 0.4677\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5441 - val_loss: 0.4667\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5425 - val_loss: 0.4658\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5410 - val_loss: 0.4648\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5394 - val_loss: 0.4639\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5379 - val_loss: 0.4630\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5363 - val_loss: 0.4621\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5348 - val_loss: 0.4612\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5334 - val_loss: 0.4603\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5319 - val_loss: 0.4595\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5304 - val_loss: 0.4586\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5289 - val_loss: 0.4577\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5275 - val_loss: 0.4569\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5260 - val_loss: 0.4561\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5246 - val_loss: 0.4552\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5232 - val_loss: 0.4544\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5218 - val_loss: 0.4536\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5204 - val_loss: 0.4528\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5191 - val_loss: 0.4520\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5177 - val_loss: 0.4512\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5164 - val_loss: 0.4504\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5150 - val_loss: 0.4497\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5137 - val_loss: 0.4489\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "dataset_windows.shape=(326472, 5, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=117, result_data[0].shape=(12, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(1, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=43, result_data[0].shape=(34, 65)\n",
      "Before prediction: train_X.shape=(14, 10, 65), train_y.shape=(14, 65), test_X.shape=(5, 10, 65), test_y.shape=(5, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4956 - val_loss: 0.7143\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4950 - val_loss: 0.7141\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4943 - val_loss: 0.7139\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4937 - val_loss: 0.7137\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4931 - val_loss: 0.7135\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4924 - val_loss: 0.7132\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4918 - val_loss: 0.7130\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4912 - val_loss: 0.7128\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4906 - val_loss: 0.7126\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4900 - val_loss: 0.7123\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4894 - val_loss: 0.7121\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4888 - val_loss: 0.7119\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4882 - val_loss: 0.7116\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4876 - val_loss: 0.7114\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4870 - val_loss: 0.7112\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4864 - val_loss: 0.7109\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4858 - val_loss: 0.7107\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4852 - val_loss: 0.7104\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4846 - val_loss: 0.7102\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4840 - val_loss: 0.7100\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4835 - val_loss: 0.7097\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4829 - val_loss: 0.7095\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4823 - val_loss: 0.7092\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4818 - val_loss: 0.7090\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4812 - val_loss: 0.7088\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4806 - val_loss: 0.7085\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4801 - val_loss: 0.7083\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4795 - val_loss: 0.7080\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4790 - val_loss: 0.7078\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4784 - val_loss: 0.7075\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4779 - val_loss: 0.7073\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4774 - val_loss: 0.7071\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4769 - val_loss: 0.7068\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4763 - val_loss: 0.7066\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4758 - val_loss: 0.7064\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4753 - val_loss: 0.7061\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4747 - val_loss: 0.7059\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4742 - val_loss: 0.7056\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4737 - val_loss: 0.7054\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4732 - val_loss: 0.7052\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(9935, 65)\n",
      "Before prediction: train_X.shape=(5955, 10, 65), train_y.shape=(5955, 65), test_X.shape=(1985, 10, 65), test_y.shape=(1985, 65)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0690 - val_loss: 0.0488\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0629 - val_loss: 0.0454\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0594 - val_loss: 0.0431\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0569 - val_loss: 0.0411\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0549 - val_loss: 0.0395\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0532 - val_loss: 0.0381\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0519 - val_loss: 0.0369\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0507 - val_loss: 0.0359\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0497 - val_loss: 0.0350\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0489 - val_loss: 0.0343\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0482 - val_loss: 0.0336\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0475 - val_loss: 0.0331\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0469 - val_loss: 0.0326\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0464 - val_loss: 0.0322\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0459 - val_loss: 0.0318\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0455 - val_loss: 0.0315\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0451 - val_loss: 0.0312\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0447 - val_loss: 0.0309\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0443 - val_loss: 0.0306\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0440 - val_loss: 0.0304\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0437 - val_loss: 0.0302\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0435 - val_loss: 0.0300\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0432 - val_loss: 0.0298\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0430 - val_loss: 0.0296\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0428 - val_loss: 0.0294\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0426 - val_loss: 0.0293\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0424 - val_loss: 0.0292\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0422 - val_loss: 0.0290\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0421 - val_loss: 0.0289\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0419 - val_loss: 0.0288\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0418 - val_loss: 0.0287\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0417 - val_loss: 0.0286\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0415 - val_loss: 0.0285\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0414 - val_loss: 0.0284\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0413 - val_loss: 0.0284\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0412 - val_loss: 0.0283\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0411 - val_loss: 0.0282\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0410 - val_loss: 0.0281\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0409 - val_loss: 0.0280\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0408 - val_loss: 0.0280\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=359, result_data[0].shape=(5, 65)\n",
      "Before prediction: train_X.shape=(23, 10, 65), train_y.shape=(23, 65), test_X.shape=(8, 10, 65), test_y.shape=(8, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4404 - val_loss: 0.4069\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4398 - val_loss: 0.4068\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4393 - val_loss: 0.4066\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4387 - val_loss: 0.4065\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4382 - val_loss: 0.4064\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4377 - val_loss: 0.4062\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4372 - val_loss: 0.4061\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4366 - val_loss: 0.4059\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4361 - val_loss: 0.4058\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4356 - val_loss: 0.4057\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4351 - val_loss: 0.4056\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4346 - val_loss: 0.4054\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4341 - val_loss: 0.4053\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4336 - val_loss: 0.4052\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4331 - val_loss: 0.4050\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4326 - val_loss: 0.4049\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4321 - val_loss: 0.4048\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4316 - val_loss: 0.4047\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4311 - val_loss: 0.4045\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4307 - val_loss: 0.4044\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4302 - val_loss: 0.4043\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4297 - val_loss: 0.4041\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4292 - val_loss: 0.4040\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4287 - val_loss: 0.4039\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4283 - val_loss: 0.4038\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4278 - val_loss: 0.4037\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4273 - val_loss: 0.4036\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4269 - val_loss: 0.4035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4264 - val_loss: 0.4033\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4260 - val_loss: 0.4032\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4255 - val_loss: 0.4031\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4251 - val_loss: 0.4030\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4246 - val_loss: 0.4029\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4242 - val_loss: 0.4028\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4238 - val_loss: 0.4027\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4233 - val_loss: 0.4025\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4229 - val_loss: 0.4024\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4225 - val_loss: 0.4023\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4221 - val_loss: 0.4022\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4217 - val_loss: 0.4021\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=159, result_data[0].shape=(21, 65)\n",
      "Before prediction: train_X.shape=(7, 10, 65), train_y.shape=(7, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3960 - val_loss: 0.3357\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3953 - val_loss: 0.3356\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3945 - val_loss: 0.3355\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3938 - val_loss: 0.3355\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3931 - val_loss: 0.3354\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3924 - val_loss: 0.3353\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3918 - val_loss: 0.3353\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3911 - val_loss: 0.3352\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3905 - val_loss: 0.3352\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3898 - val_loss: 0.3351\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3892 - val_loss: 0.3350\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3886 - val_loss: 0.3350\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3880 - val_loss: 0.3349\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3874 - val_loss: 0.3348\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3868 - val_loss: 0.3347\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3862 - val_loss: 0.3347\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3856 - val_loss: 0.3346\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3851 - val_loss: 0.3345\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3845 - val_loss: 0.3344\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3840 - val_loss: 0.3344\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3834 - val_loss: 0.3343\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3829 - val_loss: 0.3342\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3824 - val_loss: 0.3342\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3818 - val_loss: 0.3341\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3813 - val_loss: 0.3340\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3807 - val_loss: 0.3339\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3802 - val_loss: 0.3338\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3797 - val_loss: 0.3338\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3791 - val_loss: 0.3337\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3786 - val_loss: 0.3336\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3781 - val_loss: 0.3335\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.3334\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3770 - val_loss: 0.3333\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3765 - val_loss: 0.3332\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3760 - val_loss: 0.3331\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3755 - val_loss: 0.3330\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3750 - val_loss: 0.3329\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3745 - val_loss: 0.3328\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3739 - val_loss: 0.3327\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3734 - val_loss: 0.3327\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=30, result_data[0].shape=(68, 65)\n",
      "Before prediction: train_X.shape=(35, 10, 65), train_y.shape=(35, 65), test_X.shape=(12, 10, 65), test_y.shape=(12, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5501 - val_loss: 0.4959\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5481 - val_loss: 0.4948\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5462 - val_loss: 0.4938\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5444 - val_loss: 0.4927\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5425 - val_loss: 0.4917\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5407 - val_loss: 0.4907\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5389 - val_loss: 0.4897\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5371 - val_loss: 0.4887\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5353 - val_loss: 0.4878\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5336 - val_loss: 0.4868\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5319 - val_loss: 0.4859\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5302 - val_loss: 0.4849\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5285 - val_loss: 0.4840\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5269 - val_loss: 0.4831\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5253 - val_loss: 0.4821\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5238 - val_loss: 0.4812\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5222 - val_loss: 0.4803\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5207 - val_loss: 0.4795\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.5193 - val_loss: 0.4786\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5178 - val_loss: 0.4777\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5163 - val_loss: 0.4769\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5149 - val_loss: 0.4760\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5135 - val_loss: 0.4752\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5121 - val_loss: 0.4744\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5108 - val_loss: 0.4735\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5094 - val_loss: 0.4727\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5081 - val_loss: 0.4719\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5068 - val_loss: 0.4711\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5055 - val_loss: 0.4703\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5043 - val_loss: 0.4695\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5030 - val_loss: 0.4687\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5018 - val_loss: 0.4679\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5006 - val_loss: 0.4671\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4994 - val_loss: 0.4663\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4983 - val_loss: 0.4656\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4971 - val_loss: 0.4648\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4960 - val_loss: 0.4640\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4948 - val_loss: 0.4632\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4937 - val_loss: 0.4625\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4926 - val_loss: 0.4617\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=464, result_data[0].shape=(13, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "FAIL - test_X.shape=(1, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(2, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=585, result_data[0].shape=(6, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "FAIL - test_X.shape=(1, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(2, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=179, result_data[0].shape=(142, 65)\n",
      "Before prediction: train_X.shape=(79, 10, 65), train_y.shape=(79, 65), test_X.shape=(26, 10, 65), test_y.shape=(26, 65)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3790 - val_loss: 0.3551\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3781 - val_loss: 0.3547\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3774 - val_loss: 0.3543\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3767 - val_loss: 0.3540\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3760 - val_loss: 0.3536\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3753 - val_loss: 0.3533\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3746 - val_loss: 0.3530\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3740 - val_loss: 0.3526\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3733 - val_loss: 0.3523\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3727 - val_loss: 0.3520\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3721 - val_loss: 0.3517\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3715 - val_loss: 0.3514\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3709 - val_loss: 0.3511\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3703 - val_loss: 0.3508\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3697 - val_loss: 0.3505\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3691 - val_loss: 0.3502\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3685 - val_loss: 0.3499\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3679 - val_loss: 0.3496\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3674 - val_loss: 0.3493\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3668 - val_loss: 0.3490\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3662 - val_loss: 0.3487\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3657 - val_loss: 0.3484\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3651 - val_loss: 0.3481\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3646 - val_loss: 0.3478\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3641 - val_loss: 0.3476\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3635 - val_loss: 0.3473\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3630 - val_loss: 0.3470\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3625 - val_loss: 0.3468\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3620 - val_loss: 0.3465\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3615 - val_loss: 0.3463\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3610 - val_loss: 0.3460\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3605 - val_loss: 0.3458\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3600 - val_loss: 0.3455\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3595 - val_loss: 0.3453\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3590 - val_loss: 0.3451\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3585 - val_loss: 0.3448\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3581 - val_loss: 0.3446\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3576 - val_loss: 0.3444\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3572 - val_loss: 0.3441\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3567 - val_loss: 0.3439\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "dataset_windows.shape=(326472, 5, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=392, result_data[0].shape=(5, 65)\n",
      "Before prediction: train_X.shape=(24, 10, 65), train_y.shape=(24, 65), test_X.shape=(8, 10, 65), test_y.shape=(8, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4576 - val_loss: 0.4113\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4571 - val_loss: 0.4112\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4565 - val_loss: 0.4111\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4560 - val_loss: 0.4110\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4555 - val_loss: 0.4109\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4550 - val_loss: 0.4108\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4544 - val_loss: 0.4107\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4539 - val_loss: 0.4106\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4534 - val_loss: 0.4105\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4529 - val_loss: 0.4104\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4524 - val_loss: 0.4104\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4519 - val_loss: 0.4103\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4514 - val_loss: 0.4102\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4509 - val_loss: 0.4101\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4504 - val_loss: 0.4100\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4499 - val_loss: 0.4099\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4494 - val_loss: 0.4098\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4489 - val_loss: 0.4097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4484 - val_loss: 0.4096\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4479 - val_loss: 0.4096\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4474 - val_loss: 0.4095\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.4470 - val_loss: 0.4094\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4465 - val_loss: 0.4093\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4460 - val_loss: 0.4092\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4456 - val_loss: 0.4091\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4451 - val_loss: 0.4090\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4446 - val_loss: 0.4089\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4442 - val_loss: 0.4089\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4437 - val_loss: 0.4088\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4433 - val_loss: 0.4087\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4429 - val_loss: 0.4086\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4424 - val_loss: 0.4085\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4420 - val_loss: 0.4084\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4415 - val_loss: 0.4083\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4411 - val_loss: 0.4082\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4407 - val_loss: 0.4081\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4402 - val_loss: 0.4080\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4398 - val_loss: 0.4080\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4394 - val_loss: 0.4079\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4390 - val_loss: 0.4078\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=680, result_data[0].shape=(5, 65)\n",
      "Before prediction: train_X.shape=(88, 10, 65), train_y.shape=(88, 65), test_X.shape=(29, 10, 65), test_y.shape=(29, 65)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3740 - val_loss: 0.4249\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3733 - val_loss: 0.4247\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3728 - val_loss: 0.4244\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3722 - val_loss: 0.4242\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3717 - val_loss: 0.4240\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3711 - val_loss: 0.4237\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3706 - val_loss: 0.4235\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3701 - val_loss: 0.4233\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3696 - val_loss: 0.4231\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3691 - val_loss: 0.4228\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3686 - val_loss: 0.4226\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3681 - val_loss: 0.4224\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3676 - val_loss: 0.4222\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3671 - val_loss: 0.4220\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3666 - val_loss: 0.4218\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3662 - val_loss: 0.4216\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3657 - val_loss: 0.4214\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3653 - val_loss: 0.4212\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3648 - val_loss: 0.4210\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3644 - val_loss: 0.4208\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3639 - val_loss: 0.4206\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3635 - val_loss: 0.4204\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3630 - val_loss: 0.4202\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3626 - val_loss: 0.4200\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3622 - val_loss: 0.4199\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3618 - val_loss: 0.4197\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3614 - val_loss: 0.4195\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3610 - val_loss: 0.4193\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3606 - val_loss: 0.4191\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3602 - val_loss: 0.4189\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3598 - val_loss: 0.4187\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3594 - val_loss: 0.4185\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3590 - val_loss: 0.4183\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3586 - val_loss: 0.4182\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3583 - val_loss: 0.4180\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3579 - val_loss: 0.4178\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3575 - val_loss: 0.4176\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3571 - val_loss: 0.4174\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3568 - val_loss: 0.4172\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3564 - val_loss: 0.4171\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=3, result_data[0].shape=(46, 65)\n",
      "Before prediction: train_X.shape=(22, 10, 65), train_y.shape=(22, 65), test_X.shape=(7, 10, 65), test_y.shape=(7, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7392 - val_loss: 0.4033\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7374 - val_loss: 0.4025\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7355 - val_loss: 0.4016\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7337 - val_loss: 0.4008\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7319 - val_loss: 0.3999\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7301 - val_loss: 0.3991\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7284 - val_loss: 0.3982\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7266 - val_loss: 0.3974\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7249 - val_loss: 0.3966\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7232 - val_loss: 0.3958\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7215 - val_loss: 0.3950\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7198 - val_loss: 0.3942\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7181 - val_loss: 0.3934\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7165 - val_loss: 0.3926\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7148 - val_loss: 0.3919\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7132 - val_loss: 0.3911\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7115 - val_loss: 0.3904\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7099 - val_loss: 0.3897\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7084 - val_loss: 0.3890\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7068 - val_loss: 0.3883\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7052 - val_loss: 0.3876\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7037 - val_loss: 0.3869\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7021 - val_loss: 0.3862\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7006 - val_loss: 0.3856\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6991 - val_loss: 0.3849\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6976 - val_loss: 0.3843\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6962 - val_loss: 0.3837\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6947 - val_loss: 0.3831\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6932 - val_loss: 0.3825\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6918 - val_loss: 0.3820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6904 - val_loss: 0.3814\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6890 - val_loss: 0.3809\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6876 - val_loss: 0.3804\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6862 - val_loss: 0.3799\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6848 - val_loss: 0.3794\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6835 - val_loss: 0.3789\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6821 - val_loss: 0.3784\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6808 - val_loss: 0.3779\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6795 - val_loss: 0.3774\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6782 - val_loss: 0.3770\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(9935, 65)\n",
      "Before prediction: train_X.shape=(5955, 10, 65), train_y.shape=(5955, 65), test_X.shape=(1985, 10, 65), test_y.shape=(1985, 65)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0678 - val_loss: 0.0488\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0618 - val_loss: 0.0449\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0584 - val_loss: 0.0423\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0558 - val_loss: 0.0403\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0539 - val_loss: 0.0388\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0524 - val_loss: 0.0375\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0511 - val_loss: 0.0364\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0501 - val_loss: 0.0355\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0492 - val_loss: 0.0347\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0484 - val_loss: 0.0340\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0477 - val_loss: 0.0334\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0471 - val_loss: 0.0328\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0465 - val_loss: 0.0323\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0460 - val_loss: 0.0319\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0456 - val_loss: 0.0315\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0452 - val_loss: 0.0312\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0449 - val_loss: 0.0309\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0445 - val_loss: 0.0306\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0442 - val_loss: 0.0304\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0302\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0437 - val_loss: 0.0300\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0434 - val_loss: 0.0298\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0432 - val_loss: 0.0296\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0430 - val_loss: 0.0295\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0428 - val_loss: 0.0293\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0426 - val_loss: 0.0292\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0424 - val_loss: 0.0290\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0423 - val_loss: 0.0289\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0421 - val_loss: 0.0288\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0420 - val_loss: 0.0287\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0418 - val_loss: 0.0286\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0417 - val_loss: 0.0285\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0416 - val_loss: 0.0284\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0414 - val_loss: 0.0284\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0413 - val_loss: 0.0282\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0412 - val_loss: 0.0282\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0411 - val_loss: 0.0281\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 37ms/step - loss: 0.0410 - val_loss: 0.0280\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0409 - val_loss: 0.0280\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0409 - val_loss: 0.0279\n",
      "63/63 [==============================] - 1s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=39, result_data[0].shape=(206, 65)\n",
      "Before prediction: train_X.shape=(118, 10, 65), train_y.shape=(118, 65), test_X.shape=(39, 10, 65), test_y.shape=(39, 65)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6686 - val_loss: 1.0020\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6675 - val_loss: 1.0014\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6665 - val_loss: 1.0009\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6655 - val_loss: 1.0004\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6645 - val_loss: 0.9999\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6636 - val_loss: 0.9994\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6627 - val_loss: 0.9989\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6618 - val_loss: 0.9984\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6609 - val_loss: 0.9979\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6600 - val_loss: 0.9974\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6592 - val_loss: 0.9969\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6583 - val_loss: 0.9964\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6574 - val_loss: 0.9959\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6566 - val_loss: 0.9954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6558 - val_loss: 0.9949\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6550 - val_loss: 0.9945\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6542 - val_loss: 0.9940\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6534 - val_loss: 0.9935\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6527 - val_loss: 0.9930\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6519 - val_loss: 0.9925\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6512 - val_loss: 0.9921\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6505 - val_loss: 0.9916\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6497 - val_loss: 0.9911\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6490 - val_loss: 0.9907\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6483 - val_loss: 0.9902\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6476 - val_loss: 0.9898\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6469 - val_loss: 0.9894\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6462 - val_loss: 0.9889\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6455 - val_loss: 0.9885\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6449 - val_loss: 0.9880\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6442 - val_loss: 0.9876\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6435 - val_loss: 0.9872\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6428 - val_loss: 0.9867\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6422 - val_loss: 0.9863\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6415 - val_loss: 0.9859\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6409 - val_loss: 0.9855\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6403 - val_loss: 0.9850\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6396 - val_loss: 0.9846\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6390 - val_loss: 0.9842\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6384 - val_loss: 0.9838\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=110, result_data[0].shape=(304, 65)\n",
      "Before prediction: train_X.shape=(176, 10, 65), train_y.shape=(176, 65), test_X.shape=(59, 10, 65), test_y.shape=(59, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6570 - val_loss: 0.6000\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6556 - val_loss: 0.5995\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6543 - val_loss: 0.5990\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6530 - val_loss: 0.5984\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6518 - val_loss: 0.5979\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6506 - val_loss: 0.5974\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6493 - val_loss: 0.5969\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6482 - val_loss: 0.5965\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6470 - val_loss: 0.5960\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6459 - val_loss: 0.5955\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6448 - val_loss: 0.5951\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6437 - val_loss: 0.5946\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6426 - val_loss: 0.5942\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6416 - val_loss: 0.5937\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6405 - val_loss: 0.5933\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6395 - val_loss: 0.5929\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6385 - val_loss: 0.5925\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6376 - val_loss: 0.5921\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6366 - val_loss: 0.5917\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6356 - val_loss: 0.5913\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6347 - val_loss: 0.5909\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6338 - val_loss: 0.5905\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6328 - val_loss: 0.5902\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6320 - val_loss: 0.5898\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6311 - val_loss: 0.5894\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6302 - val_loss: 0.5891\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6293 - val_loss: 0.5888\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6285 - val_loss: 0.5884\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6276 - val_loss: 0.5881\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6268 - val_loss: 0.5878\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6260 - val_loss: 0.5874\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6252 - val_loss: 0.5871\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6243 - val_loss: 0.5868\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6235 - val_loss: 0.5864\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6227 - val_loss: 0.5861\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6219 - val_loss: 0.5858\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6212 - val_loss: 0.5855\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6204 - val_loss: 0.5852\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6196 - val_loss: 0.5849\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6189 - val_loss: 0.5846\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=111, result_data[0].shape=(9, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4024 - val_loss: 0.5121\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4014 - val_loss: 0.5109\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4004 - val_loss: 0.5098\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3994 - val_loss: 0.5087\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3984 - val_loss: 0.5076\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3974 - val_loss: 0.5065\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3965 - val_loss: 0.5054\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3955 - val_loss: 0.5043\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3946 - val_loss: 0.5032\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3936 - val_loss: 0.5021\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3927 - val_loss: 0.5010\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3917 - val_loss: 0.4999\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3908 - val_loss: 0.4989\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3899 - val_loss: 0.4980\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3889 - val_loss: 0.4970\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3880 - val_loss: 0.4961\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3872 - val_loss: 0.4952\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3863 - val_loss: 0.4943\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3855 - val_loss: 0.4935\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3847 - val_loss: 0.4927\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3839 - val_loss: 0.4918\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3830 - val_loss: 0.4910\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3822 - val_loss: 0.4902\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3814 - val_loss: 0.4894\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.4886\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3798 - val_loss: 0.4878\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3789 - val_loss: 0.4870\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3781 - val_loss: 0.4862\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3773 - val_loss: 0.4854\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3765 - val_loss: 0.4847\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3758 - val_loss: 0.4839\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3750 - val_loss: 0.4832\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3742 - val_loss: 0.4825\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3734 - val_loss: 0.4817\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3727 - val_loss: 0.4810\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3719 - val_loss: 0.4802\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3711 - val_loss: 0.4795\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3704 - val_loss: 0.4787\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3697 - val_loss: 0.4780\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3690 - val_loss: 0.4772\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=33, result_data[0].shape=(24, 65)\n",
      "Before prediction: train_X.shape=(8, 10, 65), train_y.shape=(8, 65), test_X.shape=(3, 10, 65), test_y.shape=(3, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4778 - val_loss: 0.4956\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4752 - val_loss: 0.4941\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4726 - val_loss: 0.4927\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4701 - val_loss: 0.4913\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4676 - val_loss: 0.4900\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4651 - val_loss: 0.4886\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4627 - val_loss: 0.4873\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4603 - val_loss: 0.4861\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4579 - val_loss: 0.4848\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4556 - val_loss: 0.4836\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4533 - val_loss: 0.4824\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4510 - val_loss: 0.4812\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4488 - val_loss: 0.4800\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4467 - val_loss: 0.4788\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4445 - val_loss: 0.4776\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4424 - val_loss: 0.4763\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4403 - val_loss: 0.4751\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4382 - val_loss: 0.4739\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4361 - val_loss: 0.4726\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4341 - val_loss: 0.4714\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4321 - val_loss: 0.4702\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4301 - val_loss: 0.4689\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4281 - val_loss: 0.4677\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4262 - val_loss: 0.4664\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4243 - val_loss: 0.4652\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4224 - val_loss: 0.4639\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4206 - val_loss: 0.4626\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4187 - val_loss: 0.4614\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4169 - val_loss: 0.4601\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4151 - val_loss: 0.4589\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4134 - val_loss: 0.4577\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4117 - val_loss: 0.4565\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4100 - val_loss: 0.4553\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4083 - val_loss: 0.4541\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4067 - val_loss: 0.4529\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4051 - val_loss: 0.4517\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4035 - val_loss: 0.4506\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4019 - val_loss: 0.4494\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4003 - val_loss: 0.4483\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3988 - val_loss: 0.4471\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=294, result_data[0].shape=(23, 65)\n",
      "Before prediction: train_X.shape=(8, 10, 65), train_y.shape=(8, 65), test_X.shape=(3, 10, 65), test_y.shape=(3, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3525 - val_loss: 0.4092\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3518 - val_loss: 0.4089\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3511 - val_loss: 0.4087\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3504 - val_loss: 0.4084\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3497 - val_loss: 0.4082\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3490 - val_loss: 0.4079\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3483 - val_loss: 0.4077\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3476 - val_loss: 0.4075\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3469 - val_loss: 0.4072\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3462 - val_loss: 0.4070\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3456 - val_loss: 0.4068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3449 - val_loss: 0.4066\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3443 - val_loss: 0.4064\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3436 - val_loss: 0.4062\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3430 - val_loss: 0.4061\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3423 - val_loss: 0.4059\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3417 - val_loss: 0.4057\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3411 - val_loss: 0.4056\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3405 - val_loss: 0.4054\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3399 - val_loss: 0.4053\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3392 - val_loss: 0.4051\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3386 - val_loss: 0.4050\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3380 - val_loss: 0.4048\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3374 - val_loss: 0.4047\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3369 - val_loss: 0.4046\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3363 - val_loss: 0.4045\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3357 - val_loss: 0.4044\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3351 - val_loss: 0.4043\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3345 - val_loss: 0.4043\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3339 - val_loss: 0.4042\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3334 - val_loss: 0.4041\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3328 - val_loss: 0.4040\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3322 - val_loss: 0.4040\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3317 - val_loss: 0.4039\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3311 - val_loss: 0.4038\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3306 - val_loss: 0.4037\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3301 - val_loss: 0.4036\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3295 - val_loss: 0.4035\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3290 - val_loss: 0.4035\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3284 - val_loss: 0.4034\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=152, result_data[0].shape=(21, 65)\n",
      "Before prediction: train_X.shape=(7, 10, 65), train_y.shape=(7, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4174 - val_loss: 0.3669\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4166 - val_loss: 0.3667\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4158 - val_loss: 0.3664\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4150 - val_loss: 0.3662\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4142 - val_loss: 0.3659\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4135 - val_loss: 0.3657\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4127 - val_loss: 0.3655\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4120 - val_loss: 0.3652\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4113 - val_loss: 0.3650\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4106 - val_loss: 0.3647\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4099 - val_loss: 0.3645\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4092 - val_loss: 0.3643\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4085 - val_loss: 0.3640\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4077 - val_loss: 0.3638\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4070 - val_loss: 0.3636\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4063 - val_loss: 0.3634\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4056 - val_loss: 0.3631\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4050 - val_loss: 0.3629\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4043 - val_loss: 0.3627\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4036 - val_loss: 0.3625\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4029 - val_loss: 0.3623\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4023 - val_loss: 0.3621\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4016 - val_loss: 0.3619\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4010 - val_loss: 0.3617\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4004 - val_loss: 0.3616\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3997 - val_loss: 0.3614\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3991 - val_loss: 0.3612\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3985 - val_loss: 0.3611\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3979 - val_loss: 0.3609\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3972 - val_loss: 0.3608\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3966 - val_loss: 0.3606\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3960 - val_loss: 0.3604\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3954 - val_loss: 0.3603\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3948 - val_loss: 0.3602\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3942 - val_loss: 0.3601\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3936 - val_loss: 0.3600\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3930 - val_loss: 0.3599\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3924 - val_loss: 0.3598\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3918 - val_loss: 0.3597\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3912 - val_loss: 0.3596\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=578, result_data[0].shape=(10, 65)\n",
      "Before prediction: train_X.shape=(5, 10, 65), train_y.shape=(5, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9361 - val_loss: 9.0621\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9332 - val_loss: 9.0617\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9304 - val_loss: 9.0613\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9277 - val_loss: 9.0608\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9249 - val_loss: 9.0604\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9223 - val_loss: 9.0600\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9197 - val_loss: 9.0595\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9171 - val_loss: 9.0591\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9146 - val_loss: 9.0587\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9121 - val_loss: 9.0583\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9096 - val_loss: 9.0578\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9072 - val_loss: 9.0574\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9048 - val_loss: 9.0570\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9024 - val_loss: 9.0566\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9000 - val_loss: 9.0563\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8977 - val_loss: 9.0559\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8954 - val_loss: 9.0556\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8931 - val_loss: 9.0552\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8909 - val_loss: 9.0549\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8886 - val_loss: 9.0545\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8864 - val_loss: 9.0542\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8843 - val_loss: 9.0539\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8821 - val_loss: 9.0535\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8800 - val_loss: 9.0532\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8780 - val_loss: 9.0529\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8760 - val_loss: 9.0526\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8741 - val_loss: 9.0523\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8723 - val_loss: 9.0520\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8704 - val_loss: 9.0517\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8686 - val_loss: 9.0514\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8668 - val_loss: 9.0512\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8650 - val_loss: 9.0509\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8633 - val_loss: 9.0507\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8616 - val_loss: 9.0505\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8598 - val_loss: 9.0503\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8581 - val_loss: 9.0502\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8564 - val_loss: 9.0501\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8547 - val_loss: 9.0500\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8530 - val_loss: 9.0499\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8513 - val_loss: 9.0498\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "dataset_windows.shape=(326467, 10, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=304, result_data[0].shape=(11, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=25, result_data[0].shape=(75, 65)\n",
      "Before prediction: train_X.shape=(39, 10, 65), train_y.shape=(39, 65), test_X.shape=(13, 10, 65), test_y.shape=(13, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5248 - val_loss: 0.5038\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5230 - val_loss: 0.5026\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5212 - val_loss: 0.5014\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5194 - val_loss: 0.5002\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5176 - val_loss: 0.4990\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5159 - val_loss: 0.4978\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5141 - val_loss: 0.4966\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5124 - val_loss: 0.4955\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5107 - val_loss: 0.4943\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5090 - val_loss: 0.4932\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5073 - val_loss: 0.4920\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5057 - val_loss: 0.4909\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5041 - val_loss: 0.4898\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5025 - val_loss: 0.4887\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5009 - val_loss: 0.4876\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4993 - val_loss: 0.4865\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4978 - val_loss: 0.4855\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4962 - val_loss: 0.4844\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4947 - val_loss: 0.4834\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4932 - val_loss: 0.4824\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.4814\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4903 - val_loss: 0.4805\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4888 - val_loss: 0.4795\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4874 - val_loss: 0.4786\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4860 - val_loss: 0.4777\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4846 - val_loss: 0.4768\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4759\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4819 - val_loss: 0.4750\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4805 - val_loss: 0.4741\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4792 - val_loss: 0.4733\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4779 - val_loss: 0.4724\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4766 - val_loss: 0.4716\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4753 - val_loss: 0.4708\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4741 - val_loss: 0.4700\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4728 - val_loss: 0.4692\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4716 - val_loss: 0.4684\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4704 - val_loss: 0.4676\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4692 - val_loss: 0.4668\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4680 - val_loss: 0.4660\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4668 - val_loss: 0.4653\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=101, result_data[0].shape=(150, 65)\n",
      "Before prediction: train_X.shape=(84, 10, 65), train_y.shape=(84, 65), test_X.shape=(28, 10, 65), test_y.shape=(28, 65)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4038 - val_loss: 0.5022\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4029 - val_loss: 0.5016\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4020 - val_loss: 0.5009\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4011 - val_loss: 0.5003\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4002 - val_loss: 0.4997\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3994 - val_loss: 0.4991\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3985 - val_loss: 0.4985\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3977 - val_loss: 0.4980\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3969 - val_loss: 0.4974\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3962 - val_loss: 0.4968\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3954 - val_loss: 0.4963\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3947 - val_loss: 0.4958\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3939 - val_loss: 0.4952\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3932 - val_loss: 0.4947\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3925 - val_loss: 0.4943\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3919 - val_loss: 0.4938\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3912 - val_loss: 0.4933\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3906 - val_loss: 0.4928\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.3899 - val_loss: 0.4923\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.3893 - val_loss: 0.4919\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3887 - val_loss: 0.4914\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3881 - val_loss: 0.4910\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3875 - val_loss: 0.4905\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3869 - val_loss: 0.4901\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3863 - val_loss: 0.4897\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3858 - val_loss: 0.4893\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3852 - val_loss: 0.4889\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3847 - val_loss: 0.4885\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3842 - val_loss: 0.4881\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3836 - val_loss: 0.4877\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3831 - val_loss: 0.4874\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3826 - val_loss: 0.4870\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3821 - val_loss: 0.4866\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3817 - val_loss: 0.4863\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3812 - val_loss: 0.4860\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3807 - val_loss: 0.4856\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3802 - val_loss: 0.4853\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3798 - val_loss: 0.4850\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3793 - val_loss: 0.4847\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3788 - val_loss: 0.4844\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=42, result_data[0].shape=(308, 65)\n",
      "Before prediction: train_X.shape=(179, 10, 65), train_y.shape=(179, 65), test_X.shape=(60, 10, 65), test_y.shape=(60, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7071 - val_loss: 0.5612\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7058 - val_loss: 0.5604\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7044 - val_loss: 0.5596\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7031 - val_loss: 0.5589\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7019 - val_loss: 0.5582\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7006 - val_loss: 0.5575\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6994 - val_loss: 0.5568\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6982 - val_loss: 0.5561\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6970 - val_loss: 0.5554\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6958 - val_loss: 0.5547\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6947 - val_loss: 0.5541\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6935 - val_loss: 0.5534\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6924 - val_loss: 0.5528\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6913 - val_loss: 0.5522\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6903 - val_loss: 0.5516\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6892 - val_loss: 0.5510\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6882 - val_loss: 0.5504\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6872 - val_loss: 0.5499\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6861 - val_loss: 0.5493\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6852 - val_loss: 0.5488\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6842 - val_loss: 0.5482\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6832 - val_loss: 0.5477\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6823 - val_loss: 0.5472\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6813 - val_loss: 0.5467\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6804 - val_loss: 0.5462\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6795 - val_loss: 0.5458\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6786 - val_loss: 0.5453\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.6777 - val_loss: 0.5448\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6768 - val_loss: 0.5444\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6760 - val_loss: 0.5439\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6751 - val_loss: 0.5435\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6742 - val_loss: 0.5430\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6734 - val_loss: 0.5426\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6726 - val_loss: 0.5421\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6717 - val_loss: 0.5417\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6709 - val_loss: 0.5412\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6701 - val_loss: 0.5408\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6693 - val_loss: 0.5404\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6685 - val_loss: 0.5399\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6677 - val_loss: 0.5395\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=412, result_data[0].shape=(16, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6508 - val_loss: 0.4240\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6479 - val_loss: 0.4223\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6451 - val_loss: 0.4205\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6422 - val_loss: 0.4188\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6395 - val_loss: 0.4170\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6368 - val_loss: 0.4152\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6341 - val_loss: 0.4135\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6314 - val_loss: 0.4117\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6287 - val_loss: 0.4100\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6261 - val_loss: 0.4082\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6235 - val_loss: 0.4065\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6210 - val_loss: 0.4047\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6185 - val_loss: 0.4030\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6160 - val_loss: 0.4013\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6136 - val_loss: 0.3997\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6112 - val_loss: 0.3981\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6087 - val_loss: 0.3964\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6064 - val_loss: 0.3948\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6040 - val_loss: 0.3932\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6016 - val_loss: 0.3916\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5992 - val_loss: 0.3901\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5968 - val_loss: 0.3885\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5944 - val_loss: 0.3869\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5920 - val_loss: 0.3854\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5896 - val_loss: 0.3839\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5873 - val_loss: 0.3823\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5849 - val_loss: 0.3808\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5827 - val_loss: 0.3792\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5804 - val_loss: 0.3778\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5781 - val_loss: 0.3765\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5759 - val_loss: 0.3753\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5738 - val_loss: 0.3740\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5717 - val_loss: 0.3728\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5696 - val_loss: 0.3715\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5676 - val_loss: 0.3703\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5656 - val_loss: 0.3691\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5636 - val_loss: 0.3678\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5618 - val_loss: 0.3666\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5599 - val_loss: 0.3653\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5581 - val_loss: 0.3641\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=186, result_data[0].shape=(263, 65)\n",
      "Before prediction: train_X.shape=(152, 10, 65), train_y.shape=(152, 65), test_X.shape=(51, 10, 65), test_y.shape=(51, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.3775 - val_loss: 0.3155\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3765 - val_loss: 0.3148\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.3756 - val_loss: 0.3141\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3746 - val_loss: 0.3134\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.3738 - val_loss: 0.3128\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3729 - val_loss: 0.3122\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3720 - val_loss: 0.3115\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3712 - val_loss: 0.3110\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3704 - val_loss: 0.3104\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3695 - val_loss: 0.3098\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3687 - val_loss: 0.3093\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3679 - val_loss: 0.3087\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3671 - val_loss: 0.3082\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3664 - val_loss: 0.3077\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3656 - val_loss: 0.3071\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3649 - val_loss: 0.3066\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3641 - val_loss: 0.3061\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3634 - val_loss: 0.3057\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3627 - val_loss: 0.3052\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3620 - val_loss: 0.3047\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3613 - val_loss: 0.3042\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3606 - val_loss: 0.3037\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3599 - val_loss: 0.3032\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3592 - val_loss: 0.3028\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3586 - val_loss: 0.3023\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3579 - val_loss: 0.3019\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3572 - val_loss: 0.3014\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3566 - val_loss: 0.3010\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3560 - val_loss: 0.3006\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3554 - val_loss: 0.3001\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3547 - val_loss: 0.2997\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3541 - val_loss: 0.2993\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3535 - val_loss: 0.2989\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3529 - val_loss: 0.2985\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3523 - val_loss: 0.2981\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3517 - val_loss: 0.2977\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3512 - val_loss: 0.2973\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3506 - val_loss: 0.2969\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3500 - val_loss: 0.2965\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3495 - val_loss: 0.2961\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=9, result_data[0].shape=(9940, 65)\n",
      "Before prediction: train_X.shape=(5958, 10, 65), train_y.shape=(5958, 65), test_X.shape=(1986, 10, 65), test_y.shape=(1986, 65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0698 - val_loss: 0.0478\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0640 - val_loss: 0.0446\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0606 - val_loss: 0.0423\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0580 - val_loss: 0.0405\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0560 - val_loss: 0.0389\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0544 - val_loss: 0.0376\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0530 - val_loss: 0.0365\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0519 - val_loss: 0.0356\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0509 - val_loss: 0.0347\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0501 - val_loss: 0.0340\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0494 - val_loss: 0.0333\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0488 - val_loss: 0.0328\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0482 - val_loss: 0.0323\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0477 - val_loss: 0.0319\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0472 - val_loss: 0.0315\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0468 - val_loss: 0.0311\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0465 - val_loss: 0.0308\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0461 - val_loss: 0.0306\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0458 - val_loss: 0.0304\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0454 - val_loss: 0.0301\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0300\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0449 - val_loss: 0.0298\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0446 - val_loss: 0.0296\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0444 - val_loss: 0.0295\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0442 - val_loss: 0.0293\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 37ms/step - loss: 0.0440 - val_loss: 0.0291\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0438 - val_loss: 0.0290\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0436 - val_loss: 0.0288\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0435 - val_loss: 0.0287\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0433 - val_loss: 0.0286\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0432 - val_loss: 0.0285\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0431 - val_loss: 0.0283\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0430 - val_loss: 0.0282\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0428 - val_loss: 0.0281\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0427 - val_loss: 0.0281\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0280\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0425 - val_loss: 0.0279\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0424 - val_loss: 0.0278\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0424 - val_loss: 0.0277\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0423 - val_loss: 0.0277\n",
      "63/63 [==============================] - 1s 13ms/step\n",
      "dataset_windows.shape=(326467, 10, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=112, result_data[0].shape=(22, 65)\n",
      "Before prediction: train_X.shape=(7, 10, 65), train_y.shape=(7, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3857 - val_loss: 0.3587\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3850 - val_loss: 0.3587\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3844 - val_loss: 0.3586\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3837 - val_loss: 0.3586\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3830 - val_loss: 0.3585\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3824 - val_loss: 0.3585\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3817 - val_loss: 0.3585\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3810 - val_loss: 0.3584\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3804 - val_loss: 0.3584\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3798 - val_loss: 0.3584\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3791 - val_loss: 0.3584\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3785 - val_loss: 0.3583\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3779 - val_loss: 0.3583\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3773 - val_loss: 0.3583\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3766 - val_loss: 0.3583\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3760 - val_loss: 0.3582\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3754 - val_loss: 0.3582\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3748 - val_loss: 0.3582\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3742 - val_loss: 0.3581\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3736 - val_loss: 0.3581\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3730 - val_loss: 0.3580\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3725 - val_loss: 0.3580\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3719 - val_loss: 0.3579\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3713 - val_loss: 0.3579\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3708 - val_loss: 0.3578\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3702 - val_loss: 0.3578\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3696 - val_loss: 0.3577\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3691 - val_loss: 0.3577\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3686 - val_loss: 0.3576\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3680 - val_loss: 0.3576\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3675 - val_loss: 0.3575\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3669 - val_loss: 0.3575\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3664 - val_loss: 0.3574\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3658 - val_loss: 0.3573\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3653 - val_loss: 0.3573\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3647 - val_loss: 0.3572\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3642 - val_loss: 0.3571\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3636 - val_loss: 0.3571\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3631 - val_loss: 0.3570\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3625 - val_loss: 0.3569\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=452, result_data[0].shape=(16, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5448 - val_loss: 0.3635\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5419 - val_loss: 0.3618\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5391 - val_loss: 0.3602\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5364 - val_loss: 0.3586\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5336 - val_loss: 0.3570\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5309 - val_loss: 0.3555\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5282 - val_loss: 0.3540\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5254 - val_loss: 0.3526\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5227 - val_loss: 0.3512\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5201 - val_loss: 0.3498\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5174 - val_loss: 0.3484\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5148 - val_loss: 0.3471\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5122 - val_loss: 0.3457\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5098 - val_loss: 0.3444\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5074 - val_loss: 0.3431\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5050 - val_loss: 0.3418\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5027 - val_loss: 0.3405\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5003 - val_loss: 0.3392\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4980 - val_loss: 0.3380\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4958 - val_loss: 0.3368\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4935 - val_loss: 0.3356\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4913 - val_loss: 0.3344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4892 - val_loss: 0.3333\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4870 - val_loss: 0.3327\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4849 - val_loss: 0.3322\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4827 - val_loss: 0.3316\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4806 - val_loss: 0.3311\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4785 - val_loss: 0.3305\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4765 - val_loss: 0.3303\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4744 - val_loss: 0.3300\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4724 - val_loss: 0.3298\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4703 - val_loss: 0.3296\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4683 - val_loss: 0.3294\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4663 - val_loss: 0.3292\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4644 - val_loss: 0.3292\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4625 - val_loss: 0.3292\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4605Restoring model weights from the end of the best epoch: 35.\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4605 - val_loss: 0.3294\n",
      "Epoch 37: early stopping\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(3251, 65)\n",
      "Before prediction: train_X.shape=(1945, 10, 65), train_y.shape=(1945, 65), test_X.shape=(648, 10, 65), test_y.shape=(648, 65)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1183 - val_loss: 0.0916\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.1131 - val_loss: 0.0899\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.1088 - val_loss: 0.0886\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1052 - val_loss: 0.0877\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1020 - val_loss: 0.0870\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0993 - val_loss: 0.0865\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0968 - val_loss: 0.0861\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0946 - val_loss: 0.0858\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0925 - val_loss: 0.0854\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0907 - val_loss: 0.0851\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0890 - val_loss: 0.0849\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0874 - val_loss: 0.0847\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0860 - val_loss: 0.0845\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0847 - val_loss: 0.0843\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0835 - val_loss: 0.0841\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0823 - val_loss: 0.0840\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0813 - val_loss: 0.0838\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0803 - val_loss: 0.0837\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0794 - val_loss: 0.0836\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0786 - val_loss: 0.0834\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0778 - val_loss: 0.0833\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0770 - val_loss: 0.0833\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0763 - val_loss: 0.0832\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0757 - val_loss: 0.0831\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0750 - val_loss: 0.0830\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0745 - val_loss: 0.0830\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0739 - val_loss: 0.0829\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0734 - val_loss: 0.0828\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0729 - val_loss: 0.0828\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0725 - val_loss: 0.0827\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0720 - val_loss: 0.0827\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0716 - val_loss: 0.0826\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0712 - val_loss: 0.0825\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0709 - val_loss: 0.0824\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0705 - val_loss: 0.0824\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0702 - val_loss: 0.0823\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0699 - val_loss: 0.0822\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0696 - val_loss: 0.0822\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0693 - val_loss: 0.0821\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0691 - val_loss: 0.0821\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=176, result_data[0].shape=(262, 65)\n",
      "Before prediction: train_X.shape=(151, 10, 65), train_y.shape=(151, 65), test_X.shape=(50, 10, 65), test_y.shape=(50, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3518 - val_loss: 0.2928\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3508 - val_loss: 0.2922\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3499 - val_loss: 0.2916\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3491 - val_loss: 0.2910\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3482 - val_loss: 0.2904\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3474 - val_loss: 0.2898\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3466 - val_loss: 0.2892\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.3458 - val_loss: 0.2886\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3450 - val_loss: 0.2881\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.3442 - val_loss: 0.2875\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.3435 - val_loss: 0.2870\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.3427 - val_loss: 0.2865\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.3420 - val_loss: 0.2859\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.3413 - val_loss: 0.2854\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3406 - val_loss: 0.2849\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.3399 - val_loss: 0.2844\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.3392 - val_loss: 0.2839\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3385 - val_loss: 0.2834\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3379 - val_loss: 0.2829\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3373 - val_loss: 0.2825\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3366 - val_loss: 0.2820\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3360 - val_loss: 0.2815\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3354 - val_loss: 0.2811\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3348 - val_loss: 0.2807\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3342 - val_loss: 0.2802\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3336 - val_loss: 0.2798\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3330 - val_loss: 0.2793\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3324 - val_loss: 0.2789\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3318 - val_loss: 0.2785\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3313 - val_loss: 0.2780\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3307 - val_loss: 0.2776\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3301 - val_loss: 0.2772\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3296 - val_loss: 0.2768\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3290 - val_loss: 0.2764\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3285 - val_loss: 0.2760\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3279 - val_loss: 0.2756\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3274 - val_loss: 0.2752\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3269 - val_loss: 0.2748\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3264 - val_loss: 0.2744\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3259 - val_loss: 0.2740\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=356, result_data[0].shape=(11, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=25, result_data[0].shape=(75, 65)\n",
      "Before prediction: train_X.shape=(39, 10, 65), train_y.shape=(39, 65), test_X.shape=(13, 10, 65), test_y.shape=(13, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5340 - val_loss: 0.5004\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5322 - val_loss: 0.4995\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5303 - val_loss: 0.4986\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5284 - val_loss: 0.4977\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5266 - val_loss: 0.4968\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5248 - val_loss: 0.4959\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5230 - val_loss: 0.4950\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5212 - val_loss: 0.4941\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5195 - val_loss: 0.4932\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5178 - val_loss: 0.4924\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5160 - val_loss: 0.4916\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5144 - val_loss: 0.4907\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5127 - val_loss: 0.4899\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5110 - val_loss: 0.4891\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5094 - val_loss: 0.4883\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5078 - val_loss: 0.4875\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5062 - val_loss: 0.4867\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5047 - val_loss: 0.4859\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5032 - val_loss: 0.4851\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5017 - val_loss: 0.4843\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5002 - val_loss: 0.4835\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4987 - val_loss: 0.4828\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4973 - val_loss: 0.4820\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4958 - val_loss: 0.4812\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4944 - val_loss: 0.4805\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4930 - val_loss: 0.4797\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4916 - val_loss: 0.4789\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4902 - val_loss: 0.4782\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4889 - val_loss: 0.4774\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4875 - val_loss: 0.4766\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4862 - val_loss: 0.4759\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4848 - val_loss: 0.4751\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4835 - val_loss: 0.4743\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4822 - val_loss: 0.4736\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4809 - val_loss: 0.4728\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4796 - val_loss: 0.4720\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4784 - val_loss: 0.4713\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4771 - val_loss: 0.4705\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4758 - val_loss: 0.4698\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4746 - val_loss: 0.4690\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=80, result_data[0].shape=(312, 65)\n",
      "Before prediction: train_X.shape=(181, 10, 65), train_y.shape=(181, 65), test_X.shape=(60, 10, 65), test_y.shape=(60, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5718 - val_loss: 0.5100\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5704 - val_loss: 0.5094\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5691 - val_loss: 0.5089\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5678 - val_loss: 0.5083\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5666 - val_loss: 0.5078\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5654 - val_loss: 0.5073\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5642 - val_loss: 0.5068\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5630 - val_loss: 0.5063\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5619 - val_loss: 0.5058\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5608 - val_loss: 0.5053\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5597 - val_loss: 0.5048\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5587 - val_loss: 0.5044\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5576 - val_loss: 0.5039\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5566 - val_loss: 0.5035\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5556 - val_loss: 0.5030\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5546 - val_loss: 0.5026\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5536 - val_loss: 0.5022\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5527 - val_loss: 0.5017\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5518 - val_loss: 0.5013\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5508 - val_loss: 0.5009\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5499 - val_loss: 0.5005\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5490 - val_loss: 0.5001\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5481 - val_loss: 0.4997\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5472 - val_loss: 0.4993\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5463 - val_loss: 0.4989\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5454 - val_loss: 0.4985\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5446 - val_loss: 0.4980\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5437 - val_loss: 0.4976\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5429 - val_loss: 0.4973\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5420 - val_loss: 0.4969\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5412 - val_loss: 0.4965\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5403 - val_loss: 0.4961\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5395 - val_loss: 0.4957\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5387 - val_loss: 0.4953\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5379 - val_loss: 0.4949\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.5371 - val_loss: 0.4946\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.5363 - val_loss: 0.4942\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5355 - val_loss: 0.4938\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.5347 - val_loss: 0.4935\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.5339 - val_loss: 0.4931\n",
      "2/2 [==============================] - 0s 24ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=28, result_data[0].shape=(207, 65)\n",
      "Before prediction: train_X.shape=(118, 10, 65), train_y.shape=(118, 65), test_X.shape=(39, 10, 65), test_y.shape=(39, 65)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6383 - val_loss: 0.9363\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6374 - val_loss: 0.9359\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6364 - val_loss: 0.9354\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6355 - val_loss: 0.9350\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6346 - val_loss: 0.9346\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6337 - val_loss: 0.9341\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6329 - val_loss: 0.9337\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6320 - val_loss: 0.9332\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6311 - val_loss: 0.9328\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6303 - val_loss: 0.9324\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6295 - val_loss: 0.9320\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6287 - val_loss: 0.9315\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6279 - val_loss: 0.9311\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6271 - val_loss: 0.9307\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6263 - val_loss: 0.9303\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6256 - val_loss: 0.9299\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6248 - val_loss: 0.9294\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6241 - val_loss: 0.9290\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6233 - val_loss: 0.9286\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6226 - val_loss: 0.9282\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6219 - val_loss: 0.9278\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6211 - val_loss: 0.9274\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6204 - val_loss: 0.9270\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6197 - val_loss: 0.9266\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6190 - val_loss: 0.9262\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6183 - val_loss: 0.9258\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6177 - val_loss: 0.9254\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6170 - val_loss: 0.9250\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6163 - val_loss: 0.9246\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6156 - val_loss: 0.9242\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6149 - val_loss: 0.9238\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6143 - val_loss: 0.9234\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6136 - val_loss: 0.9231\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6129 - val_loss: 0.9227\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6123 - val_loss: 0.9223\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6116 - val_loss: 0.9220\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6110 - val_loss: 0.9216\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6104 - val_loss: 0.9213\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6097 - val_loss: 0.9209\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.6091 - val_loss: 0.9206\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=1, result_data[0].shape=(2622, 65)\n",
      "Before prediction: train_X.shape=(1567, 10, 65), train_y.shape=(1567, 65), test_X.shape=(522, 10, 65), test_y.shape=(522, 65)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2457 - val_loss: 0.2877\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2346 - val_loss: 0.2770\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2262 - val_loss: 0.2685\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2196 - val_loss: 0.2618\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2144 - val_loss: 0.2562\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2100 - val_loss: 0.2512\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.2061 - val_loss: 0.2468\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.2026 - val_loss: 0.2427\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1994 - val_loss: 0.2391\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1964 - val_loss: 0.2357\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1936 - val_loss: 0.2324\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1909 - val_loss: 0.2295\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.1884 - val_loss: 0.2267\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1861 - val_loss: 0.2241\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1838 - val_loss: 0.2216\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1818 - val_loss: 0.2194\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1798 - val_loss: 0.2173\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1781 - val_loss: 0.2155\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1765 - val_loss: 0.2138\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1750 - val_loss: 0.2122\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1737 - val_loss: 0.2107\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1725 - val_loss: 0.2093\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1713 - val_loss: 0.2080\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1703 - val_loss: 0.2067\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1692 - val_loss: 0.2055\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.1683 - val_loss: 0.2044\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.1673 - val_loss: 0.2033\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.1664 - val_loss: 0.2023\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1656 - val_loss: 0.2013\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1648 - val_loss: 0.2003\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1640 - val_loss: 0.1995\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1633 - val_loss: 0.1986\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1626 - val_loss: 0.1978\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.1619 - val_loss: 0.1970\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1613 - val_loss: 0.1963\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1607 - val_loss: 0.1955\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1601 - val_loss: 0.1948\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1596 - val_loss: 0.1942\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.1590 - val_loss: 0.1935\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1585 - val_loss: 0.1930\n",
      "17/17 [==============================] - 0s 13ms/step\n",
      "dataset_windows.shape=(326467, 10, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=285, result_data[0].shape=(10, 65)\n",
      "Before prediction: train_X.shape=(17, 10, 65), train_y.shape=(17, 65), test_X.shape=(6, 10, 65), test_y.shape=(6, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3585 - val_loss: 0.4217\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3579 - val_loss: 0.4216\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3573 - val_loss: 0.4215\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3567 - val_loss: 0.4214\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3562 - val_loss: 0.4214\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3556 - val_loss: 0.4213\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3551 - val_loss: 0.4212\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3545 - val_loss: 0.4212\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3540 - val_loss: 0.4211\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3535 - val_loss: 0.4211\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3530 - val_loss: 0.4210\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3525 - val_loss: 0.4209\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3521 - val_loss: 0.4209\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3516 - val_loss: 0.4208\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3511 - val_loss: 0.4208\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3507 - val_loss: 0.4207\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3502 - val_loss: 0.4207\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3498 - val_loss: 0.4206\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3493 - val_loss: 0.4206\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3489 - val_loss: 0.4206\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3484 - val_loss: 0.4205\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3480 - val_loss: 0.4205\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3475 - val_loss: 0.4204\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3471 - val_loss: 0.4204\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3467 - val_loss: 0.4204\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3463 - val_loss: 0.4203\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3459 - val_loss: 0.4203\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3455 - val_loss: 0.4203\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3451 - val_loss: 0.4202\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3447 - val_loss: 0.4202\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3443 - val_loss: 0.4202\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3439 - val_loss: 0.4201\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3435 - val_loss: 0.4201\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3431 - val_loss: 0.4201\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3427 - val_loss: 0.4200\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3423 - val_loss: 0.4200\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3419 - val_loss: 0.4200\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3416 - val_loss: 0.4200\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3412 - val_loss: 0.4200\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3408 - val_loss: 0.4199\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=96, result_data[0].shape=(113, 65)\n",
      "Before prediction: train_X.shape=(62, 10, 65), train_y.shape=(62, 65), test_X.shape=(21, 10, 65), test_y.shape=(21, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3842 - val_loss: 0.4250\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3838 - val_loss: 0.4249\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3833 - val_loss: 0.4249\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3829 - val_loss: 0.4248\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3824 - val_loss: 0.4247\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3820 - val_loss: 0.4246\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3816 - val_loss: 0.4245\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3811 - val_loss: 0.4245\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3807 - val_loss: 0.4244\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3803 - val_loss: 0.4243\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3799 - val_loss: 0.4242\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3795 - val_loss: 0.4242\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3791 - val_loss: 0.4241\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3787 - val_loss: 0.4240\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3783 - val_loss: 0.4240\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3779 - val_loss: 0.4239\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3775 - val_loss: 0.4238\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3771 - val_loss: 0.4238\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3767 - val_loss: 0.4237\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3764 - val_loss: 0.4237\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3760 - val_loss: 0.4236\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3756 - val_loss: 0.4236\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3753 - val_loss: 0.4235\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3749 - val_loss: 0.4234\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3746 - val_loss: 0.4234\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3742 - val_loss: 0.4233\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3739 - val_loss: 0.4233\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3736 - val_loss: 0.4232\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3732 - val_loss: 0.4232\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3729 - val_loss: 0.4231\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3726 - val_loss: 0.4230\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3722 - val_loss: 0.4230\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3719 - val_loss: 0.4229\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3716 - val_loss: 0.4229\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3713 - val_loss: 0.4228\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3710 - val_loss: 0.4227\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3707 - val_loss: 0.4227\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3704 - val_loss: 0.4226\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3700 - val_loss: 0.4226\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3697 - val_loss: 0.4225\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=23, result_data[0].shape=(34, 65)\n",
      "Before prediction: train_X.shape=(14, 10, 65), train_y.shape=(14, 65), test_X.shape=(5, 10, 65), test_y.shape=(5, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4114 - val_loss: 0.4880\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4107 - val_loss: 0.4880\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4101 - val_loss: 0.4879\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4095 - val_loss: 0.4879\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4090 - val_loss: 0.4878\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4084 - val_loss: 0.4878\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4078 - val_loss: 0.4877\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4072 - val_loss: 0.4877\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4067 - val_loss: 0.4877\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4061 - val_loss: 0.4876\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4056 - val_loss: 0.4875\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4050 - val_loss: 0.4875\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4045 - val_loss: 0.4874\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4039 - val_loss: 0.4874\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4034 - val_loss: 0.4873\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4029 - val_loss: 0.4872\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4023 - val_loss: 0.4872\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4018 - val_loss: 0.4871\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4013 - val_loss: 0.4871\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4008 - val_loss: 0.4870\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4003 - val_loss: 0.4869\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3998 - val_loss: 0.4869\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3993 - val_loss: 0.4868\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3988 - val_loss: 0.4868\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3984 - val_loss: 0.4867\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3979 - val_loss: 0.4866\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3974 - val_loss: 0.4866\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3970 - val_loss: 0.4865\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3965 - val_loss: 0.4865\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.4864\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3956 - val_loss: 0.4864\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3952 - val_loss: 0.4863\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3948 - val_loss: 0.4862\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3943 - val_loss: 0.4862\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3939 - val_loss: 0.4861\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3935 - val_loss: 0.4860\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3930 - val_loss: 0.4860\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3926 - val_loss: 0.4859\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3922 - val_loss: 0.4858\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3918 - val_loss: 0.4858\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=137, result_data[0].shape=(158, 65)\n",
      "Before prediction: train_X.shape=(89, 10, 65), train_y.shape=(89, 65), test_X.shape=(30, 10, 65), test_y.shape=(30, 65)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.3434 - val_loss: 0.3410\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3427 - val_loss: 0.3407\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3420 - val_loss: 0.3403\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3413 - val_loss: 0.3399\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3407 - val_loss: 0.3396\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3401 - val_loss: 0.3392\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3394 - val_loss: 0.3389\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3388 - val_loss: 0.3385\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3382 - val_loss: 0.3382\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3376 - val_loss: 0.3379\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.3370 - val_loss: 0.3376\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3365 - val_loss: 0.3373\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3359 - val_loss: 0.3370\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3353 - val_loss: 0.3367\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3348 - val_loss: 0.3364\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3342 - val_loss: 0.3361\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3337 - val_loss: 0.3358\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3331 - val_loss: 0.3355\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3326 - val_loss: 0.3352\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3321 - val_loss: 0.3349\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3316 - val_loss: 0.3346\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3311 - val_loss: 0.3344\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3306 - val_loss: 0.3341\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3301 - val_loss: 0.3338\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3296 - val_loss: 0.3335\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3291 - val_loss: 0.3333\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3287 - val_loss: 0.3330\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3282 - val_loss: 0.3328\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3277 - val_loss: 0.3325\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3273 - val_loss: 0.3323\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3269 - val_loss: 0.3321\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3264 - val_loss: 0.3318\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3260 - val_loss: 0.3316\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3256 - val_loss: 0.3313\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3252 - val_loss: 0.3311\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3247 - val_loss: 0.3309\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3243 - val_loss: 0.3307\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3239 - val_loss: 0.3305\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3235 - val_loss: 0.3303\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3231 - val_loss: 0.3300\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=113, result_data[0].shape=(11, 65)\n",
      "Before prediction: train_X.shape=(1, 10, 65), train_y.shape=(1, 65), test_X.shape=(0, 10, 65), test_y.shape=(0, 65)\n",
      "FAIL - test_X.shape=(0, 10, 65), valid_X.shape=(0, 10, 65), train_X.shape=(1, 10, 65)\n",
      "In transform\n",
      " -> in transform: len(result_data)=1, result_data[0].shape=(2622, 65)\n",
      "Before prediction: train_X.shape=(1567, 10, 65), train_y.shape=(1567, 65), test_X.shape=(522, 10, 65), test_y.shape=(522, 65)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2417 - val_loss: 0.2817\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.2318 - val_loss: 0.2718\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.2242 - val_loss: 0.2641\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2183 - val_loss: 0.2578\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2133 - val_loss: 0.2525\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2091 - val_loss: 0.2479\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2053 - val_loss: 0.2438\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.2020 - val_loss: 0.2400\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1989 - val_loss: 0.2366\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.1960 - val_loss: 0.2335\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.1933 - val_loss: 0.2305\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1908 - val_loss: 0.2277\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1884 - val_loss: 0.2251\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1861 - val_loss: 0.2227\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1839 - val_loss: 0.2204\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1819 - val_loss: 0.2183\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.1801 - val_loss: 0.2163\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1784 - val_loss: 0.2145\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1768 - val_loss: 0.2129\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1754 - val_loss: 0.2113\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1741 - val_loss: 0.2098\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1728 - val_loss: 0.2085\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1717 - val_loss: 0.2072\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.1706 - val_loss: 0.2060\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1696 - val_loss: 0.2048\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1686 - val_loss: 0.2038\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1677 - val_loss: 0.2027\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1668 - val_loss: 0.2017\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1660 - val_loss: 0.2008\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.1652 - val_loss: 0.1999\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.1644 - val_loss: 0.1990\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1637 - val_loss: 0.1982\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1630 - val_loss: 0.1974\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1623 - val_loss: 0.1966\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1617 - val_loss: 0.1959\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1611 - val_loss: 0.1952\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1605 - val_loss: 0.1945\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 0.1599 - val_loss: 0.1938\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1594 - val_loss: 0.1932\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1588 - val_loss: 0.1926\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=361, result_data[0].shape=(18, 65)\n",
      "Before prediction: train_X.shape=(5, 10, 65), train_y.shape=(5, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3787 - val_loss: 0.3469\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3763 - val_loss: 0.3460\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3740 - val_loss: 0.3450\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3717 - val_loss: 0.3441\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3694 - val_loss: 0.3432\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3672 - val_loss: 0.3422\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3650 - val_loss: 0.3413\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3628 - val_loss: 0.3404\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3607 - val_loss: 0.3396\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3585 - val_loss: 0.3387\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3564 - val_loss: 0.3381\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3543 - val_loss: 0.3374\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3523 - val_loss: 0.3367\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3503 - val_loss: 0.3361\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3483 - val_loss: 0.3354\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3464 - val_loss: 0.3349\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3445 - val_loss: 0.3343\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3426 - val_loss: 0.3338\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3408 - val_loss: 0.3332\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3390 - val_loss: 0.3327\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3372 - val_loss: 0.3323\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3355 - val_loss: 0.3319\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3338 - val_loss: 0.3314\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3321 - val_loss: 0.3310\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3305 - val_loss: 0.3306\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3289 - val_loss: 0.3303\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3273 - val_loss: 0.3299\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3258 - val_loss: 0.3297\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3243 - val_loss: 0.3294\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3229 - val_loss: 0.3292\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3215 - val_loss: 0.3289\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3201 - val_loss: 0.3286\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3187 - val_loss: 0.3282\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3174 - val_loss: 0.3279\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3161 - val_loss: 0.3275\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3147 - val_loss: 0.3271\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3134 - val_loss: 0.3267\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3121 - val_loss: 0.3262\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3108 - val_loss: 0.3258\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3095 - val_loss: 0.3253\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=470, result_data[0].shape=(10, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.7573 - val_loss: 1.1598\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.7546 - val_loss: 1.1589\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.7519 - val_loss: 1.1581\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.7492 - val_loss: 1.1572\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.7465 - val_loss: 1.1562\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.7438 - val_loss: 1.1553\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.7412 - val_loss: 1.1543\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7384 - val_loss: 1.1533\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.7357 - val_loss: 1.1523\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.7330 - val_loss: 1.1513\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7304 - val_loss: 1.1504\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7276 - val_loss: 1.1495\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.7249 - val_loss: 1.1486\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.7223 - val_loss: 1.1478\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.7196 - val_loss: 1.1470\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.7170 - val_loss: 1.1463\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.7144 - val_loss: 1.1456\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.7117 - val_loss: 1.1449\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 2.7090 - val_loss: 1.1442\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.7063 - val_loss: 1.1436\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.7037 - val_loss: 1.1429\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.7011 - val_loss: 1.1422\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.6984 - val_loss: 1.1415\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.6957 - val_loss: 1.1408\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.6931 - val_loss: 1.1402\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.6905 - val_loss: 1.1395\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.6882 - val_loss: 1.1388\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.6858 - val_loss: 1.1381\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.6835 - val_loss: 1.1373\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.6810 - val_loss: 1.1365\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.6786 - val_loss: 1.1358\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.6761 - val_loss: 1.1351\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.6737 - val_loss: 1.1343\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.6713 - val_loss: 1.1336\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.6690 - val_loss: 1.1330\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.6667 - val_loss: 1.1323\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.6644 - val_loss: 1.1316\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 2.6621 - val_loss: 1.1308\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.6598 - val_loss: 1.1301\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.6577 - val_loss: 1.1293\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(3251, 65)\n",
      "Before prediction: train_X.shape=(1945, 10, 65), train_y.shape=(1945, 65), test_X.shape=(648, 10, 65), test_y.shape=(648, 65)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1191 - val_loss: 0.0928\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1136 - val_loss: 0.0909\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.1092 - val_loss: 0.0894\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1055 - val_loss: 0.0884\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1022 - val_loss: 0.0876\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0994 - val_loss: 0.0870\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0969 - val_loss: 0.0866\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0946 - val_loss: 0.0863\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0926 - val_loss: 0.0860\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0907 - val_loss: 0.0857\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0890 - val_loss: 0.0855\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0874 - val_loss: 0.0852\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0859 - val_loss: 0.0850\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0848\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0833 - val_loss: 0.0846\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0821 - val_loss: 0.0844\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0810 - val_loss: 0.0843\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0800 - val_loss: 0.0841\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0790 - val_loss: 0.0840\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0781 - val_loss: 0.0839\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0773 - val_loss: 0.0838\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0764 - val_loss: 0.0836\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0757 - val_loss: 0.0836\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0750 - val_loss: 0.0835\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0743 - val_loss: 0.0833\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0738 - val_loss: 0.0833\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0732 - val_loss: 0.0832\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0727 - val_loss: 0.0831\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0723 - val_loss: 0.0830\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0719 - val_loss: 0.0829\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0715 - val_loss: 0.0828\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0711 - val_loss: 0.0827\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0708 - val_loss: 0.0826\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0704 - val_loss: 0.0825\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0701 - val_loss: 0.0825\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0698 - val_loss: 0.0824\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0695 - val_loss: 0.0823\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0693 - val_loss: 0.0823\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0690 - val_loss: 0.0822\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0687 - val_loss: 0.0821\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=60, result_data[0].shape=(313, 65)\n",
      "Before prediction: train_X.shape=(182, 10, 65), train_y.shape=(182, 65), test_X.shape=(61, 10, 65), test_y.shape=(61, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7268 - val_loss: 0.6076\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7252 - val_loss: 0.6067\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7237 - val_loss: 0.6058\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7222 - val_loss: 0.6049\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7208 - val_loss: 0.6041\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7194 - val_loss: 0.6032\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7180 - val_loss: 0.6024\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7167 - val_loss: 0.6016\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7154 - val_loss: 0.6008\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7140 - val_loss: 0.6000\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7128 - val_loss: 0.5993\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7115 - val_loss: 0.5986\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7103 - val_loss: 0.5978\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7091 - val_loss: 0.5971\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7079 - val_loss: 0.5964\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7068 - val_loss: 0.5958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7056 - val_loss: 0.5951\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7045 - val_loss: 0.5945\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7034 - val_loss: 0.5938\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7023 - val_loss: 0.5932\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7012 - val_loss: 0.5926\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7001 - val_loss: 0.5920\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.6991 - val_loss: 0.5913\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.6981 - val_loss: 0.5908\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6970 - val_loss: 0.5902\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6960 - val_loss: 0.5896\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6950 - val_loss: 0.5890\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6940 - val_loss: 0.5884\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6930 - val_loss: 0.5878\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6920 - val_loss: 0.5872\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6911 - val_loss: 0.5867\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6901 - val_loss: 0.5861\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6891 - val_loss: 0.5855\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6882 - val_loss: 0.5850\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6873 - val_loss: 0.5844\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6863 - val_loss: 0.5838\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6854 - val_loss: 0.5833\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6845 - val_loss: 0.5827\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6835 - val_loss: 0.5822\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6827 - val_loss: 0.5816\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=26, result_data[0].shape=(73, 65)\n",
      "Before prediction: train_X.shape=(38, 10, 65), train_y.shape=(38, 65), test_X.shape=(13, 10, 65), test_y.shape=(13, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5290 - val_loss: 0.4661\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5272 - val_loss: 0.4650\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5254 - val_loss: 0.4639\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5236 - val_loss: 0.4629\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5218 - val_loss: 0.4619\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5200 - val_loss: 0.4608\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5183 - val_loss: 0.4598\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5166 - val_loss: 0.4588\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5149 - val_loss: 0.4579\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5132 - val_loss: 0.4569\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5116 - val_loss: 0.4559\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5099 - val_loss: 0.4550\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5083 - val_loss: 0.4540\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5066 - val_loss: 0.4531\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5050 - val_loss: 0.4522\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5035 - val_loss: 0.4512\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5019 - val_loss: 0.4504\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5003 - val_loss: 0.4495\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4988 - val_loss: 0.4486\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4973 - val_loss: 0.4477\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4958 - val_loss: 0.4469\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4943 - val_loss: 0.4460\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4928 - val_loss: 0.4452\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4913 - val_loss: 0.4443\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4899 - val_loss: 0.4435\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4884 - val_loss: 0.4426\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4870 - val_loss: 0.4418\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4856 - val_loss: 0.4410\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4842 - val_loss: 0.4401\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4828 - val_loss: 0.4393\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4814 - val_loss: 0.4385\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4801 - val_loss: 0.4377\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4787 - val_loss: 0.4369\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4774 - val_loss: 0.4361\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4760 - val_loss: 0.4352\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4747 - val_loss: 0.4344\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4734 - val_loss: 0.4336\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4721 - val_loss: 0.4328\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4708 - val_loss: 0.4320\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4696 - val_loss: 0.4312\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "dataset_windows.shape=(326462, 15, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=86, result_data[0].shape=(155, 65)\n",
      "Before prediction: train_X.shape=(87, 10, 65), train_y.shape=(87, 65), test_X.shape=(29, 10, 65), test_y.shape=(29, 65)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3914 - val_loss: 0.4767\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3907 - val_loss: 0.4762\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3900 - val_loss: 0.4757\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3893 - val_loss: 0.4752\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3887 - val_loss: 0.4748\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3881 - val_loss: 0.4743\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.4738\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3868 - val_loss: 0.4734\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3862 - val_loss: 0.4729\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3856 - val_loss: 0.4725\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3851 - val_loss: 0.4721\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3845 - val_loss: 0.4717\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3840 - val_loss: 0.4713\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3834 - val_loss: 0.4709\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3829 - val_loss: 0.4705\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3824 - val_loss: 0.4701\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3818 - val_loss: 0.4697\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3813 - val_loss: 0.4693\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3808 - val_loss: 0.4690\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3803 - val_loss: 0.4686\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3798 - val_loss: 0.4682\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3794 - val_loss: 0.4679\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3789 - val_loss: 0.4675\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3784 - val_loss: 0.4671\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3780 - val_loss: 0.4668\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3775 - val_loss: 0.4664\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3771 - val_loss: 0.4661\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3766 - val_loss: 0.4657\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3762 - val_loss: 0.4654\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3757 - val_loss: 0.4651\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3753 - val_loss: 0.4648\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3749 - val_loss: 0.4645\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3745 - val_loss: 0.4642\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3740 - val_loss: 0.4639\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.3736 - val_loss: 0.4636\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3732 - val_loss: 0.4633\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3728 - val_loss: 0.4630\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3724 - val_loss: 0.4627\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3720 - val_loss: 0.4624\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3716 - val_loss: 0.4621\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=168, result_data[0].shape=(267, 65)\n",
      "Before prediction: train_X.shape=(154, 10, 65), train_y.shape=(154, 65), test_X.shape=(51, 10, 65), test_y.shape=(51, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.3706 - val_loss: 0.3154\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3696 - val_loss: 0.3147\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3687 - val_loss: 0.3141\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3678 - val_loss: 0.3134\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3670 - val_loss: 0.3127\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3661 - val_loss: 0.3121\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3653 - val_loss: 0.3115\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3645 - val_loss: 0.3109\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3637 - val_loss: 0.3103\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3629 - val_loss: 0.3097\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3621 - val_loss: 0.3092\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3614 - val_loss: 0.3087\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3606 - val_loss: 0.3081\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3599 - val_loss: 0.3076\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3592 - val_loss: 0.3071\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3585 - val_loss: 0.3066\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3578 - val_loss: 0.3061\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3572 - val_loss: 0.3056\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3565 - val_loss: 0.3051\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3559 - val_loss: 0.3047\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3552 - val_loss: 0.3042\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3546 - val_loss: 0.3038\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3540 - val_loss: 0.3033\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3533 - val_loss: 0.3029\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3527 - val_loss: 0.3024\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3521 - val_loss: 0.3020\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3516 - val_loss: 0.3016\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3510 - val_loss: 0.3012\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3504 - val_loss: 0.3008\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3498 - val_loss: 0.3004\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3493 - val_loss: 0.3000\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3487 - val_loss: 0.2996\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3482 - val_loss: 0.2992\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3476 - val_loss: 0.2988\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3471 - val_loss: 0.2984\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.3466 - val_loss: 0.2980\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.3460 - val_loss: 0.2976\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.3455 - val_loss: 0.2972\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.3450 - val_loss: 0.2968\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.3445 - val_loss: 0.2965\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=24, result_data[0].shape=(81, 65)\n",
      "Before prediction: train_X.shape=(43, 10, 65), train_y.shape=(43, 65), test_X.shape=(14, 10, 65), test_y.shape=(14, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5513 - val_loss: 0.6476\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5498 - val_loss: 0.6470\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5484 - val_loss: 0.6464\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5469 - val_loss: 0.6457\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5455 - val_loss: 0.6451\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5441 - val_loss: 0.6445\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5427 - val_loss: 0.6439\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5413 - val_loss: 0.6433\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5399 - val_loss: 0.6428\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5385 - val_loss: 0.6422\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5371 - val_loss: 0.6416\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5357 - val_loss: 0.6411\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5344 - val_loss: 0.6405\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5330 - val_loss: 0.6400\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5317 - val_loss: 0.6394\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5304 - val_loss: 0.6389\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5291 - val_loss: 0.6384\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5278 - val_loss: 0.6378\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5265 - val_loss: 0.6373\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5252 - val_loss: 0.6368\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5239 - val_loss: 0.6363\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5227 - val_loss: 0.6357\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5215 - val_loss: 0.6352\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5202 - val_loss: 0.6347\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5190 - val_loss: 0.6342\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5178 - val_loss: 0.6337\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5166 - val_loss: 0.6332\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5154 - val_loss: 0.6327\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5143 - val_loss: 0.6322\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5131 - val_loss: 0.6317\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5119 - val_loss: 0.6313\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5108 - val_loss: 0.6308\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5096 - val_loss: 0.6304\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5085 - val_loss: 0.6299\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5073 - val_loss: 0.6295\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5062 - val_loss: 0.6290\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5051 - val_loss: 0.6286\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5041 - val_loss: 0.6282\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5030 - val_loss: 0.6278\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5019 - val_loss: 0.6274\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=9, result_data[0].shape=(9946, 65)\n",
      "Before prediction: train_X.shape=(5962, 10, 65), train_y.shape=(5962, 65), test_X.shape=(1987, 10, 65), test_y.shape=(1987, 65)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0695 - val_loss: 0.0459\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0634 - val_loss: 0.0427\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0599 - val_loss: 0.0406\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0573 - val_loss: 0.0389\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0553 - val_loss: 0.0377\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0537 - val_loss: 0.0367\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0524 - val_loss: 0.0358\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0513 - val_loss: 0.0351\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0503 - val_loss: 0.0345\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0495 - val_loss: 0.0340\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0488 - val_loss: 0.0335\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0482 - val_loss: 0.0330\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0476 - val_loss: 0.0326\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0471 - val_loss: 0.0323\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0467 - val_loss: 0.0319\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0462 - val_loss: 0.0316\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0459 - val_loss: 0.0313\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0455 - val_loss: 0.0309\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0452 - val_loss: 0.0307\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0449 - val_loss: 0.0304\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0446 - val_loss: 0.0302\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0444 - val_loss: 0.0300\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0441 - val_loss: 0.0298\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0296\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0437 - val_loss: 0.0294\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0435 - val_loss: 0.0292\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0433 - val_loss: 0.0291\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0432 - val_loss: 0.0289\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0288\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0429 - val_loss: 0.0287\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0427 - val_loss: 0.0285\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0426 - val_loss: 0.0284\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0425 - val_loss: 0.0283\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0424 - val_loss: 0.0282\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0423 - val_loss: 0.0282\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 37ms/step - loss: 0.0422 - val_loss: 0.0281\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0421 - val_loss: 0.0280\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 35ms/step - loss: 0.0420 - val_loss: 0.0279\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0419 - val_loss: 0.0278\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 36ms/step - loss: 0.0418 - val_loss: 0.0278\n",
      "63/63 [==============================] - 1s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=255, result_data[0].shape=(17, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6404 - val_loss: 0.5489\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6382 - val_loss: 0.5475\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6361 - val_loss: 0.5461\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6339 - val_loss: 0.5447\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6318 - val_loss: 0.5432\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6296 - val_loss: 0.5418\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6275 - val_loss: 0.5404\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6254 - val_loss: 0.5390\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6233 - val_loss: 0.5375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6212 - val_loss: 0.5361\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6191 - val_loss: 0.5347\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6170 - val_loss: 0.5332\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6150 - val_loss: 0.5318\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6130 - val_loss: 0.5305\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6110 - val_loss: 0.5292\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6089 - val_loss: 0.5280\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6069 - val_loss: 0.5268\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6049 - val_loss: 0.5255\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6029 - val_loss: 0.5243\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6009 - val_loss: 0.5231\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5988 - val_loss: 0.5219\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5968 - val_loss: 0.5207\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5948 - val_loss: 0.5195\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5928 - val_loss: 0.5183\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5909 - val_loss: 0.5172\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5889 - val_loss: 0.5162\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5869 - val_loss: 0.5152\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5849 - val_loss: 0.5143\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5829 - val_loss: 0.5134\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5810 - val_loss: 0.5125\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5790 - val_loss: 0.5116\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5771 - val_loss: 0.5108\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5752 - val_loss: 0.5099\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5733 - val_loss: 0.5090\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5714 - val_loss: 0.5081\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5695 - val_loss: 0.5071\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5676 - val_loss: 0.5062\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5657 - val_loss: 0.5052\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5639 - val_loss: 0.5043\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5620 - val_loss: 0.5034\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=357, result_data[0].shape=(19, 65)\n",
      "Before prediction: train_X.shape=(5, 10, 65), train_y.shape=(5, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5633 - val_loss: 0.4182\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5609 - val_loss: 0.4164\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5585 - val_loss: 0.4146\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5562 - val_loss: 0.4129\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5539 - val_loss: 0.4111\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5517 - val_loss: 0.4094\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5497 - val_loss: 0.4077\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5476 - val_loss: 0.4061\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5457 - val_loss: 0.4045\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5438 - val_loss: 0.4029\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5419 - val_loss: 0.4014\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5400 - val_loss: 0.3999\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5381 - val_loss: 0.3983\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5363 - val_loss: 0.3969\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5345 - val_loss: 0.3954\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5326 - val_loss: 0.3941\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5309 - val_loss: 0.3927\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5291 - val_loss: 0.3914\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5274 - val_loss: 0.3902\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5256 - val_loss: 0.3890\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5239 - val_loss: 0.3878\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5222 - val_loss: 0.3867\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5205 - val_loss: 0.3856\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5188 - val_loss: 0.3846\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5172 - val_loss: 0.3836\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5156 - val_loss: 0.3826\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5140 - val_loss: 0.3815\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5125 - val_loss: 0.3805\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5109 - val_loss: 0.3795\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5094 - val_loss: 0.3785\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5080 - val_loss: 0.3776\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5066 - val_loss: 0.3766\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5052 - val_loss: 0.3757\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5038 - val_loss: 0.3748\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5024 - val_loss: 0.3739\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5010 - val_loss: 0.3730\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4997 - val_loss: 0.3721\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4983 - val_loss: 0.3713\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4970 - val_loss: 0.3705\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4957 - val_loss: 0.3697\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=35, result_data[0].shape=(310, 65)\n",
      "Before prediction: train_X.shape=(180, 10, 65), train_y.shape=(180, 65), test_X.shape=(60, 10, 65), test_y.shape=(60, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7045 - val_loss: 0.5715\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7031 - val_loss: 0.5708\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7017 - val_loss: 0.5701\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7004 - val_loss: 0.5694\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6991 - val_loss: 0.5687\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6979 - val_loss: 0.5681\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6967 - val_loss: 0.5674\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6955 - val_loss: 0.5668\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6943 - val_loss: 0.5662\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6931 - val_loss: 0.5655\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6920 - val_loss: 0.5649\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6909 - val_loss: 0.5644\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6898 - val_loss: 0.5638\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6887 - val_loss: 0.5632\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.6876 - val_loss: 0.5626\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6865 - val_loss: 0.5621\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6855 - val_loss: 0.5615\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6844 - val_loss: 0.5610\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6834 - val_loss: 0.5604\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6824 - val_loss: 0.5599\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6814 - val_loss: 0.5594\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6804 - val_loss: 0.5588\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6795 - val_loss: 0.5583\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6785 - val_loss: 0.5578\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6776 - val_loss: 0.5573\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6766 - val_loss: 0.5568\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6757 - val_loss: 0.5563\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6748 - val_loss: 0.5558\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6739 - val_loss: 0.5553\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6730 - val_loss: 0.5548\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6721 - val_loss: 0.5544\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6713 - val_loss: 0.5539\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6704 - val_loss: 0.5534\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6696 - val_loss: 0.5530\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6687 - val_loss: 0.5525\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6679 - val_loss: 0.5520\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6670 - val_loss: 0.5516\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6662 - val_loss: 0.5511\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6654 - val_loss: 0.5506\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6645 - val_loss: 0.5502\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "dataset_windows.shape=(326462, 15, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=1, result_data[0].shape=(2628, 65)\n",
      "Before prediction: train_X.shape=(1571, 10, 65), train_y.shape=(1571, 65), test_X.shape=(524, 10, 65), test_y.shape=(524, 65)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.2468 - val_loss: 0.2876\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2346 - val_loss: 0.2753\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2253 - val_loss: 0.2658\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.2181 - val_loss: 0.2584\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.2123 - val_loss: 0.2525\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2076 - val_loss: 0.2475\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2035 - val_loss: 0.2431\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1999 - val_loss: 0.2392\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1966 - val_loss: 0.2356\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1937 - val_loss: 0.2324\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.1909 - val_loss: 0.2295\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.1884 - val_loss: 0.2268\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1862 - val_loss: 0.2243\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1841 - val_loss: 0.2221\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1822 - val_loss: 0.2200\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1805 - val_loss: 0.2181\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.1789 - val_loss: 0.2164\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1774 - val_loss: 0.2147\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1760 - val_loss: 0.2132\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1747 - val_loss: 0.2117\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.1735 - val_loss: 0.2103\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1724 - val_loss: 0.2090\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.1713 - val_loss: 0.2077\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.1702 - val_loss: 0.2065\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 37ms/step - loss: 0.1692 - val_loss: 0.2054\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1683 - val_loss: 0.2044\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1674 - val_loss: 0.2033\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1665 - val_loss: 0.2024\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1657 - val_loss: 0.2014\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.1649 - val_loss: 0.2005\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.1642 - val_loss: 0.1997\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1635 - val_loss: 0.1988\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1628 - val_loss: 0.1980\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1621 - val_loss: 0.1972\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1615 - val_loss: 0.1965\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.1609 - val_loss: 0.1958\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.1603 - val_loss: 0.1951\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.1597 - val_loss: 0.1944\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1592 - val_loss: 0.1938\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1587 - val_loss: 0.1932\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=98, result_data[0].shape=(24, 65)\n",
      "Before prediction: train_X.shape=(8, 10, 65), train_y.shape=(8, 65), test_X.shape=(3, 10, 65), test_y.shape=(3, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3641 - val_loss: 0.3355\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3634 - val_loss: 0.3354\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3628 - val_loss: 0.3353\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3622 - val_loss: 0.3352\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3616 - val_loss: 0.3351\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3611 - val_loss: 0.3350\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3605 - val_loss: 0.3349\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3599 - val_loss: 0.3348\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3593 - val_loss: 0.3347\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3587 - val_loss: 0.3346\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3582 - val_loss: 0.3345\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3576 - val_loss: 0.3344\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3570 - val_loss: 0.3343\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3565 - val_loss: 0.3342\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3559 - val_loss: 0.3341\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3554 - val_loss: 0.3340\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3549 - val_loss: 0.3339\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3543 - val_loss: 0.3338\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3538 - val_loss: 0.3337\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3533 - val_loss: 0.3336\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3528 - val_loss: 0.3335\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3522 - val_loss: 0.3334\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3517 - val_loss: 0.3333\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3512 - val_loss: 0.3332\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3507 - val_loss: 0.3331\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3503 - val_loss: 0.3330\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3498 - val_loss: 0.3329\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3493 - val_loss: 0.3329\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3488 - val_loss: 0.3328\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3483 - val_loss: 0.3327\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3478 - val_loss: 0.3326\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3473 - val_loss: 0.3325\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3469 - val_loss: 0.3324\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3464 - val_loss: 0.3323\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3460 - val_loss: 0.3322\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3455 - val_loss: 0.3322\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3451 - val_loss: 0.3321\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3446 - val_loss: 0.3320\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3441 - val_loss: 0.3319\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3437 - val_loss: 0.3319\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=309, result_data[0].shape=(17, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6441 - val_loss: 0.6426\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6416 - val_loss: 0.6408\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6391 - val_loss: 0.6390\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6366 - val_loss: 0.6373\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6342 - val_loss: 0.6356\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6318 - val_loss: 0.6339\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6295 - val_loss: 0.6323\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6271 - val_loss: 0.6307\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6248 - val_loss: 0.6292\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6225 - val_loss: 0.6277\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6203 - val_loss: 0.6263\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6181 - val_loss: 0.6250\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6159 - val_loss: 0.6236\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6138 - val_loss: 0.6222\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6117 - val_loss: 0.6209\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6095 - val_loss: 0.6195\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6074 - val_loss: 0.6182\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6053 - val_loss: 0.6169\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6032 - val_loss: 0.6156\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6011 - val_loss: 0.6143\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5992 - val_loss: 0.6130\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5973 - val_loss: 0.6119\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5955 - val_loss: 0.6107\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5937 - val_loss: 0.6096\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5919 - val_loss: 0.6085\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5900 - val_loss: 0.6074\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5882 - val_loss: 0.6063\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5864 - val_loss: 0.6052\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5846 - val_loss: 0.6042\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5828 - val_loss: 0.6032\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5812 - val_loss: 0.6022\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5796 - val_loss: 0.6013\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5780 - val_loss: 0.6003\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5765 - val_loss: 0.5993\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5750 - val_loss: 0.5983\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5735 - val_loss: 0.5973\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5720 - val_loss: 0.5963\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5706 - val_loss: 0.5953\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5691 - val_loss: 0.5943\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5677 - val_loss: 0.5933\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=23, result_data[0].shape=(83, 65)\n",
      "Before prediction: train_X.shape=(44, 10, 65), train_y.shape=(44, 65), test_X.shape=(15, 10, 65), test_y.shape=(15, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5606 - val_loss: 0.7722\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5589 - val_loss: 0.7716\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5573 - val_loss: 0.7710\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5558 - val_loss: 0.7704\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5542 - val_loss: 0.7698\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5526 - val_loss: 0.7692\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5511 - val_loss: 0.7686\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5496 - val_loss: 0.7681\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5481 - val_loss: 0.7675\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5465 - val_loss: 0.7669\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5451 - val_loss: 0.7664\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5436 - val_loss: 0.7658\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5421 - val_loss: 0.7653\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5407 - val_loss: 0.7648\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5392 - val_loss: 0.7642\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5378 - val_loss: 0.7637\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5363 - val_loss: 0.7632\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5349 - val_loss: 0.7627\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5335 - val_loss: 0.7622\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5321 - val_loss: 0.7617\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5308 - val_loss: 0.7613\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5294 - val_loss: 0.7608\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5280 - val_loss: 0.7603\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5267 - val_loss: 0.7599\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5253 - val_loss: 0.7594\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5240 - val_loss: 0.7590\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5227 - val_loss: 0.7585\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5213 - val_loss: 0.7581\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5200 - val_loss: 0.7576\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5187 - val_loss: 0.7572\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5174 - val_loss: 0.7567\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5161 - val_loss: 0.7563\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5149 - val_loss: 0.7558\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5136 - val_loss: 0.7554\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5124 - val_loss: 0.7549\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5111 - val_loss: 0.7545\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5099 - val_loss: 0.7541\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5087 - val_loss: 0.7536\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5075 - val_loss: 0.7532\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5063 - val_loss: 0.7528\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=396, result_data[0].shape=(20, 65)\n",
      "Before prediction: train_X.shape=(6, 10, 65), train_y.shape=(6, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5294 - val_loss: 0.3938\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5266 - val_loss: 0.3933\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5238 - val_loss: 0.3929\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5210 - val_loss: 0.3925\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5182 - val_loss: 0.3922\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5155 - val_loss: 0.3918\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5128 - val_loss: 0.3914\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5101 - val_loss: 0.3910\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5075 - val_loss: 0.3906\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5051 - val_loss: 0.3901\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5027 - val_loss: 0.3897\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5003 - val_loss: 0.3893\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4979 - val_loss: 0.3890\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4956 - val_loss: 0.3887\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4933 - val_loss: 0.3884\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4910 - val_loss: 0.3880\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4888 - val_loss: 0.3878\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4866 - val_loss: 0.3875\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4844 - val_loss: 0.3872\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4823 - val_loss: 0.3869\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4803 - val_loss: 0.3866\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4782 - val_loss: 0.3863\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4762 - val_loss: 0.3860\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4741 - val_loss: 0.3856\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4722 - val_loss: 0.3853\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4703 - val_loss: 0.3849\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4684 - val_loss: 0.3845\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4665 - val_loss: 0.3842\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4647 - val_loss: 0.3839\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4629 - val_loss: 0.3836\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4611 - val_loss: 0.3834\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4593 - val_loss: 0.3831\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4575 - val_loss: 0.3828\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4557 - val_loss: 0.3825\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4540 - val_loss: 0.3822\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4523 - val_loss: 0.3820\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4506 - val_loss: 0.3818\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4489 - val_loss: 0.3816\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4472 - val_loss: 0.3814\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4456 - val_loss: 0.3812\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=25, result_data[0].shape=(210, 65)\n",
      "Before prediction: train_X.shape=(120, 10, 65), train_y.shape=(120, 65), test_X.shape=(40, 10, 65), test_y.shape=(40, 65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6878 - val_loss: 0.9676\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6868 - val_loss: 0.9671\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6858 - val_loss: 0.9665\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6849 - val_loss: 0.9660\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6840 - val_loss: 0.9654\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6830 - val_loss: 0.9649\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6821 - val_loss: 0.9644\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6812 - val_loss: 0.9639\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6803 - val_loss: 0.9634\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6795 - val_loss: 0.9629\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6786 - val_loss: 0.9624\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.6777 - val_loss: 0.9619\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6769 - val_loss: 0.9614\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6760 - val_loss: 0.9610\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6752 - val_loss: 0.9605\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6744 - val_loss: 0.9601\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6736 - val_loss: 0.9596\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6728 - val_loss: 0.9592\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6720 - val_loss: 0.9588\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6712 - val_loss: 0.9584\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6705 - val_loss: 0.9580\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6697 - val_loss: 0.9576\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6690 - val_loss: 0.9572\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6682 - val_loss: 0.9568\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6675 - val_loss: 0.9564\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6668 - val_loss: 0.9560\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6661 - val_loss: 0.9556\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6654 - val_loss: 0.9552\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6647 - val_loss: 0.9549\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6640 - val_loss: 0.9545\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6633 - val_loss: 0.9542\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6626 - val_loss: 0.9538\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6620 - val_loss: 0.9535\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6613 - val_loss: 0.9532\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6606 - val_loss: 0.9528\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6600 - val_loss: 0.9525\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6593 - val_loss: 0.9522\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6587 - val_loss: 0.9518\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6580 - val_loss: 0.9515\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6574 - val_loss: 0.9512\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=156, result_data[0].shape=(265, 65)\n",
      "Before prediction: train_X.shape=(153, 10, 65), train_y.shape=(153, 65), test_X.shape=(51, 10, 65), test_y.shape=(51, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.3545 - val_loss: 0.2948\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3535 - val_loss: 0.2942\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3525 - val_loss: 0.2936\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3516 - val_loss: 0.2930\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3507 - val_loss: 0.2924\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3499 - val_loss: 0.2918\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3490 - val_loss: 0.2912\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3482 - val_loss: 0.2907\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3473 - val_loss: 0.2902\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3465 - val_loss: 0.2896\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3457 - val_loss: 0.2891\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3450 - val_loss: 0.2886\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3442 - val_loss: 0.2881\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.3434 - val_loss: 0.2877\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3427 - val_loss: 0.2872\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3420 - val_loss: 0.2867\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3413 - val_loss: 0.2863\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.3406 - val_loss: 0.2859\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.3399 - val_loss: 0.2854\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.3392 - val_loss: 0.2850\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3386 - val_loss: 0.2846\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.3379 - val_loss: 0.2842\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3373 - val_loss: 0.2838\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3366 - val_loss: 0.2835\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3360 - val_loss: 0.2831\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3354 - val_loss: 0.2827\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3348 - val_loss: 0.2824\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3342 - val_loss: 0.2820\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3336 - val_loss: 0.2816\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3331 - val_loss: 0.2813\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3325 - val_loss: 0.2809\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3319 - val_loss: 0.2806\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3314 - val_loss: 0.2802\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3308 - val_loss: 0.2798\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3303 - val_loss: 0.2795\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3297 - val_loss: 0.2791\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3292 - val_loss: 0.2788\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3287 - val_loss: 0.2785\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3281 - val_loss: 0.2781\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3276 - val_loss: 0.2778\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=72, result_data[0].shape=(317, 65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before prediction: train_X.shape=(184, 10, 65), train_y.shape=(184, 65), test_X.shape=(61, 10, 65), test_y.shape=(61, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.5385 - val_loss: 0.4830\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5370 - val_loss: 0.4823\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5356 - val_loss: 0.4817\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5344 - val_loss: 0.4810\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5330 - val_loss: 0.4804\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5318 - val_loss: 0.4798\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5306 - val_loss: 0.4792\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5294 - val_loss: 0.4787\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5283 - val_loss: 0.4781\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5271 - val_loss: 0.4776\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5260 - val_loss: 0.4770\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5249 - val_loss: 0.4765\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5238 - val_loss: 0.4760\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.5227 - val_loss: 0.4755\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.5217 - val_loss: 0.4750\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.5207 - val_loss: 0.4746\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5197 - val_loss: 0.4741\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5187 - val_loss: 0.4736\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5177 - val_loss: 0.4732\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5168 - val_loss: 0.4727\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5158 - val_loss: 0.4723\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.5149 - val_loss: 0.4718\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.5140 - val_loss: 0.4714\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5131 - val_loss: 0.4709\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5122 - val_loss: 0.4705\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5113 - val_loss: 0.4701\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5104 - val_loss: 0.4697\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5095 - val_loss: 0.4693\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5087 - val_loss: 0.4689\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5079 - val_loss: 0.4685\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5070 - val_loss: 0.4681\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5062 - val_loss: 0.4677\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5054 - val_loss: 0.4673\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5046 - val_loss: 0.4669\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5038 - val_loss: 0.4666\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5030 - val_loss: 0.4662\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5022 - val_loss: 0.4658\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5014 - val_loss: 0.4655\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5007 - val_loss: 0.4651\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4999 - val_loss: 0.4648\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(3255, 65)\n",
      "Before prediction: train_X.shape=(1947, 10, 65), train_y.shape=(1947, 65), test_X.shape=(649, 10, 65), test_y.shape=(649, 65)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1193 - val_loss: 0.0920\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1142 - val_loss: 0.0900\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.1102 - val_loss: 0.0887\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.1067 - val_loss: 0.0878\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1038 - val_loss: 0.0871\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1011 - val_loss: 0.0865\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0988 - val_loss: 0.0861\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0967 - val_loss: 0.0856\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0947 - val_loss: 0.0853\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0930 - val_loss: 0.0849\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0914 - val_loss: 0.0846\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0899 - val_loss: 0.0843\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0886 - val_loss: 0.0840\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0873 - val_loss: 0.0837\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0862 - val_loss: 0.0834\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0832\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0841 - val_loss: 0.0830\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0832 - val_loss: 0.0827\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0823 - val_loss: 0.0826\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0815 - val_loss: 0.0824\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0808 - val_loss: 0.0822\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0801 - val_loss: 0.0821\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0794 - val_loss: 0.0819\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0788 - val_loss: 0.0817\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0782 - val_loss: 0.0815\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0776 - val_loss: 0.0814\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0771 - val_loss: 0.0812\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0766 - val_loss: 0.0811\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0761 - val_loss: 0.0810\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0756 - val_loss: 0.0809\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0752 - val_loss: 0.0809\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0747 - val_loss: 0.0808\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0743 - val_loss: 0.0807\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0739 - val_loss: 0.0806\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0736 - val_loss: 0.0806\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0732 - val_loss: 0.0806\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0729 - val_loss: 0.0806\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0726 - val_loss: 0.0805\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0723 - val_loss: 0.0805\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0720 - val_loss: 0.0805\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "dataset_windows.shape=(326462, 15, 65)\n",
      "In split_to_clusters: len(dataset)=326477, (len(labels) + W)=326477\n",
      "In transform\n",
      " -> in transform: len(result_data)=433, result_data[0].shape=(14, 65)\n",
      "Before prediction: train_X.shape=(2, 10, 65), train_y.shape=(2, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6780 - val_loss: 0.7427\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6751 - val_loss: 0.7413\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6722 - val_loss: 0.7398\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6693 - val_loss: 0.7384\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6665 - val_loss: 0.7370\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6636 - val_loss: 0.7357\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6608 - val_loss: 0.7343\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6581 - val_loss: 0.7330\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6553 - val_loss: 0.7317\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6525 - val_loss: 0.7304\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6498 - val_loss: 0.7292\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6470 - val_loss: 0.7279\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6444 - val_loss: 0.7266\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6418 - val_loss: 0.7254\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6391 - val_loss: 0.7241\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6365 - val_loss: 0.7229\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6340 - val_loss: 0.7216\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6315 - val_loss: 0.7204\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6291 - val_loss: 0.7192\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6267 - val_loss: 0.7179\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6243 - val_loss: 0.7168\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6220 - val_loss: 0.7158\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6197 - val_loss: 0.7147\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6173 - val_loss: 0.7136\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6151 - val_loss: 0.7126\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6129 - val_loss: 0.7115\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6107 - val_loss: 0.7105\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6085 - val_loss: 0.7095\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6064 - val_loss: 0.7085\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6043 - val_loss: 0.7075\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6022 - val_loss: 0.7066\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6001 - val_loss: 0.7056\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5980 - val_loss: 0.7047\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5959 - val_loss: 0.7037\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5939 - val_loss: 0.7028\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5918 - val_loss: 0.7019\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5898 - val_loss: 0.7009\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5877 - val_loss: 0.7000\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5857 - val_loss: 0.6991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5836 - val_loss: 0.6981\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=375, result_data[0].shape=(20, 65)\n",
      "Before prediction: train_X.shape=(6, 10, 65), train_y.shape=(6, 65), test_X.shape=(2, 10, 65), test_y.shape=(2, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4878 - val_loss: 0.3604\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4853 - val_loss: 0.3591\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4829 - val_loss: 0.3578\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4804 - val_loss: 0.3566\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4780 - val_loss: 0.3553\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4755 - val_loss: 0.3540\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4731 - val_loss: 0.3527\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4708 - val_loss: 0.3515\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4685 - val_loss: 0.3503\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4662 - val_loss: 0.3491\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4639 - val_loss: 0.3479\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4616 - val_loss: 0.3468\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4594 - val_loss: 0.3457\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4571 - val_loss: 0.3446\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4549 - val_loss: 0.3435\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4528 - val_loss: 0.3424\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4506 - val_loss: 0.3413\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4485 - val_loss: 0.3403\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4464 - val_loss: 0.3392\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4443 - val_loss: 0.3383\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4422 - val_loss: 0.3373\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4401 - val_loss: 0.3363\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4381 - val_loss: 0.3354\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4361 - val_loss: 0.3345\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4341 - val_loss: 0.3335\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4321 - val_loss: 0.3326\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4301 - val_loss: 0.3317\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4282 - val_loss: 0.3308\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4262 - val_loss: 0.3299\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4243 - val_loss: 0.3290\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4224 - val_loss: 0.3281\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4206 - val_loss: 0.3273\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4187 - val_loss: 0.3265\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4169 - val_loss: 0.3258\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4150 - val_loss: 0.3251\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4132 - val_loss: 0.3244\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4114 - val_loss: 0.3238\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4097 - val_loss: 0.3232\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4080 - val_loss: 0.3227\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4063 - val_loss: 0.3222\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=103, result_data[0].shape=(17, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8924 - val_loss: 0.6986\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8897 - val_loss: 0.6976\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8871 - val_loss: 0.6966\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8845 - val_loss: 0.6956\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8820 - val_loss: 0.6946\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8796 - val_loss: 0.6936\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8772 - val_loss: 0.6927\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8748 - val_loss: 0.6917\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8724 - val_loss: 0.6907\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8700 - val_loss: 0.6897\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8677 - val_loss: 0.6887\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8654 - val_loss: 0.6877\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8630 - val_loss: 0.6867\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8606 - val_loss: 0.6857\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8583 - val_loss: 0.6847\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8560 - val_loss: 0.6836\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8537 - val_loss: 0.6826\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8514 - val_loss: 0.6816\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8491 - val_loss: 0.6805\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8468 - val_loss: 0.6795\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8445 - val_loss: 0.6785\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8423 - val_loss: 0.6775\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8401 - val_loss: 0.6764\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8379 - val_loss: 0.6754\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8356 - val_loss: 0.6745\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8334 - val_loss: 0.6735\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8313 - val_loss: 0.6725\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8291 - val_loss: 0.6715\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8270 - val_loss: 0.6705\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8249 - val_loss: 0.6696\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8228 - val_loss: 0.6687\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8207 - val_loss: 0.6678\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8186 - val_loss: 0.6668\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8165 - val_loss: 0.6659\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8144 - val_loss: 0.6650\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8125 - val_loss: 0.6642\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8105 - val_loss: 0.6634\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8085 - val_loss: 0.6626\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8066 - val_loss: 0.6618\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8047 - val_loss: 0.6611\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=178, result_data[0].shape=(46, 65)\n",
      "Before prediction: train_X.shape=(22, 10, 65), train_y.shape=(22, 65), test_X.shape=(7, 10, 65), test_y.shape=(7, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3371 - val_loss: 0.2777\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3365 - val_loss: 0.2775\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3359 - val_loss: 0.2772\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3353 - val_loss: 0.2770\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3347 - val_loss: 0.2768\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3340 - val_loss: 0.2765\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3334 - val_loss: 0.2763\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3328 - val_loss: 0.2761\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3322 - val_loss: 0.2759\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3317 - val_loss: 0.2757\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3311 - val_loss: 0.2755\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3305 - val_loss: 0.2752\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3299 - val_loss: 0.2750\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3294 - val_loss: 0.2748\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3288 - val_loss: 0.2746\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3283 - val_loss: 0.2744\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3277 - val_loss: 0.2742\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3272 - val_loss: 0.2741\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3267 - val_loss: 0.2739\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3261 - val_loss: 0.2737\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3256 - val_loss: 0.2735\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3251 - val_loss: 0.2733\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3245 - val_loss: 0.2731\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3240 - val_loss: 0.2729\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3235 - val_loss: 0.2728\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3230 - val_loss: 0.2726\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3225 - val_loss: 0.2724\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3220 - val_loss: 0.2722\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3215 - val_loss: 0.2721\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3210 - val_loss: 0.2719\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3205 - val_loss: 0.2718\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3200 - val_loss: 0.2716\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3195 - val_loss: 0.2714\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3190 - val_loss: 0.2713\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3186 - val_loss: 0.2711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3181 - val_loss: 0.2710\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3176 - val_loss: 0.2709\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3172 - val_loss: 0.2707\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3167 - val_loss: 0.2706\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3162 - val_loss: 0.2705\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=30, result_data[0].shape=(24, 65)\n",
      "Before prediction: train_X.shape=(8, 10, 65), train_y.shape=(8, 65), test_X.shape=(3, 10, 65), test_y.shape=(3, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4443 - val_loss: 0.4629\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4415 - val_loss: 0.4611\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4387 - val_loss: 0.4593\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4359 - val_loss: 0.4575\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4333 - val_loss: 0.4558\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4307 - val_loss: 0.4541\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4281 - val_loss: 0.4524\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4257 - val_loss: 0.4508\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4233 - val_loss: 0.4493\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4209 - val_loss: 0.4478\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4186 - val_loss: 0.4463\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4164 - val_loss: 0.4449\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4142 - val_loss: 0.4435\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4120 - val_loss: 0.4421\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4098 - val_loss: 0.4408\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4077 - val_loss: 0.4395\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4056 - val_loss: 0.4383\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4035 - val_loss: 0.4370\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4015 - val_loss: 0.4358\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3996 - val_loss: 0.4346\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3976 - val_loss: 0.4334\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3957 - val_loss: 0.4322\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3938 - val_loss: 0.4310\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3920 - val_loss: 0.4299\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3903 - val_loss: 0.4288\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3885 - val_loss: 0.4277\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3869 - val_loss: 0.4267\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3852 - val_loss: 0.4256\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3837 - val_loss: 0.4246\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3821 - val_loss: 0.4235\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3806 - val_loss: 0.4225\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3791 - val_loss: 0.4215\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4205\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3761 - val_loss: 0.4195\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3747 - val_loss: 0.4185\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3733 - val_loss: 0.4176\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3719 - val_loss: 0.4167\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3705 - val_loss: 0.4157\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3691 - val_loss: 0.4148\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3678 - val_loss: 0.4139\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=49, result_data[0].shape=(318, 65)\n",
      "Before prediction: train_X.shape=(185, 10, 65), train_y.shape=(185, 65), test_X.shape=(62, 10, 65), test_y.shape=(62, 65)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.6966 - val_loss: 0.6467\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6951 - val_loss: 0.6457\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6938 - val_loss: 0.6447\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6925 - val_loss: 0.6438\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6912 - val_loss: 0.6429\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6899 - val_loss: 0.6420\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6886 - val_loss: 0.6411\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6874 - val_loss: 0.6403\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6863 - val_loss: 0.6394\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6851 - val_loss: 0.6386\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6839 - val_loss: 0.6377\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6828 - val_loss: 0.6369\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6816 - val_loss: 0.6361\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6805 - val_loss: 0.6354\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6794 - val_loss: 0.6346\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6784 - val_loss: 0.6339\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6773 - val_loss: 0.6331\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6763 - val_loss: 0.6324\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6753 - val_loss: 0.6317\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6743 - val_loss: 0.6310\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6733 - val_loss: 0.6303\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6724 - val_loss: 0.6297\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6714 - val_loss: 0.6290\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6705 - val_loss: 0.6283\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6695 - val_loss: 0.6277\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6686 - val_loss: 0.6270\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6677 - val_loss: 0.6264\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6668 - val_loss: 0.6257\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6659 - val_loss: 0.6251\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6650 - val_loss: 0.6245\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6641 - val_loss: 0.6239\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6632 - val_loss: 0.6233\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6623 - val_loss: 0.6227\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6614 - val_loss: 0.6220\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6606 - val_loss: 0.6214\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6597 - val_loss: 0.6208\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6588 - val_loss: 0.6202\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6579 - val_loss: 0.6196\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6571 - val_loss: 0.6190\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6562 - val_loss: 0.6184\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=19, result_data[0].shape=(42, 65)\n",
      "Before prediction: train_X.shape=(19, 10, 65), train_y.shape=(19, 65), test_X.shape=(6, 10, 65), test_y.shape=(6, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4039 - val_loss: 0.5782\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4034 - val_loss: 0.5780\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4029 - val_loss: 0.5778\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4023 - val_loss: 0.5777\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4018 - val_loss: 0.5775\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4013 - val_loss: 0.5774\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4008 - val_loss: 0.5772\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4003 - val_loss: 0.5771\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3999 - val_loss: 0.5769\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3994 - val_loss: 0.5768\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3989 - val_loss: 0.5766\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3984 - val_loss: 0.5765\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3980 - val_loss: 0.5764\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3975 - val_loss: 0.5762\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3970 - val_loss: 0.5761\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3966 - val_loss: 0.5760\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3961 - val_loss: 0.5758\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3957 - val_loss: 0.5757\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3952 - val_loss: 0.5756\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3948 - val_loss: 0.5755\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3944 - val_loss: 0.5754\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3939 - val_loss: 0.5752\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3935 - val_loss: 0.5751\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3931 - val_loss: 0.5750\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3927 - val_loss: 0.5749\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3923 - val_loss: 0.5748\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3919 - val_loss: 0.5747\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3914 - val_loss: 0.5746\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3910 - val_loss: 0.5744\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3906 - val_loss: 0.5743\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3903 - val_loss: 0.5742\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3899 - val_loss: 0.5741\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3895 - val_loss: 0.5740\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3891 - val_loss: 0.5739\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3887 - val_loss: 0.5737\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3883 - val_loss: 0.5736\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3880 - val_loss: 0.5735\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3876 - val_loss: 0.5734\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3872 - val_loss: 0.5733\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3869 - val_loss: 0.5732\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=248, result_data[0].shape=(16, 65)\n",
      "Before prediction: train_X.shape=(4, 10, 65), train_y.shape=(4, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6277 - val_loss: 0.5767\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6246 - val_loss: 0.5751\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6216 - val_loss: 0.5735\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6185 - val_loss: 0.5718\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6154 - val_loss: 0.5703\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6125 - val_loss: 0.5688\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6095 - val_loss: 0.5674\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6066 - val_loss: 0.5659\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6037 - val_loss: 0.5645\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6008 - val_loss: 0.5630\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5980 - val_loss: 0.5616\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5952 - val_loss: 0.5602\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5924 - val_loss: 0.5588\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5896 - val_loss: 0.5573\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5868 - val_loss: 0.5559\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5840 - val_loss: 0.5546\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5814 - val_loss: 0.5532\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5787 - val_loss: 0.5519\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5761 - val_loss: 0.5506\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5736 - val_loss: 0.5493\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5711 - val_loss: 0.5479\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5686 - val_loss: 0.5465\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5661 - val_loss: 0.5452\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5637 - val_loss: 0.5438\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5613 - val_loss: 0.5425\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5589 - val_loss: 0.5412\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5566 - val_loss: 0.5399\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5542 - val_loss: 0.5386\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5520 - val_loss: 0.5373\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5498 - val_loss: 0.5360\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5476 - val_loss: 0.5346\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5455 - val_loss: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5435 - val_loss: 0.5320\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5415 - val_loss: 0.5307\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5395 - val_loss: 0.5295\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5376 - val_loss: 0.5283\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5357 - val_loss: 0.5272\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5338 - val_loss: 0.5260\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5319 - val_loss: 0.5250\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5300 - val_loss: 0.5239\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=64, result_data[0].shape=(15, 65)\n",
      "Before prediction: train_X.shape=(3, 10, 65), train_y.shape=(3, 65), test_X.shape=(1, 10, 65), test_y.shape=(1, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2477 - val_loss: 0.2905\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2471 - val_loss: 0.2901\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2465 - val_loss: 0.2897\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2458 - val_loss: 0.2893\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2452 - val_loss: 0.2889\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2446 - val_loss: 0.2885\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2440 - val_loss: 0.2881\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2434 - val_loss: 0.2877\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2428 - val_loss: 0.2873\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2422 - val_loss: 0.2868\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2416 - val_loss: 0.2864\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2410 - val_loss: 0.2860\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2404 - val_loss: 0.2856\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2399 - val_loss: 0.2852\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2393 - val_loss: 0.2848\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2388 - val_loss: 0.2845\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2382 - val_loss: 0.2842\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2377 - val_loss: 0.2839\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2371 - val_loss: 0.2836\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2366 - val_loss: 0.2833\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2361 - val_loss: 0.2830\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2355 - val_loss: 0.2827\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2350 - val_loss: 0.2825\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2345 - val_loss: 0.2822\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2340 - val_loss: 0.2820\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2335 - val_loss: 0.2817\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2330 - val_loss: 0.2815\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2326 - val_loss: 0.2814\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2321 - val_loss: 0.2812\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2316 - val_loss: 0.2811\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2311 - val_loss: 0.2810\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2307 - val_loss: 0.2809\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2302 - val_loss: 0.2807\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2298 - val_loss: 0.2806\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2293 - val_loss: 0.2804\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2289 - val_loss: 0.2803\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2285 - val_loss: 0.2801\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2280 - val_loss: 0.2799\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2276 - val_loss: 0.2798\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2271 - val_loss: 0.2796\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=85, result_data[0].shape=(113, 65)\n",
      "Before prediction: train_X.shape=(62, 10, 65), train_y.shape=(62, 65), test_X.shape=(21, 10, 65), test_y.shape=(21, 65)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3744 - val_loss: 0.4214\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3740 - val_loss: 0.4213\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3736 - val_loss: 0.4212\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3732 - val_loss: 0.4211\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3728 - val_loss: 0.4210\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3724 - val_loss: 0.4209\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3720 - val_loss: 0.4208\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3716 - val_loss: 0.4207\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3712 - val_loss: 0.4206\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3708 - val_loss: 0.4205\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3704 - val_loss: 0.4204\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3700 - val_loss: 0.4203\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3697 - val_loss: 0.4202\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3693 - val_loss: 0.4201\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3689 - val_loss: 0.4200\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3686 - val_loss: 0.4199\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3682 - val_loss: 0.4198\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3678 - val_loss: 0.4197\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3675 - val_loss: 0.4196\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3671 - val_loss: 0.4195\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3668 - val_loss: 0.4194\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3664 - val_loss: 0.4193\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3661 - val_loss: 0.4192\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3657 - val_loss: 0.4191\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3654 - val_loss: 0.4190\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3650 - val_loss: 0.4189\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3647 - val_loss: 0.4188\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3644 - val_loss: 0.4188\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3641 - val_loss: 0.4187\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3637 - val_loss: 0.4186\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3634 - val_loss: 0.4185\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3631 - val_loss: 0.4184\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3628 - val_loss: 0.4183\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3624 - val_loss: 0.4182\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3621 - val_loss: 0.4181\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3618 - val_loss: 0.4180\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3615 - val_loss: 0.4180\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3612 - val_loss: 0.4179\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3609 - val_loss: 0.4178\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3606 - val_loss: 0.4177\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "In transform\n",
      " -> in transform: len(result_data)=10, result_data[0].shape=(3257, 65)\n",
      "Before prediction: train_X.shape=(1948, 10, 65), train_y.shape=(1948, 65), test_X.shape=(649, 10, 65), test_y.shape=(649, 65)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1218 - val_loss: 0.0941\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1166 - val_loss: 0.0919\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1123 - val_loss: 0.0903\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1088 - val_loss: 0.0892\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.1057 - val_loss: 0.0883\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1030 - val_loss: 0.0877\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1006 - val_loss: 0.0872\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0985 - val_loss: 0.0867\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0965 - val_loss: 0.0863\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0947 - val_loss: 0.0859\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0930 - val_loss: 0.0856\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0915 - val_loss: 0.0852\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0901 - val_loss: 0.0850\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0888 - val_loss: 0.0847\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0876 - val_loss: 0.0845\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0865 - val_loss: 0.0843\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.0854 - val_loss: 0.0841\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0845 - val_loss: 0.0839\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0836 - val_loss: 0.0837\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0827 - val_loss: 0.0836\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0819 - val_loss: 0.0834\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0811 - val_loss: 0.0833\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0804 - val_loss: 0.0831\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0798 - val_loss: 0.0830\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0791 - val_loss: 0.0828\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0785 - val_loss: 0.0827\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0780 - val_loss: 0.0826\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.0775 - val_loss: 0.0824\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0769 - val_loss: 0.0823\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0765 - val_loss: 0.0822\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0760 - val_loss: 0.0821\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0756 - val_loss: 0.0820\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0751 - val_loss: 0.0819\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.0747 - val_loss: 0.0818\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0743 - val_loss: 0.0818\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0740 - val_loss: 0.0817\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0736 - val_loss: 0.0816\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.0733 - val_loss: 0.0816\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.0730 - val_loss: 0.0815\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0727 - val_loss: 0.0814\n",
      "21/21 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"N_clusters\":Ns_clusters, \"window_size_for_clustering\":window_sizes_for_clustering, \"dif\":True}\n",
    "models, model_mase = Forecasting.try_parameters(parameters, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [<keras.engine.sequential.Sequential at 0x7fec7c41cbe0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7fecb25f9d30>,\n",
       "  <keras.engine.sequential.Sequential at 0x7fec99c3c490>,\n",
       "  <keras.engine.sequential.Sequential at 0x7fecae055250>,\n",
       "  <keras.engine.sequential.Sequential at 0x7fec99c14f40>,\n",
       "  <keras.engine.sequential.Sequential at 0x7fec742ef9d0>,\n",
       "  <keras.engine.sequential.Sequential at 0x7fecafd38250>,\n",
       "  <keras.engine.sequential.Sequential at 0x7fec99c3f550>,\n",
       "  <keras.engine.sequential.Sequential at 0x7fecafb01be0>],\n",
       " 'scalers': [<Forecasting.MyStandardScaler at 0x7fec7441dc10>,\n",
       "  <Forecasting.MyStandardScaler at 0x7fec7c428370>,\n",
       "  <Forecasting.MyStandardScaler at 0x7fecb291c1f0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7fec99a73eb0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7fecafd51340>,\n",
       "  <Forecasting.MyStandardScaler at 0x7fecafafab80>,\n",
       "  <Forecasting.MyStandardScaler at 0x7fecb2892970>,\n",
       "  <Forecasting.MyStandardScaler at 0x7fec7c43fdf0>,\n",
       "  <Forecasting.MyStandardScaler at 0x7fec743c9520>],\n",
       " 'clusters_model': KMeans(init='random', max_iter=100, n_clusters=9)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_55_layer_call_fn, lstm_cell_55_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/0/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_56_layer_call_fn, lstm_cell_56_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/1/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_57_layer_call_fn, lstm_cell_57_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_58_layer_call_fn, lstm_cell_58_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/3/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_59_layer_call_fn, lstm_cell_59_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/4/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_60_layer_call_fn, lstm_cell_60_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/5/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_61_layer_call_fn, lstm_cell_61_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/6/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_62_layer_call_fn, lstm_cell_62_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/7/assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_63_layer_call_fn, lstm_cell_63_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models['models'])):\n",
    "    models['models'][i].save(\"models/\"+str(i))\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "tmp_model = keras.models.load_model('models/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530569945.8690366"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_model = models[\"clusters_model\"]\n",
    "forecasting_models = models['models']\n",
    "scalers = models['scalers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Forecasting' from '/home/grinenko/anna/time_series/Forecasting.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Clustering, Forecasting\n",
    "importlib.reload(Clustering)\n",
    "importlib.reload(Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 10, 15]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_sizes_for_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.shape=(81619, 65), dataset_windows.shape=(81604, 975), cluster_nums.shape=(81604,), 15\n",
      "After pad: dataset.shape=(81619, 65), cluster_nums.shape=(81619,)\n",
      "dataset_windows.shape=(81609, 1, 11, 65)\n",
      "cluster_nums.shape=(81609,)\n",
      "cur_windows.shape=(512, 11, 65)\n",
      "N=1, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=512, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(512, 10, 65)\n",
      "cur_windows.shape=(45889, 11, 65)\n",
      "N=2, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=45889, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(45889, 10, 65)\n",
      "cur_windows.shape=(719, 11, 65)\n",
      "N=3, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=719, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(719, 10, 65)\n",
      "cur_windows.shape=(31288, 11, 65)\n",
      "N=4, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=31288, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(31288, 10, 65)\n",
      "cur_windows.shape=(1072, 11, 65)\n",
      "N=6, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=1072, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(1072, 10, 65)\n",
      "cur_windows.shape=(2129, 11, 65)\n",
      "N=8, len(scalers)=9\n",
      "In transform\n",
      " -> in transform: len(result_data)=2129, result_data[0].shape=(10, 65)\n",
      "cur_windows.shape=(2129, 10, 65)\n"
     ]
    }
   ],
   "source": [
    "window_size_for_clustering = clusters_model.cluster_centers_.shape[-1] // dataset_test.shape[-1]\n",
    "y_pred = Forecasting.predict_through_clusters(dataset_test, clusters_model, forecasting_models, scalers, window_size_clustering=window_size_for_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81609, 65)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape=(81609, 65), dataset_test.shape=(81619, 65)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{y_pred.shape=}, {dataset_test.shape=}\")\n",
    "y_true = dataset_test[-y_pred.shape[0]:]\n",
    "cur_mase = Forecasting.my_mase(y_true, y_pred, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mase[cur_mase <= np.percentile(cur_mase, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MASE\")\n",
    "plt.title(\"50% best MASE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cur_mape = mape(y_true, y_pred)\n",
    "plt.plot(cur_mape[cur_mape < np.percentile(cur_mape, 50)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"50% best MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cur_mape[cur_mape <= np.percentile(cur_mape,100)])\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"MAPE\")\n",
    "plt.title(\"MAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 67), dtype=float32, numpy=\n",
       "array([[ 8.25200696e-04, -2.52360152e-03,  1.24429585e-03,\n",
       "         5.61252143e-03,  2.41480279e-03,  6.91283401e-03,\n",
       "        -1.55929942e-04,  5.05245430e-03, -3.45375156e-03,\n",
       "         2.31756223e-03, -5.02947718e-03,  5.21133933e-03,\n",
       "         2.63487943e-03, -1.15680450e-03, -8.61713605e-04,\n",
       "        -4.27721906e-03,  1.65054473e-04,  1.98029215e-03,\n",
       "         1.16372411e-03, -6.18001819e-03,  1.38662616e-03,\n",
       "        -3.87507980e-03, -5.78831602e-03, -4.70064487e-03,\n",
       "        -4.91938740e-03, -9.45061352e-03, -6.37044199e-03,\n",
       "        -1.24200690e-03, -2.50279880e-03,  6.26629405e-03,\n",
       "         7.07075465e-03,  4.37504100e-03,  8.11321661e-06,\n",
       "         6.27311785e-03, -2.45433138e-03,  6.55709300e-04,\n",
       "         1.01655931e-03,  3.92863574e-03, -7.48858880e-03,\n",
       "        -3.09383660e-03, -3.60715576e-03,  3.58439516e-04,\n",
       "         5.01208124e-04,  4.94992966e-03,  4.09077760e-03,\n",
       "        -1.00721011e-03, -6.26226794e-03, -6.27841754e-03,\n",
       "         5.10353828e-03,  4.80458234e-03, -2.42970185e-03,\n",
       "         3.23574082e-03,  4.15166654e-03,  1.97961787e-03,\n",
       "         2.42814887e-03, -2.23055086e-03, -2.55294633e-03,\n",
       "        -3.07056517e-03, -7.46782962e-03,  4.13405150e-03,\n",
       "         4.82963771e-03,  6.89104025e-04, -1.09297456e-04,\n",
       "         3.91600234e-03, -8.97214864e-04, -1.08612701e-03,\n",
       "         4.65779193e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.zeros(67 * 10).reshape(1, 10, 67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=2, 2, 22, (30608, 67)\n",
      "Before prediction: train_X.shape=(18358, 10, 67), train_y.shape=(18358, 67), test_X.shape=(6119, 10, 67), test_y.shape=(6119, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3112 - val_loss: 0.3270\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2915 - val_loss: 0.3111\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2761 - val_loss: 0.2987\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2646 - val_loss: 0.2898\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2564 - val_loss: 0.2830\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2504 - val_loss: 0.2777\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2456 - val_loss: 0.2732\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2415 - val_loss: 0.2694\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2378 - val_loss: 0.2660\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2345 - val_loss: 0.2630\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2314 - val_loss: 0.2603\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2286 - val_loss: 0.2579\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2262 - val_loss: 0.2559\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2241 - val_loss: 0.2541\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2222 - val_loss: 0.2526\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2206 - val_loss: 0.2513\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2191 - val_loss: 0.2500\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2179 - val_loss: 0.2489\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2167 - val_loss: 0.2478\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2156 - val_loss: 0.2470\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2147 - val_loss: 0.2461\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2138 - val_loss: 0.2453\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2129 - val_loss: 0.2444\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2122 - val_loss: 0.2439\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2115 - val_loss: 0.2432\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2109 - val_loss: 0.2427\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2103 - val_loss: 0.2421\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2097 - val_loss: 0.2416\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2092 - val_loss: 0.2410\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2087 - val_loss: 0.2407\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2082 - val_loss: 0.2401\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2397\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2073 - val_loss: 0.2394\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2069 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2065 - val_loss: 0.2386\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2062 - val_loss: 0.2382\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2058 - val_loss: 0.2380\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2055 - val_loss: 0.2376\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2052 - val_loss: 0.2373\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2049 - val_loss: 0.2370\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6119, 67), test_y.shape=(6119, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1578.0531622950014, my average MASE = 2807.2183134542065\n",
      "Cluster 0, 1578.0531622950014\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4317 - val_loss: 1.2280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4299 - val_loss: 1.2276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4282 - val_loss: 1.2273\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4264 - val_loss: 1.2269\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4247 - val_loss: 1.2266\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 1.2263\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 1.2259\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4198 - val_loss: 1.2256\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4182 - val_loss: 1.2253\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4166 - val_loss: 1.2251\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4151 - val_loss: 1.2248\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4135 - val_loss: 1.2245\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4120 - val_loss: 1.2242\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4105 - val_loss: 1.2239\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4089 - val_loss: 1.2236\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4074 - val_loss: 1.2233\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4060 - val_loss: 1.2229\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4045 - val_loss: 1.2226\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 1.2223\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4017 - val_loss: 1.2220\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4004 - val_loss: 1.2216\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3990 - val_loss: 1.2213\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3977 - val_loss: 1.2210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3964 - val_loss: 1.2207\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3951 - val_loss: 1.2204\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3938 - val_loss: 1.2201\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3926 - val_loss: 1.2198\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3914 - val_loss: 1.2195\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3901 - val_loss: 1.2192\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3889 - val_loss: 1.2189\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3877 - val_loss: 1.2186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3866 - val_loss: 1.2184\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 1.2181\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3842 - val_loss: 1.2178\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3831 - val_loss: 1.2175\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 1.2173\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3809 - val_loss: 1.2170\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3798 - val_loss: 1.2167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3787 - val_loss: 1.2165\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3776 - val_loss: 1.2162\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 708619678.5307182, my average MASE = 1911068024.4320867\n",
      "Cluster 1, 708619678.5307182\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=5, 5, 1026, (269, 67)\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5683 - val_loss: 0.4789\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5669 - val_loss: 0.4779\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5656 - val_loss: 0.4770\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5643 - val_loss: 0.4760\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5631 - val_loss: 0.4751\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5619 - val_loss: 0.4743\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5607 - val_loss: 0.4734\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5595 - val_loss: 0.4726\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5584 - val_loss: 0.4718\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5573 - val_loss: 0.4710\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5562 - val_loss: 0.4702\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5552 - val_loss: 0.4694\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5542 - val_loss: 0.4687\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5532 - val_loss: 0.4679\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5522 - val_loss: 0.4672\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5512 - val_loss: 0.4665\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5502 - val_loss: 0.4658\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5493 - val_loss: 0.4651\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5483 - val_loss: 0.4644\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5474 - val_loss: 0.4637\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5465 - val_loss: 0.4630\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5456 - val_loss: 0.4624\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5447 - val_loss: 0.4617\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5438 - val_loss: 0.4611\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5429 - val_loss: 0.4605\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5421 - val_loss: 0.4598\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5412 - val_loss: 0.4592\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5404 - val_loss: 0.4586\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5396 - val_loss: 0.4579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5388 - val_loss: 0.4573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5379 - val_loss: 0.4567\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5371 - val_loss: 0.4561\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5363 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5355 - val_loss: 0.4549\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5348 - val_loss: 0.4543\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5340 - val_loss: 0.4538\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5332 - val_loss: 0.4532\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5324 - val_loss: 0.4526\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5317 - val_loss: 0.4521\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5309 - val_loss: 0.4515\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.40868807431647, my average MASE = 112470179.11258063\n",
      "Cluster 0, 139.40868807431647\n",
      "Before prediction: train_X.shape=(31, 10, 67), train_y.shape=(31, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3364 - val_loss: 0.3469\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3360 - val_loss: 0.3468\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3355 - val_loss: 0.3468\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3350 - val_loss: 0.3467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3346 - val_loss: 0.3466\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3341 - val_loss: 0.3465\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3337 - val_loss: 0.3464\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3332 - val_loss: 0.3463\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3328 - val_loss: 0.3463\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3323 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3319 - val_loss: 0.3461\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3315 - val_loss: 0.3460\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3310 - val_loss: 0.3459\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3306 - val_loss: 0.3458\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3302 - val_loss: 0.3457\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3298 - val_loss: 0.3457\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3294 - val_loss: 0.3456\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3290 - val_loss: 0.3455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3286 - val_loss: 0.3454\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3282 - val_loss: 0.3453\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3278 - val_loss: 0.3453\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3274 - val_loss: 0.3452\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3270 - val_loss: 0.3451\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3267 - val_loss: 0.3450\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3263 - val_loss: 0.3450\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3259 - val_loss: 0.3449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3255 - val_loss: 0.3448\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3252 - val_loss: 0.3448\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3248 - val_loss: 0.3447\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3245 - val_loss: 0.3446\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3242 - val_loss: 0.3445\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3238 - val_loss: 0.3445\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3235 - val_loss: 0.3444\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3231 - val_loss: 0.3443\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3228 - val_loss: 0.3443\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3225 - val_loss: 0.3442\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3222 - val_loss: 0.3441\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3440\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3216 - val_loss: 0.3440\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3213 - val_loss: 0.3439\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3523641.3982873675, my average MASE = 66808534.66599488\n",
      "Cluster 1, 3523641.3982873675\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1130 - val_loss: 0.1021\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1076 - val_loss: 0.1000\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1032 - val_loss: 0.0984\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0995 - val_loss: 0.0974\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0964 - val_loss: 0.0968\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0912 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0889 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0869 - val_loss: 0.0951\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0834 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0804 - val_loss: 0.0940\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0791 - val_loss: 0.0938\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0936\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0934\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0757 - val_loss: 0.0933\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0748 - val_loss: 0.0931\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0739 - val_loss: 0.0930\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0730 - val_loss: 0.0929\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0722 - val_loss: 0.0927\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0926\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0707 - val_loss: 0.0925\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0701 - val_loss: 0.0924\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0694 - val_loss: 0.0923\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0922\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0922\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0677 - val_loss: 0.0922\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0672 - val_loss: 0.0921\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0921\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0663 - val_loss: 0.0920\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0919\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0656 - val_loss: 0.0919\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0918\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0918\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0646 - val_loss: 0.0917\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0638 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0635 - val_loss: 0.0915\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 869790828.2820631, my average MASE = 17262168691.962505\n",
      "Cluster 2, 869790828.2820631\n",
      "Before prediction: train_X.shape=(2219, 10, 67), train_y.shape=(2219, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5462 - val_loss: 0.4045\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5391 - val_loss: 0.4010\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5333 - val_loss: 0.3979\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5281 - val_loss: 0.3951\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5234 - val_loss: 0.3925\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5190 - val_loss: 0.3900\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5147 - val_loss: 0.3877\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5107 - val_loss: 0.3856\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.5068 - val_loss: 0.3835\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5031 - val_loss: 0.3816\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4996 - val_loss: 0.3797\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4961 - val_loss: 0.3780\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4928 - val_loss: 0.3763\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4896 - val_loss: 0.3747\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4865 - val_loss: 0.3732\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4835 - val_loss: 0.3717\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4806 - val_loss: 0.3704\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4778 - val_loss: 0.3691\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4750 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4723 - val_loss: 0.3666\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4697 - val_loss: 0.3655\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4672 - val_loss: 0.3644\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4647 - val_loss: 0.3633\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4623 - val_loss: 0.3624\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4600 - val_loss: 0.3614\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4577 - val_loss: 0.3605\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4556 - val_loss: 0.3596\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4535 - val_loss: 0.3588\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4515 - val_loss: 0.3580\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4495 - val_loss: 0.3572\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4476 - val_loss: 0.3564\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4458 - val_loss: 0.3557\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4440 - val_loss: 0.3551\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4423 - val_loss: 0.3544\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4406 - val_loss: 0.3538\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4390 - val_loss: 0.3532\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4374 - val_loss: 0.3525\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4359 - val_loss: 0.3519\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4343 - val_loss: 0.3514\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4329 - val_loss: 0.3508\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 408.78828000932964, my average MASE = 1218.6998180420371\n",
      "Cluster 3, 408.78828000932964\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5668 - val_loss: 0.4468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5648 - val_loss: 0.4459\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5628 - val_loss: 0.4451\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5609 - val_loss: 0.4443\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5589 - val_loss: 0.4435\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5570 - val_loss: 0.4427\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5551 - val_loss: 0.4419\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5533 - val_loss: 0.4412\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5514 - val_loss: 0.4404\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5496 - val_loss: 0.4397\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5478 - val_loss: 0.4389\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5460 - val_loss: 0.4382\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5442 - val_loss: 0.4374\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5425 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5408 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5391 - val_loss: 0.4352\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5374 - val_loss: 0.4344\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5358 - val_loss: 0.4337\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5342 - val_loss: 0.4329\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.4322\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5310 - val_loss: 0.4315\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5295 - val_loss: 0.4308\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5280 - val_loss: 0.4300\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5264 - val_loss: 0.4293\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5250 - val_loss: 0.4286\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5235 - val_loss: 0.4279\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5221 - val_loss: 0.4273\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5207 - val_loss: 0.4266\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5193 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5179 - val_loss: 0.4254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5165 - val_loss: 0.4248\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5151 - val_loss: 0.4241\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5138 - val_loss: 0.4235\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5125 - val_loss: 0.4229\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5112 - val_loss: 0.4223\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5099 - val_loss: 0.4217\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5086 - val_loss: 0.4212\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5073 - val_loss: 0.4206\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5061 - val_loss: 0.4200\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5048 - val_loss: 0.4194\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2631402082.882854, my average MASE = 5288471031.0194235\n",
      "Cluster 4, 2631402082.882854\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=7, 7, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1149 - val_loss: 0.1029\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1092 - val_loss: 0.1008\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1047 - val_loss: 0.0992\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1009 - val_loss: 0.0980\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0972\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0947 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0922 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0899 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0878 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0859 - val_loss: 0.0948\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0842 - val_loss: 0.0945\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0826 - val_loss: 0.0942\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0812 - val_loss: 0.0939\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0799 - val_loss: 0.0936\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0934\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0775 - val_loss: 0.0931\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0929\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0755 - val_loss: 0.0928\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0746 - val_loss: 0.0926\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0737 - val_loss: 0.0924\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0923\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0922\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0921\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0708 - val_loss: 0.0920\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0919\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0696 - val_loss: 0.0918\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0690 - val_loss: 0.0917\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0685 - val_loss: 0.0916\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0680 - val_loss: 0.0916\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0675 - val_loss: 0.0915\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0670 - val_loss: 0.0915\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0666 - val_loss: 0.0915\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0662 - val_loss: 0.0914\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0658 - val_loss: 0.0914\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0654 - val_loss: 0.0913\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0651 - val_loss: 0.0913\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0648 - val_loss: 0.0912\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0645 - val_loss: 0.0912\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0642 - val_loss: 0.0911\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0911\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 1397145651.915293, my average MASE = 8779028319.064796\n",
      "Cluster 0, 1397145651.915293\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4446 - val_loss: 0.4248\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.4440 - val_loss: 0.4245\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4434 - val_loss: 0.4242\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4429 - val_loss: 0.4239\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4423 - val_loss: 0.4236\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4418 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4413 - val_loss: 0.4231\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4408 - val_loss: 0.4228\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4403 - val_loss: 0.4226\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4398 - val_loss: 0.4223\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4393 - val_loss: 0.4221\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4388 - val_loss: 0.4219\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4383 - val_loss: 0.4216\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4378 - val_loss: 0.4214\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4212\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4369 - val_loss: 0.4209\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4364 - val_loss: 0.4207\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4360 - val_loss: 0.4205\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4355 - val_loss: 0.4202\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4351 - val_loss: 0.4200\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4346 - val_loss: 0.4198\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4342 - val_loss: 0.4195\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.4193\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4333 - val_loss: 0.4191\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4329 - val_loss: 0.4189\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4325 - val_loss: 0.4187\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4321 - val_loss: 0.4184\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4317 - val_loss: 0.4182\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4313 - val_loss: 0.4180\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4309 - val_loss: 0.4178\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4305 - val_loss: 0.4176\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4301 - val_loss: 0.4175\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4297 - val_loss: 0.4173\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4293 - val_loss: 0.4171\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4289 - val_loss: 0.4169\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4286 - val_loss: 0.4167\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4282 - val_loss: 0.4165\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4278 - val_loss: 0.4163\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4274 - val_loss: 0.4161\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4271 - val_loss: 0.4159\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 86.00366340249806, my average MASE = 69691247.07168306\n",
      "Cluster 1, 86.00366340249806\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9826 - val_loss: 1.3468\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9801 - val_loss: 1.3460\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9776 - val_loss: 1.3453\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9751 - val_loss: 1.3446\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9726 - val_loss: 1.3439\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9701 - val_loss: 1.3432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9677 - val_loss: 1.3425\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9653 - val_loss: 1.3419\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9628 - val_loss: 1.3413\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9604 - val_loss: 1.3408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9580 - val_loss: 1.3402\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9556 - val_loss: 1.3396\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9532 - val_loss: 1.3390\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9508 - val_loss: 1.3384\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9486 - val_loss: 1.3379\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9463 - val_loss: 1.3374\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9440 - val_loss: 1.3368\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9418 - val_loss: 1.3363\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9397 - val_loss: 1.3358\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9375 - val_loss: 1.3352\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9353 - val_loss: 1.3347\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9331 - val_loss: 1.3341\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9309 - val_loss: 1.3337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9287 - val_loss: 1.3332\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9266 - val_loss: 1.3328\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9245 - val_loss: 1.3324\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9224 - val_loss: 1.3321\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9203 - val_loss: 1.3317\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9183 - val_loss: 1.3314\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9162 - val_loss: 1.3311\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9141 - val_loss: 1.3308\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.9120 - val_loss: 1.3305\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.9100 - val_loss: 1.3303\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9079 - val_loss: 1.3300\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9059 - val_loss: 1.3298\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9039 - val_loss: 1.3295\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9019 - val_loss: 1.3293\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9000 - val_loss: 1.3291\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8981 - val_loss: 1.3288\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8963 - val_loss: 1.3286\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1.6636413128548868, my average MASE = 8.526439257891766\n",
      "Cluster 2, 1.6636413128548868\n",
      "Before prediction: train_X.shape=(177, 10, 67), train_y.shape=(177, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7327 - val_loss: 0.5966\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7311 - val_loss: 0.5956\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7296 - val_loss: 0.5946\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7281 - val_loss: 0.5936\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7266 - val_loss: 0.5927\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7252 - val_loss: 0.5918\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7239 - val_loss: 0.5909\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7225 - val_loss: 0.5901\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7212 - val_loss: 0.5892\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7199 - val_loss: 0.5884\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7186 - val_loss: 0.5875\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7174 - val_loss: 0.5867\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7162 - val_loss: 0.5859\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7150 - val_loss: 0.5852\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7138 - val_loss: 0.5844\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7127 - val_loss: 0.5837\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7116 - val_loss: 0.5829\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7104 - val_loss: 0.5822\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7093 - val_loss: 0.5815\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7082 - val_loss: 0.5808\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7071 - val_loss: 0.5801\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7061 - val_loss: 0.5794\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7050 - val_loss: 0.5788\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7040 - val_loss: 0.5781\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7030 - val_loss: 0.5775\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7020 - val_loss: 0.5768\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7010 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7000 - val_loss: 0.5756\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6990 - val_loss: 0.5750\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6981 - val_loss: 0.5744\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6971 - val_loss: 0.5738\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6962 - val_loss: 0.5732\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6953 - val_loss: 0.5726\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6944 - val_loss: 0.5721\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6935 - val_loss: 0.5715\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6925 - val_loss: 0.5710\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6917 - val_loss: 0.5704\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6908 - val_loss: 0.5699\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6899 - val_loss: 0.5694\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6890 - val_loss: 0.5688\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 148.95203283848892, my average MASE = 195949093.5023566\n",
      "Cluster 3, 148.95203283848892\n",
      "Before prediction: train_X.shape=(59, 10, 67), train_y.shape=(59, 67), test_X.shape=(20, 10, 67), test_y.shape=(20, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4242 - val_loss: 0.4717\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4237 - val_loss: 0.4716\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4715\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4228 - val_loss: 0.4714\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4223 - val_loss: 0.4713\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4219 - val_loss: 0.4712\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4214 - val_loss: 0.4711\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4210 - val_loss: 0.4710\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.4709\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4201 - val_loss: 0.4708\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4197 - val_loss: 0.4707\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4193 - val_loss: 0.4706\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4189 - val_loss: 0.4705\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.4705\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4180 - val_loss: 0.4704\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4176 - val_loss: 0.4703\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4702\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4168 - val_loss: 0.4701\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4164 - val_loss: 0.4700\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4160 - val_loss: 0.4699\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4157 - val_loss: 0.4698\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4153 - val_loss: 0.4698\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4149 - val_loss: 0.4697\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4145 - val_loss: 0.4696\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4141 - val_loss: 0.4695\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4138 - val_loss: 0.4694\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4134 - val_loss: 0.4694\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4130 - val_loss: 0.4693\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4127 - val_loss: 0.4692\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4123 - val_loss: 0.4691\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4119 - val_loss: 0.4690\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4116 - val_loss: 0.4690\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4112 - val_loss: 0.4689\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.4688\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4105 - val_loss: 0.4687\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4101 - val_loss: 0.4687\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4098 - val_loss: 0.4686\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4094 - val_loss: 0.4685\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4091 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4087 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(20, 67), test_y.shape=(20, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 138.4214035546147, my average MASE = 76438634.40084383\n",
      "Cluster 4, 138.4214035546147\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4144 - val_loss: 0.4072\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4116 - val_loss: 0.4056\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4089 - val_loss: 0.4039\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4061 - val_loss: 0.4022\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4034 - val_loss: 0.4005\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4008 - val_loss: 0.3988\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3982 - val_loss: 0.3971\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3957 - val_loss: 0.3954\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3932 - val_loss: 0.3937\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3908 - val_loss: 0.3920\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3885 - val_loss: 0.3903\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3861 - val_loss: 0.3887\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3838 - val_loss: 0.3870\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3816 - val_loss: 0.3854\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3795 - val_loss: 0.3838\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3775 - val_loss: 0.3822\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3755 - val_loss: 0.3807\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3735 - val_loss: 0.3793\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3716 - val_loss: 0.3779\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3697 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3679 - val_loss: 0.3751\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3661 - val_loss: 0.3737\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3644 - val_loss: 0.3723\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3710\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3611 - val_loss: 0.3697\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3594 - val_loss: 0.3684\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3578 - val_loss: 0.3672\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3562 - val_loss: 0.3659\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3547 - val_loss: 0.3646\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3533 - val_loss: 0.3634\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.3621\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3506 - val_loss: 0.3608\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3493 - val_loss: 0.3596\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3481 - val_loss: 0.3583\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3468 - val_loss: 0.3571\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3456 - val_loss: 0.3558\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3443 - val_loss: 0.3546\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3431 - val_loss: 0.3534\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3419 - val_loss: 0.3521\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3407 - val_loss: 0.3509\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 697989181.1057402, my average MASE = 1714132782.1928625\n",
      "Cluster 5, 697989181.1057402\n",
      "Before prediction: train_X.shape=(95, 10, 67), train_y.shape=(95, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3944 - val_loss: 0.3555\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3937 - val_loss: 0.3552\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3930 - val_loss: 0.3549\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3924 - val_loss: 0.3546\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3917 - val_loss: 0.3543\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3910 - val_loss: 0.3540\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3904 - val_loss: 0.3537\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3898 - val_loss: 0.3534\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3892 - val_loss: 0.3532\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3886 - val_loss: 0.3529\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3880 - val_loss: 0.3526\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3874 - val_loss: 0.3523\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3868 - val_loss: 0.3520\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3863 - val_loss: 0.3518\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3857 - val_loss: 0.3515\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3852 - val_loss: 0.3512\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3846 - val_loss: 0.3510\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3841 - val_loss: 0.3507\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3835 - val_loss: 0.3504\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3830 - val_loss: 0.3502\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3825 - val_loss: 0.3499\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3820 - val_loss: 0.3496\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3815 - val_loss: 0.3494\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3810 - val_loss: 0.3491\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3805 - val_loss: 0.3489\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3799 - val_loss: 0.3486\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3795 - val_loss: 0.3484\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3790 - val_loss: 0.3481\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3785 - val_loss: 0.3479\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.3476\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3776 - val_loss: 0.3474\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3771 - val_loss: 0.3471\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3767 - val_loss: 0.3469\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3762 - val_loss: 0.3466\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3758 - val_loss: 0.3464\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3753 - val_loss: 0.3461\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3749 - val_loss: 0.3459\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3745 - val_loss: 0.3456\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3740 - val_loss: 0.3454\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3736 - val_loss: 0.3451\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 265.33452450872096, my average MASE = 56598015.30805221\n",
      "Cluster 6, 265.33452450872096\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=9, 9, 1486, (3, 67)\n",
      "Before prediction: train_X.shape=(97, 10, 67), train_y.shape=(97, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4153 - val_loss: 0.4398\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.4396\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4138 - val_loss: 0.4393\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4131 - val_loss: 0.4391\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4124 - val_loss: 0.4388\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4118 - val_loss: 0.4386\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4111 - val_loss: 0.4383\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4105 - val_loss: 0.4381\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4099 - val_loss: 0.4378\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4093 - val_loss: 0.4376\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4087 - val_loss: 0.4374\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4081 - val_loss: 0.4371\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.4369\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4069 - val_loss: 0.4367\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4064 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4058 - val_loss: 0.4362\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.4360\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4047 - val_loss: 0.4358\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4042 - val_loss: 0.4356\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4037 - val_loss: 0.4353\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4032 - val_loss: 0.4351\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4349\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4022 - val_loss: 0.4347\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4017 - val_loss: 0.4345\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4012 - val_loss: 0.4343\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4007 - val_loss: 0.4341\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4003 - val_loss: 0.4339\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3998 - val_loss: 0.4337\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3993 - val_loss: 0.4335\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3989 - val_loss: 0.4334\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3984 - val_loss: 0.4332\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3980 - val_loss: 0.4330\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3976 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3967 - val_loss: 0.4324\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3963 - val_loss: 0.4322\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4320\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3955 - val_loss: 0.4318\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3950 - val_loss: 0.4316\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.4314\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 106.62824359839709, my average MASE = 181907103.45341906\n",
      "Cluster 0, 106.62824359839709\n",
      "Before prediction: train_X.shape=(1415, 10, 67), train_y.shape=(1415, 67), test_X.shape=(472, 10, 67), test_y.shape=(472, 67)\n",
      "Epoch 1/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.1435 - val_loss: 0.0272\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1388 - val_loss: 0.0264\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1347 - val_loss: 0.0256\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1311 - val_loss: 0.0250\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1278 - val_loss: 0.0244\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1249 - val_loss: 0.0239\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1221 - val_loss: 0.0234\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1196 - val_loss: 0.0231\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.1173 - val_loss: 0.0227\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 1s 33ms/step - loss: 0.1151 - val_loss: 0.0224\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1132 - val_loss: 0.0221\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.1113 - val_loss: 0.0220\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1096 - val_loss: 0.0217\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1080 - val_loss: 0.0216\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1065 - val_loss: 0.0214\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1051 - val_loss: 0.0212\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.1038 - val_loss: 0.0211\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1026 - val_loss: 0.0209\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1014 - val_loss: 0.0208\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.1004 - val_loss: 0.0206\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0993 - val_loss: 0.0206\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0983 - val_loss: 0.0205\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0974 - val_loss: 0.0204\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0965 - val_loss: 0.0202\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0957 - val_loss: 0.0201\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 1s 32ms/step - loss: 0.0949 - val_loss: 0.0200\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0941 - val_loss: 0.0200\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0934 - val_loss: 0.0199\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0927 - val_loss: 0.0198\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0920 - val_loss: 0.0197\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0914 - val_loss: 0.0197\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0907 - val_loss: 0.0196\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0902 - val_loss: 0.0195\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0896 - val_loss: 0.0195\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0890 - val_loss: 0.0195\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0885 - val_loss: 0.0194\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0880 - val_loss: 0.0194\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 1s 31ms/step - loss: 0.0875 - val_loss: 0.0193\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0871 - val_loss: 0.0194\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.0867 - val_loss: 0.0193\n",
      "15/15 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(472, 67), test_y.shape=(472, 67)\n",
      "average MASE = 484561401.3912065, my average MASE = 2109803098.5295365\n",
      "Cluster 1, 484561401.3912065\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4184 - val_loss: 0.4085\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4174 - val_loss: 0.4084\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4165 - val_loss: 0.4083\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4155 - val_loss: 0.4082\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4146 - val_loss: 0.4082\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4136 - val_loss: 0.4081\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4127 - val_loss: 0.4080\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4118 - val_loss: 0.4079\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4109 - val_loss: 0.4078\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4100 - val_loss: 0.4077\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4091 - val_loss: 0.4077\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4083 - val_loss: 0.4076\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4074 - val_loss: 0.4075\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4066 - val_loss: 0.4074\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4057 - val_loss: 0.4074\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4049 - val_loss: 0.4073\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4041 - val_loss: 0.4072\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4033 - val_loss: 0.4071\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4025 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4017 - val_loss: 0.4069\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4009 - val_loss: 0.4069\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4001 - val_loss: 0.4068\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3994 - val_loss: 0.4067\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3986 - val_loss: 0.4066\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3979 - val_loss: 0.4065\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3971 - val_loss: 0.4065\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3964 - val_loss: 0.4064\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3957 - val_loss: 0.4063\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3949 - val_loss: 0.4062\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3942 - val_loss: 0.4062\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3936 - val_loss: 0.4061\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3929 - val_loss: 0.4060\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3922 - val_loss: 0.4059\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4058\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3909 - val_loss: 0.4058\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3902 - val_loss: 0.4057\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3896 - val_loss: 0.4056\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3889 - val_loss: 0.4055\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3883 - val_loss: 0.4055\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3877 - val_loss: 0.4054\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 146.41485105295615, my average MASE = 90287364.09726365\n",
      "Cluster 2, 146.41485105295615\n",
      "Before prediction: train_X.shape=(32, 10, 67), train_y.shape=(32, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5429 - val_loss: 0.4489\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5408 - val_loss: 0.4477\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5388 - val_loss: 0.4466\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5367 - val_loss: 0.4454\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5348 - val_loss: 0.4443\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5328 - val_loss: 0.4432\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5308 - val_loss: 0.4421\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5289 - val_loss: 0.4410\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5270 - val_loss: 0.4399\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5251 - val_loss: 0.4389\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5232 - val_loss: 0.4378\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5214 - val_loss: 0.4368\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5195 - val_loss: 0.4357\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5177 - val_loss: 0.4347\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5159 - val_loss: 0.4336\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5140 - val_loss: 0.4326\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5123 - val_loss: 0.4316\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5105 - val_loss: 0.4306\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5087 - val_loss: 0.4296\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5069 - val_loss: 0.4287\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5052 - val_loss: 0.4277\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5034 - val_loss: 0.4268\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5017 - val_loss: 0.4258\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5000 - val_loss: 0.4249\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4983 - val_loss: 0.4240\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4967 - val_loss: 0.4230\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4950 - val_loss: 0.4221\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4934 - val_loss: 0.4212\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4918 - val_loss: 0.4204\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4903 - val_loss: 0.4195\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4887 - val_loss: 0.4186\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.4177\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4857 - val_loss: 0.4169\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4843 - val_loss: 0.4161\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4828 - val_loss: 0.4152\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4814 - val_loss: 0.4144\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4800 - val_loss: 0.4136\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4786 - val_loss: 0.4127\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4772 - val_loss: 0.4119\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4758 - val_loss: 0.4111\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1177081/3287276626.py:67: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(12, 10))\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3556660081.750684, my average MASE = 7865462670.190711\n",
      "Cluster 3, 3556660081.750684\n",
      "Before prediction: train_X.shape=(173, 10, 67), train_y.shape=(173, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7286 - val_loss: 0.5747\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7270 - val_loss: 0.5740\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7256 - val_loss: 0.5733\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7243 - val_loss: 0.5725\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7229 - val_loss: 0.5718\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7216 - val_loss: 0.5712\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7203 - val_loss: 0.5705\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7190 - val_loss: 0.5698\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7178 - val_loss: 0.5692\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7166 - val_loss: 0.5686\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7154 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7142 - val_loss: 0.5673\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7130 - val_loss: 0.5667\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7119 - val_loss: 0.5662\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7108 - val_loss: 0.5656\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7096 - val_loss: 0.5650\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7086 - val_loss: 0.5645\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.7075 - val_loss: 0.5639\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7064 - val_loss: 0.5634\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7054 - val_loss: 0.5629\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7044 - val_loss: 0.5624\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7034 - val_loss: 0.5619\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5614\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7014 - val_loss: 0.5609\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7004 - val_loss: 0.5604\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6995 - val_loss: 0.5599\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6986 - val_loss: 0.5595\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6976 - val_loss: 0.5590\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6967 - val_loss: 0.5585\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6958 - val_loss: 0.5581\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6949 - val_loss: 0.5576\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6940 - val_loss: 0.5571\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6931 - val_loss: 0.5567\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5562\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6914 - val_loss: 0.5558\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6905 - val_loss: 0.5553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6896 - val_loss: 0.5549\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6887 - val_loss: 0.5545\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6879 - val_loss: 0.5540\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5536\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 122.19340890523425, my average MASE = 115345826.80728418\n",
      "Cluster 4, 122.19340890523425\n",
      "Before prediction: train_X.shape=(1562, 10, 67), train_y.shape=(1562, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2392 - val_loss: 0.2772\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2287 - val_loss: 0.2673\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2207 - val_loss: 0.2595\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2144 - val_loss: 0.2534\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2094 - val_loss: 0.2481\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2050 - val_loss: 0.2435\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2013 - val_loss: 0.2394\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1978 - val_loss: 0.2357\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1947 - val_loss: 0.2322\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1919 - val_loss: 0.2289\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1892 - val_loss: 0.2259\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1867 - val_loss: 0.2231\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2204\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1821 - val_loss: 0.2179\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1800 - val_loss: 0.2156\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1761 - val_loss: 0.2114\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1743 - val_loss: 0.2096\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1727 - val_loss: 0.2078\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1712 - val_loss: 0.2062\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1698 - val_loss: 0.2047\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2033\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1672 - val_loss: 0.2020\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1661 - val_loss: 0.2007\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1650 - val_loss: 0.1996\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1640 - val_loss: 0.1985\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1631 - val_loss: 0.1974\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1622 - val_loss: 0.1964\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1614 - val_loss: 0.1954\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1598 - val_loss: 0.1936\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1578 - val_loss: 0.1912\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1572 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1566 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1560 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1554 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1549 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1544 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 151.79409601094594, my average MASE = 3866050940.760538\n",
      "Cluster 5, 151.79409601094594\n",
      "Before prediction: train_X.shape=(83, 10, 67), train_y.shape=(83, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4279 - val_loss: 0.5018\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4270 - val_loss: 0.5012\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4262 - val_loss: 0.5006\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4254 - val_loss: 0.5000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4246 - val_loss: 0.4995\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4239 - val_loss: 0.4989\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4231 - val_loss: 0.4984\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4224 - val_loss: 0.4978\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4217 - val_loss: 0.4973\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4968\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4203 - val_loss: 0.4962\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4197 - val_loss: 0.4958\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4191 - val_loss: 0.4953\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4184 - val_loss: 0.4948\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4178 - val_loss: 0.4943\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4172 - val_loss: 0.4939\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4167 - val_loss: 0.4934\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4161 - val_loss: 0.4930\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4155 - val_loss: 0.4926\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4150 - val_loss: 0.4921\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4144 - val_loss: 0.4917\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4139 - val_loss: 0.4913\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4133 - val_loss: 0.4908\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4128 - val_loss: 0.4904\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4123 - val_loss: 0.4900\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4118 - val_loss: 0.4895\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4113 - val_loss: 0.4891\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4107 - val_loss: 0.4887\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4103 - val_loss: 0.4883\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.4098 - val_loss: 0.4879\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4093 - val_loss: 0.4875\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4088 - val_loss: 0.4871\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4083 - val_loss: 0.4867\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4079 - val_loss: 0.4863\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4074 - val_loss: 0.4859\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4069 - val_loss: 0.4855\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4065 - val_loss: 0.4851\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4061 - val_loss: 0.4848\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4056 - val_loss: 0.4844\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4052 - val_loss: 0.4840\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 155.68618683798326, my average MASE = 97738271.39222205\n",
      "Cluster 6, 155.68618683798326\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2911 - val_loss: 0.2917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2907 - val_loss: 0.2915\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2902 - val_loss: 0.2913\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2897 - val_loss: 0.2911\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2892 - val_loss: 0.2909\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2888 - val_loss: 0.2907\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2883 - val_loss: 0.2905\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2878 - val_loss: 0.2903\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2874 - val_loss: 0.2901\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2869 - val_loss: 0.2899\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2865 - val_loss: 0.2898\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2861 - val_loss: 0.2896\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2856 - val_loss: 0.2894\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2852 - val_loss: 0.2892\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2848 - val_loss: 0.2890\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2844 - val_loss: 0.2889\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2840 - val_loss: 0.2887\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2836 - val_loss: 0.2885\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2832 - val_loss: 0.2883\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2828 - val_loss: 0.2882\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2824 - val_loss: 0.2880\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2820 - val_loss: 0.2878\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2816 - val_loss: 0.2877\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2812 - val_loss: 0.2875\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2808 - val_loss: 0.2874\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2804 - val_loss: 0.2872\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2800 - val_loss: 0.2870\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2796 - val_loss: 0.2869\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2793 - val_loss: 0.2867\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2789 - val_loss: 0.2865\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2785 - val_loss: 0.2864\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2781 - val_loss: 0.2862\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2778 - val_loss: 0.2861\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2774 - val_loss: 0.2859\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2770 - val_loss: 0.2858\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2767 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2763 - val_loss: 0.2855\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2759 - val_loss: 0.2853\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2756 - val_loss: 0.2852\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2752 - val_loss: 0.2851\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 112.24086700274312, my average MASE = 119826311.76187374\n",
      "Cluster 8, 112.24086700274312\n",
      "clusters_labels.shape=(408095,)\n",
      "N_clusters=11, 11, 17, (3243, 67)\n",
      "Before prediction: train_X.shape=(1939, 10, 67), train_y.shape=(1939, 67), test_X.shape=(646, 10, 67), test_y.shape=(646, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1118 - val_loss: 0.1019\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1064 - val_loss: 0.0996\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1022 - val_loss: 0.0982\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0987 - val_loss: 0.0973\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0956 - val_loss: 0.0966\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0930 - val_loss: 0.0962\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0958\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0885 - val_loss: 0.0954\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0866 - val_loss: 0.0952\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0848 - val_loss: 0.0949\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0832 - val_loss: 0.0946\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0818 - val_loss: 0.0944\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0804 - val_loss: 0.0941\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0792 - val_loss: 0.0939\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0780 - val_loss: 0.0937\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0769 - val_loss: 0.0936\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0759 - val_loss: 0.0934\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0749 - val_loss: 0.0933\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0740 - val_loss: 0.0932\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0732 - val_loss: 0.0931\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0724 - val_loss: 0.0929\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0716 - val_loss: 0.0928\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0927\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0926\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0696 - val_loss: 0.0926\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0690 - val_loss: 0.0925\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0924\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0923\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0674 - val_loss: 0.0923\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0922\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0921\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0662 - val_loss: 0.0921\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0658 - val_loss: 0.0920\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0919\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0651 - val_loss: 0.0919\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0648 - val_loss: 0.0918\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0645 - val_loss: 0.0917\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0642 - val_loss: 0.0917\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0640 - val_loss: 0.0916\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0637 - val_loss: 0.0916\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(646, 67), test_y.shape=(646, 67)\n",
      "average MASE = 876211806.5152007, my average MASE = 21477700395.128197\n",
      "Cluster 0, 876211806.5152007\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7012 - val_loss: 0.5689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7001 - val_loss: 0.5688\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6990 - val_loss: 0.5687\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6979 - val_loss: 0.5686\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6968 - val_loss: 0.5685\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6958 - val_loss: 0.5684\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6947 - val_loss: 0.5683\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6936 - val_loss: 0.5682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6926 - val_loss: 0.5681\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6916 - val_loss: 0.5680\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6906 - val_loss: 0.5679\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6896 - val_loss: 0.5678\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6887 - val_loss: 0.5677\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6877 - val_loss: 0.5676\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6868 - val_loss: 0.5675\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6859 - val_loss: 0.5674\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6849 - val_loss: 0.5673\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6840 - val_loss: 0.5672\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6831 - val_loss: 0.5671\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6822 - val_loss: 0.5670\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6813 - val_loss: 0.5669\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6805 - val_loss: 0.5668\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6796 - val_loss: 0.5667\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6787 - val_loss: 0.5666\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6779 - val_loss: 0.5665\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6771 - val_loss: 0.5665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6762 - val_loss: 0.5664\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6754 - val_loss: 0.5663\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6746 - val_loss: 0.5662\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6738 - val_loss: 0.5661\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6730 - val_loss: 0.5660\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6722 - val_loss: 0.5659\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6715 - val_loss: 0.5658\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6707 - val_loss: 0.5657\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6699 - val_loss: 0.5656\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6691 - val_loss: 0.5655\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6684 - val_loss: 0.5654\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6676 - val_loss: 0.5653\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6668 - val_loss: 0.5652\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6661 - val_loss: 0.5651\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1104923.1929255812, my average MASE = 35973487.14565515\n",
      "Cluster 1, 1104923.1929255812\n",
      "Before prediction: train_X.shape=(134, 10, 67), train_y.shape=(134, 67), test_X.shape=(45, 10, 67), test_y.shape=(45, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4388 - val_loss: 0.7635\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4381 - val_loss: 0.7630\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4375 - val_loss: 0.7625\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4369 - val_loss: 0.7620\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4363 - val_loss: 0.7616\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4358 - val_loss: 0.7611\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4353 - val_loss: 0.7607\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4348 - val_loss: 0.7603\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4343 - val_loss: 0.7598\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4338 - val_loss: 0.7594\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4333 - val_loss: 0.7590\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4328 - val_loss: 0.7585\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4323 - val_loss: 0.7581\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4318 - val_loss: 0.7576\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4314 - val_loss: 0.7572\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4309 - val_loss: 0.7568\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4305 - val_loss: 0.7564\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4301 - val_loss: 0.7561\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4296 - val_loss: 0.7557\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4292 - val_loss: 0.7554\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4288 - val_loss: 0.7550\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4284 - val_loss: 0.7546\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4280 - val_loss: 0.7543\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4276 - val_loss: 0.7539\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4272 - val_loss: 0.7535\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4268 - val_loss: 0.7532\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4264 - val_loss: 0.7528\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4260 - val_loss: 0.7525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4257 - val_loss: 0.7521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4253 - val_loss: 0.7517\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4249 - val_loss: 0.7514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4245 - val_loss: 0.7511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4242 - val_loss: 0.7508\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4238 - val_loss: 0.7505\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4235 - val_loss: 0.7502\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4231 - val_loss: 0.7499\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4228 - val_loss: 0.7496\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4225 - val_loss: 0.7492\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4221 - val_loss: 0.7489\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4218 - val_loss: 0.7486\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(45, 67), test_y.shape=(45, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 134.01886625392066, my average MASE = 180554408.61752364\n",
      "Cluster 2, 134.01886625392066\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3365 - val_loss: 0.4571\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3346 - val_loss: 0.4566\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3328 - val_loss: 0.4560\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.4555\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3293 - val_loss: 0.4550\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.4544\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3260 - val_loss: 0.4539\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.4534\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3229 - val_loss: 0.4528\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3213 - val_loss: 0.4523\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3197 - val_loss: 0.4518\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3182 - val_loss: 0.4512\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3166 - val_loss: 0.4507\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3152 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3137 - val_loss: 0.4496\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3123 - val_loss: 0.4490\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3109 - val_loss: 0.4485\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3095 - val_loss: 0.4479\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3082 - val_loss: 0.4473\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3070 - val_loss: 0.4468\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3058 - val_loss: 0.4462\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3045 - val_loss: 0.4456\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.4450\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3021 - val_loss: 0.4444\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3009 - val_loss: 0.4438\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2998 - val_loss: 0.4432\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2986 - val_loss: 0.4426\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2974 - val_loss: 0.4420\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2963 - val_loss: 0.4414\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2952 - val_loss: 0.4407\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2940 - val_loss: 0.4401\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2929 - val_loss: 0.4395\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.4389\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2907 - val_loss: 0.4384\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2896 - val_loss: 0.4379\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2885 - val_loss: 0.4373\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2875 - val_loss: 0.4369\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2865 - val_loss: 0.4364\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2854 - val_loss: 0.4359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2844 - val_loss: 0.4355\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.28495017155315366, my average MASE = 0.3992586255016426\n",
      "Cluster 3, 0.28495017155315366\n",
      "Before prediction: train_X.shape=(77, 10, 67), train_y.shape=(77, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6320 - val_loss: 1.0222\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6307 - val_loss: 1.0218\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 1.0214\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6284 - val_loss: 1.0211\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6273 - val_loss: 1.0208\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6262 - val_loss: 1.0205\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6252 - val_loss: 1.0201\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6241 - val_loss: 1.0198\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6231 - val_loss: 1.0195\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6221 - val_loss: 1.0192\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6212 - val_loss: 1.0188\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6202 - val_loss: 1.0185\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6193 - val_loss: 1.0182\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6183 - val_loss: 1.0179\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6174 - val_loss: 1.0176\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6166 - val_loss: 1.0172\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6157 - val_loss: 1.0169\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6148 - val_loss: 1.0166\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6139 - val_loss: 1.0162\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6131 - val_loss: 1.0159\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6122 - val_loss: 1.0155\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6114 - val_loss: 1.0152\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6106 - val_loss: 1.0148\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6097 - val_loss: 1.0145\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6089 - val_loss: 1.0141\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6081 - val_loss: 1.0138\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6073 - val_loss: 1.0134\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6066 - val_loss: 1.0131\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6057 - val_loss: 1.0127\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6050 - val_loss: 1.0124\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6042 - val_loss: 1.0121\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6035 - val_loss: 1.0118\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6027 - val_loss: 1.0114\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6020 - val_loss: 1.0111\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6013 - val_loss: 1.0108\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6005 - val_loss: 1.0104\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5998 - val_loss: 1.0101\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5991 - val_loss: 1.0098\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5984 - val_loss: 1.0094\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5977 - val_loss: 1.0091\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 98.33747704062574, my average MASE = 204772160.73570046\n",
      "Cluster 4, 98.33747704062574\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4785 - val_loss: 0.4645\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4760 - val_loss: 0.4629\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4734 - val_loss: 0.4612\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4709 - val_loss: 0.4596\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4684 - val_loss: 0.4580\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4661 - val_loss: 0.4564\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4638 - val_loss: 0.4548\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4615 - val_loss: 0.4532\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4593 - val_loss: 0.4516\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4572 - val_loss: 0.4500\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4551 - val_loss: 0.4484\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4530 - val_loss: 0.4468\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4509 - val_loss: 0.4453\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4489 - val_loss: 0.4438\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4469 - val_loss: 0.4422\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4449 - val_loss: 0.4407\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4429 - val_loss: 0.4393\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4410 - val_loss: 0.4380\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4391 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4371 - val_loss: 0.4354\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4353 - val_loss: 0.4343\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4335 - val_loss: 0.4332\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4317 - val_loss: 0.4322\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4300 - val_loss: 0.4311\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4282 - val_loss: 0.4301\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4265 - val_loss: 0.4291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4248 - val_loss: 0.4281\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4231 - val_loss: 0.4270\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4214 - val_loss: 0.4260\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4197 - val_loss: 0.4250\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4181 - val_loss: 0.4240\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4165 - val_loss: 0.4229\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4149 - val_loss: 0.4218\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4134 - val_loss: 0.4208\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4118 - val_loss: 0.4197\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4103 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4088 - val_loss: 0.4176\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.4167\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4060 - val_loss: 0.4157\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4046 - val_loss: 0.4148\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 931833756.986838, my average MASE = 2420970654.4710827\n",
      "Cluster 5, 931833756.986838\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4346 - val_loss: 0.4628\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4334 - val_loss: 0.4625\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4323 - val_loss: 0.4621\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4312 - val_loss: 0.4618\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4301 - val_loss: 0.4615\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4290 - val_loss: 0.4612\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4280 - val_loss: 0.4609\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4269 - val_loss: 0.4605\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4259 - val_loss: 0.4602\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4249 - val_loss: 0.4599\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4239 - val_loss: 0.4596\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4228 - val_loss: 0.4593\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4218 - val_loss: 0.4590\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4208 - val_loss: 0.4587\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4198 - val_loss: 0.4584\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4188 - val_loss: 0.4582\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4179 - val_loss: 0.4579\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4169 - val_loss: 0.4576\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4160 - val_loss: 0.4573\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4151 - val_loss: 0.4570\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4141 - val_loss: 0.4567\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4132 - val_loss: 0.4564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4123 - val_loss: 0.4561\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4114 - val_loss: 0.4558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4106 - val_loss: 0.4555\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4097 - val_loss: 0.4552\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4089 - val_loss: 0.4549\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4080 - val_loss: 0.4546\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4072 - val_loss: 0.4544\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4063 - val_loss: 0.4541\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4055 - val_loss: 0.4538\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4047 - val_loss: 0.4536\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4039 - val_loss: 0.4533\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4031 - val_loss: 0.4531\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4023 - val_loss: 0.4529\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4015 - val_loss: 0.4527\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4007 - val_loss: 0.4526\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3999 - val_loss: 0.4524\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3991 - val_loss: 0.4522\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3983 - val_loss: 0.4520\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 806621.4868706047, my average MASE = 27017424.126969155\n",
      "Cluster 6, 806621.4868706047\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8616 - val_loss: 0.8556\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8588 - val_loss: 0.8539\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8561 - val_loss: 0.8522\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8534 - val_loss: 0.8505\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8508 - val_loss: 0.8489\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8484 - val_loss: 0.8472\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8459 - val_loss: 0.8456\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8435 - val_loss: 0.8440\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8412 - val_loss: 0.8424\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8389 - val_loss: 0.8408\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8366 - val_loss: 0.8392\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8343 - val_loss: 0.8376\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8320 - val_loss: 0.8361\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8298 - val_loss: 0.8345\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8276 - val_loss: 0.8329\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8254 - val_loss: 0.8314\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8232 - val_loss: 0.8298\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8210 - val_loss: 0.8283\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 0.8267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8168 - val_loss: 0.8253\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8146 - val_loss: 0.8238\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8125 - val_loss: 0.8224\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8104 - val_loss: 0.8210\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8084 - val_loss: 0.8197\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8064 - val_loss: 0.8184\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8045 - val_loss: 0.8170\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8025 - val_loss: 0.8157\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8006 - val_loss: 0.8143\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7987 - val_loss: 0.8129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7969 - val_loss: 0.8115\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7950 - val_loss: 0.8102\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7932 - val_loss: 0.8089\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7913 - val_loss: 0.8077\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7894 - val_loss: 0.8065\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7876 - val_loss: 0.8053\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7857 - val_loss: 0.8041\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7839 - val_loss: 0.8030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7821 - val_loss: 0.8019\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7803 - val_loss: 0.8008\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7785 - val_loss: 0.7997\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 964635493.0745914, my average MASE = 2107611139.389815\n",
      "Cluster 7, 964635493.0745914\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3952 - val_loss: 0.3689\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3946 - val_loss: 0.3689\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3941 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3935 - val_loss: 0.3687\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3930 - val_loss: 0.3687\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3924 - val_loss: 0.3686\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3919 - val_loss: 0.3685\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3914 - val_loss: 0.3685\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3909 - val_loss: 0.3684\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3903 - val_loss: 0.3684\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3898 - val_loss: 0.3683\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3893 - val_loss: 0.3682\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3888 - val_loss: 0.3682\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3883 - val_loss: 0.3681\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3878 - val_loss: 0.3680\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3873 - val_loss: 0.3680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3869 - val_loss: 0.3679\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3864 - val_loss: 0.3679\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 0.3678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3855 - val_loss: 0.3677\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3850 - val_loss: 0.3677\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3845 - val_loss: 0.3676\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3841 - val_loss: 0.3676\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3836 - val_loss: 0.3675\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3832 - val_loss: 0.3674\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3828 - val_loss: 0.3674\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3823 - val_loss: 0.3673\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3819 - val_loss: 0.3673\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3815 - val_loss: 0.3672\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3811 - val_loss: 0.3672\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3806 - val_loss: 0.3671\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3802 - val_loss: 0.3670\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3798 - val_loss: 0.3670\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.3669\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3790 - val_loss: 0.3669\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3786 - val_loss: 0.3668\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3782 - val_loss: 0.3668\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3778 - val_loss: 0.3667\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3774 - val_loss: 0.3666\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3770 - val_loss: 0.3666\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 51.171495934252626, my average MASE = 30811708.472042836\n",
      "Cluster 8, 51.171495934252626\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4416 - val_loss: 0.4387\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4409 - val_loss: 0.4386\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4402 - val_loss: 0.4384\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4395 - val_loss: 0.4383\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4388 - val_loss: 0.4381\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4382 - val_loss: 0.4380\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4375 - val_loss: 0.4379\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4368 - val_loss: 0.4377\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4362 - val_loss: 0.4376\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4355 - val_loss: 0.4375\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4348 - val_loss: 0.4373\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4342 - val_loss: 0.4372\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4335 - val_loss: 0.4371\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4329 - val_loss: 0.4370\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4323 - val_loss: 0.4368\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4316 - val_loss: 0.4367\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4310 - val_loss: 0.4366\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4304 - val_loss: 0.4365\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4298 - val_loss: 0.4364\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4292 - val_loss: 0.4363\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4286 - val_loss: 0.4362\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4280 - val_loss: 0.4361\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4274 - val_loss: 0.4359\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4268 - val_loss: 0.4358\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4262 - val_loss: 0.4357\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4256 - val_loss: 0.4356\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4250 - val_loss: 0.4355\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4245 - val_loss: 0.4354\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4239 - val_loss: 0.4353\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4233 - val_loss: 0.4352\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4227 - val_loss: 0.4351\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4221 - val_loss: 0.4350\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.4349\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4210 - val_loss: 0.4348\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4204 - val_loss: 0.4347\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4199 - val_loss: 0.4346\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4193 - val_loss: 0.4345\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4187 - val_loss: 0.4345\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4182 - val_loss: 0.4344\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4176 - val_loss: 0.4343\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 67.68630348587587, my average MASE = 34346224.36796317\n",
      "Cluster 9, 67.68630348587587\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=2, 2, 18, (30610, 67)\n",
      "Before prediction: train_X.shape=(18359, 10, 67), train_y.shape=(18359, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3046 - val_loss: 0.3213\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2853 - val_loss: 0.3058\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2698 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2588 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2516 - val_loss: 0.2788\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2460 - val_loss: 0.2736\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2412 - val_loss: 0.2691\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2371 - val_loss: 0.2652\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2335 - val_loss: 0.2618\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2301 - val_loss: 0.2588\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2271 - val_loss: 0.2562\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2243 - val_loss: 0.2538\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2219 - val_loss: 0.2516\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2199 - val_loss: 0.2498\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2181 - val_loss: 0.2483\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2166 - val_loss: 0.2469\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2153 - val_loss: 0.2458\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2142 - val_loss: 0.2448\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2122 - val_loss: 0.2430\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2114 - val_loss: 0.2422\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2106 - val_loss: 0.2414\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2099 - val_loss: 0.2407\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2092 - val_loss: 0.2401\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2086 - val_loss: 0.2395\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2080 - val_loss: 0.2389\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2074 - val_loss: 0.2385\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2069 - val_loss: 0.2380\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2064 - val_loss: 0.2376\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2059 - val_loss: 0.2370\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2054 - val_loss: 0.2367\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2050 - val_loss: 0.2362\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2046 - val_loss: 0.2359\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2042 - val_loss: 0.2356\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2038 - val_loss: 0.2351\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2034 - val_loss: 0.2349\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2031 - val_loss: 0.2345\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2021 - val_loss: 0.2337\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1675.644817755528, my average MASE = 2652.7812514268226\n",
      "Cluster 0, 1675.644817755528\n",
      "Before prediction: train_X.shape=(8, 10, 67), train_y.shape=(8, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4228 - val_loss: 1.1321\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4209 - val_loss: 1.1320\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4191 - val_loss: 1.1319\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4173 - val_loss: 1.1318\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 1.1317\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4139 - val_loss: 1.1315\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4122 - val_loss: 1.1314\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4106 - val_loss: 1.1313\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4090 - val_loss: 1.1311\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4075 - val_loss: 1.1310\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4059 - val_loss: 1.1308\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4044 - val_loss: 1.1306\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4030 - val_loss: 1.1304\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4015 - val_loss: 1.1302\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4001 - val_loss: 1.1300\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 1.1298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3973 - val_loss: 1.1296\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3960 - val_loss: 1.1294\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3946 - val_loss: 1.1292\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3933 - val_loss: 1.1290\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 1.1288\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3907 - val_loss: 1.1286\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3895 - val_loss: 1.1283\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3883 - val_loss: 1.1281\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3871 - val_loss: 1.1279\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3859 - val_loss: 1.1277\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3847 - val_loss: 1.1275\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3836 - val_loss: 1.1272\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3825 - val_loss: 1.1270\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3814 - val_loss: 1.1268\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3803 - val_loss: 1.1266\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3792 - val_loss: 1.1264\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3781 - val_loss: 1.1262\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3771 - val_loss: 1.1259\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3761 - val_loss: 1.1257\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3750 - val_loss: 1.1255\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3740 - val_loss: 1.1253\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 1.1251\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3721 - val_loss: 1.1249\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3711 - val_loss: 1.1247\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 993839931.13901, my average MASE = 2723871222.022616\n",
      "Cluster 1, 993839931.13901\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=5, 5, 75, (319, 67)\n",
      "Before prediction: train_X.shape=(185, 10, 67), train_y.shape=(185, 67), test_X.shape=(62, 10, 67), test_y.shape=(62, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6944 - val_loss: 0.6444\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6929 - val_loss: 0.6434\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6914 - val_loss: 0.6425\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6901 - val_loss: 0.6415\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6887 - val_loss: 0.6406\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6874 - val_loss: 0.6397\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6860 - val_loss: 0.6388\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6847 - val_loss: 0.6380\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6834 - val_loss: 0.6372\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6822 - val_loss: 0.6363\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6810 - val_loss: 0.6355\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6798 - val_loss: 0.6347\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.6340\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6775 - val_loss: 0.6332\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.6325\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6753 - val_loss: 0.6318\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6742 - val_loss: 0.6310\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6732 - val_loss: 0.6303\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6721 - val_loss: 0.6296\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6711 - val_loss: 0.6289\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6701 - val_loss: 0.6283\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6692 - val_loss: 0.6276\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6682 - val_loss: 0.6270\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6672 - val_loss: 0.6263\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6663 - val_loss: 0.6257\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6654 - val_loss: 0.6251\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.6244\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6636 - val_loss: 0.6238\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6627 - val_loss: 0.6232\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6618 - val_loss: 0.6226\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6610 - val_loss: 0.6220\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6601 - val_loss: 0.6214\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6593 - val_loss: 0.6208\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6584 - val_loss: 0.6202\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6576 - val_loss: 0.6196\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6568 - val_loss: 0.6191\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6559 - val_loss: 0.6185\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6551 - val_loss: 0.6179\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6543 - val_loss: 0.6173\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6535 - val_loss: 0.6167\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(62, 67), test_y.shape=(62, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 141.38884780958514, my average MASE = 173942620.82410374\n",
      "Cluster 0, 141.38884780958514\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0665 - val_loss: 0.0455\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0607 - val_loss: 0.0424\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0575 - val_loss: 0.0402\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0551 - val_loss: 0.0384\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0531 - val_loss: 0.0370\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0515 - val_loss: 0.0358\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0502 - val_loss: 0.0347\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0491 - val_loss: 0.0338\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0481 - val_loss: 0.0331\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0473 - val_loss: 0.0324\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0466 - val_loss: 0.0319\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0460 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0454 - val_loss: 0.0311\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0449 - val_loss: 0.0307\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0304\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0301\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0437 - val_loss: 0.0299\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0433 - val_loss: 0.0297\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0294\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0292\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0424 - val_loss: 0.0290\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0422 - val_loss: 0.0288\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0420 - val_loss: 0.0287\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0418 - val_loss: 0.0285\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0416 - val_loss: 0.0284\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0414 - val_loss: 0.0283\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0412 - val_loss: 0.0281\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0411 - val_loss: 0.0280\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0279\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0278\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0278\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0277\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0276\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0403 - val_loss: 0.0276\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0275\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0401 - val_loss: 0.0274\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0274\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0273\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0273\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0272\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1157555182.6490364, my average MASE = 73085160895.13536\n",
      "Cluster 1, 1157555182.6490364\n",
      "Before prediction: train_X.shape=(37, 10, 67), train_y.shape=(37, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5516 - val_loss: 0.5380\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5498 - val_loss: 0.5365\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5480 - val_loss: 0.5350\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5462 - val_loss: 0.5335\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5444 - val_loss: 0.5321\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5427 - val_loss: 0.5306\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5410 - val_loss: 0.5292\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5393 - val_loss: 0.5278\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5376 - val_loss: 0.5264\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5360 - val_loss: 0.5250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5343 - val_loss: 0.5237\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5328 - val_loss: 0.5223\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5312 - val_loss: 0.5210\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5297 - val_loss: 0.5197\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5281 - val_loss: 0.5184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5266 - val_loss: 0.5171\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5252 - val_loss: 0.5158\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5237 - val_loss: 0.5146\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5223 - val_loss: 0.5133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5208 - val_loss: 0.5121\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5194 - val_loss: 0.5109\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5181 - val_loss: 0.5098\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5167 - val_loss: 0.5086\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5154 - val_loss: 0.5075\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5141 - val_loss: 0.5063\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5128 - val_loss: 0.5052\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5115 - val_loss: 0.5041\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5103 - val_loss: 0.5031\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5091 - val_loss: 0.5020\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5078 - val_loss: 0.5010\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.5000\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5055 - val_loss: 0.4990\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5043 - val_loss: 0.4980\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5031 - val_loss: 0.4970\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5020 - val_loss: 0.4961\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5008 - val_loss: 0.4952\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.4943\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4986 - val_loss: 0.4934\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4975 - val_loss: 0.4926\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4964 - val_loss: 0.4917\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4324881186.205308, my average MASE = 10393885205.318085\n",
      "Cluster 2, 4324881186.205308\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4066 - val_loss: 0.3845\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4060 - val_loss: 0.3840\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.3836\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4048 - val_loss: 0.3831\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4042 - val_loss: 0.3826\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4036 - val_loss: 0.3822\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4031 - val_loss: 0.3817\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4025 - val_loss: 0.3812\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4019 - val_loss: 0.3808\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4014 - val_loss: 0.3803\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3799\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4003 - val_loss: 0.3795\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3791\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3992 - val_loss: 0.3787\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3987 - val_loss: 0.3783\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3982 - val_loss: 0.3779\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3977 - val_loss: 0.3775\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3971 - val_loss: 0.3772\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3966 - val_loss: 0.3768\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3764\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3956 - val_loss: 0.3761\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3757\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3946 - val_loss: 0.3754\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3942 - val_loss: 0.3751\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3937 - val_loss: 0.3747\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3932 - val_loss: 0.3744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3927 - val_loss: 0.3741\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3922 - val_loss: 0.3738\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3918 - val_loss: 0.3735\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3913 - val_loss: 0.3732\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3908 - val_loss: 0.3729\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3903 - val_loss: 0.3726\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.3723\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3894 - val_loss: 0.3720\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3890 - val_loss: 0.3718\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3885 - val_loss: 0.3715\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3881 - val_loss: 0.3712\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3877 - val_loss: 0.3709\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3872 - val_loss: 0.3706\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3868 - val_loss: 0.3704\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n",
      "average MASE = 1110146.2653270473, my average MASE = 43278995.990564056\n",
      "Cluster 3, 1110146.2653270473\n",
      "Before prediction: train_X.shape=(25, 10, 67), train_y.shape=(25, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5208 - val_loss: 0.4711\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5196 - val_loss: 0.4707\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5184 - val_loss: 0.4702\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5173 - val_loss: 0.4698\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5161 - val_loss: 0.4694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5150 - val_loss: 0.4690\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4686\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5127 - val_loss: 0.4682\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5116 - val_loss: 0.4678\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5105 - val_loss: 0.4675\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5094 - val_loss: 0.4671\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5084 - val_loss: 0.4667\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5073 - val_loss: 0.4664\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5063 - val_loss: 0.4660\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5052 - val_loss: 0.4657\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5042 - val_loss: 0.4654\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5031 - val_loss: 0.4651\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4648\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5011 - val_loss: 0.4645\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5001 - val_loss: 0.4643\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4991 - val_loss: 0.4641\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.4638\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4971 - val_loss: 0.4636\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4962 - val_loss: 0.4634\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.4632\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4942 - val_loss: 0.4629\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4933 - val_loss: 0.4627\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4923 - val_loss: 0.4625\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4914 - val_loss: 0.4623\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4904 - val_loss: 0.4621\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4895 - val_loss: 0.4619\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4886 - val_loss: 0.4617\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4876 - val_loss: 0.4616\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4867 - val_loss: 0.4614\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4858 - val_loss: 0.4613\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4849 - val_loss: 0.4611\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4841 - val_loss: 0.4610\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4608\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4823 - val_loss: 0.4607\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4815 - val_loss: 0.4605\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 111.6892159594304, my average MASE = 112347014.53903662\n",
      "Cluster 4, 111.6892159594304\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=7, 7, 884, (12, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5954, 10, 67), train_y.shape=(5954, 67), test_X.shape=(1985, 10, 67), test_y.shape=(1985, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0672 - val_loss: 0.0440\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0611 - val_loss: 0.0410\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0576 - val_loss: 0.0390\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0552 - val_loss: 0.0374\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0533 - val_loss: 0.0361\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0517 - val_loss: 0.0350\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0504 - val_loss: 0.0340\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0493 - val_loss: 0.0332\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0484 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0476 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0469 - val_loss: 0.0313\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0462 - val_loss: 0.0308\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0457 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0447 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0442 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0435 - val_loss: 0.0287\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0285\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0283\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0281\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0280\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0278\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0277\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0275\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0274\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0273\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0411 - val_loss: 0.0271\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0270\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0408 - val_loss: 0.0269\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0407 - val_loss: 0.0268\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0267\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0405 - val_loss: 0.0266\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0403 - val_loss: 0.0265\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0401 - val_loss: 0.0264\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0263\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 28ms/step - loss: 0.0399 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0398 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1985, 67), test_y.shape=(1985, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1103404601.9868512, my average MASE = 55700347192.937294\n",
      "Cluster 1, 1103404601.9868512\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5205 - val_loss: 0.4218\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5186 - val_loss: 0.4208\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5167 - val_loss: 0.4198\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5148 - val_loss: 0.4189\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5129 - val_loss: 0.4179\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5111 - val_loss: 0.4170\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5093 - val_loss: 0.4161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5074 - val_loss: 0.4152\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5057 - val_loss: 0.4143\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5039 - val_loss: 0.4134\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5022 - val_loss: 0.4125\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5004 - val_loss: 0.4117\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4987 - val_loss: 0.4108\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4971 - val_loss: 0.4100\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4954 - val_loss: 0.4092\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4938 - val_loss: 0.4083\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4922 - val_loss: 0.4075\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4906 - val_loss: 0.4067\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4890 - val_loss: 0.4060\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4875 - val_loss: 0.4052\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4860 - val_loss: 0.4044\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4845 - val_loss: 0.4036\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4830 - val_loss: 0.4028\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4815 - val_loss: 0.4021\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4800 - val_loss: 0.4013\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4771 - val_loss: 0.3999\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4757 - val_loss: 0.3992\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4743 - val_loss: 0.3985\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4730 - val_loss: 0.3978\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4716 - val_loss: 0.3971\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4703 - val_loss: 0.3964\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4689 - val_loss: 0.3958\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.3951\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.3945\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4650 - val_loss: 0.3939\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4637 - val_loss: 0.3932\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4625 - val_loss: 0.3926\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4612 - val_loss: 0.3920\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4600 - val_loss: 0.3913\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3560489905.356454, my average MASE = 9030960108.787361\n",
      "Cluster 2, 3560489905.356454\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3774 - val_loss: 0.3465\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3767 - val_loss: 0.3460\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3759 - val_loss: 0.3456\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3752 - val_loss: 0.3452\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3744 - val_loss: 0.3448\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3737 - val_loss: 0.3444\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3730 - val_loss: 0.3440\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3723 - val_loss: 0.3436\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3716 - val_loss: 0.3432\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3710 - val_loss: 0.3429\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3703 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3696 - val_loss: 0.3421\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.3418\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3683 - val_loss: 0.3415\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3411\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3671 - val_loss: 0.3408\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3665 - val_loss: 0.3405\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3659 - val_loss: 0.3401\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3653 - val_loss: 0.3398\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3647 - val_loss: 0.3395\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3641 - val_loss: 0.3392\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3635 - val_loss: 0.3389\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3630 - val_loss: 0.3386\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.3383\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.3380\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3613 - val_loss: 0.3377\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3608 - val_loss: 0.3374\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3602 - val_loss: 0.3371\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3597 - val_loss: 0.3368\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3592 - val_loss: 0.3365\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3362\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3581 - val_loss: 0.3359\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3576 - val_loss: 0.3356\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3571 - val_loss: 0.3353\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3566 - val_loss: 0.3350\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3561 - val_loss: 0.3347\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3556 - val_loss: 0.3344\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3551 - val_loss: 0.3342\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3546 - val_loss: 0.3339\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3541 - val_loss: 0.3336\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 332.8608286989534, my average MASE = 85442913.95523748\n",
      "Cluster 3, 332.8608286989534\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7187 - val_loss: 0.5712\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7172 - val_loss: 0.5706\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7158 - val_loss: 0.5700\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7145 - val_loss: 0.5694\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7132 - val_loss: 0.5688\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7119 - val_loss: 0.5682\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7107 - val_loss: 0.5677\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7095 - val_loss: 0.5671\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7083 - val_loss: 0.5666\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7071 - val_loss: 0.5660\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7060 - val_loss: 0.5655\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7049 - val_loss: 0.5650\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7038 - val_loss: 0.5646\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7028 - val_loss: 0.5641\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7018 - val_loss: 0.5636\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7008 - val_loss: 0.5631\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6999 - val_loss: 0.5627\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6989 - val_loss: 0.5622\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6980 - val_loss: 0.5618\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6971 - val_loss: 0.5613\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5609\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6953 - val_loss: 0.5604\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6944 - val_loss: 0.5600\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6935 - val_loss: 0.5596\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6927 - val_loss: 0.5592\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6918 - val_loss: 0.5587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6910 - val_loss: 0.5583\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6902 - val_loss: 0.5579\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6894 - val_loss: 0.5576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6886 - val_loss: 0.5572\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6878 - val_loss: 0.5568\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6870 - val_loss: 0.5564\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6862 - val_loss: 0.5560\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6854 - val_loss: 0.5557\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6846 - val_loss: 0.5553\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6839 - val_loss: 0.5549\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6831 - val_loss: 0.5546\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6824 - val_loss: 0.5542\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6816 - val_loss: 0.5538\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6809 - val_loss: 0.5535\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 139.45484282658396, my average MASE = 350849744.5231373\n",
      "Cluster 4, 139.45484282658396\n",
      "Before prediction: train_X.shape=(133, 10, 67), train_y.shape=(133, 67), test_X.shape=(44, 10, 67), test_y.shape=(44, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4266 - val_loss: 0.6651\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4259 - val_loss: 0.6645\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4253 - val_loss: 0.6639\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4247 - val_loss: 0.6633\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4242 - val_loss: 0.6628\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4236 - val_loss: 0.6623\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4231 - val_loss: 0.6618\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4226 - val_loss: 0.6613\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4221 - val_loss: 0.6608\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4216 - val_loss: 0.6603\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4211 - val_loss: 0.6599\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4206 - val_loss: 0.6594\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4201 - val_loss: 0.6590\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4197 - val_loss: 0.6585\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4192 - val_loss: 0.6581\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4188 - val_loss: 0.6576\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4184 - val_loss: 0.6572\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4180 - val_loss: 0.6568\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4175 - val_loss: 0.6564\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4171 - val_loss: 0.6559\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4167 - val_loss: 0.6554\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4163 - val_loss: 0.6550\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4159 - val_loss: 0.6545\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4155 - val_loss: 0.6541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4151 - val_loss: 0.6537\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4147 - val_loss: 0.6533\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4143 - val_loss: 0.6529\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4139 - val_loss: 0.6525\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4135 - val_loss: 0.6521\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4131 - val_loss: 0.6518\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4128 - val_loss: 0.6514\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4124 - val_loss: 0.6511\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4120 - val_loss: 0.6507\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4117 - val_loss: 0.6504\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4114 - val_loss: 0.6501\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4110 - val_loss: 0.6498\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4107 - val_loss: 0.6494\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4103 - val_loss: 0.6491\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4100 - val_loss: 0.6487\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4096 - val_loss: 0.6484\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(44, 67), test_y.shape=(44, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 116.65244791791511, my average MASE = 142786035.78420427\n",
      "Cluster 5, 116.65244791791511\n",
      "Before prediction: train_X.shape=(78, 10, 67), train_y.shape=(78, 67), test_X.shape=(26, 10, 67), test_y.shape=(26, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4078 - val_loss: 0.4868\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4070 - val_loss: 0.4862\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4062 - val_loss: 0.4856\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4055 - val_loss: 0.4850\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4048 - val_loss: 0.4845\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4041 - val_loss: 0.4839\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.4833\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4027 - val_loss: 0.4828\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4021 - val_loss: 0.4823\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4015 - val_loss: 0.4818\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4008 - val_loss: 0.4813\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4002 - val_loss: 0.4808\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3997 - val_loss: 0.4803\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3991 - val_loss: 0.4798\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3985 - val_loss: 0.4794\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3980 - val_loss: 0.4789\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3974 - val_loss: 0.4785\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3969 - val_loss: 0.4780\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3964 - val_loss: 0.4776\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3959 - val_loss: 0.4772\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3954 - val_loss: 0.4768\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3949 - val_loss: 0.4764\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3944 - val_loss: 0.4760\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.4757\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3934 - val_loss: 0.4753\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3930 - val_loss: 0.4750\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3925 - val_loss: 0.4747\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3921 - val_loss: 0.4743\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3916 - val_loss: 0.4740\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3912 - val_loss: 0.4737\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3907 - val_loss: 0.4733\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3903 - val_loss: 0.4730\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3899 - val_loss: 0.4727\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3895 - val_loss: 0.4724\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3890 - val_loss: 0.4721\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3886 - val_loss: 0.4718\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4715\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3878 - val_loss: 0.4712\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.4709\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3870 - val_loss: 0.4706\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(26, 67), test_y.shape=(26, 67)\n",
      "average MASE = 221.65144919995234, my average MASE = 102271349.10812314\n",
      "Cluster 6, 221.65144919995234\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=9, 9, 14, (3245, 67)\n",
      "Before prediction: train_X.shape=(1940, 10, 67), train_y.shape=(1940, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1141 - val_loss: 0.1031\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1086 - val_loss: 0.1010\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1042 - val_loss: 0.0995\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1005 - val_loss: 0.0982\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0973 - val_loss: 0.0973\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0945 - val_loss: 0.0965\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0920 - val_loss: 0.0960\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0897 - val_loss: 0.0955\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0877 - val_loss: 0.0950\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0858 - val_loss: 0.0947\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0841 - val_loss: 0.0943\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0826 - val_loss: 0.0941\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0812 - val_loss: 0.0938\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0798 - val_loss: 0.0935\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0786 - val_loss: 0.0933\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0930\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0765 - val_loss: 0.0928\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0755 - val_loss: 0.0926\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0746 - val_loss: 0.0925\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0737 - val_loss: 0.0923\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0729 - val_loss: 0.0921\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0722 - val_loss: 0.0920\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0715 - val_loss: 0.0919\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0708 - val_loss: 0.0917\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0916\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0915\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0691 - val_loss: 0.0914\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0686 - val_loss: 0.0913\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0681 - val_loss: 0.0912\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0676 - val_loss: 0.0911\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0910\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0668 - val_loss: 0.0910\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0664 - val_loss: 0.0909\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0660 - val_loss: 0.0909\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0656 - val_loss: 0.0908\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0653 - val_loss: 0.0908\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0650 - val_loss: 0.0907\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0647 - val_loss: 0.0907\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0644 - val_loss: 0.0907\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0906\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1289233887.8234715, my average MASE = 15636865244.557127\n",
      "Cluster 0, 1289233887.8234715\n",
      "Before prediction: train_X.shape=(29, 10, 67), train_y.shape=(29, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4693 - val_loss: 0.6570\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4687 - val_loss: 0.6567\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4680 - val_loss: 0.6563\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4674 - val_loss: 0.6560\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4668 - val_loss: 0.6557\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4662 - val_loss: 0.6554\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4656 - val_loss: 0.6551\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4650 - val_loss: 0.6548\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4644 - val_loss: 0.6545\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4638 - val_loss: 0.6542\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4633 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4627 - val_loss: 0.6536\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4621 - val_loss: 0.6533\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.6530\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4610 - val_loss: 0.6527\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4605 - val_loss: 0.6524\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4599 - val_loss: 0.6521\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4594 - val_loss: 0.6519\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4588 - val_loss: 0.6516\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4583 - val_loss: 0.6513\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4578 - val_loss: 0.6510\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4573 - val_loss: 0.6508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4568 - val_loss: 0.6505\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4563 - val_loss: 0.6502\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4558 - val_loss: 0.6499\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4553 - val_loss: 0.6496\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4548 - val_loss: 0.6493\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4543 - val_loss: 0.6491\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4538 - val_loss: 0.6488\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4533 - val_loss: 0.6485\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4528 - val_loss: 0.6483\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4524 - val_loss: 0.6480\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4519 - val_loss: 0.6478\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4514 - val_loss: 0.6475\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4510 - val_loss: 0.6473\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4505 - val_loss: 0.6470\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4500 - val_loss: 0.6468\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4496 - val_loss: 0.6465\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4492 - val_loss: 0.6463\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.6460\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 10049120.449906044, my average MASE = 246733533.9412494\n",
      "Cluster 1, 10049120.449906044\n",
      "Before prediction: train_X.shape=(1564, 10, 67), train_y.shape=(1564, 67), test_X.shape=(521, 10, 67), test_y.shape=(521, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2359 - val_loss: 0.2748\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2264 - val_loss: 0.2656\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2192 - val_loss: 0.2584\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2135 - val_loss: 0.2523\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2087 - val_loss: 0.2471\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2045 - val_loss: 0.2424\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2007 - val_loss: 0.2382\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1973 - val_loss: 0.2342\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1941 - val_loss: 0.2307\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1912 - val_loss: 0.2273\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1884 - val_loss: 0.2242\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1858 - val_loss: 0.2214\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1833 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1810 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1789 - val_loss: 0.2140\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1769 - val_loss: 0.2119\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1750 - val_loss: 0.2100\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1733 - val_loss: 0.2082\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1717 - val_loss: 0.2066\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1702 - val_loss: 0.2051\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1689 - val_loss: 0.2038\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1677 - val_loss: 0.2024\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2012\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2001\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1645 - val_loss: 0.1989\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1979\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1627 - val_loss: 0.1969\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1619 - val_loss: 0.1959\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1611 - val_loss: 0.1950\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1603 - val_loss: 0.1941\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1596 - val_loss: 0.1933\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1589 - val_loss: 0.1925\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1582 - val_loss: 0.1917\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1576 - val_loss: 0.1910\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1570 - val_loss: 0.1903\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1564 - val_loss: 0.1895\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1558 - val_loss: 0.1889\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1553 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1548 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1543 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(521, 67), test_y.shape=(521, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 187.65491616156584, my average MASE = 1727876346.7517292\n",
      "Cluster 2, 187.65491616156584\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5179 - val_loss: 0.4772\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5158 - val_loss: 0.4757\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.4743\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5118 - val_loss: 0.4729\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5098 - val_loss: 0.4715\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5079 - val_loss: 0.4701\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5059 - val_loss: 0.4687\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5040 - val_loss: 0.4673\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5021 - val_loss: 0.4660\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5002 - val_loss: 0.4646\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4984 - val_loss: 0.4633\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4966 - val_loss: 0.4620\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4948 - val_loss: 0.4607\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4931 - val_loss: 0.4594\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4913 - val_loss: 0.4581\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4896 - val_loss: 0.4568\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4879 - val_loss: 0.4555\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4862 - val_loss: 0.4543\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4845 - val_loss: 0.4531\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4828 - val_loss: 0.4518\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4812 - val_loss: 0.4506\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4795 - val_loss: 0.4495\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4779 - val_loss: 0.4483\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4763 - val_loss: 0.4471\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4747 - val_loss: 0.4460\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4731 - val_loss: 0.4449\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4716 - val_loss: 0.4438\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4700 - val_loss: 0.4427\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4685 - val_loss: 0.4416\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4670 - val_loss: 0.4405\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4655 - val_loss: 0.4395\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4640 - val_loss: 0.4385\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4626 - val_loss: 0.4374\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4611 - val_loss: 0.4364\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4597 - val_loss: 0.4354\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4582 - val_loss: 0.4344\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4568 - val_loss: 0.4334\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4555 - val_loss: 0.4324\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4541 - val_loss: 0.4314\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4527 - val_loss: 0.4304\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3258333520.23763, my average MASE = 7487984704.271554\n",
      "Cluster 3, 3258333520.23763\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3367 - val_loss: 0.3564\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3362 - val_loss: 0.3564\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3356 - val_loss: 0.3564\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3351 - val_loss: 0.3563\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3346 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3340 - val_loss: 0.3563\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3335 - val_loss: 0.3563\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3330 - val_loss: 0.3562\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3325 - val_loss: 0.3562\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3319 - val_loss: 0.3562\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3314 - val_loss: 0.3561\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3309 - val_loss: 0.3561\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3304 - val_loss: 0.3561\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3560\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3294 - val_loss: 0.3560\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3289 - val_loss: 0.3560\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.3559\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3280 - val_loss: 0.3559\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3275 - val_loss: 0.3559\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3270 - val_loss: 0.3559\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3266 - val_loss: 0.3558\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3261 - val_loss: 0.3558\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3256 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3252 - val_loss: 0.3558\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3248 - val_loss: 0.3558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3243 - val_loss: 0.3557\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3239 - val_loss: 0.3557\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.3557\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3230 - val_loss: 0.3557\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3226 - val_loss: 0.3557\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3222 - val_loss: 0.3556\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3218 - val_loss: 0.3556\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3214 - val_loss: 0.3556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3556\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3205 - val_loss: 0.3556\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3201 - val_loss: 0.3556\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.3556\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3193 - val_loss: 0.3555\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3189 - val_loss: 0.3555\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3185 - val_loss: 0.3555\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 544.8910068645505, my average MASE = 25915172.7591836\n",
      "Cluster 4, 544.8910068645505\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5189 - val_loss: 0.8510\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5183 - val_loss: 0.8507\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5176 - val_loss: 0.8503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5170 - val_loss: 0.8500\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5163 - val_loss: 0.8496\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5157 - val_loss: 0.8493\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5151 - val_loss: 0.8490\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5145 - val_loss: 0.8487\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5138 - val_loss: 0.8484\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5132 - val_loss: 0.8481\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5126 - val_loss: 0.8478\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5120 - val_loss: 0.8476\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5114 - val_loss: 0.8473\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5108 - val_loss: 0.8471\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5102 - val_loss: 0.8468\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5096 - val_loss: 0.8466\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5090 - val_loss: 0.8463\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5084 - val_loss: 0.8461\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5078 - val_loss: 0.8458\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5072 - val_loss: 0.8456\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5066 - val_loss: 0.8454\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5060 - val_loss: 0.8451\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5055 - val_loss: 0.8449\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5049 - val_loss: 0.8447\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5043 - val_loss: 0.8445\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5038 - val_loss: 0.8443\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5032 - val_loss: 0.8441\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5027 - val_loss: 0.8439\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5021 - val_loss: 0.8437\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5016 - val_loss: 0.8435\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5010 - val_loss: 0.8433\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5005 - val_loss: 0.8431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4999 - val_loss: 0.8429\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4994 - val_loss: 0.8428\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4989 - val_loss: 0.8426\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4983 - val_loss: 0.8424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4978 - val_loss: 0.8422\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4973 - val_loss: 0.8420\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4967 - val_loss: 0.8419\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4962 - val_loss: 0.8417\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1963484.3822421303, my average MASE = 64800710.430740915\n",
      "Cluster 5, 1963484.3822421303\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8495 - val_loss: 4.3516\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8473 - val_loss: 4.3510\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8451 - val_loss: 4.3503\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8429 - val_loss: 4.3497\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8408 - val_loss: 4.3491\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8386 - val_loss: 4.3485\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8365 - val_loss: 4.3479\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8344 - val_loss: 4.3473\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8323 - val_loss: 4.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8301 - val_loss: 4.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8280 - val_loss: 4.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8259 - val_loss: 4.3451\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8238 - val_loss: 4.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8217 - val_loss: 4.3440\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8197 - val_loss: 4.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8176 - val_loss: 4.3428\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8156 - val_loss: 4.3423\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8136 - val_loss: 4.3417\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8117 - val_loss: 4.3412\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8098 - val_loss: 4.3407\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 4.3403\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8061 - val_loss: 4.3399\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8042 - val_loss: 4.3395\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8023 - val_loss: 4.3390\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8004 - val_loss: 4.3386\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7986 - val_loss: 4.3382\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7967 - val_loss: 4.3378\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7949 - val_loss: 4.3374\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7930 - val_loss: 4.3370\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7912 - val_loss: 4.3365\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7893 - val_loss: 4.3361\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7874 - val_loss: 4.3357\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7856 - val_loss: 4.3353\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7839 - val_loss: 4.3349\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7822 - val_loss: 4.3345\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7805 - val_loss: 4.3341\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7787 - val_loss: 4.3338\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7771 - val_loss: 4.3334\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7754 - val_loss: 4.3330\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7738 - val_loss: 4.3327\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 4.116072897890656, my average MASE = 12.21206426084865\n",
      "Cluster 6, 4.116072897890656\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(96, 10, 67), train_y.shape=(96, 67), test_X.shape=(32, 10, 67), test_y.shape=(32, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.3660 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3652 - val_loss: 0.3455\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3645 - val_loss: 0.3451\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3638 - val_loss: 0.3448\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3632 - val_loss: 0.3445\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3625 - val_loss: 0.3441\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3619 - val_loss: 0.3438\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3435\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3606 - val_loss: 0.3431\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3599 - val_loss: 0.3428\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3593 - val_loss: 0.3425\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3587 - val_loss: 0.3422\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3581 - val_loss: 0.3419\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3576 - val_loss: 0.3416\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3570 - val_loss: 0.3413\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3564 - val_loss: 0.3410\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3558 - val_loss: 0.3407\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3553 - val_loss: 0.3404\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3547 - val_loss: 0.3401\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3542 - val_loss: 0.3398\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3536 - val_loss: 0.3395\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3531 - val_loss: 0.3393\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3526 - val_loss: 0.3390\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3521 - val_loss: 0.3387\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3516 - val_loss: 0.3384\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3511 - val_loss: 0.3382\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3506 - val_loss: 0.3379\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3501 - val_loss: 0.3376\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3496 - val_loss: 0.3373\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3491 - val_loss: 0.3371\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3487 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3482 - val_loss: 0.3366\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3477 - val_loss: 0.3363\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3473 - val_loss: 0.3360\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3464 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3459 - val_loss: 0.3353\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3455 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3451 - val_loss: 0.3348\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3446 - val_loss: 0.3345\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(32, 67), test_y.shape=(32, 67)\n",
      "average MASE = 266.09609302896547, my average MASE = 71685898.00003502\n",
      "Cluster 8, 266.09609302896547\n",
      "clusters_labels.shape=(408093,)\n",
      "N_clusters=11, 11, 663, (11, 67)\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3610 - val_loss: 0.4969\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3601 - val_loss: 0.4969\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3592 - val_loss: 0.4970\n",
      "Epoch 3: early stopping\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.35712691602972574, my average MASE = 0.5241910168311086\n",
      "Cluster 0, 0.35712691602972574\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2752 - val_loss: 0.2714\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2747 - val_loss: 0.2712\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2742 - val_loss: 0.2710\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2737 - val_loss: 0.2707\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2733 - val_loss: 0.2705\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2728 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2723 - val_loss: 0.2701\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2718 - val_loss: 0.2699\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2714 - val_loss: 0.2697\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2709 - val_loss: 0.2695\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2704 - val_loss: 0.2693\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2700 - val_loss: 0.2691\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2695 - val_loss: 0.2690\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2691 - val_loss: 0.2688\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2687 - val_loss: 0.2686\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2682 - val_loss: 0.2684\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2678 - val_loss: 0.2682\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2673 - val_loss: 0.2680\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2669 - val_loss: 0.2678\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2665 - val_loss: 0.2676\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2661 - val_loss: 0.2674\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.2672\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2653 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2649 - val_loss: 0.2669\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2645 - val_loss: 0.2667\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2641 - val_loss: 0.2665\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2637 - val_loss: 0.2663\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2633 - val_loss: 0.2662\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2629 - val_loss: 0.2660\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2625 - val_loss: 0.2658\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2621 - val_loss: 0.2656\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2618 - val_loss: 0.2655\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2614 - val_loss: 0.2653\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2610 - val_loss: 0.2652\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2606 - val_loss: 0.2650\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2602 - val_loss: 0.2649\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2599 - val_loss: 0.2647\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2595 - val_loss: 0.2646\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2591 - val_loss: 0.2644\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2588 - val_loss: 0.2643\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 114.92828938190037, my average MASE = 64775351.69732988\n",
      "Cluster 1, 114.92828938190037\n",
      "Before prediction: train_X.shape=(21, 10, 67), train_y.shape=(21, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6587 - val_loss: 0.2666\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6569 - val_loss: 0.2655\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6551 - val_loss: 0.2645\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6533 - val_loss: 0.2635\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6515 - val_loss: 0.2624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6497 - val_loss: 0.2614\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6480 - val_loss: 0.2604\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6463 - val_loss: 0.2594\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6446 - val_loss: 0.2584\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6429 - val_loss: 0.2574\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6412 - val_loss: 0.2565\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6395 - val_loss: 0.2555\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6379 - val_loss: 0.2546\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6363 - val_loss: 0.2538\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6346 - val_loss: 0.2529\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6331 - val_loss: 0.2520\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6315 - val_loss: 0.2512\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6300 - val_loss: 0.2504\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6285 - val_loss: 0.2496\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6270 - val_loss: 0.2488\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6255 - val_loss: 0.2480\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6240 - val_loss: 0.2473\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6225 - val_loss: 0.2466\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6211 - val_loss: 0.2458\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6197 - val_loss: 0.2451\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6182 - val_loss: 0.2444\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6168 - val_loss: 0.2437\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6155 - val_loss: 0.2430\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6141 - val_loss: 0.2423\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6127 - val_loss: 0.2416\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6114 - val_loss: 0.2410\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6101 - val_loss: 0.2403\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6088 - val_loss: 0.2397\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6075 - val_loss: 0.2390\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6063 - val_loss: 0.2384\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6050 - val_loss: 0.2378\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6038 - val_loss: 0.2372\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6026 - val_loss: 0.2365\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6014 - val_loss: 0.2359\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6002 - val_loss: 0.2353\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 26456338.054780327, my average MASE = 1170397376.6808207\n",
      "Cluster 2, 26456338.054780327\n",
      "Before prediction: train_X.shape=(62, 10, 67), train_y.shape=(62, 67), test_X.shape=(21, 10, 67), test_y.shape=(21, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3828 - val_loss: 0.5067\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3824 - val_loss: 0.5064\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3820 - val_loss: 0.5062\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3816 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3812 - val_loss: 0.5056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3808 - val_loss: 0.5053\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3804 - val_loss: 0.5051\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3801 - val_loss: 0.5048\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3797 - val_loss: 0.5045\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3793 - val_loss: 0.5043\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3790 - val_loss: 0.5040\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3786 - val_loss: 0.5038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3783 - val_loss: 0.5035\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3779 - val_loss: 0.5032\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3776 - val_loss: 0.5030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3772 - val_loss: 0.5027\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3769 - val_loss: 0.5025\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3765 - val_loss: 0.5022\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3762 - val_loss: 0.5020\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3758 - val_loss: 0.5017\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3755 - val_loss: 0.5015\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3752 - val_loss: 0.5012\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3748 - val_loss: 0.5010\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3745 - val_loss: 0.5008\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3742 - val_loss: 0.5005\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3738 - val_loss: 0.5003\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3735 - val_loss: 0.5000\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3732 - val_loss: 0.4998\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3729 - val_loss: 0.4995\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3726 - val_loss: 0.4993\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3722 - val_loss: 0.4991\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3719 - val_loss: 0.4988\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3716 - val_loss: 0.4986\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3713 - val_loss: 0.4984\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3710 - val_loss: 0.4982\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3707 - val_loss: 0.4979\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3704 - val_loss: 0.4977\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3701 - val_loss: 0.4975\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3698 - val_loss: 0.4973\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3695 - val_loss: 0.4971\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(21, 67), test_y.shape=(21, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 88.873907317969, my average MASE = 105114880.66517946\n",
      "Cluster 3, 88.873907317969\n",
      "Before prediction: train_X.shape=(58, 10, 67), train_y.shape=(58, 67), test_X.shape=(19, 10, 67), test_y.shape=(19, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6113 - val_loss: 0.3397\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6107 - val_loss: 0.3395\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6100 - val_loss: 0.3394\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6094 - val_loss: 0.3393\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6087 - val_loss: 0.3392\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6081 - val_loss: 0.3391\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6075 - val_loss: 0.3390\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6069 - val_loss: 0.3389\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6062 - val_loss: 0.3388\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6056 - val_loss: 0.3387\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6050 - val_loss: 0.3386\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6044 - val_loss: 0.3385\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6038 - val_loss: 0.3384\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6032 - val_loss: 0.3383\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6026 - val_loss: 0.3382\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6020 - val_loss: 0.3381\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6014 - val_loss: 0.3380\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6009 - val_loss: 0.3379\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6003 - val_loss: 0.3378\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5997 - val_loss: 0.3377\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5992 - val_loss: 0.3376\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5986 - val_loss: 0.3375\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5981 - val_loss: 0.3374\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5976 - val_loss: 0.3373\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5970 - val_loss: 0.3372\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5965 - val_loss: 0.3372\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5960 - val_loss: 0.3371\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5955 - val_loss: 0.3370\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5949 - val_loss: 0.3369\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5944 - val_loss: 0.3369\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5939 - val_loss: 0.3368\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5934 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5929 - val_loss: 0.3366\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5924 - val_loss: 0.3366\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5919 - val_loss: 0.3365\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5915 - val_loss: 0.3364\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5910 - val_loss: 0.3364\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5905 - val_loss: 0.3363\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5900 - val_loss: 0.3362\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5895 - val_loss: 0.3362\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(19, 67), test_y.shape=(19, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2288977.9462372796, my average MASE = 275894539.3328722\n",
      "Cluster 4, 2288977.9462372796\n",
      "Before prediction: train_X.shape=(22, 10, 67), train_y.shape=(22, 67), test_X.shape=(7, 10, 67), test_y.shape=(7, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6507 - val_loss: 0.5866\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6499 - val_loss: 0.5864\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6491 - val_loss: 0.5862\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6483 - val_loss: 0.5861\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6475 - val_loss: 0.5859\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6467 - val_loss: 0.5857\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6459 - val_loss: 0.5855\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6451 - val_loss: 0.5854\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6443 - val_loss: 0.5852\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6435 - val_loss: 0.5851\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6427 - val_loss: 0.5849\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6420 - val_loss: 0.5848\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6412 - val_loss: 0.5846\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6405 - val_loss: 0.5844\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6397 - val_loss: 0.5843\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6389 - val_loss: 0.5841\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6382 - val_loss: 0.5840\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6374 - val_loss: 0.5838\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6367 - val_loss: 0.5837\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6359 - val_loss: 0.5836\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6352 - val_loss: 0.5834\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6345 - val_loss: 0.5833\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6337 - val_loss: 0.5832\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6330 - val_loss: 0.5830\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6323 - val_loss: 0.5829\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6316 - val_loss: 0.5827\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6309 - val_loss: 0.5826\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6302 - val_loss: 0.5825\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6295 - val_loss: 0.5824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6288 - val_loss: 0.5822\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6281 - val_loss: 0.5821\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6275 - val_loss: 0.5820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6268 - val_loss: 0.5819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6261 - val_loss: 0.5818\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6254 - val_loss: 0.5816\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6248 - val_loss: 0.5815\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6241 - val_loss: 0.5814\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6235 - val_loss: 0.5813\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6228 - val_loss: 0.5811\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6222 - val_loss: 0.5810\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(7, 67), test_y.shape=(7, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 56.939779008571485, my average MASE = 37107546.21609385\n",
      "Cluster 5, 56.939779008571485\n",
      "Before prediction: train_X.shape=(4681, 10, 67), train_y.shape=(4681, 67), test_X.shape=(1560, 10, 67), test_y.shape=(1560, 67)\n",
      "Epoch 1/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0785 - val_loss: 0.0245\n",
      "Epoch 2/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0726 - val_loss: 0.0222\n",
      "Epoch 3/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0688 - val_loss: 0.0210\n",
      "Epoch 4/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0661 - val_loss: 0.0201\n",
      "Epoch 5/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0638 - val_loss: 0.0195\n",
      "Epoch 6/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0620 - val_loss: 0.0189\n",
      "Epoch 7/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0604 - val_loss: 0.0185\n",
      "Epoch 8/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0590 - val_loss: 0.0182\n",
      "Epoch 9/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0579 - val_loss: 0.0179\n",
      "Epoch 10/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0569 - val_loss: 0.0176\n",
      "Epoch 11/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0560 - val_loss: 0.0174\n",
      "Epoch 12/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0552 - val_loss: 0.0172\n",
      "Epoch 13/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0545 - val_loss: 0.0171\n",
      "Epoch 14/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0539 - val_loss: 0.0169\n",
      "Epoch 15/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0533 - val_loss: 0.0168\n",
      "Epoch 16/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0528 - val_loss: 0.0167\n",
      "Epoch 17/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0524 - val_loss: 0.0166\n",
      "Epoch 18/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0519 - val_loss: 0.0165\n",
      "Epoch 19/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0516 - val_loss: 0.0165\n",
      "Epoch 20/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0512 - val_loss: 0.0164\n",
      "Epoch 21/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0509 - val_loss: 0.0163\n",
      "Epoch 22/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0505 - val_loss: 0.0163\n",
      "Epoch 23/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0502 - val_loss: 0.0162\n",
      "Epoch 24/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0500 - val_loss: 0.0162\n",
      "Epoch 25/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0497 - val_loss: 0.0161\n",
      "Epoch 26/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0495 - val_loss: 0.0161\n",
      "Epoch 27/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0492 - val_loss: 0.0161\n",
      "Epoch 28/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0490 - val_loss: 0.0160\n",
      "Epoch 29/40\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0488 - val_loss: 0.0160\n",
      "Epoch 30/40\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0486 - val_loss: 0.0159\n",
      "Epoch 31/40\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0485 - val_loss: 0.0159\n",
      "Epoch 32/40\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0483 - val_loss: 0.0158\n",
      "Epoch 33/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0481 - val_loss: 0.0158\n",
      "Epoch 34/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0480 - val_loss: 0.0158\n",
      "Epoch 35/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0479 - val_loss: 0.0157\n",
      "Epoch 36/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0477 - val_loss: 0.0157\n",
      "Epoch 37/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0476 - val_loss: 0.0157\n",
      "Epoch 38/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0475 - val_loss: 0.0156\n",
      "Epoch 39/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0474 - val_loss: 0.0156\n",
      "Epoch 40/40\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0473 - val_loss: 0.0156\n",
      "49/49 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1560, 67), test_y.shape=(1560, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 149408746.52177918, my average MASE = 566572768.961764\n",
      "Cluster 6, 149408746.52177918\n",
      "Before prediction: train_X.shape=(34, 10, 67), train_y.shape=(34, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5377 - val_loss: 0.4682\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5358 - val_loss: 0.4667\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5339 - val_loss: 0.4653\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5320 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5302 - val_loss: 0.4624\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5283 - val_loss: 0.4609\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5265 - val_loss: 0.4595\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5247 - val_loss: 0.4581\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5229 - val_loss: 0.4567\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5211 - val_loss: 0.4554\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5194 - val_loss: 0.4540\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5177 - val_loss: 0.4527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5160 - val_loss: 0.4514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5143 - val_loss: 0.4501\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5126 - val_loss: 0.4488\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5110 - val_loss: 0.4475\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5093 - val_loss: 0.4462\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5077 - val_loss: 0.4450\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5062 - val_loss: 0.4438\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5046 - val_loss: 0.4425\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5030 - val_loss: 0.4413\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5015 - val_loss: 0.4401\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5000 - val_loss: 0.4390\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4985 - val_loss: 0.4378\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4970 - val_loss: 0.4367\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4955 - val_loss: 0.4355\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4940 - val_loss: 0.4344\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4925 - val_loss: 0.4334\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4911 - val_loss: 0.4323\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4897 - val_loss: 0.4312\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4882 - val_loss: 0.4302\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4868 - val_loss: 0.4292\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4854 - val_loss: 0.4281\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4840 - val_loss: 0.4271\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4826 - val_loss: 0.4261\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4813 - val_loss: 0.4251\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4242\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4786 - val_loss: 0.4232\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4772 - val_loss: 0.4223\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4759 - val_loss: 0.4214\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3453236106.5511885, my average MASE = 6985920382.132476\n",
      "Cluster 7, 3453236106.5511885\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3084 - val_loss: 0.3104\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3075 - val_loss: 0.3100\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3066 - val_loss: 0.3095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3058 - val_loss: 0.3091\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3050 - val_loss: 0.3086\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3042 - val_loss: 0.3082\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3034 - val_loss: 0.3077\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3026 - val_loss: 0.3073\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3018 - val_loss: 0.3068\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3010 - val_loss: 0.3064\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3002 - val_loss: 0.3059\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2995 - val_loss: 0.3055\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2987 - val_loss: 0.3051\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2980 - val_loss: 0.3047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2973 - val_loss: 0.3043\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2965 - val_loss: 0.3039\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2958 - val_loss: 0.3035\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2951 - val_loss: 0.3031\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2944 - val_loss: 0.3027\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2937 - val_loss: 0.3024\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2930 - val_loss: 0.3020\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2924 - val_loss: 0.3017\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2917 - val_loss: 0.3014\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2911 - val_loss: 0.3011\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2904 - val_loss: 0.3008\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2898 - val_loss: 0.3006\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2891 - val_loss: 0.3003\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2885 - val_loss: 0.3001\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2878 - val_loss: 0.2998\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2872 - val_loss: 0.2996\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2866 - val_loss: 0.2994\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2859 - val_loss: 0.2992\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2853 - val_loss: 0.2990\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2846 - val_loss: 0.2988\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2840 - val_loss: 0.2985\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2834 - val_loss: 0.2983\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2827 - val_loss: 0.2981\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2822 - val_loss: 0.2979\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2816 - val_loss: 0.2977\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2810 - val_loss: 0.2975\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2112740905793214, my average MASE = 0.3813496945040607\n",
      "Cluster 8, 0.2112740905793214\n",
      "Before prediction: train_X.shape=(33, 10, 67), train_y.shape=(33, 67), test_X.shape=(11, 10, 67), test_y.shape=(11, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5052 - val_loss: 0.6961\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5045 - val_loss: 0.6956\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5038 - val_loss: 0.6950\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5030 - val_loss: 0.6945\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5023 - val_loss: 0.6939\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5016 - val_loss: 0.6934\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5009 - val_loss: 0.6928\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5002 - val_loss: 0.6923\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4995 - val_loss: 0.6918\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4988 - val_loss: 0.6913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4981 - val_loss: 0.6908\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4975 - val_loss: 0.6903\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4968 - val_loss: 0.6898\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4961 - val_loss: 0.6893\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4955 - val_loss: 0.6888\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4948 - val_loss: 0.6883\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4942 - val_loss: 0.6879\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4935 - val_loss: 0.6874\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4929 - val_loss: 0.6869\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4923 - val_loss: 0.6865\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.6860\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4910 - val_loss: 0.6855\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4904 - val_loss: 0.6851\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4898 - val_loss: 0.6846\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4892 - val_loss: 0.6842\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4886 - val_loss: 0.6837\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4880 - val_loss: 0.6833\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4874 - val_loss: 0.6829\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4868 - val_loss: 0.6824\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4863 - val_loss: 0.6820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4857 - val_loss: 0.6816\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4851 - val_loss: 0.6811\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4845 - val_loss: 0.6807\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4840 - val_loss: 0.6803\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4834 - val_loss: 0.6799\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4828 - val_loss: 0.6794\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6790\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4817 - val_loss: 0.6786\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4811 - val_loss: 0.6782\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4806 - val_loss: 0.6778\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(11, 67), test_y.shape=(11, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 74.79960857799604, my average MASE = 23518054.91533832\n",
      "Cluster 9, 74.79960857799604\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3521 - val_loss: 0.2993\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3508 - val_loss: 0.2987\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3496 - val_loss: 0.2982\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3483 - val_loss: 0.2976\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3470 - val_loss: 0.2971\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3458 - val_loss: 0.2966\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3446 - val_loss: 0.2961\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3435 - val_loss: 0.2957\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3423 - val_loss: 0.2954\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3412 - val_loss: 0.2950\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3400 - val_loss: 0.2946\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3389 - val_loss: 0.2943\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3378 - val_loss: 0.2939\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3368 - val_loss: 0.2935\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3357 - val_loss: 0.2932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3347 - val_loss: 0.2928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3337 - val_loss: 0.2925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3326 - val_loss: 0.2921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3317 - val_loss: 0.2918\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3307 - val_loss: 0.2915\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3298 - val_loss: 0.2912\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3289 - val_loss: 0.2910\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3279 - val_loss: 0.2908\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.2905\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3261 - val_loss: 0.2903\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3252 - val_loss: 0.2901\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3244 - val_loss: 0.2899\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3235 - val_loss: 0.2897\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3227 - val_loss: 0.2895\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3219 - val_loss: 0.2894\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3211 - val_loss: 0.2892\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3203 - val_loss: 0.2891\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3195 - val_loss: 0.2890\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3187 - val_loss: 0.2889\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3179 - val_loss: 0.2888\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3171 - val_loss: 0.2887\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3163 - val_loss: 0.2886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3155 - val_loss: 0.2886\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.2885\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3139 - val_loss: 0.2885\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.1864435054204945, my average MASE = 0.27675363785512175\n",
      "Cluster 10, 0.1864435054204945\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=2, 2, 18, (30612, 67)\n",
      "Before prediction: train_X.shape=(18361, 10, 67), train_y.shape=(18361, 67), test_X.shape=(6120, 10, 67), test_y.shape=(6120, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.3015 - val_loss: 0.3194\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2836 - val_loss: 0.3051\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2695 - val_loss: 0.2935\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2585 - val_loss: 0.2851\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2510 - val_loss: 0.2789\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2456 - val_loss: 0.2737\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2410 - val_loss: 0.2693\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2369 - val_loss: 0.2653\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2332 - val_loss: 0.2616\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2298 - val_loss: 0.2584\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2267 - val_loss: 0.2555\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2238 - val_loss: 0.2531\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2212 - val_loss: 0.2509\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2190 - val_loss: 0.2490\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2172 - val_loss: 0.2474\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2156 - val_loss: 0.2461\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2143 - val_loss: 0.2448\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2438\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2120 - val_loss: 0.2428\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2110 - val_loss: 0.2420\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2101 - val_loss: 0.2412\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2092 - val_loss: 0.2404\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2084 - val_loss: 0.2395\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2077 - val_loss: 0.2390\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2070 - val_loss: 0.2383\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2064 - val_loss: 0.2377\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2058 - val_loss: 0.2371\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2052 - val_loss: 0.2365\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2047 - val_loss: 0.2361\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2041 - val_loss: 0.2356\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2352\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2032 - val_loss: 0.2348\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2028 - val_loss: 0.2343\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2024 - val_loss: 0.2340\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2020 - val_loss: 0.2336\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2016 - val_loss: 0.2332\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2013 - val_loss: 0.2329\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2009 - val_loss: 0.2327\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2006 - val_loss: 0.2324\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2321\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6120, 67), test_y.shape=(6120, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2046.5122369835897, my average MASE = 2805.5341357338157\n",
      "Cluster 0, 2046.5122369835897\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5756 - val_loss: 1.2952\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5738 - val_loss: 1.2950\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5721 - val_loss: 1.2949\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5703 - val_loss: 1.2948\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5686 - val_loss: 1.2947\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5670 - val_loss: 1.2946\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5653 - val_loss: 1.2945\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5637 - val_loss: 1.2944\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5621 - val_loss: 1.2943\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5605 - val_loss: 1.2941\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5589 - val_loss: 1.2940\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5573 - val_loss: 1.2939\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5558 - val_loss: 1.2937\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5542 - val_loss: 1.2936\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5527 - val_loss: 1.2934\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5512 - val_loss: 1.2932\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5497 - val_loss: 1.2930\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 1.2929\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5468 - val_loss: 1.2927\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 1.2925\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5440 - val_loss: 1.2924\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5426 - val_loss: 1.2922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5413 - val_loss: 1.2921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5400 - val_loss: 1.2920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5386 - val_loss: 1.2919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5374 - val_loss: 1.2918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 1.2918\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5349 - val_loss: 1.2917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5337 - val_loss: 1.2916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5325 - val_loss: 1.2915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5314 - val_loss: 1.2914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5302 - val_loss: 1.2912\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5290 - val_loss: 1.2911\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5279 - val_loss: 1.2909\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5268 - val_loss: 1.2907\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5256 - val_loss: 1.2905\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5246 - val_loss: 1.2903\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5235 - val_loss: 1.2902\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5224 - val_loss: 1.2901\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5213 - val_loss: 1.2900\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 950350834.5172157, my average MASE = 2745439088.6097794\n",
      "Cluster 1, 950350834.5172157\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=5, 5, 599, (8, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3119 - val_loss: 0.2829\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3116 - val_loss: 0.2829\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3112 - val_loss: 0.2828\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3109 - val_loss: 0.2828\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3106 - val_loss: 0.2828\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3102 - val_loss: 0.2827\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3099 - val_loss: 0.2827\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3096 - val_loss: 0.2827\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3092 - val_loss: 0.2827\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3089 - val_loss: 0.2826\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3086 - val_loss: 0.2826\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3083 - val_loss: 0.2826\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3080 - val_loss: 0.2826\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3077 - val_loss: 0.2825\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3074 - val_loss: 0.2825\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3070 - val_loss: 0.2825\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3067 - val_loss: 0.2825\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3064 - val_loss: 0.2824\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3061 - val_loss: 0.2824\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3058 - val_loss: 0.2824\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3055 - val_loss: 0.2823\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3052 - val_loss: 0.2823\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3049 - val_loss: 0.2823\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3047 - val_loss: 0.2822\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3044 - val_loss: 0.2822\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3041 - val_loss: 0.2822\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3038 - val_loss: 0.2821\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3035 - val_loss: 0.2821\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3032 - val_loss: 0.2821\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3029 - val_loss: 0.2820\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3027 - val_loss: 0.2820\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3024 - val_loss: 0.2820\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3021 - val_loss: 0.2819\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.2819\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3016 - val_loss: 0.2818\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3013 - val_loss: 0.2818\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3010 - val_loss: 0.2818\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3008 - val_loss: 0.2817\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3005 - val_loss: 0.2817\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3002 - val_loss: 0.2816\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 104.97029321074898, my average MASE = 15924142.879668588\n",
      "Cluster 0, 104.97029321074898\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5420 - val_loss: 0.4071\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5399 - val_loss: 0.4062\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5378 - val_loss: 0.4054\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5357 - val_loss: 0.4045\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5337 - val_loss: 0.4037\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5316 - val_loss: 0.4029\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5296 - val_loss: 0.4021\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5276 - val_loss: 0.4013\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5257 - val_loss: 0.4005\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5237 - val_loss: 0.3998\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5218 - val_loss: 0.3990\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5199 - val_loss: 0.3983\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5179 - val_loss: 0.3975\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5161 - val_loss: 0.3968\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5142 - val_loss: 0.3961\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5124 - val_loss: 0.3954\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5106 - val_loss: 0.3947\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5088 - val_loss: 0.3940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5070 - val_loss: 0.3933\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5052 - val_loss: 0.3926\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5035 - val_loss: 0.3919\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5018 - val_loss: 0.3913\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5001 - val_loss: 0.3906\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4985 - val_loss: 0.3899\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4968 - val_loss: 0.3892\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4952 - val_loss: 0.3886\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4936 - val_loss: 0.3879\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4920 - val_loss: 0.3873\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4905 - val_loss: 0.3866\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4889 - val_loss: 0.3860\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4874 - val_loss: 0.3853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4858 - val_loss: 0.3847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4843 - val_loss: 0.3840\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4828 - val_loss: 0.3834\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4813 - val_loss: 0.3828\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4798 - val_loss: 0.3821\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4783 - val_loss: 0.3815\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4769 - val_loss: 0.3809\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4754 - val_loss: 0.3803\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4740 - val_loss: 0.3797\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3145368812.0062547, my average MASE = 5974295545.526059\n",
      "Cluster 1, 3145368812.0062547\n",
      "Before prediction: train_X.shape=(2220, 10, 67), train_y.shape=(2220, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.5043 - val_loss: 0.3721\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4967 - val_loss: 0.3684\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4907 - val_loss: 0.3653\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4855 - val_loss: 0.3625\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4810 - val_loss: 0.3601\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4769 - val_loss: 0.3579\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4731 - val_loss: 0.3558\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4695 - val_loss: 0.3540\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4661 - val_loss: 0.3522\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4629 - val_loss: 0.3506\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4598 - val_loss: 0.3490\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4568 - val_loss: 0.3476\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4539 - val_loss: 0.3462\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4510 - val_loss: 0.3448\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4483 - val_loss: 0.3435\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4455 - val_loss: 0.3422\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4429 - val_loss: 0.3410\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4402 - val_loss: 0.3398\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4376 - val_loss: 0.3386\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4351 - val_loss: 0.3375\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4326 - val_loss: 0.3363\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4302 - val_loss: 0.3352\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4278 - val_loss: 0.3342\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4255 - val_loss: 0.3331\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4232 - val_loss: 0.3321\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4211 - val_loss: 0.3311\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4189 - val_loss: 0.3302\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4169 - val_loss: 0.3292\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4149 - val_loss: 0.3284\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4129 - val_loss: 0.3276\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4111 - val_loss: 0.3268\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4093 - val_loss: 0.3260\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4076 - val_loss: 0.3253\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4060 - val_loss: 0.3246\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4044 - val_loss: 0.3240\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4029 - val_loss: 0.3234\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4014 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4000 - val_loss: 0.3222\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3986 - val_loss: 0.3217\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3972 - val_loss: 0.3211\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 487.922050733615, my average MASE = 1880.6635092100216\n",
      "Cluster 2, 487.922050733615\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1089 - val_loss: 0.0991\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1039 - val_loss: 0.0970\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0998 - val_loss: 0.0956\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0965 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0936 - val_loss: 0.0938\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0911 - val_loss: 0.0932\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0889 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0869 - val_loss: 0.0924\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0852 - val_loss: 0.0922\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0836 - val_loss: 0.0920\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0821 - val_loss: 0.0918\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0808 - val_loss: 0.0917\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0795 - val_loss: 0.0915\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0783 - val_loss: 0.0913\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0773 - val_loss: 0.0912\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0763 - val_loss: 0.0910\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0908\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0744 - val_loss: 0.0907\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0736 - val_loss: 0.0905\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0729 - val_loss: 0.0903\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0721 - val_loss: 0.0901\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0714 - val_loss: 0.0900\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0708 - val_loss: 0.0899\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0702 - val_loss: 0.0897\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0696 - val_loss: 0.0896\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0690 - val_loss: 0.0895\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0685 - val_loss: 0.0894\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0680 - val_loss: 0.0893\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0675 - val_loss: 0.0892\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0670 - val_loss: 0.0892\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0666 - val_loss: 0.0891\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0661 - val_loss: 0.0890\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0658 - val_loss: 0.0890\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0654 - val_loss: 0.0889\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0650 - val_loss: 0.0889\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0647 - val_loss: 0.0888\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0644 - val_loss: 0.0888\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0641 - val_loss: 0.0888\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0887\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0636 - val_loss: 0.0887\n",
      "21/21 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1152398695.5185678, my average MASE = 7118534712.468365\n",
      "Cluster 3, 1152398695.5185678\n",
      "Before prediction: train_X.shape=(156, 10, 67), train_y.shape=(156, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5146 - val_loss: 0.4378\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5133 - val_loss: 0.4370\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5122 - val_loss: 0.4361\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5111 - val_loss: 0.4352\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5100 - val_loss: 0.4344\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5089 - val_loss: 0.4335\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5078 - val_loss: 0.4327\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5068 - val_loss: 0.4319\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5057 - val_loss: 0.4311\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4303\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5037 - val_loss: 0.4296\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5028 - val_loss: 0.4288\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5018 - val_loss: 0.4281\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5008 - val_loss: 0.4273\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4999 - val_loss: 0.4266\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4990 - val_loss: 0.4259\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4981 - val_loss: 0.4252\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4972 - val_loss: 0.4245\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4963 - val_loss: 0.4238\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4954 - val_loss: 0.4232\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4945 - val_loss: 0.4225\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4937 - val_loss: 0.4219\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4929 - val_loss: 0.4213\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4920 - val_loss: 0.4207\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4912 - val_loss: 0.4201\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4905 - val_loss: 0.4195\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4897 - val_loss: 0.4189\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4889 - val_loss: 0.4183\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4881 - val_loss: 0.4177\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4874 - val_loss: 0.4172\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4867 - val_loss: 0.4166\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4859 - val_loss: 0.4161\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4852 - val_loss: 0.4155\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4845 - val_loss: 0.4150\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4838 - val_loss: 0.4145\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4831 - val_loss: 0.4139\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4824 - val_loss: 0.4134\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4817 - val_loss: 0.4129\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4811 - val_loss: 0.4124\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4804 - val_loss: 0.4119\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 117.29272898284657, my average MASE = 138077149.3198319\n",
      "Cluster 4, 117.29272898284657\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=7, 7, 49, (317, 67)\n",
      "Before prediction: train_X.shape=(184, 10, 67), train_y.shape=(184, 67), test_X.shape=(61, 10, 67), test_y.shape=(61, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6997 - val_loss: 0.6374\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6982 - val_loss: 0.6363\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6968 - val_loss: 0.6352\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6954 - val_loss: 0.6341\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.6331\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6927 - val_loss: 0.6320\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.6310\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6901 - val_loss: 0.6300\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6889 - val_loss: 0.6290\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6876 - val_loss: 0.6281\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6864 - val_loss: 0.6272\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6852 - val_loss: 0.6262\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6840 - val_loss: 0.6253\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6829 - val_loss: 0.6244\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6818 - val_loss: 0.6235\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6807 - val_loss: 0.6227\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6796 - val_loss: 0.6218\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6785 - val_loss: 0.6210\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6774 - val_loss: 0.6202\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6763 - val_loss: 0.6194\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.6186\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6743 - val_loss: 0.6178\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6733 - val_loss: 0.6171\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6723 - val_loss: 0.6163\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6713 - val_loss: 0.6156\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6704 - val_loss: 0.6149\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6694 - val_loss: 0.6142\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6685 - val_loss: 0.6135\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6676 - val_loss: 0.6127\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6666 - val_loss: 0.6121\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6658 - val_loss: 0.6114\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6649 - val_loss: 0.6107\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6640 - val_loss: 0.6100\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6631 - val_loss: 0.6093\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6622 - val_loss: 0.6086\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6614 - val_loss: 0.6079\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6605 - val_loss: 0.6073\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6597 - val_loss: 0.6066\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6588 - val_loss: 0.6060\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6580 - val_loss: 0.6053\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(61, 67), test_y.shape=(61, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 140.79883300988942, my average MASE = 132025753.41047312\n",
      "Cluster 0, 140.79883300988942\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5180 - val_loss: 0.4305\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5161 - val_loss: 0.4294\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5142 - val_loss: 0.4283\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5123 - val_loss: 0.4272\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5104 - val_loss: 0.4261\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5085 - val_loss: 0.4251\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5067 - val_loss: 0.4241\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5049 - val_loss: 0.4230\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.4221\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5013 - val_loss: 0.4211\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4996 - val_loss: 0.4202\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4978 - val_loss: 0.4193\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4961 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4944 - val_loss: 0.4175\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4927 - val_loss: 0.4166\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4911 - val_loss: 0.4158\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4895 - val_loss: 0.4149\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4879 - val_loss: 0.4141\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4863 - val_loss: 0.4133\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4847 - val_loss: 0.4126\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4832 - val_loss: 0.4118\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4816 - val_loss: 0.4110\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4801 - val_loss: 0.4103\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4787 - val_loss: 0.4095\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4772 - val_loss: 0.4088\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4758 - val_loss: 0.4080\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4743 - val_loss: 0.4073\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4729 - val_loss: 0.4066\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4715 - val_loss: 0.4058\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4701 - val_loss: 0.4051\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4687 - val_loss: 0.4044\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4673 - val_loss: 0.4038\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4660 - val_loss: 0.4031\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4646 - val_loss: 0.4024\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4633 - val_loss: 0.4017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4620 - val_loss: 0.4010\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4607 - val_loss: 0.4004\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4594 - val_loss: 0.3997\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4582 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4569 - val_loss: 0.3985\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3225148693.3924103, my average MASE = 6345532768.562708\n",
      "Cluster 1, 3225148693.3924103\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1129 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1075 - val_loss: 0.0981\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1032 - val_loss: 0.0968\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0996 - val_loss: 0.0960\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0965 - val_loss: 0.0953\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0938 - val_loss: 0.0949\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0913 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0892 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0872 - val_loss: 0.0938\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0854 - val_loss: 0.0935\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0838 - val_loss: 0.0933\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0823 - val_loss: 0.0931\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0809 - val_loss: 0.0928\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0796 - val_loss: 0.0926\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0784 - val_loss: 0.0924\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0773 - val_loss: 0.0921\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0762 - val_loss: 0.0919\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0752 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0743 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0734 - val_loss: 0.0913\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0726 - val_loss: 0.0912\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0719 - val_loss: 0.0910\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0907\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0699 - val_loss: 0.0906\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0693 - val_loss: 0.0904\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0687 - val_loss: 0.0903\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0682 - val_loss: 0.0903\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0677 - val_loss: 0.0902\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0672 - val_loss: 0.0901\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0668 - val_loss: 0.0901\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0663 - val_loss: 0.0900\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0659 - val_loss: 0.0899\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0655 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0898\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0648 - val_loss: 0.0897\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0645 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0639 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0636 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1209643109.1461504, my average MASE = 20216236756.2103\n",
      "Cluster 2, 1209643109.1461504\n",
      "Before prediction: train_X.shape=(47, 10, 67), train_y.shape=(47, 67), test_X.shape=(16, 10, 67), test_y.shape=(16, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.4112 - val_loss: 0.3544\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4108 - val_loss: 0.3542\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4104 - val_loss: 0.3540\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4100 - val_loss: 0.3538\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4095 - val_loss: 0.3536\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4091 - val_loss: 0.3534\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4087 - val_loss: 0.3533\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4083 - val_loss: 0.3531\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4079 - val_loss: 0.3529\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4075 - val_loss: 0.3527\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4071 - val_loss: 0.3525\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4067 - val_loss: 0.3524\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4063 - val_loss: 0.3522\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4059 - val_loss: 0.3520\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4055 - val_loss: 0.3519\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4051 - val_loss: 0.3517\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4047 - val_loss: 0.3515\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4043 - val_loss: 0.3514\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4039 - val_loss: 0.3512\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3511\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4032 - val_loss: 0.3509\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4028 - val_loss: 0.3508\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4024 - val_loss: 0.3506\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4020 - val_loss: 0.3505\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4017 - val_loss: 0.3503\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4009 - val_loss: 0.3501\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4006 - val_loss: 0.3499\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4002 - val_loss: 0.3498\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3999 - val_loss: 0.3497\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.3495\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3992 - val_loss: 0.3494\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.3493\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3985 - val_loss: 0.3492\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3982 - val_loss: 0.3491\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3978 - val_loss: 0.3489\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3975 - val_loss: 0.3488\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3972 - val_loss: 0.3487\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3968 - val_loss: 0.3486\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3965 - val_loss: 0.3485\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(16, 67), test_y.shape=(16, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 66.79284837728264, my average MASE = 54990938.33317367\n",
      "Cluster 3, 66.79284837728264\n",
      "Before prediction: train_X.shape=(155, 10, 67), train_y.shape=(155, 67), test_X.shape=(52, 10, 67), test_y.shape=(52, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5009 - val_loss: 0.4222\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4998 - val_loss: 0.4214\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4988 - val_loss: 0.4207\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4978 - val_loss: 0.4200\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4968 - val_loss: 0.4193\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4958 - val_loss: 0.4186\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4949 - val_loss: 0.4179\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4939 - val_loss: 0.4172\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4930 - val_loss: 0.4165\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4921 - val_loss: 0.4159\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4912 - val_loss: 0.4153\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4903 - val_loss: 0.4146\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4894 - val_loss: 0.4140\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4886 - val_loss: 0.4134\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4877 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4869 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4861 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4853 - val_loss: 0.4111\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4845 - val_loss: 0.4105\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4837 - val_loss: 0.4100\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4829 - val_loss: 0.4094\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4822 - val_loss: 0.4089\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4814 - val_loss: 0.4084\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4807 - val_loss: 0.4078\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4799 - val_loss: 0.4073\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4792 - val_loss: 0.4068\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4785 - val_loss: 0.4063\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4777 - val_loss: 0.4058\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4770 - val_loss: 0.4052\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4763 - val_loss: 0.4047\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4756 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4749 - val_loss: 0.4037\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4742 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4735 - val_loss: 0.4027\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4728 - val_loss: 0.4023\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4721 - val_loss: 0.4018\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4715 - val_loss: 0.4013\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4708 - val_loss: 0.4008\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4701 - val_loss: 0.4003\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4695 - val_loss: 0.3999\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(52, 67), test_y.shape=(52, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.45341483860946, my average MASE = 95916870.45268953\n",
      "Cluster 4, 127.45341483860946\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2476 - val_loss: 0.2883\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2353 - val_loss: 0.2762\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2258 - val_loss: 0.2666\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2185 - val_loss: 0.2589\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2127 - val_loss: 0.2526\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.2078 - val_loss: 0.2473\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2036 - val_loss: 0.2426\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1999 - val_loss: 0.2383\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1966 - val_loss: 0.2346\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1935 - val_loss: 0.2311\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1907 - val_loss: 0.2280\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1881 - val_loss: 0.2251\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1857 - val_loss: 0.2225\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1834 - val_loss: 0.2200\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1813 - val_loss: 0.2178\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1794 - val_loss: 0.2157\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1777 - val_loss: 0.2137\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1760 - val_loss: 0.2120\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1746 - val_loss: 0.2103\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1732 - val_loss: 0.2087\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1719 - val_loss: 0.2072\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1707 - val_loss: 0.2058\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1695 - val_loss: 0.2045\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1684 - val_loss: 0.2032\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1674 - val_loss: 0.2020\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1664 - val_loss: 0.2009\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1655 - val_loss: 0.1998\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1646 - val_loss: 0.1988\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1638 - val_loss: 0.1978\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1630 - val_loss: 0.1968\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1622 - val_loss: 0.1960\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1614 - val_loss: 0.1951\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1607 - val_loss: 0.1943\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1600 - val_loss: 0.1935\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1594 - val_loss: 0.1927\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1587 - val_loss: 0.1920\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1913\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1575 - val_loss: 0.1906\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1570 - val_loss: 0.1899\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1893\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 224.71735313764052, my average MASE = 374017026.3746446\n",
      "Cluster 5, 224.71735313764052\n",
      "Before prediction: train_X.shape=(51, 10, 67), train_y.shape=(51, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4065 - val_loss: 0.3790\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4060 - val_loss: 0.3788\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4055 - val_loss: 0.3787\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4049 - val_loss: 0.3786\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4044 - val_loss: 0.3784\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4038 - val_loss: 0.3783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4033 - val_loss: 0.3782\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4028 - val_loss: 0.3780\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4023 - val_loss: 0.3779\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4018 - val_loss: 0.3778\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4013 - val_loss: 0.3776\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4008 - val_loss: 0.3775\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4003 - val_loss: 0.3774\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3998 - val_loss: 0.3773\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3993 - val_loss: 0.3771\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3988 - val_loss: 0.3770\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3984 - val_loss: 0.3769\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3768\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3975 - val_loss: 0.3767\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3970 - val_loss: 0.3765\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3966 - val_loss: 0.3764\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3763\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3762\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3953 - val_loss: 0.3761\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3949 - val_loss: 0.3760\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3945 - val_loss: 0.3759\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3941 - val_loss: 0.3757\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3937 - val_loss: 0.3756\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3933 - val_loss: 0.3755\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3929 - val_loss: 0.3754\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3925 - val_loss: 0.3753\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3921 - val_loss: 0.3752\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3917 - val_loss: 0.3751\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3913 - val_loss: 0.3750\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3749\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3905 - val_loss: 0.3748\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3902 - val_loss: 0.3747\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3898 - val_loss: 0.3745\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3894 - val_loss: 0.3744\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3891 - val_loss: 0.3743\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 82.26261385879712, my average MASE = 20260153.97451399\n",
      "Cluster 6, 82.26261385879712\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=9, 9, 48, (301, 67)\n",
      "Before prediction: train_X.shape=(174, 10, 67), train_y.shape=(174, 67), test_X.shape=(58, 10, 67), test_y.shape=(58, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.7089 - val_loss: 0.5627\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7074 - val_loss: 0.5619\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7059 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7045 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7031 - val_loss: 0.5598\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7017 - val_loss: 0.5591\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7004 - val_loss: 0.5585\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6991 - val_loss: 0.5578\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6979 - val_loss: 0.5572\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6966 - val_loss: 0.5566\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6954 - val_loss: 0.5559\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6941 - val_loss: 0.5553\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6930 - val_loss: 0.5548\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6918 - val_loss: 0.5542\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6907 - val_loss: 0.5536\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6895 - val_loss: 0.5531\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6884 - val_loss: 0.5525\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6873 - val_loss: 0.5520\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6863 - val_loss: 0.5515\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6852 - val_loss: 0.5509\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6842 - val_loss: 0.5504\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6831 - val_loss: 0.5499\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6821 - val_loss: 0.5494\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6811 - val_loss: 0.5489\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6801 - val_loss: 0.5484\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6792 - val_loss: 0.5479\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6782 - val_loss: 0.5475\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6772 - val_loss: 0.5470\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6763 - val_loss: 0.5465\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6753 - val_loss: 0.5461\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6744 - val_loss: 0.5456\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6735 - val_loss: 0.5452\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6726 - val_loss: 0.5447\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5443\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6707 - val_loss: 0.5439\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6698 - val_loss: 0.5434\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6689 - val_loss: 0.5430\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6680 - val_loss: 0.5426\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6671 - val_loss: 0.5422\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6663 - val_loss: 0.5417\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(58, 67), test_y.shape=(58, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 144.45290178213432, my average MASE = 192607450.5447097\n",
      "Cluster 0, 144.45290178213432\n",
      "Before prediction: train_X.shape=(86, 10, 67), train_y.shape=(86, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3954 - val_loss: 0.4825\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3947 - val_loss: 0.4820\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3940 - val_loss: 0.4815\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3933 - val_loss: 0.4810\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3927 - val_loss: 0.4806\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3921 - val_loss: 0.4801\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3915 - val_loss: 0.4797\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3909 - val_loss: 0.4793\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3903 - val_loss: 0.4789\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3898 - val_loss: 0.4785\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3892 - val_loss: 0.4781\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3887 - val_loss: 0.4777\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3882 - val_loss: 0.4774\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3877 - val_loss: 0.4770\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3872 - val_loss: 0.4767\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4763\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3862 - val_loss: 0.4760\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.4757\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3853 - val_loss: 0.4753\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3848 - val_loss: 0.4750\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3844 - val_loss: 0.4747\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3840 - val_loss: 0.4744\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3835 - val_loss: 0.4741\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3831 - val_loss: 0.4738\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3827 - val_loss: 0.4735\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3822 - val_loss: 0.4732\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3818 - val_loss: 0.4729\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3814 - val_loss: 0.4726\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3810 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3806 - val_loss: 0.4720\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3802 - val_loss: 0.4717\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3798 - val_loss: 0.4714\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3794 - val_loss: 0.4711\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3790 - val_loss: 0.4708\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3786 - val_loss: 0.4705\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3783 - val_loss: 0.4703\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3779 - val_loss: 0.4700\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3775 - val_loss: 0.4697\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3771 - val_loss: 0.4695\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3768 - val_loss: 0.4692\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 261.83661307224526, my average MASE = 165152999.01271424\n",
      "Cluster 1, 261.83661307224526\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3860 - val_loss: 0.4764\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3839 - val_loss: 0.4752\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3818 - val_loss: 0.4741\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3798 - val_loss: 0.4730\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3778 - val_loss: 0.4719\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3758 - val_loss: 0.4709\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3738 - val_loss: 0.4699\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3718 - val_loss: 0.4689\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3699 - val_loss: 0.4680\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3680 - val_loss: 0.4670\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4660\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3643 - val_loss: 0.4650\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3624 - val_loss: 0.4640\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3606 - val_loss: 0.4630\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3588 - val_loss: 0.4620\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3570 - val_loss: 0.4610\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3553 - val_loss: 0.4599\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3535 - val_loss: 0.4588\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3518 - val_loss: 0.4578\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3501 - val_loss: 0.4567\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3484 - val_loss: 0.4557\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3468 - val_loss: 0.4547\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3452 - val_loss: 0.4537\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3437 - val_loss: 0.4528\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3422 - val_loss: 0.4521\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3407 - val_loss: 0.4513\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.4506\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3378 - val_loss: 0.4498\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3363 - val_loss: 0.4493\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3349 - val_loss: 0.4487\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3336 - val_loss: 0.4481\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3323 - val_loss: 0.4475\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3311 - val_loss: 0.4470\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3299 - val_loss: 0.4464\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3287 - val_loss: 0.4459\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3276 - val_loss: 0.4453\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3264 - val_loss: 0.4447\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3253 - val_loss: 0.4441\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3241 - val_loss: 0.4436\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3231 - val_loss: 0.4430\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.29600762869721386, my average MASE = 0.4272698543687938\n",
      "Cluster 2, 0.29600762869721386\n",
      "Before prediction: train_X.shape=(35, 10, 67), train_y.shape=(35, 67), test_X.shape=(12, 10, 67), test_y.shape=(12, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4866 - val_loss: 0.4310\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4848 - val_loss: 0.4300\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4830 - val_loss: 0.4290\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4812 - val_loss: 0.4280\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.4271\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4777 - val_loss: 0.4261\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4760 - val_loss: 0.4252\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4744 - val_loss: 0.4243\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4727 - val_loss: 0.4235\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4711 - val_loss: 0.4226\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4695 - val_loss: 0.4217\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4679 - val_loss: 0.4209\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4663 - val_loss: 0.4200\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4648 - val_loss: 0.4192\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4633 - val_loss: 0.4184\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4618 - val_loss: 0.4175\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4603 - val_loss: 0.4167\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4589 - val_loss: 0.4159\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4574 - val_loss: 0.4150\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4560 - val_loss: 0.4142\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4546 - val_loss: 0.4134\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4532 - val_loss: 0.4126\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4518 - val_loss: 0.4118\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4504 - val_loss: 0.4109\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4491 - val_loss: 0.4101\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4477 - val_loss: 0.4093\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4464 - val_loss: 0.4085\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4451 - val_loss: 0.4077\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4438 - val_loss: 0.4069\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4425 - val_loss: 0.4061\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4412 - val_loss: 0.4053\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4399 - val_loss: 0.4045\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4387 - val_loss: 0.4037\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4374 - val_loss: 0.4029\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4362 - val_loss: 0.4021\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4350 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4337 - val_loss: 0.4006\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4325 - val_loss: 0.3998\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4313 - val_loss: 0.3991\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4301 - val_loss: 0.3983\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(12, 67), test_y.shape=(12, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3346396028.9972167, my average MASE = 7814754000.575592\n",
      "Cluster 3, 3346396028.9972167\n",
      "Before prediction: train_X.shape=(19, 10, 67), train_y.shape=(19, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3142 - val_loss: 0.7771\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3138 - val_loss: 0.7770\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3135 - val_loss: 0.7769\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3131 - val_loss: 0.7768\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3127 - val_loss: 0.7767\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3123 - val_loss: 0.7765\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3119 - val_loss: 0.7764\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3116 - val_loss: 0.7763\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3112 - val_loss: 0.7762\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3108 - val_loss: 0.7761\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3105 - val_loss: 0.7759\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3101 - val_loss: 0.7758\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3097 - val_loss: 0.7757\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3094 - val_loss: 0.7756\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3090 - val_loss: 0.7755\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3087 - val_loss: 0.7754\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3083 - val_loss: 0.7753\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3080 - val_loss: 0.7752\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3076 - val_loss: 0.7751\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3073 - val_loss: 0.7749\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3069 - val_loss: 0.7748\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3066 - val_loss: 0.7747\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3063 - val_loss: 0.7746\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3059 - val_loss: 0.7746\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3056 - val_loss: 0.7745\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3053 - val_loss: 0.7744\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3049 - val_loss: 0.7743\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3046 - val_loss: 0.7742\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3043 - val_loss: 0.7741\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3040 - val_loss: 0.7740\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3037 - val_loss: 0.7739\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3033 - val_loss: 0.7739\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3030 - val_loss: 0.7738\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3027 - val_loss: 0.7737\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3024 - val_loss: 0.7736\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3021 - val_loss: 0.7735\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3018 - val_loss: 0.7734\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3015 - val_loss: 0.7733\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3012 - val_loss: 0.7732\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3009 - val_loss: 0.7731\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 93.69104182165661, my average MASE = 20945629.206220664\n",
      "Cluster 4, 93.69104182165661\n",
      "Before prediction: train_X.shape=(89, 10, 67), train_y.shape=(89, 67), test_X.shape=(30, 10, 67), test_y.shape=(30, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.3424 - val_loss: 0.3360\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3416 - val_loss: 0.3355\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3408 - val_loss: 0.3350\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3400 - val_loss: 0.3346\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3393 - val_loss: 0.3341\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3386 - val_loss: 0.3337\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3379 - val_loss: 0.3333\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3372 - val_loss: 0.3329\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3365 - val_loss: 0.3324\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3358 - val_loss: 0.3320\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3351 - val_loss: 0.3316\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3344 - val_loss: 0.3312\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3338 - val_loss: 0.3309\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3331 - val_loss: 0.3305\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3325 - val_loss: 0.3301\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3319 - val_loss: 0.3297\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3312 - val_loss: 0.3293\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3306 - val_loss: 0.3290\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3300 - val_loss: 0.3286\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3294 - val_loss: 0.3282\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3288 - val_loss: 0.3279\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3282 - val_loss: 0.3275\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3276 - val_loss: 0.3272\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3271 - val_loss: 0.3268\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3265 - val_loss: 0.3265\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3260 - val_loss: 0.3262\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3254 - val_loss: 0.3258\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3249 - val_loss: 0.3255\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3244 - val_loss: 0.3252\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.3249\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3234 - val_loss: 0.3246\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3228 - val_loss: 0.3243\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3223 - val_loss: 0.3240\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3219 - val_loss: 0.3237\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3214 - val_loss: 0.3234\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.3231\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3204 - val_loss: 0.3228\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3199 - val_loss: 0.3225\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3195 - val_loss: 0.3222\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3190 - val_loss: 0.3219\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(30, 67), test_y.shape=(30, 67)\n",
      "average MASE = 188.45046029060867, my average MASE = 121680879.21353056\n",
      "Cluster 5, 188.45046029060867\n",
      "Before prediction: train_X.shape=(1942, 10, 67), train_y.shape=(1942, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1120 - val_loss: 0.1007\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0987\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1025 - val_loss: 0.0974\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0990 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0960 - val_loss: 0.0954\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0933 - val_loss: 0.0947\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0942\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0888 - val_loss: 0.0938\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0868 - val_loss: 0.0934\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0851 - val_loss: 0.0931\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0834 - val_loss: 0.0928\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0819 - val_loss: 0.0926\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0806 - val_loss: 0.0923\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0793 - val_loss: 0.0921\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0781 - val_loss: 0.0919\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0770 - val_loss: 0.0917\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0759 - val_loss: 0.0916\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0749 - val_loss: 0.0914\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0740 - val_loss: 0.0912\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0732 - val_loss: 0.0911\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0724 - val_loss: 0.0910\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0716 - val_loss: 0.0909\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0709 - val_loss: 0.0908\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0908\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0695 - val_loss: 0.0907\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0689 - val_loss: 0.0906\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0683 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0678 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0673 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0660 - val_loss: 0.0902\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0901\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0652 - val_loss: 0.0900\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0645 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0642 - val_loss: 0.0897\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0896\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0637 - val_loss: 0.0895\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0634 - val_loss: 0.0895\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1073797047.1669116, my average MASE = 13075073766.705614\n",
      "Cluster 6, 1073797047.1669116\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2348 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2252 - val_loss: 0.2653\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2178 - val_loss: 0.2575\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2120 - val_loss: 0.2511\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2071 - val_loss: 0.2457\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2029 - val_loss: 0.2409\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1991 - val_loss: 0.2366\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1956 - val_loss: 0.2328\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1924 - val_loss: 0.2293\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1895 - val_loss: 0.2261\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1868 - val_loss: 0.2231\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1843 - val_loss: 0.2203\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1820 - val_loss: 0.2178\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1799 - val_loss: 0.2155\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1780 - val_loss: 0.2134\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1762 - val_loss: 0.2114\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1745 - val_loss: 0.2096\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1730 - val_loss: 0.2079\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1715 - val_loss: 0.2063\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1702 - val_loss: 0.2048\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1689 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1678 - val_loss: 0.2020\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1666 - val_loss: 0.2007\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1656 - val_loss: 0.1995\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1646 - val_loss: 0.1984\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1636 - val_loss: 0.1973\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1627 - val_loss: 0.1962\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1619 - val_loss: 0.1952\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1610 - val_loss: 0.1943\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1934\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1595 - val_loss: 0.1925\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1588 - val_loss: 0.1917\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1581 - val_loss: 0.1909\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1574 - val_loss: 0.1901\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1568 - val_loss: 0.1894\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1886\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1556 - val_loss: 0.1880\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1550 - val_loss: 0.1873\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1867\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1539 - val_loss: 0.1860\n",
      "17/17 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 180.26488918007823, my average MASE = 179278352.44392422\n",
      "Cluster 7, 180.26488918007823\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408091,)\n",
      "N_clusters=11, 11, 904, (6, 67)\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3401 - val_loss: 0.3875\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3395 - val_loss: 0.3872\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3390 - val_loss: 0.3870\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3385 - val_loss: 0.3868\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3380 - val_loss: 0.3866\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3375 - val_loss: 0.3863\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3370 - val_loss: 0.3861\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3366 - val_loss: 0.3859\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3361 - val_loss: 0.3856\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3357 - val_loss: 0.3854\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3352 - val_loss: 0.3852\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3348 - val_loss: 0.3850\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3343 - val_loss: 0.3848\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3339 - val_loss: 0.3846\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3335 - val_loss: 0.3844\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3331 - val_loss: 0.3842\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3327 - val_loss: 0.3840\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3323 - val_loss: 0.3837\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3318 - val_loss: 0.3835\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3314 - val_loss: 0.3833\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3311 - val_loss: 0.3831\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3307 - val_loss: 0.3829\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3303 - val_loss: 0.3827\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3299 - val_loss: 0.3825\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3295 - val_loss: 0.3823\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3292 - val_loss: 0.3821\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3288 - val_loss: 0.3820\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3284 - val_loss: 0.3818\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3281 - val_loss: 0.3816\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3277 - val_loss: 0.3814\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3274 - val_loss: 0.3812\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3270 - val_loss: 0.3810\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3267 - val_loss: 0.3808\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3263 - val_loss: 0.3806\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3260 - val_loss: 0.3805\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3257 - val_loss: 0.3803\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3254 - val_loss: 0.3801\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3250 - val_loss: 0.3799\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3247 - val_loss: 0.3798\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3244 - val_loss: 0.3796\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 122.2598699731945, my average MASE = 164200403.28208458\n",
      "Cluster 0, 122.2598699731945\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5011 - val_loss: 0.7038\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5005 - val_loss: 0.7036\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4998 - val_loss: 0.7034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4991 - val_loss: 0.7032\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4984 - val_loss: 0.7030\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4978 - val_loss: 0.7028\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4971 - val_loss: 0.7026\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4964 - val_loss: 0.7024\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4958 - val_loss: 0.7022\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4951 - val_loss: 0.7020\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4945 - val_loss: 0.7017\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4938 - val_loss: 0.7015\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4932 - val_loss: 0.7014\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4926 - val_loss: 0.7012\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4919 - val_loss: 0.7010\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4913 - val_loss: 0.7008\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4907 - val_loss: 0.7006\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4901 - val_loss: 0.7004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4894 - val_loss: 0.7002\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4888 - val_loss: 0.7000\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4882 - val_loss: 0.6998\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4877 - val_loss: 0.6997\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4871 - val_loss: 0.6995\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4865 - val_loss: 0.6993\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4859 - val_loss: 0.6991\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4853 - val_loss: 0.6989\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4847 - val_loss: 0.6988\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4842 - val_loss: 0.6986\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4836 - val_loss: 0.6984\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4831 - val_loss: 0.6983\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4825 - val_loss: 0.6981\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4820 - val_loss: 0.6979\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4815 - val_loss: 0.6978\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4809 - val_loss: 0.6976\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4804 - val_loss: 0.6974\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4799 - val_loss: 0.6973\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4794 - val_loss: 0.6971\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4789 - val_loss: 0.6970\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4783 - val_loss: 0.6968\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4778 - val_loss: 0.6966\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2966824.6919978233, my average MASE = 79205816.45072892\n",
      "Cluster 1, 2966824.6919978233\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1998 - val_loss: 0.3035\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1993 - val_loss: 0.3034\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1988 - val_loss: 0.3034\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1982 - val_loss: 0.3033\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1977 - val_loss: 0.3033\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1972 - val_loss: 0.3032\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1967 - val_loss: 0.3032\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1962 - val_loss: 0.3032\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1957 - val_loss: 0.3031\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1952 - val_loss: 0.3031\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1947 - val_loss: 0.3031\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1942 - val_loss: 0.3031\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1938 - val_loss: 0.3030\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1933 - val_loss: 0.3030\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1928 - val_loss: 0.3030\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1924 - val_loss: 0.3030\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1919 - val_loss: 0.3030\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1915 - val_loss: 0.3030\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1911 - val_loss: 0.3030\n",
      "Epoch 19: early stopping\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 130.97936905502368, my average MASE = 132554988.34305501\n",
      "Cluster 2, 130.97936905502368\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4496 - val_loss: 0.4061\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4490 - val_loss: 0.4060\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4484 - val_loss: 0.4058\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4478 - val_loss: 0.4057\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4472 - val_loss: 0.4056\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4466 - val_loss: 0.4055\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4461 - val_loss: 0.4054\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4455 - val_loss: 0.4053\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4450 - val_loss: 0.4052\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4444 - val_loss: 0.4051\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4439 - val_loss: 0.4050\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4433 - val_loss: 0.4049\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4428 - val_loss: 0.4048\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4423 - val_loss: 0.4047\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4417 - val_loss: 0.4046\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4412 - val_loss: 0.4045\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4407 - val_loss: 0.4044\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4402 - val_loss: 0.4043\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4397 - val_loss: 0.4042\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4041\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4387 - val_loss: 0.4040\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4382 - val_loss: 0.4039\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4377 - val_loss: 0.4038\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4372 - val_loss: 0.4037\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4367 - val_loss: 0.4036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4362 - val_loss: 0.4035\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4357 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4352 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4032\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4343 - val_loss: 0.4031\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4338 - val_loss: 0.4030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4333 - val_loss: 0.4029\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4329 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4028\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4027\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4315 - val_loss: 0.4026\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4311 - val_loss: 0.4025\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4306 - val_loss: 0.4024\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4302 - val_loss: 0.4023\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4297 - val_loss: 0.4022\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1437.7621485075726, my average MASE = 33408169.939470924\n",
      "Cluster 3, 1437.7621485075726\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3791 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3768 - val_loss: 0.4780\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3745 - val_loss: 0.4765\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4750\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3700 - val_loss: 0.4735\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3678 - val_loss: 0.4721\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3657 - val_loss: 0.4707\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3636 - val_loss: 0.4693\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3616 - val_loss: 0.4679\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3595 - val_loss: 0.4665\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3576 - val_loss: 0.4652\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3556 - val_loss: 0.4639\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3537 - val_loss: 0.4626\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3519 - val_loss: 0.4614\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3500 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3482 - val_loss: 0.4590\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3464 - val_loss: 0.4578\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3447 - val_loss: 0.4567\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3430 - val_loss: 0.4556\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3414 - val_loss: 0.4545\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3398 - val_loss: 0.4534\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3382 - val_loss: 0.4524\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3366 - val_loss: 0.4513\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3351 - val_loss: 0.4504\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3335 - val_loss: 0.4494\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3320 - val_loss: 0.4484\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3305 - val_loss: 0.4475\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3291 - val_loss: 0.4466\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3277 - val_loss: 0.4457\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3263 - val_loss: 0.4448\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3249 - val_loss: 0.4439\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3236 - val_loss: 0.4431\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3222 - val_loss: 0.4422\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3209 - val_loss: 0.4413\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3197 - val_loss: 0.4404\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3184 - val_loss: 0.4395\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3171 - val_loss: 0.4386\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3159 - val_loss: 0.4378\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3147 - val_loss: 0.4369\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3135 - val_loss: 0.4360\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1399316882.5162897, my average MASE = 3857319737.5045514\n",
      "Cluster 4, 1399316882.5162897\n",
      "Before prediction: train_X.shape=(1565, 10, 67), train_y.shape=(1565, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.2312 - val_loss: 0.2708\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.2231 - val_loss: 0.2627\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2165 - val_loss: 0.2559\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2110 - val_loss: 0.2500\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.2061 - val_loss: 0.2449\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.2018 - val_loss: 0.2403\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1979 - val_loss: 0.2361\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1944 - val_loss: 0.2322\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1912 - val_loss: 0.2287\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1882 - val_loss: 0.2255\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1854 - val_loss: 0.2224\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1829 - val_loss: 0.2197\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1806 - val_loss: 0.2172\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1785 - val_loss: 0.2150\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1767 - val_loss: 0.2129\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1750 - val_loss: 0.2110\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1734 - val_loss: 0.2093\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1720 - val_loss: 0.2077\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1707 - val_loss: 0.2061\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1695 - val_loss: 0.2047\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1683 - val_loss: 0.2033\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1672 - val_loss: 0.2021\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1661 - val_loss: 0.2009\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1651 - val_loss: 0.1997\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1641 - val_loss: 0.1986\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1632 - val_loss: 0.1975\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1623 - val_loss: 0.1965\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1615 - val_loss: 0.1955\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1606 - val_loss: 0.1945\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1599 - val_loss: 0.1937\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1591 - val_loss: 0.1928\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1584 - val_loss: 0.1920\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1577 - val_loss: 0.1912\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1570 - val_loss: 0.1904\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1564 - val_loss: 0.1897\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1558 - val_loss: 0.1890\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1552 - val_loss: 0.1883\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1547 - val_loss: 0.1877\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1542 - val_loss: 0.1871\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1537 - val_loss: 0.1864\n",
      "17/17 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n",
      "average MASE = 146.93947390831542, my average MASE = 534465305.08164215\n",
      "Cluster 5, 146.93947390831542\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3864 - val_loss: 0.3280\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3857 - val_loss: 0.3279\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3849 - val_loss: 0.3278\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3842 - val_loss: 0.3277\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3834 - val_loss: 0.3276\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3827 - val_loss: 0.3275\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3820 - val_loss: 0.3274\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3813 - val_loss: 0.3274\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.3273\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3799 - val_loss: 0.3272\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.3272\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3785 - val_loss: 0.3271\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3778 - val_loss: 0.3270\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3772 - val_loss: 0.3270\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3765 - val_loss: 0.3269\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.3269\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3753 - val_loss: 0.3268\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3746 - val_loss: 0.3268\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3740 - val_loss: 0.3267\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3734 - val_loss: 0.3266\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3728 - val_loss: 0.3266\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3722 - val_loss: 0.3265\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3717 - val_loss: 0.3265\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3711 - val_loss: 0.3264\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3705 - val_loss: 0.3264\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3699 - val_loss: 0.3263\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3694 - val_loss: 0.3263\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3688 - val_loss: 0.3262\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3682 - val_loss: 0.3262\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3677 - val_loss: 0.3262\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3671 - val_loss: 0.3261\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3666 - val_loss: 0.3261\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3660 - val_loss: 0.3260\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3655 - val_loss: 0.3260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3649 - val_loss: 0.3260\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3643 - val_loss: 0.3259\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3632 - val_loss: 0.3259\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.3259\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3621 - val_loss: 0.3259\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 304.5484747914777, my average MASE = 15252291.46578898\n",
      "Cluster 6, 304.5484747914777\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8703 - val_loss: 8.9197\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8672 - val_loss: 8.9197\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8642 - val_loss: 8.9196\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8613 - val_loss: 8.9196\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8586 - val_loss: 8.9196\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8558 - val_loss: 8.9195\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8532 - val_loss: 8.9194\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8506 - val_loss: 8.9194\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8480 - val_loss: 8.9193\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8455 - val_loss: 8.9192\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8431 - val_loss: 8.9192\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8407 - val_loss: 8.9191\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8383 - val_loss: 8.9190\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8360 - val_loss: 8.9189\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8337 - val_loss: 8.9188\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8315 - val_loss: 8.9187\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8293 - val_loss: 8.9187\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8271 - val_loss: 8.9186\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8250 - val_loss: 8.9185\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 8.9184\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8209 - val_loss: 8.9184\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8189 - val_loss: 8.9183\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8170 - val_loss: 8.9182\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8150 - val_loss: 8.9181\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8131 - val_loss: 8.9180\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8113 - val_loss: 8.9179\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8095 - val_loss: 8.9179\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8079 - val_loss: 8.9178\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8062 - val_loss: 8.9177\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8046 - val_loss: 8.9176\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8031 - val_loss: 8.9175\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8016 - val_loss: 8.9175\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8000 - val_loss: 8.9174\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7985 - val_loss: 8.9173\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7970 - val_loss: 8.9172\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7955 - val_loss: 8.9171\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7941 - val_loss: 8.9171\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7927 - val_loss: 8.9170\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7913 - val_loss: 8.9170\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7899 - val_loss: 8.9170\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 192382848.4747458, my average MASE = 882590618.8453726\n",
      "Cluster 7, 192382848.4747458\n",
      "Before prediction: train_X.shape=(1941, 10, 67), train_y.shape=(1941, 67), test_X.shape=(647, 10, 67), test_y.shape=(647, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1119 - val_loss: 0.1001\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1067 - val_loss: 0.0986\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1024 - val_loss: 0.0973\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0988 - val_loss: 0.0963\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0957 - val_loss: 0.0956\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0930 - val_loss: 0.0950\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0905 - val_loss: 0.0945\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0883 - val_loss: 0.0941\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0863 - val_loss: 0.0937\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0933\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0828 - val_loss: 0.0930\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0813 - val_loss: 0.0928\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0799 - val_loss: 0.0925\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0787 - val_loss: 0.0924\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0775 - val_loss: 0.0922\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0764 - val_loss: 0.0920\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0754 - val_loss: 0.0918\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0744 - val_loss: 0.0917\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0735 - val_loss: 0.0915\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0727 - val_loss: 0.0914\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0719 - val_loss: 0.0913\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0711 - val_loss: 0.0912\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0705 - val_loss: 0.0910\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0909\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0692 - val_loss: 0.0908\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0687 - val_loss: 0.0907\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0682 - val_loss: 0.0906\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0677 - val_loss: 0.0905\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0904\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0903\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0664 - val_loss: 0.0902\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0660 - val_loss: 0.0901\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0656 - val_loss: 0.0900\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0653 - val_loss: 0.0899\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0649 - val_loss: 0.0899\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0646 - val_loss: 0.0898\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0643 - val_loss: 0.0898\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0640 - val_loss: 0.0897\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0638 - val_loss: 0.0896\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0635 - val_loss: 0.0896\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(647, 67), test_y.shape=(647, 67)\n",
      "average MASE = 1222984943.0994627, my average MASE = 34180380931.05725\n",
      "Cluster 8, 1222984943.0994627\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3097 - val_loss: 0.3956\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3089 - val_loss: 0.3954\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3081 - val_loss: 0.3952\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3074 - val_loss: 0.3950\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3066 - val_loss: 0.3948\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3059 - val_loss: 0.3945\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3051 - val_loss: 0.3943\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3044 - val_loss: 0.3941\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3037 - val_loss: 0.3939\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3030 - val_loss: 0.3937\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.3935\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3017 - val_loss: 0.3934\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3010 - val_loss: 0.3933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3003 - val_loss: 0.3931\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2997 - val_loss: 0.3930\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2990 - val_loss: 0.3929\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2984 - val_loss: 0.3927\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2977 - val_loss: 0.3926\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2971 - val_loss: 0.3925\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2965 - val_loss: 0.3924\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2959 - val_loss: 0.3923\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2953 - val_loss: 0.3922\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2947 - val_loss: 0.3921\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2941 - val_loss: 0.3920\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2935 - val_loss: 0.3919\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2930 - val_loss: 0.3918\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2924 - val_loss: 0.3917\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2918 - val_loss: 0.3917\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2913 - val_loss: 0.3916\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2907 - val_loss: 0.3915\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2902 - val_loss: 0.3914\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2896 - val_loss: 0.3914\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2891 - val_loss: 0.3913\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2885 - val_loss: 0.3912\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2880 - val_loss: 0.3911\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2875 - val_loss: 0.3910\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2870 - val_loss: 0.3909\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2865 - val_loss: 0.3908\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2859 - val_loss: 0.3907\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2854 - val_loss: 0.3907\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 561.7864488366092, my average MASE = 24722978.57949824\n",
      "Cluster 10, 561.7864488366092\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=2, 2, 13, (10045, 67)\n",
      "Before prediction: train_X.shape=(6020, 10, 67), train_y.shape=(6020, 67), test_X.shape=(2007, 10, 67), test_y.shape=(2007, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0647 - val_loss: 0.0484\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0596 - val_loss: 0.0453\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0565 - val_loss: 0.0429\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0542 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0523 - val_loss: 0.0394\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0508 - val_loss: 0.0381\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0495 - val_loss: 0.0370\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0484 - val_loss: 0.0360\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0475 - val_loss: 0.0351\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0467 - val_loss: 0.0344\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0461 - val_loss: 0.0338\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0454 - val_loss: 0.0333\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0328\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0444 - val_loss: 0.0323\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0440 - val_loss: 0.0320\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0435 - val_loss: 0.0316\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0431 - val_loss: 0.0313\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0428 - val_loss: 0.0311\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0308\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0306\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0304\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0415 - val_loss: 0.0303\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0412 - val_loss: 0.0301\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0410 - val_loss: 0.0300\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0408 - val_loss: 0.0298\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0406 - val_loss: 0.0297\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0404 - val_loss: 0.0296\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0402 - val_loss: 0.0294\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0400 - val_loss: 0.0293\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0399 - val_loss: 0.0292\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0397 - val_loss: 0.0291\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0396 - val_loss: 0.0291\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0395 - val_loss: 0.0290\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0394 - val_loss: 0.0289\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0393 - val_loss: 0.0289\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0288\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0391 - val_loss: 0.0287\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0390 - val_loss: 0.0287\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0389 - val_loss: 0.0286\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0388 - val_loss: 0.0286\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2007, 67), test_y.shape=(2007, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 124611449.52884135, my average MASE = 52097635280.213745\n",
      "Cluster 0, 124611449.52884135\n",
      "Before prediction: train_X.shape=(18364, 10, 67), train_y.shape=(18364, 67), test_X.shape=(6121, 10, 67), test_y.shape=(6121, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3019 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2812 - val_loss: 0.3011\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2652 - val_loss: 0.2888\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2545 - val_loss: 0.2808\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2479 - val_loss: 0.2750\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2428 - val_loss: 0.2703\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2385 - val_loss: 0.2663\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2348 - val_loss: 0.2629\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2315 - val_loss: 0.2599\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2283 - val_loss: 0.2570\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2254 - val_loss: 0.2544\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2226 - val_loss: 0.2520\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2201 - val_loss: 0.2499\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2179 - val_loss: 0.2480\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2161 - val_loss: 0.2464\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2145 - val_loss: 0.2449\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2131 - val_loss: 0.2436\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2118 - val_loss: 0.2425\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2107 - val_loss: 0.2414\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2096 - val_loss: 0.2403\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2087 - val_loss: 0.2395\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2078 - val_loss: 0.2387\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2070 - val_loss: 0.2379\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2063 - val_loss: 0.2371\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2056 - val_loss: 0.2364\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2049 - val_loss: 0.2358\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2352\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2038 - val_loss: 0.2346\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 8s 28ms/step - loss: 0.2032 - val_loss: 0.2342\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2027 - val_loss: 0.2337\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2023 - val_loss: 0.2332\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2018 - val_loss: 0.2329\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2014 - val_loss: 0.2325\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2321\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2006 - val_loss: 0.2318\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2003 - val_loss: 0.2314\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1999 - val_loss: 0.2311\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.1996 - val_loss: 0.2308\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.1993 - val_loss: 0.2305\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1990 - val_loss: 0.2302\n",
      "192/192 [==============================] - 2s 11ms/step\n",
      "predicted_original.shape=(6121, 67), test_y.shape=(6121, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1515.0877642124253, my average MASE = 2752.3099444505265\n",
      "Cluster 1, 1515.0877642124253\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=5, 5, 12, (3253, 67)\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.1101 - val_loss: 0.0983\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1050 - val_loss: 0.0966\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1009 - val_loss: 0.0954\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0975 - val_loss: 0.0944\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0945 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0919 - val_loss: 0.0931\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0895 - val_loss: 0.0927\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0923\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0855 - val_loss: 0.0921\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0838 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0915\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0807 - val_loss: 0.0912\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0794 - val_loss: 0.0910\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0782 - val_loss: 0.0908\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0771 - val_loss: 0.0906\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0760 - val_loss: 0.0904\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0750 - val_loss: 0.0902\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0741 - val_loss: 0.0901\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0733 - val_loss: 0.0899\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0725 - val_loss: 0.0898\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0717 - val_loss: 0.0897\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0710 - val_loss: 0.0895\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0704 - val_loss: 0.0895\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0894\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0691 - val_loss: 0.0893\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0686 - val_loss: 0.0892\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0681 - val_loss: 0.0892\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0891\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0671 - val_loss: 0.0891\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0666 - val_loss: 0.0890\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.0662 - val_loss: 0.0889\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0658 - val_loss: 0.0889\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0654 - val_loss: 0.0888\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0651 - val_loss: 0.0887\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0647 - val_loss: 0.0887\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0644 - val_loss: 0.0886\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0641 - val_loss: 0.0885\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0638 - val_loss: 0.0885\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0636 - val_loss: 0.0884\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0633 - val_loss: 0.0883\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n",
      "average MASE = 1286975259.8033035, my average MASE = 26869301348.284866\n",
      "Cluster 0, 1286975259.8033035\n",
      "Before prediction: train_X.shape=(2221, 10, 67), train_y.shape=(2221, 67), test_X.shape=(740, 10, 67), test_y.shape=(740, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.5056 - val_loss: 0.3755\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4985 - val_loss: 0.3720\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4926 - val_loss: 0.3688\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4874 - val_loss: 0.3660\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4828 - val_loss: 0.3635\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4785 - val_loss: 0.3611\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4745 - val_loss: 0.3590\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4707 - val_loss: 0.3570\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4671 - val_loss: 0.3552\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4637 - val_loss: 0.3535\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4604 - val_loss: 0.3519\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4572 - val_loss: 0.3504\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4542 - val_loss: 0.3489\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4512 - val_loss: 0.3475\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4483 - val_loss: 0.3462\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4455 - val_loss: 0.3449\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4428 - val_loss: 0.3436\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4401 - val_loss: 0.3424\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4375 - val_loss: 0.3412\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4350 - val_loss: 0.3401\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4325 - val_loss: 0.3390\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4301 - val_loss: 0.3380\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4278 - val_loss: 0.3370\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4255 - val_loss: 0.3360\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4233 - val_loss: 0.3350\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4211 - val_loss: 0.3341\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4190 - val_loss: 0.3332\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4170 - val_loss: 0.3324\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4150 - val_loss: 0.3315\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4131 - val_loss: 0.3307\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4113 - val_loss: 0.3299\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4095 - val_loss: 0.3292\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4078 - val_loss: 0.3285\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4061 - val_loss: 0.3278\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4045 - val_loss: 0.3271\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4030 - val_loss: 0.3265\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4014 - val_loss: 0.3259\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3999 - val_loss: 0.3253\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3985 - val_loss: 0.3247\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3971 - val_loss: 0.3242\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(740, 67), test_y.shape=(740, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 455.57479189703486, my average MASE = 880.739926655778\n",
      "Cluster 1, 455.57479189703486\n",
      "Before prediction: train_X.shape=(41, 10, 67), train_y.shape=(41, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4961 - val_loss: 0.6170\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4945 - val_loss: 0.6160\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4928 - val_loss: 0.6151\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4912 - val_loss: 0.6141\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4896 - val_loss: 0.6132\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4880 - val_loss: 0.6123\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4864 - val_loss: 0.6114\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4849 - val_loss: 0.6105\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4834 - val_loss: 0.6096\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4818 - val_loss: 0.6088\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4803 - val_loss: 0.6080\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4788 - val_loss: 0.6071\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4774 - val_loss: 0.6063\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4759 - val_loss: 0.6055\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4745 - val_loss: 0.6047\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4731 - val_loss: 0.6040\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4717 - val_loss: 0.6033\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4703 - val_loss: 0.6025\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4689 - val_loss: 0.6018\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4676 - val_loss: 0.6012\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4663 - val_loss: 0.6005\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4649 - val_loss: 0.5998\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4636 - val_loss: 0.5992\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4624 - val_loss: 0.5985\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4611 - val_loss: 0.5979\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4598 - val_loss: 0.5973\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4586 - val_loss: 0.5967\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4574 - val_loss: 0.5961\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4561 - val_loss: 0.5955\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4549 - val_loss: 0.5950\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4537 - val_loss: 0.5944\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4525 - val_loss: 0.5939\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4513 - val_loss: 0.5933\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4501 - val_loss: 0.5928\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4489 - val_loss: 0.5922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4478 - val_loss: 0.5917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4466 - val_loss: 0.5912\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4455 - val_loss: 0.5907\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4443 - val_loss: 0.5902\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4432 - val_loss: 0.5897\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3633974576.8812943, my average MASE = 9316750037.661146\n",
      "Cluster 2, 3633974576.8812943\n",
      "Before prediction: train_X.shape=(158, 10, 67), train_y.shape=(158, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5152 - val_loss: 0.4273\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5139 - val_loss: 0.4265\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5128 - val_loss: 0.4257\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5117 - val_loss: 0.4249\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5105 - val_loss: 0.4241\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5095 - val_loss: 0.4234\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5084 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5074 - val_loss: 0.4219\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5064 - val_loss: 0.4212\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5054 - val_loss: 0.4204\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5044 - val_loss: 0.4197\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5034 - val_loss: 0.4191\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5025 - val_loss: 0.4184\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5015 - val_loss: 0.4178\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5006 - val_loss: 0.4171\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4997 - val_loss: 0.4165\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4988 - val_loss: 0.4159\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4979 - val_loss: 0.4153\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4970 - val_loss: 0.4147\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4961 - val_loss: 0.4141\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4953 - val_loss: 0.4135\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4944 - val_loss: 0.4129\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4936 - val_loss: 0.4123\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4928 - val_loss: 0.4118\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4920 - val_loss: 0.4112\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4912 - val_loss: 0.4107\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4904 - val_loss: 0.4101\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4096\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4889 - val_loss: 0.4091\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4882 - val_loss: 0.4086\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4874 - val_loss: 0.4080\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4867 - val_loss: 0.4075\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4860 - val_loss: 0.4070\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4852 - val_loss: 0.4065\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4845 - val_loss: 0.4060\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4838 - val_loss: 0.4055\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.4831 - val_loss: 0.4050\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4045\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4818 - val_loss: 0.4040\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4811 - val_loss: 0.4036\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 113.07393682707622, my average MASE = 188079219.47717956\n",
      "Cluster 3, 113.07393682707622\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7117 - val_loss: 0.7129\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7087 - val_loss: 0.7117\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7057 - val_loss: 0.7104\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7028 - val_loss: 0.7094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7000 - val_loss: 0.7084\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6972 - val_loss: 0.7075\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6945 - val_loss: 0.7066\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6918 - val_loss: 0.7056\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6891 - val_loss: 0.7047\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6865 - val_loss: 0.7037\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6838 - val_loss: 0.7028\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6811 - val_loss: 0.7018\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6785 - val_loss: 0.7009\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6758 - val_loss: 0.6999\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6732 - val_loss: 0.6990\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6706 - val_loss: 0.6981\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6680 - val_loss: 0.6971\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6654 - val_loss: 0.6961\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6628 - val_loss: 0.6951\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6604 - val_loss: 0.6942\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6580 - val_loss: 0.6934\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6556 - val_loss: 0.6926\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6534 - val_loss: 0.6918\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6512 - val_loss: 0.6910\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6491 - val_loss: 0.6902\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6470 - val_loss: 0.6894\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6449 - val_loss: 0.6886\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6429 - val_loss: 0.6877\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6409 - val_loss: 0.6869\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6389 - val_loss: 0.6861\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6369 - val_loss: 0.6853\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6350 - val_loss: 0.6847\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6332 - val_loss: 0.6841\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6314 - val_loss: 0.6836\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6297 - val_loss: 0.6831\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6280 - val_loss: 0.6827\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6263 - val_loss: 0.6825\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6246 - val_loss: 0.6824\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6229 - val_loss: 0.6823\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6212 - val_loss: 0.6822\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2798887382418345, my average MASE = 0.5334982550486497\n",
      "Cluster 4, 0.2798887382418345\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=7, 7, 431, (13, 67)\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(1, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(180, 10, 67), train_y.shape=(180, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6852 - val_loss: 0.5575\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6838 - val_loss: 0.5569\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6824 - val_loss: 0.5563\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6811 - val_loss: 0.5557\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6799 - val_loss: 0.5551\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6786 - val_loss: 0.5545\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6774 - val_loss: 0.5540\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6762 - val_loss: 0.5534\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6750 - val_loss: 0.5528\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6739 - val_loss: 0.5523\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6727 - val_loss: 0.5518\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6716 - val_loss: 0.5512\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6705 - val_loss: 0.5507\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6694 - val_loss: 0.5501\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6684 - val_loss: 0.5496\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6673 - val_loss: 0.5491\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6663 - val_loss: 0.5486\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6653 - val_loss: 0.5481\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6643 - val_loss: 0.5475\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6632 - val_loss: 0.5470\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6623 - val_loss: 0.5465\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6613 - val_loss: 0.5461\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6603 - val_loss: 0.5456\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6594 - val_loss: 0.5451\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6584 - val_loss: 0.5446\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6575 - val_loss: 0.5441\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6566 - val_loss: 0.5437\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6557 - val_loss: 0.5432\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6548 - val_loss: 0.5427\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6539 - val_loss: 0.5423\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6531 - val_loss: 0.5418\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6522 - val_loss: 0.5414\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6513 - val_loss: 0.5409\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6505 - val_loss: 0.5405\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6497 - val_loss: 0.5400\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6489 - val_loss: 0.5396\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6480 - val_loss: 0.5392\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6472 - val_loss: 0.5387\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6464 - val_loss: 0.5383\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6456 - val_loss: 0.5379\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 161.0036674860674, my average MASE = 412096886.9283237\n",
      "Cluster 1, 161.0036674860674\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6031 - val_loss: 0.4390\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6002 - val_loss: 0.4369\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5975 - val_loss: 0.4349\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5947 - val_loss: 0.4328\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5919 - val_loss: 0.4307\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5892 - val_loss: 0.4287\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5864 - val_loss: 0.4267\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5838 - val_loss: 0.4248\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5812 - val_loss: 0.4230\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5786 - val_loss: 0.4213\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5761 - val_loss: 0.4196\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5736 - val_loss: 0.4180\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5712 - val_loss: 0.4164\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5687 - val_loss: 0.4148\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5663 - val_loss: 0.4132\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5638 - val_loss: 0.4116\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5614 - val_loss: 0.4101\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5590 - val_loss: 0.4085\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5566 - val_loss: 0.4070\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5542 - val_loss: 0.4054\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5518 - val_loss: 0.4039\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5494 - val_loss: 0.4024\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5471 - val_loss: 0.4008\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5448 - val_loss: 0.3992\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5424 - val_loss: 0.3977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5401 - val_loss: 0.3961\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5378 - val_loss: 0.3945\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5355 - val_loss: 0.3930\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5333 - val_loss: 0.3914\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5310 - val_loss: 0.3898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5288 - val_loss: 0.3883\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5266 - val_loss: 0.3868\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5243 - val_loss: 0.3855\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5221 - val_loss: 0.3842\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5199 - val_loss: 0.3830\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5176 - val_loss: 0.3817\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5154 - val_loss: 0.3804\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5133 - val_loss: 0.3792\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5111 - val_loss: 0.3780\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5089 - val_loss: 0.3770\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.22679251401977166, my average MASE = 0.3179573135228401\n",
      "Cluster 2, 0.22679251401977166\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4783 - val_loss: 0.4457\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4766 - val_loss: 0.4444\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4750 - val_loss: 0.4432\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4734 - val_loss: 0.4420\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4719 - val_loss: 0.4408\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4703 - val_loss: 0.4397\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4687 - val_loss: 0.4385\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4672 - val_loss: 0.4374\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4657 - val_loss: 0.4362\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4642 - val_loss: 0.4351\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4627 - val_loss: 0.4340\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4613 - val_loss: 0.4329\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4598 - val_loss: 0.4318\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4584 - val_loss: 0.4307\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4296\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4555 - val_loss: 0.4286\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4541 - val_loss: 0.4275\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4527 - val_loss: 0.4265\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4513 - val_loss: 0.4255\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4499 - val_loss: 0.4245\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4486 - val_loss: 0.4235\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4472 - val_loss: 0.4225\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4459 - val_loss: 0.4215\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4445 - val_loss: 0.4205\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4432 - val_loss: 0.4195\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4186\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4406 - val_loss: 0.4176\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4167\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4380 - val_loss: 0.4158\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4368 - val_loss: 0.4149\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4355 - val_loss: 0.4139\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4343 - val_loss: 0.4130\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4330 - val_loss: 0.4121\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4318 - val_loss: 0.4112\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4306 - val_loss: 0.4103\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4294 - val_loss: 0.4094\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4282 - val_loss: 0.4085\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4270 - val_loss: 0.4077\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4258 - val_loss: 0.4068\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4246 - val_loss: 0.4059\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3532936323.38913, my average MASE = 7800622104.848636\n",
      "Cluster 3, 3532936323.38913\n",
      "Before prediction: train_X.shape=(152, 10, 67), train_y.shape=(152, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3354 - val_loss: 0.2774\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3344 - val_loss: 0.2769\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3336 - val_loss: 0.2763\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3328 - val_loss: 0.2758\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3320 - val_loss: 0.2753\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3312 - val_loss: 0.2747\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3304 - val_loss: 0.2742\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3297 - val_loss: 0.2737\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3290 - val_loss: 0.2733\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3282 - val_loss: 0.2728\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3275 - val_loss: 0.2723\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3268 - val_loss: 0.2718\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3262 - val_loss: 0.2714\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3255 - val_loss: 0.2709\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3248 - val_loss: 0.2705\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3242 - val_loss: 0.2700\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3235 - val_loss: 0.2696\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3229 - val_loss: 0.2692\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3223 - val_loss: 0.2687\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3217 - val_loss: 0.2683\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3210 - val_loss: 0.2678\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3204 - val_loss: 0.2674\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3198 - val_loss: 0.2670\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3192 - val_loss: 0.2666\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3187 - val_loss: 0.2662\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3181 - val_loss: 0.2658\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3175 - val_loss: 0.2654\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3170 - val_loss: 0.2650\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3164 - val_loss: 0.2647\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3158 - val_loss: 0.2643\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3153 - val_loss: 0.2639\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3148 - val_loss: 0.2635\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3142 - val_loss: 0.2632\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3137 - val_loss: 0.2628\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3132 - val_loss: 0.2624\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3127 - val_loss: 0.2621\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3122 - val_loss: 0.2617\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3117 - val_loss: 0.2614\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3112 - val_loss: 0.2610\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3107 - val_loss: 0.2607\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 185.09520141259705, my average MASE = 132066880.5161765\n",
      "Cluster 4, 185.09520141259705\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0679 - val_loss: 0.0461\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0619 - val_loss: 0.0426\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0586 - val_loss: 0.0401\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0561 - val_loss: 0.0381\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0542 - val_loss: 0.0366\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0527 - val_loss: 0.0352\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0514 - val_loss: 0.0341\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0503 - val_loss: 0.0333\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0325\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0318\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0312\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0473 - val_loss: 0.0307\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0468 - val_loss: 0.0303\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0463 - val_loss: 0.0299\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0459 - val_loss: 0.0296\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0455 - val_loss: 0.0293\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0452 - val_loss: 0.0290\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0448 - val_loss: 0.0288\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0445 - val_loss: 0.0286\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0443 - val_loss: 0.0284\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0440 - val_loss: 0.0283\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0438 - val_loss: 0.0281\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0436 - val_loss: 0.0279\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0434 - val_loss: 0.0278\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0277\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0430 - val_loss: 0.0276\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0274\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0427 - val_loss: 0.0273\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0426 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0425 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0423 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0422 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0421 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0420 - val_loss: 0.0269\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0419 - val_loss: 0.0268\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0267\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 1042799882.6542007, my average MASE = 20591462481.802387\n",
      "Cluster 5, 1042799882.6542007\n",
      "Before prediction: train_X.shape=(82, 10, 67), train_y.shape=(82, 67), test_X.shape=(27, 10, 67), test_y.shape=(27, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3924 - val_loss: 0.4859\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3915 - val_loss: 0.4852\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3907 - val_loss: 0.4846\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3899 - val_loss: 0.4840\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3891 - val_loss: 0.4835\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3883 - val_loss: 0.4829\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3876 - val_loss: 0.4824\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3868 - val_loss: 0.4818\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3861 - val_loss: 0.4813\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3854 - val_loss: 0.4808\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3847 - val_loss: 0.4802\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3841 - val_loss: 0.4797\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3834 - val_loss: 0.4792\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3828 - val_loss: 0.4787\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3821 - val_loss: 0.4783\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3815 - val_loss: 0.4778\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3809 - val_loss: 0.4773\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3804 - val_loss: 0.4769\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3798 - val_loss: 0.4764\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3792 - val_loss: 0.4760\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3787 - val_loss: 0.4755\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3781 - val_loss: 0.4751\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4747\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3771 - val_loss: 0.4743\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3766 - val_loss: 0.4738\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3761 - val_loss: 0.4734\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3756 - val_loss: 0.4731\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3751 - val_loss: 0.4727\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3746 - val_loss: 0.4723\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3741 - val_loss: 0.4719\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3737 - val_loss: 0.4715\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3732 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3728 - val_loss: 0.4707\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3723 - val_loss: 0.4703\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3719 - val_loss: 0.4699\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3715 - val_loss: 0.4696\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3710 - val_loss: 0.4692\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3706 - val_loss: 0.4688\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3702 - val_loss: 0.4684\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3698 - val_loss: 0.4681\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(27, 67), test_y.shape=(27, 67)\n",
      "average MASE = 307.7375965485456, my average MASE = 158440912.42565766\n",
      "Cluster 6, 307.7375965485456\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=9, 9, 32, (76, 67)\n",
      "Before prediction: train_X.shape=(39, 10, 67), train_y.shape=(39, 67), test_X.shape=(13, 10, 67), test_y.shape=(13, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4763 - val_loss: 0.4497\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4746 - val_loss: 0.4487\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4729 - val_loss: 0.4477\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4713 - val_loss: 0.4467\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4696 - val_loss: 0.4458\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4680 - val_loss: 0.4448\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4663 - val_loss: 0.4439\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4647 - val_loss: 0.4429\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4631 - val_loss: 0.4420\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4616 - val_loss: 0.4410\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4600 - val_loss: 0.4401\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4585 - val_loss: 0.4392\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4554 - val_loss: 0.4373\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4539 - val_loss: 0.4364\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4524 - val_loss: 0.4355\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4510 - val_loss: 0.4345\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4495 - val_loss: 0.4336\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4481 - val_loss: 0.4327\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.4319\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4453 - val_loss: 0.4310\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4439 - val_loss: 0.4301\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4425 - val_loss: 0.4293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4412 - val_loss: 0.4284\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4398 - val_loss: 0.4276\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4385 - val_loss: 0.4267\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4371 - val_loss: 0.4259\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4358 - val_loss: 0.4251\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.4243\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4332 - val_loss: 0.4234\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4320 - val_loss: 0.4226\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4307 - val_loss: 0.4218\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4294 - val_loss: 0.4210\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4282 - val_loss: 0.4202\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4270 - val_loss: 0.4195\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4258 - val_loss: 0.4187\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4246 - val_loss: 0.4179\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4234 - val_loss: 0.4172\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4222 - val_loss: 0.4164\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4211 - val_loss: 0.4157\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(13, 67), test_y.shape=(13, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 3502979890.5184355, my average MASE = 5633924620.870799\n",
      "Cluster 0, 3502979890.5184355\n",
      "Before prediction: train_X.shape=(1945, 10, 67), train_y.shape=(1945, 67), test_X.shape=(648, 10, 67), test_y.shape=(648, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.1163 - val_loss: 0.0998\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1111 - val_loss: 0.0974\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1069 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1034 - val_loss: 0.0946\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1003 - val_loss: 0.0937\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0976 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0952 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0929 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0909 - val_loss: 0.0914\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0891 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0874 - val_loss: 0.0907\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0859 - val_loss: 0.0904\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0845 - val_loss: 0.0902\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0831 - val_loss: 0.0900\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0819 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0808 - val_loss: 0.0896\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0797 - val_loss: 0.0894\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0787 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0778 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0769 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0761 - val_loss: 0.0890\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0753 - val_loss: 0.0889\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0745 - val_loss: 0.0888\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0738 - val_loss: 0.0887\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0731 - val_loss: 0.0886\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0725 - val_loss: 0.0886\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0885\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0713 - val_loss: 0.0885\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0707 - val_loss: 0.0884\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0702 - val_loss: 0.0884\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0697 - val_loss: 0.0883\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0692 - val_loss: 0.0883\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0688 - val_loss: 0.0882\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0683 - val_loss: 0.0882\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0679 - val_loss: 0.0881\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0676 - val_loss: 0.0881\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0672 - val_loss: 0.0880\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0668 - val_loss: 0.0880\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0665 - val_loss: 0.0879\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0662 - val_loss: 0.0879\n",
      "21/21 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(648, 67), test_y.shape=(648, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1199834821.8603294, my average MASE = 15362171394.25593\n",
      "Cluster 1, 1199834821.8603294\n",
      "Before prediction: train_X.shape=(1567, 10, 67), train_y.shape=(1567, 67), test_X.shape=(522, 10, 67), test_y.shape=(522, 67)\n",
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 36ms/step - loss: 0.2378 - val_loss: 0.2753\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2280 - val_loss: 0.2658\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2204 - val_loss: 0.2582\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2142 - val_loss: 0.2520\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2091 - val_loss: 0.2467\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2046 - val_loss: 0.2420\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.2006 - val_loss: 0.2378\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1971 - val_loss: 0.2340\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1938 - val_loss: 0.2304\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1908 - val_loss: 0.2272\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1880 - val_loss: 0.2241\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1853 - val_loss: 0.2213\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1829 - val_loss: 0.2187\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1806 - val_loss: 0.2163\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1784 - val_loss: 0.2141\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1765 - val_loss: 0.2121\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1747 - val_loss: 0.2103\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1730 - val_loss: 0.2086\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1715 - val_loss: 0.2071\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1702 - val_loss: 0.2056\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1689 - val_loss: 0.2042\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1677 - val_loss: 0.2029\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1666 - val_loss: 0.2016\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1655 - val_loss: 0.2005\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1645 - val_loss: 0.1993\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1636 - val_loss: 0.1983\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1626 - val_loss: 0.1973\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1618 - val_loss: 0.1962\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1610 - val_loss: 0.1953\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1602 - val_loss: 0.1944\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 35ms/step - loss: 0.1594 - val_loss: 0.1935\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 0.1587 - val_loss: 0.1927\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 0.1580 - val_loss: 0.1919\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.1573 - val_loss: 0.1911\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1567 - val_loss: 0.1904\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1561 - val_loss: 0.1897\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1555 - val_loss: 0.1890\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1550 - val_loss: 0.1883\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 0.1544 - val_loss: 0.1877\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.1539 - val_loss: 0.1871\n",
      "17/17 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(522, 67), test_y.shape=(522, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 164.5516081334958, my average MASE = 793528060.8539205\n",
      "Cluster 2, 164.5516081334958\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3929 - val_loss: 0.4650\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3920 - val_loss: 0.4646\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3912 - val_loss: 0.4642\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3904 - val_loss: 0.4638\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3896 - val_loss: 0.4635\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3889 - val_loss: 0.4631\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3881 - val_loss: 0.4627\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3874 - val_loss: 0.4624\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3867 - val_loss: 0.4621\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.4617\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3854 - val_loss: 0.4614\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3847 - val_loss: 0.4611\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3841 - val_loss: 0.4608\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3835 - val_loss: 0.4605\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3829 - val_loss: 0.4602\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3823 - val_loss: 0.4600\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3817 - val_loss: 0.4597\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3812 - val_loss: 0.4594\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3806 - val_loss: 0.4591\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3800 - val_loss: 0.4588\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3795 - val_loss: 0.4585\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3790 - val_loss: 0.4583\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3785 - val_loss: 0.4580\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3780 - val_loss: 0.4578\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3775 - val_loss: 0.4575\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3770 - val_loss: 0.4572\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3765 - val_loss: 0.4570\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3761 - val_loss: 0.4567\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3756 - val_loss: 0.4565\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3752 - val_loss: 0.4563\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3747 - val_loss: 0.4560\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3738 - val_loss: 0.4555\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3734 - val_loss: 0.4553\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3730 - val_loss: 0.4551\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3725 - val_loss: 0.4549\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3721 - val_loss: 0.4547\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3717 - val_loss: 0.4545\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3713 - val_loss: 0.4542\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3709 - val_loss: 0.4540\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 177.05816941536048, my average MASE = 104373067.45181417\n",
      "Cluster 3, 177.05816941536048\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4712 - val_loss: 0.3171\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4689 - val_loss: 0.3159\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.3148\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4644 - val_loss: 0.3137\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4621 - val_loss: 0.3125\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4598 - val_loss: 0.3114\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4576 - val_loss: 0.3103\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4553 - val_loss: 0.3092\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4531 - val_loss: 0.3081\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4509 - val_loss: 0.3071\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4487 - val_loss: 0.3062\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4465 - val_loss: 0.3053\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4444 - val_loss: 0.3044\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4422 - val_loss: 0.3036\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4401 - val_loss: 0.3028\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4379 - val_loss: 0.3020\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4358 - val_loss: 0.3012\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4337 - val_loss: 0.3004\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4317 - val_loss: 0.2996\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4297 - val_loss: 0.2988\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4278 - val_loss: 0.2979\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4259 - val_loss: 0.2970\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4240 - val_loss: 0.2961\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4222 - val_loss: 0.2952\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4204 - val_loss: 0.2943\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4186 - val_loss: 0.2934\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4168 - val_loss: 0.2924\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4151 - val_loss: 0.2915\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4134 - val_loss: 0.2906\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4118 - val_loss: 0.2898\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4102 - val_loss: 0.2890\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4086 - val_loss: 0.2883\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4070 - val_loss: 0.2876\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4054 - val_loss: 0.2869\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4039 - val_loss: 0.2863\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.2856\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4009 - val_loss: 0.2850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3995 - val_loss: 0.2845\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3980 - val_loss: 0.2840\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3966 - val_loss: 0.2835\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 254.89087963107983, my average MASE = 19795911.088192035\n",
      "Cluster 5, 254.89087963107983\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(176, 10, 67), train_y.shape=(176, 67), test_X.shape=(59, 10, 67), test_y.shape=(59, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7010 - val_loss: 0.5674\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6997 - val_loss: 0.5667\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6984 - val_loss: 0.5660\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6972 - val_loss: 0.5654\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6960 - val_loss: 0.5647\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6948 - val_loss: 0.5641\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6937 - val_loss: 0.5635\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6925 - val_loss: 0.5629\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6914 - val_loss: 0.5623\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6903 - val_loss: 0.5617\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6893 - val_loss: 0.5611\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6882 - val_loss: 0.5605\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6871 - val_loss: 0.5599\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6861 - val_loss: 0.5594\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6851 - val_loss: 0.5588\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6841 - val_loss: 0.5583\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6831 - val_loss: 0.5577\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6821 - val_loss: 0.5572\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6811 - val_loss: 0.5567\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6802 - val_loss: 0.5562\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6792 - val_loss: 0.5556\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6783 - val_loss: 0.5551\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6774 - val_loss: 0.5546\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6765 - val_loss: 0.5541\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6756 - val_loss: 0.5536\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6747 - val_loss: 0.5531\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6738 - val_loss: 0.5526\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6729 - val_loss: 0.5521\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6720 - val_loss: 0.5516\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6712 - val_loss: 0.5512\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6703 - val_loss: 0.5507\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6695 - val_loss: 0.5502\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6686 - val_loss: 0.5497\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6678 - val_loss: 0.5493\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6670 - val_loss: 0.5488\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6661 - val_loss: 0.5483\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6653 - val_loss: 0.5479\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6645 - val_loss: 0.5474\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6637 - val_loss: 0.5469\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6629 - val_loss: 0.5464\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(59, 67), test_y.shape=(59, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 154.34881195949765, my average MASE = 318959730.30915844\n",
      "Cluster 7, 154.34881195949765\n",
      "Before prediction: train_X.shape=(150, 10, 67), train_y.shape=(150, 67), test_X.shape=(50, 10, 67), test_y.shape=(50, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3127 - val_loss: 0.2620\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3118 - val_loss: 0.2614\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3110 - val_loss: 0.2608\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3103 - val_loss: 0.2603\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3096 - val_loss: 0.2597\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3088 - val_loss: 0.2592\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3081 - val_loss: 0.2587\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3074 - val_loss: 0.2582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3067 - val_loss: 0.2577\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3060 - val_loss: 0.2572\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3054 - val_loss: 0.2567\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3047 - val_loss: 0.2563\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.3041 - val_loss: 0.2558\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3035 - val_loss: 0.2554\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3029 - val_loss: 0.2549\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3023 - val_loss: 0.2545\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3017 - val_loss: 0.2541\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3011 - val_loss: 0.2537\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3005 - val_loss: 0.2533\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3000 - val_loss: 0.2529\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.2994 - val_loss: 0.2525\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2988 - val_loss: 0.2521\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2983 - val_loss: 0.2517\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2978 - val_loss: 0.2513\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2973 - val_loss: 0.2509\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2967 - val_loss: 0.2505\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2962 - val_loss: 0.2502\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2957 - val_loss: 0.2498\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2952 - val_loss: 0.2494\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2948 - val_loss: 0.2491\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2943 - val_loss: 0.2487\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2938 - val_loss: 0.2484\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.2933 - val_loss: 0.2480\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2929 - val_loss: 0.2477\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2924 - val_loss: 0.2473\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2920 - val_loss: 0.2470\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2915 - val_loss: 0.2467\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.2911 - val_loss: 0.2463\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2907 - val_loss: 0.2460\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2902 - val_loss: 0.2457\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(50, 67), test_y.shape=(50, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 222.6692241509544, my average MASE = 77008768.33506098\n",
      "Cluster 8, 222.6692241509544\n",
      "clusters_labels.shape=(408086,)\n",
      "N_clusters=11, 11, 435, (11, 67)\n",
      "Before prediction: train_X.shape=(5, 10, 67), train_y.shape=(5, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4436 - val_loss: 0.3307\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4426 - val_loss: 0.3306\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4417 - val_loss: 0.3306\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4408 - val_loss: 0.3305\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4398 - val_loss: 0.3305\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4389 - val_loss: 0.3304\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4380 - val_loss: 0.3303\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4371 - val_loss: 0.3303\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4362 - val_loss: 0.3302\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4354 - val_loss: 0.3301\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4345 - val_loss: 0.3301\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4337 - val_loss: 0.3300\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4329 - val_loss: 0.3299\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4320 - val_loss: 0.3299\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4312 - val_loss: 0.3298\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4304 - val_loss: 0.3298\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4296 - val_loss: 0.3297\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4288 - val_loss: 0.3296\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4280 - val_loss: 0.3295\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4273 - val_loss: 0.3295\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4265 - val_loss: 0.3294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4258 - val_loss: 0.3293\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4250 - val_loss: 0.3293\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4243 - val_loss: 0.3292\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4235 - val_loss: 0.3291\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4228 - val_loss: 0.3291\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4221 - val_loss: 0.3290\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4213 - val_loss: 0.3290\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4206 - val_loss: 0.3289\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4199 - val_loss: 0.3288\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4191 - val_loss: 0.3288\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4184 - val_loss: 0.3287\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4177 - val_loss: 0.3287\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4170 - val_loss: 0.3286\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4163 - val_loss: 0.3286\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4156 - val_loss: 0.3285\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4149 - val_loss: 0.3285\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4143 - val_loss: 0.3285\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4136 - val_loss: 0.3284\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4129 - val_loss: 0.3284\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 623.4242587364998, my average MASE = 13116998.58946489\n",
      "Cluster 0, 623.4242587364998\n",
      "Before prediction: train_X.shape=(18, 10, 67), train_y.shape=(18, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4512 - val_loss: 0.5917\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4491 - val_loss: 0.5900\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4470 - val_loss: 0.5884\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4449 - val_loss: 0.5867\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4429 - val_loss: 0.5851\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4408 - val_loss: 0.5835\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.5818\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4369 - val_loss: 0.5802\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4349 - val_loss: 0.5786\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4330 - val_loss: 0.5770\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4311 - val_loss: 0.5755\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4293 - val_loss: 0.5739\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4275 - val_loss: 0.5724\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4257 - val_loss: 0.5709\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4239 - val_loss: 0.5694\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4222 - val_loss: 0.5680\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4205 - val_loss: 0.5666\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4188 - val_loss: 0.5652\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4171 - val_loss: 0.5638\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4155 - val_loss: 0.5625\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4139 - val_loss: 0.5611\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4123 - val_loss: 0.5598\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4107 - val_loss: 0.5584\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4092 - val_loss: 0.5571\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4077 - val_loss: 0.5558\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4062 - val_loss: 0.5545\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4047 - val_loss: 0.5532\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4032 - val_loss: 0.5519\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4017 - val_loss: 0.5506\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4003 - val_loss: 0.5494\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3988 - val_loss: 0.5482\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5470\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3960 - val_loss: 0.5458\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3946 - val_loss: 0.5446\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3933 - val_loss: 0.5435\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3920 - val_loss: 0.5424\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3906 - val_loss: 0.5414\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3893 - val_loss: 0.5403\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3881 - val_loss: 0.5393\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3868 - val_loss: 0.5382\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1669347283.8471758, my average MASE = 4344504132.76493\n",
      "Cluster 1, 1669347283.8471758\n",
      "Before prediction: train_X.shape=(5958, 10, 67), train_y.shape=(5958, 67), test_X.shape=(1986, 10, 67), test_y.shape=(1986, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0678 - val_loss: 0.0460\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0618 - val_loss: 0.0427\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0585 - val_loss: 0.0404\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 33ms/step - loss: 0.0561 - val_loss: 0.0385\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0542 - val_loss: 0.0369\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0527 - val_loss: 0.0355\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0514 - val_loss: 0.0344\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0503 - val_loss: 0.0335\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0494 - val_loss: 0.0327\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0486 - val_loss: 0.0321\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0479 - val_loss: 0.0315\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0473 - val_loss: 0.0310\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0468 - val_loss: 0.0306\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0463 - val_loss: 0.0302\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0458 - val_loss: 0.0299\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0454 - val_loss: 0.0296\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0451 - val_loss: 0.0293\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0447 - val_loss: 0.0291\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0444 - val_loss: 0.0289\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0442 - val_loss: 0.0287\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0439 - val_loss: 0.0285\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0283\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0434 - val_loss: 0.0281\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0432 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0430 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0429 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0427 - val_loss: 0.0276\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0425 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0424 - val_loss: 0.0273\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0423 - val_loss: 0.0272\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0421 - val_loss: 0.0271\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0420 - val_loss: 0.0270\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0419 - val_loss: 0.0269\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0418 - val_loss: 0.0268\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0417 - val_loss: 0.0267\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0266\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0415 - val_loss: 0.0265\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0264\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0413 - val_loss: 0.0263\n",
      "63/63 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(1986, 67), test_y.shape=(1986, 67)\n",
      "average MASE = 811440996.3412759, my average MASE = 40052487777.48425\n",
      "Cluster 2, 811440996.3412759\n",
      "Before prediction: train_X.shape=(11, 10, 67), train_y.shape=(11, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.1986 - val_loss: 0.8095\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1967 - val_loss: 0.8095\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1948 - val_loss: 0.8095\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.1930 - val_loss: 0.8094\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1912 - val_loss: 0.8094\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1894 - val_loss: 0.8094\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1876 - val_loss: 0.8094\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.1858 - val_loss: 0.8094\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.1840 - val_loss: 0.8094\n",
      "Epoch 9: early stopping\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 72.88641883174732, my average MASE = 50002377.286928184\n",
      "Cluster 3, 72.88641883174732\n",
      "Before prediction: train_X.shape=(87, 10, 67), train_y.shape=(87, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5691 - val_loss: 0.5072\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5682 - val_loss: 0.5068\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5674 - val_loss: 0.5063\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5666 - val_loss: 0.5059\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5659 - val_loss: 0.5055\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5651 - val_loss: 0.5051\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5643 - val_loss: 0.5047\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5636 - val_loss: 0.5042\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5628 - val_loss: 0.5038\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5621 - val_loss: 0.5034\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5614 - val_loss: 0.5030\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5606 - val_loss: 0.5026\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5600 - val_loss: 0.5022\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5592 - val_loss: 0.5018\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5586 - val_loss: 0.5014\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5579 - val_loss: 0.5011\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5572 - val_loss: 0.5007\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5565 - val_loss: 0.5003\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5558 - val_loss: 0.4999\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5552 - val_loss: 0.4996\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5545 - val_loss: 0.4993\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5539 - val_loss: 0.4989\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5532 - val_loss: 0.4986\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5526 - val_loss: 0.4983\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5520 - val_loss: 0.4979\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5513 - val_loss: 0.4976\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5507 - val_loss: 0.4973\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5501 - val_loss: 0.4970\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5495 - val_loss: 0.4967\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5489 - val_loss: 0.4964\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5483 - val_loss: 0.4961\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5477 - val_loss: 0.4958\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5471 - val_loss: 0.4956\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5465 - val_loss: 0.4953\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5459 - val_loss: 0.4950\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5453 - val_loss: 0.4947\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5447 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5442 - val_loss: 0.4942\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.4939\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5430 - val_loss: 0.4936\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 98.29689269118158, my average MASE = 78492579.83265808\n",
      "Cluster 4, 98.29689269118158\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "Before prediction: train_X.shape=(13, 10, 67), train_y.shape=(13, 67), test_X.shape=(4, 10, 67), test_y.shape=(4, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4003 - val_loss: 0.3997\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3997 - val_loss: 0.3991\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3991 - val_loss: 0.3986\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3985 - val_loss: 0.3981\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3979 - val_loss: 0.3976\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3973 - val_loss: 0.3971\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3968 - val_loss: 0.3967\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3962 - val_loss: 0.3962\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3957 - val_loss: 0.3958\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3951 - val_loss: 0.3953\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3946 - val_loss: 0.3949\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3940 - val_loss: 0.3945\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3935 - val_loss: 0.3941\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3930 - val_loss: 0.3937\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3924 - val_loss: 0.3932\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3919 - val_loss: 0.3928\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3914 - val_loss: 0.3925\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3909 - val_loss: 0.3921\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3904 - val_loss: 0.3917\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3899 - val_loss: 0.3913\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3894 - val_loss: 0.3909\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3889 - val_loss: 0.3906\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3884 - val_loss: 0.3902\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3879 - val_loss: 0.3898\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3874 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3870 - val_loss: 0.3891\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3865 - val_loss: 0.3887\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3860 - val_loss: 0.3883\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3856 - val_loss: 0.3880\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3851 - val_loss: 0.3876\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3847 - val_loss: 0.3872\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3842 - val_loss: 0.3869\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3838 - val_loss: 0.3865\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3833 - val_loss: 0.3861\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3829 - val_loss: 0.3857\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3824 - val_loss: 0.3853\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3820 - val_loss: 0.3850\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3815 - val_loss: 0.3846\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3811 - val_loss: 0.3842\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3807 - val_loss: 0.3838\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(4, 67), test_y.shape=(4, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 517837.8778283109, my average MASE = 16943290.739345513\n",
      "Cluster 6, 517837.8778283109\n",
      "Before prediction: train_X.shape=(17, 10, 67), train_y.shape=(17, 67), test_X.shape=(6, 10, 67), test_y.shape=(6, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2151 - val_loss: 0.4042\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2146 - val_loss: 0.4041\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2142 - val_loss: 0.4041\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2137 - val_loss: 0.4040\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2133 - val_loss: 0.4040\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2128 - val_loss: 0.4040\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2124 - val_loss: 0.4039\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2119 - val_loss: 0.4039\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2115 - val_loss: 0.4038\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2111 - val_loss: 0.4038\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2107 - val_loss: 0.4038\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2103 - val_loss: 0.4038\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2099 - val_loss: 0.4037\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2096 - val_loss: 0.4037\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2092 - val_loss: 0.4037\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2088 - val_loss: 0.4036\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2084 - val_loss: 0.4036\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2081 - val_loss: 0.4036\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2077 - val_loss: 0.4035\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2074 - val_loss: 0.4035\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2070 - val_loss: 0.4035\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2067 - val_loss: 0.4035\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2063 - val_loss: 0.4035\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2060 - val_loss: 0.4034\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2057 - val_loss: 0.4034\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2054 - val_loss: 0.4034\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2050 - val_loss: 0.4034\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2047 - val_loss: 0.4033\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2044 - val_loss: 0.4033\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2041 - val_loss: 0.4033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2038 - val_loss: 0.4032\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2035 - val_loss: 0.4032\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2032 - val_loss: 0.4032\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2029 - val_loss: 0.4031\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2026 - val_loss: 0.4031\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2023 - val_loss: 0.4031\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2020 - val_loss: 0.4030\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2017 - val_loss: 0.4030\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2014 - val_loss: 0.4029\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2011 - val_loss: 0.4029\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(6, 67), test_y.shape=(6, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 181.01448499364625, my average MASE = 73613295.18701741\n",
      "Cluster 7, 181.01448499364625\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "FAIL - test_X.shape=(1, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(2, 10, 67)\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2941 - val_loss: 0.3652\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2932 - val_loss: 0.3650\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2923 - val_loss: 0.3648\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2914 - val_loss: 0.3646\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2905 - val_loss: 0.3644\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2897 - val_loss: 0.3641\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2888 - val_loss: 0.3639\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2880 - val_loss: 0.3638\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2872 - val_loss: 0.3636\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2864 - val_loss: 0.3634\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2856 - val_loss: 0.3632\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2848 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2840 - val_loss: 0.3629\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2832 - val_loss: 0.3628\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2824 - val_loss: 0.3626\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2817 - val_loss: 0.3625\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2809 - val_loss: 0.3624\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2802 - val_loss: 0.3622\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2794 - val_loss: 0.3621\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2787 - val_loss: 0.3620\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2780 - val_loss: 0.3619\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2772 - val_loss: 0.3618\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2765 - val_loss: 0.3617\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2758 - val_loss: 0.3616\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2751 - val_loss: 0.3615\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2744 - val_loss: 0.3615\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2738 - val_loss: 0.3614\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2731 - val_loss: 0.3613\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2725 - val_loss: 0.3613\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2718 - val_loss: 0.3612\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2712 - val_loss: 0.3612\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2705 - val_loss: 0.3611\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2699 - val_loss: 0.3611\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2693 - val_loss: 0.3610\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2687 - val_loss: 0.3610\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2681 - val_loss: 0.3610\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2675 - val_loss: 0.3609\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2669 - val_loss: 0.3609\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2663 - val_loss: 0.3608\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2657 - val_loss: 0.3608\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 679.6913673037432, my average MASE = 68962615.13093176\n",
      "Cluster 9, 679.6913673037432\n",
      "Before prediction: train_X.shape=(1, 10, 67), train_y.shape=(1, 67), test_X.shape=(0, 10, 67), test_y.shape=(0, 67)\n",
      "FAIL - test_X.shape=(0, 10, 67), valid_X.shape=(0, 10, 67), train_X.shape=(1, 10, 67)\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=2, 2, 11, (10056, 67)\n",
      "Before prediction: train_X.shape=(6027, 10, 67), train_y.shape=(6027, 67), test_X.shape=(2009, 10, 67), test_y.shape=(2009, 67)\n",
      "Epoch 1/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0641 - val_loss: 0.0494\n",
      "Epoch 2/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0590 - val_loss: 0.0459\n",
      "Epoch 3/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0558 - val_loss: 0.0432\n",
      "Epoch 4/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0535 - val_loss: 0.0410\n",
      "Epoch 5/40\n",
      "95/95 [==============================] - 3s 33ms/step - loss: 0.0516 - val_loss: 0.0393\n",
      "Epoch 6/40\n",
      "95/95 [==============================] - 3s 32ms/step - loss: 0.0501 - val_loss: 0.0378\n",
      "Epoch 7/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0489 - val_loss: 0.0366\n",
      "Epoch 8/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0478 - val_loss: 0.0357\n",
      "Epoch 9/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0470 - val_loss: 0.0348\n",
      "Epoch 10/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0462 - val_loss: 0.0341\n",
      "Epoch 11/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0455 - val_loss: 0.0335\n",
      "Epoch 12/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0449 - val_loss: 0.0330\n",
      "Epoch 13/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0443 - val_loss: 0.0325\n",
      "Epoch 14/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0321\n",
      "Epoch 15/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0317\n",
      "Epoch 16/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0314\n",
      "Epoch 17/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0311\n",
      "Epoch 18/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0423 - val_loss: 0.0308\n",
      "Epoch 19/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0419 - val_loss: 0.0305\n",
      "Epoch 20/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0416 - val_loss: 0.0303\n",
      "Epoch 21/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0414 - val_loss: 0.0300\n",
      "Epoch 22/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0298\n",
      "Epoch 23/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0409 - val_loss: 0.0296\n",
      "Epoch 24/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0406 - val_loss: 0.0294\n",
      "Epoch 25/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0404 - val_loss: 0.0293\n",
      "Epoch 26/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0403 - val_loss: 0.0291\n",
      "Epoch 27/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0401 - val_loss: 0.0290\n",
      "Epoch 28/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0399 - val_loss: 0.0289\n",
      "Epoch 29/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0397 - val_loss: 0.0287\n",
      "Epoch 30/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0396 - val_loss: 0.0286\n",
      "Epoch 31/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0394 - val_loss: 0.0286\n",
      "Epoch 32/40\n",
      "95/95 [==============================] - 3s 31ms/step - loss: 0.0393 - val_loss: 0.0285\n",
      "Epoch 33/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0392 - val_loss: 0.0284\n",
      "Epoch 34/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0391 - val_loss: 0.0283\n",
      "Epoch 35/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0389 - val_loss: 0.0282\n",
      "Epoch 36/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0388 - val_loss: 0.0282\n",
      "Epoch 37/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0387 - val_loss: 0.0281\n",
      "Epoch 38/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0386 - val_loss: 0.0281\n",
      "Epoch 39/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0385 - val_loss: 0.0280\n",
      "Epoch 40/40\n",
      "95/95 [==============================] - 3s 30ms/step - loss: 0.0384 - val_loss: 0.0280\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(2009, 67), test_y.shape=(2009, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 137177179.8661396, my average MASE = 15662264218.215044\n",
      "Cluster 0, 137177179.8661396\n",
      "Before prediction: train_X.shape=(18366, 10, 67), train_y.shape=(18366, 67), test_X.shape=(6122, 10, 67), test_y.shape=(6122, 67)\n",
      "Epoch 1/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.3004 - val_loss: 0.3159\n",
      "Epoch 2/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2809 - val_loss: 0.3004\n",
      "Epoch 3/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2655 - val_loss: 0.2878\n",
      "Epoch 4/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2540 - val_loss: 0.2790\n",
      "Epoch 5/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2465 - val_loss: 0.2727\n",
      "Epoch 6/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2409 - val_loss: 0.2676\n",
      "Epoch 7/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2364 - val_loss: 0.2633\n",
      "Epoch 8/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2324 - val_loss: 0.2598\n",
      "Epoch 9/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2290 - val_loss: 0.2567\n",
      "Epoch 10/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2259 - val_loss: 0.2539\n",
      "Epoch 11/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2230 - val_loss: 0.2514\n",
      "Epoch 12/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2204 - val_loss: 0.2493\n",
      "Epoch 13/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2181 - val_loss: 0.2474\n",
      "Epoch 14/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.2161 - val_loss: 0.2457\n",
      "Epoch 15/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.2144 - val_loss: 0.2442\n",
      "Epoch 16/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2129 - val_loss: 0.2429\n",
      "Epoch 17/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2115 - val_loss: 0.2418\n",
      "Epoch 18/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2103 - val_loss: 0.2406\n",
      "Epoch 19/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2092 - val_loss: 0.2396\n",
      "Epoch 20/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2083 - val_loss: 0.2386\n",
      "Epoch 21/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2073 - val_loss: 0.2378\n",
      "Epoch 22/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2065 - val_loss: 0.2370\n",
      "Epoch 23/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2057 - val_loss: 0.2363\n",
      "Epoch 24/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2050 - val_loss: 0.2356\n",
      "Epoch 25/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2043 - val_loss: 0.2350\n",
      "Epoch 26/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2037 - val_loss: 0.2344\n",
      "Epoch 27/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2031 - val_loss: 0.2338\n",
      "Epoch 28/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2025 - val_loss: 0.2333\n",
      "Epoch 29/40\n",
      "287/287 [==============================] - 9s 32ms/step - loss: 0.2020 - val_loss: 0.2328\n",
      "Epoch 30/40\n",
      "287/287 [==============================] - 8s 29ms/step - loss: 0.2015 - val_loss: 0.2324\n",
      "Epoch 31/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2010 - val_loss: 0.2319\n",
      "Epoch 32/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.2006 - val_loss: 0.2314\n",
      "Epoch 33/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.2002 - val_loss: 0.2311\n",
      "Epoch 34/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1998 - val_loss: 0.2307\n",
      "Epoch 35/40\n",
      "287/287 [==============================] - 9s 33ms/step - loss: 0.1994 - val_loss: 0.2304\n",
      "Epoch 36/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1991 - val_loss: 0.2301\n",
      "Epoch 37/40\n",
      "287/287 [==============================] - 8s 30ms/step - loss: 0.1987 - val_loss: 0.2298\n",
      "Epoch 38/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1984 - val_loss: 0.2294\n",
      "Epoch 39/40\n",
      "287/287 [==============================] - 9s 31ms/step - loss: 0.1981 - val_loss: 0.2291\n",
      "Epoch 40/40\n",
      "287/287 [==============================] - 9s 30ms/step - loss: 0.1978 - val_loss: 0.2290\n",
      "192/192 [==============================] - 2s 10ms/step\n",
      "predicted_original.shape=(6122, 67), test_y.shape=(6122, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1800.7465590842255, my average MASE = 3633.615501921918\n",
      "Cluster 1, 1800.7465590842255\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=5, 5, 58, (3715, 67)\n",
      "Before prediction: train_X.shape=(2222, 10, 67), train_y.shape=(2222, 67), test_X.shape=(741, 10, 67), test_y.shape=(741, 67)\n",
      "Epoch 1/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.5001 - val_loss: 0.3691\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4918 - val_loss: 0.3651\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4851 - val_loss: 0.3618\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4795 - val_loss: 0.3589\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4744 - val_loss: 0.3563\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4699 - val_loss: 0.3539\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4657 - val_loss: 0.3517\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4618 - val_loss: 0.3497\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4582 - val_loss: 0.3478\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4548 - val_loss: 0.3460\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4516 - val_loss: 0.3443\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4485 - val_loss: 0.3427\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4455 - val_loss: 0.3412\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4426 - val_loss: 0.3398\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4398 - val_loss: 0.3384\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4370 - val_loss: 0.3370\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4342 - val_loss: 0.3357\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.4315 - val_loss: 0.3345\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4289 - val_loss: 0.3332\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4263 - val_loss: 0.3321\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4237 - val_loss: 0.3309\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4213 - val_loss: 0.3298\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.4189 - val_loss: 0.3287\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4166 - val_loss: 0.3277\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4143 - val_loss: 0.3266\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4120 - val_loss: 0.3256\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4099 - val_loss: 0.3247\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4079 - val_loss: 0.3238\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.4059 - val_loss: 0.3230\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.4040 - val_loss: 0.3222\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4022 - val_loss: 0.3214\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 0.4005 - val_loss: 0.3206\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3988 - val_loss: 0.3199\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3972 - val_loss: 0.3193\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3956 - val_loss: 0.3186\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3941 - val_loss: 0.3180\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3927 - val_loss: 0.3175\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 1s 32ms/step - loss: 0.3912 - val_loss: 0.3169\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 1s 33ms/step - loss: 0.3899 - val_loss: 0.3163\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.3885 - val_loss: 0.3158\n",
      "24/24 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(741, 67), test_y.shape=(741, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 461.9721639366225, my average MASE = 1222.9207656733142\n",
      "Cluster 0, 461.9721639366225\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1169 - val_loss: 0.0965\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1118 - val_loss: 0.0947\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1077 - val_loss: 0.0935\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1043 - val_loss: 0.0926\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1013 - val_loss: 0.0919\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0987 - val_loss: 0.0913\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0964 - val_loss: 0.0909\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0942 - val_loss: 0.0906\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0923 - val_loss: 0.0904\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0906 - val_loss: 0.0901\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0890 - val_loss: 0.0899\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0875 - val_loss: 0.0897\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0861 - val_loss: 0.0895\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0849 - val_loss: 0.0894\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0837 - val_loss: 0.0892\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0826 - val_loss: 0.0891\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0816 - val_loss: 0.0889\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0807 - val_loss: 0.0888\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0798 - val_loss: 0.0886\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0790 - val_loss: 0.0885\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0782 - val_loss: 0.0884\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0775 - val_loss: 0.0883\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0768 - val_loss: 0.0881\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0761 - val_loss: 0.0880\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0755 - val_loss: 0.0879\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0749 - val_loss: 0.0878\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0743 - val_loss: 0.0877\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0738 - val_loss: 0.0876\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0732 - val_loss: 0.0875\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0727 - val_loss: 0.0875\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0722 - val_loss: 0.0874\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0718 - val_loss: 0.0874\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0713 - val_loss: 0.0874\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0873\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0705 - val_loss: 0.0873\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0702 - val_loss: 0.0873\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0698 - val_loss: 0.0872\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0695 - val_loss: 0.0872\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0689 - val_loss: 0.0871\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 979857680.8759673, my average MASE = 20246393999.460716\n",
      "Cluster 1, 979857680.8759673\n",
      "Before prediction: train_X.shape=(160, 10, 67), train_y.shape=(160, 67), test_X.shape=(53, 10, 67), test_y.shape=(53, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5150 - val_loss: 0.4228\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5137 - val_loss: 0.4220\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5125 - val_loss: 0.4212\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5113 - val_loss: 0.4205\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5101 - val_loss: 0.4197\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5090 - val_loss: 0.4189\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5079 - val_loss: 0.4182\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5068 - val_loss: 0.4175\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5058 - val_loss: 0.4168\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5047 - val_loss: 0.4161\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5037 - val_loss: 0.4154\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5026 - val_loss: 0.4148\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5016 - val_loss: 0.4141\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5006 - val_loss: 0.4135\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4997 - val_loss: 0.4128\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4987 - val_loss: 0.4122\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4977 - val_loss: 0.4116\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4968 - val_loss: 0.4110\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4958 - val_loss: 0.4104\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4949 - val_loss: 0.4098\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4940 - val_loss: 0.4092\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4931 - val_loss: 0.4086\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4923 - val_loss: 0.4081\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4914 - val_loss: 0.4075\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4905 - val_loss: 0.4069\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4897 - val_loss: 0.4064\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4888 - val_loss: 0.4059\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4880 - val_loss: 0.4053\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.4871 - val_loss: 0.4048\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4863 - val_loss: 0.4043\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4855 - val_loss: 0.4038\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.4847 - val_loss: 0.4033\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4840 - val_loss: 0.4028\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4832 - val_loss: 0.4023\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4824 - val_loss: 0.4018\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4817 - val_loss: 0.4013\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4809 - val_loss: 0.4008\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4802 - val_loss: 0.4003\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4795 - val_loss: 0.3998\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4787 - val_loss: 0.3994\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "predicted_original.shape=(53, 67), test_y.shape=(53, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 127.13783551729924, my average MASE = 51951538.633395046\n",
      "Cluster 2, 127.13783551729924\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8383 - val_loss: 0.5938\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8360 - val_loss: 0.5928\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8338 - val_loss: 0.5919\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8316 - val_loss: 0.5910\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8294 - val_loss: 0.5901\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8272 - val_loss: 0.5891\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8251 - val_loss: 0.5882\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8229 - val_loss: 0.5873\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8208 - val_loss: 0.5864\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8187 - val_loss: 0.5855\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8167 - val_loss: 0.5847\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8146 - val_loss: 0.5838\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8126 - val_loss: 0.5830\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8107 - val_loss: 0.5821\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8087 - val_loss: 0.5812\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8068 - val_loss: 0.5803\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8048 - val_loss: 0.5794\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8029 - val_loss: 0.5786\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8009 - val_loss: 0.5777\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7989 - val_loss: 0.5768\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7970 - val_loss: 0.5760\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7951 - val_loss: 0.5751\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7932 - val_loss: 0.5743\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7913 - val_loss: 0.5735\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7894 - val_loss: 0.5727\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7875 - val_loss: 0.5720\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7857 - val_loss: 0.5712\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7839 - val_loss: 0.5704\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7820 - val_loss: 0.5697\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7802 - val_loss: 0.5690\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7784 - val_loss: 0.5682\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7767 - val_loss: 0.5675\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7749 - val_loss: 0.5668\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7732 - val_loss: 0.5661\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7715 - val_loss: 0.5655\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7698 - val_loss: 0.5648\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7681 - val_loss: 0.5641\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7664 - val_loss: 0.5635\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7647 - val_loss: 0.5629\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7630 - val_loss: 0.5623\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1378.9503839591846, my average MASE = 44152799.2879618\n",
      "Cluster 3, 1378.9503839591846\n",
      "Before prediction: train_X.shape=(44, 10, 67), train_y.shape=(44, 67), test_X.shape=(15, 10, 67), test_y.shape=(15, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5170 - val_loss: 0.7315\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5154 - val_loss: 0.7308\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5138 - val_loss: 0.7300\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5122 - val_loss: 0.7293\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5107 - val_loss: 0.7285\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5092 - val_loss: 0.7278\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5077 - val_loss: 0.7271\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5062 - val_loss: 0.7264\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5047 - val_loss: 0.7257\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5033 - val_loss: 0.7250\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5018 - val_loss: 0.7243\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.7236\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4990 - val_loss: 0.7229\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4977 - val_loss: 0.7222\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4963 - val_loss: 0.7215\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4949 - val_loss: 0.7209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4936 - val_loss: 0.7202\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4923 - val_loss: 0.7196\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4910 - val_loss: 0.7189\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4897 - val_loss: 0.7183\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4884 - val_loss: 0.7177\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4872 - val_loss: 0.7170\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4859 - val_loss: 0.7164\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4847 - val_loss: 0.7158\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4835 - val_loss: 0.7152\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4823 - val_loss: 0.7146\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4811 - val_loss: 0.7140\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4799 - val_loss: 0.7135\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4788 - val_loss: 0.7129\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4776 - val_loss: 0.7123\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4765 - val_loss: 0.7118\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4753 - val_loss: 0.7113\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4742 - val_loss: 0.7107\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4731 - val_loss: 0.7102\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4720 - val_loss: 0.7097\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4709 - val_loss: 0.7092\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4698 - val_loss: 0.7087\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4687 - val_loss: 0.7082\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4676 - val_loss: 0.7077\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4666 - val_loss: 0.7073\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(15, 67), test_y.shape=(15, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2846600473.0797715, my average MASE = 8256296780.299102\n",
      "Cluster 4, 2846600473.0797715\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=7, 7, 176, (267, 67)\n",
      "Before prediction: train_X.shape=(154, 10, 67), train_y.shape=(154, 67), test_X.shape=(51, 10, 67), test_y.shape=(51, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.3225 - val_loss: 0.2694\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3217 - val_loss: 0.2689\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3209 - val_loss: 0.2684\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3201 - val_loss: 0.2679\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3194 - val_loss: 0.2674\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3187 - val_loss: 0.2669\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3179 - val_loss: 0.2664\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3172 - val_loss: 0.2659\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3165 - val_loss: 0.2655\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3159 - val_loss: 0.2650\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3152 - val_loss: 0.2646\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3145 - val_loss: 0.2641\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3139 - val_loss: 0.2637\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3133 - val_loss: 0.2633\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3127 - val_loss: 0.2629\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3121 - val_loss: 0.2624\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3115 - val_loss: 0.2620\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3109 - val_loss: 0.2616\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3103 - val_loss: 0.2612\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3098 - val_loss: 0.2609\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3092 - val_loss: 0.2605\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3087 - val_loss: 0.2601\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3081 - val_loss: 0.2598\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.3076 - val_loss: 0.2594\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3071 - val_loss: 0.2590\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3066 - val_loss: 0.2587\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3061 - val_loss: 0.2584\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3056 - val_loss: 0.2580\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3051 - val_loss: 0.2576\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3046 - val_loss: 0.2573\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3041 - val_loss: 0.2569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3037 - val_loss: 0.2566\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3032 - val_loss: 0.2563\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3027 - val_loss: 0.2559\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3023 - val_loss: 0.2556\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.3018 - val_loss: 0.2553\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3013 - val_loss: 0.2550\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3009 - val_loss: 0.2546\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3005 - val_loss: 0.2543\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3000 - val_loss: 0.2540\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(51, 67), test_y.shape=(51, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 173.3029589389659, my average MASE = 89033224.06135572\n",
      "Cluster 0, 173.3029589389659\n",
      "Before prediction: train_X.shape=(5960, 10, 67), train_y.shape=(5960, 67), test_X.shape=(1987, 10, 67), test_y.shape=(1987, 67)\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0675 - val_loss: 0.0464\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0617 - val_loss: 0.0432\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0584 - val_loss: 0.0410\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0560 - val_loss: 0.0393\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0541 - val_loss: 0.0377\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0525 - val_loss: 0.0364\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0512 - val_loss: 0.0353\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0501 - val_loss: 0.0343\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0492 - val_loss: 0.0335\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0484 - val_loss: 0.0327\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0477 - val_loss: 0.0321\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0471 - val_loss: 0.0315\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0466 - val_loss: 0.0310\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0461 - val_loss: 0.0306\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0457 - val_loss: 0.0302\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 3s 34ms/step - loss: 0.0453 - val_loss: 0.0299\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 3s 32ms/step - loss: 0.0449 - val_loss: 0.0296\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0445 - val_loss: 0.0293\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0442 - val_loss: 0.0291\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0439 - val_loss: 0.0288\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0437 - val_loss: 0.0286\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0434 - val_loss: 0.0284\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0432 - val_loss: 0.0282\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0430 - val_loss: 0.0280\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - val_loss: 0.0278\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0426 - val_loss: 0.0277\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0424 - val_loss: 0.0275\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0423 - val_loss: 0.0274\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0421 - val_loss: 0.0272\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0420 - val_loss: 0.0271\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0419 - val_loss: 0.0270\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0417 - val_loss: 0.0269\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0416 - val_loss: 0.0268\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0415 - val_loss: 0.0266\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0414 - val_loss: 0.0265\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0413 - val_loss: 0.0265\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 3s 31ms/step - loss: 0.0412 - val_loss: 0.0264\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 3s 30ms/step - loss: 0.0411 - val_loss: 0.0263\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0410 - val_loss: 0.0262\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 3s 29ms/step - loss: 0.0409 - val_loss: 0.0261\n",
      "63/63 [==============================] - 1s 10ms/step\n",
      "predicted_original.shape=(1987, 67), test_y.shape=(1987, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 783030752.0753396, my average MASE = 36192993113.38622\n",
      "Cluster 1, 783030752.0753396\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5458 - val_loss: 0.3458\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.3449\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.3440\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5391 - val_loss: 0.3431\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5369 - val_loss: 0.3422\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5348 - val_loss: 0.3413\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5326 - val_loss: 0.3405\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5304 - val_loss: 0.3396\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5283 - val_loss: 0.3387\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5261 - val_loss: 0.3379\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5240 - val_loss: 0.3371\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5219 - val_loss: 0.3362\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5198 - val_loss: 0.3354\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5177 - val_loss: 0.3346\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5157 - val_loss: 0.3338\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5137 - val_loss: 0.3330\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5117 - val_loss: 0.3322\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5097 - val_loss: 0.3314\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5078 - val_loss: 0.3308\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5059 - val_loss: 0.3301\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5041 - val_loss: 0.3295\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5022 - val_loss: 0.3290\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5004 - val_loss: 0.3284\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4986 - val_loss: 0.3279\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4968 - val_loss: 0.3274\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4951 - val_loss: 0.3269\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4933 - val_loss: 0.3264\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4917 - val_loss: 0.3260\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4900 - val_loss: 0.3257\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4884 - val_loss: 0.3254\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4868 - val_loss: 0.3251\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4852 - val_loss: 0.3249\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4836 - val_loss: 0.3247\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4821 - val_loss: 0.3245\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4805 - val_loss: 0.3244\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4790 - val_loss: 0.3242\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4775 - val_loss: 0.3241\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4760 - val_loss: 0.3240\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4745 - val_loss: 0.3239\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4730 - val_loss: 0.3238\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 300.2247881778862, my average MASE = 45822553.10580316\n",
      "Cluster 2, 300.2247881778862\n",
      "Before prediction: train_X.shape=(85, 10, 67), train_y.shape=(85, 67), test_X.shape=(28, 10, 67), test_y.shape=(28, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3796 - val_loss: 0.4594\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3789 - val_loss: 0.4589\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3782 - val_loss: 0.4585\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3776 - val_loss: 0.4581\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3770 - val_loss: 0.4577\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3764 - val_loss: 0.4573\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3759 - val_loss: 0.4569\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3753 - val_loss: 0.4565\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3748 - val_loss: 0.4561\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3743 - val_loss: 0.4558\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3737 - val_loss: 0.4554\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3732 - val_loss: 0.4550\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3727 - val_loss: 0.4547\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3722 - val_loss: 0.4543\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3717 - val_loss: 0.4540\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3713 - val_loss: 0.4537\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3708 - val_loss: 0.4533\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3703 - val_loss: 0.4530\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3699 - val_loss: 0.4527\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3694 - val_loss: 0.4524\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3690 - val_loss: 0.4521\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3685 - val_loss: 0.4517\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3681 - val_loss: 0.4514\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3677 - val_loss: 0.4512\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3673 - val_loss: 0.4509\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3669 - val_loss: 0.4506\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3664 - val_loss: 0.4503\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3661 - val_loss: 0.4501\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3657 - val_loss: 0.4498\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3653 - val_loss: 0.4495\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3649 - val_loss: 0.4493\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3645 - val_loss: 0.4490\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3641 - val_loss: 0.4487\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3638 - val_loss: 0.4485\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3634 - val_loss: 0.4482\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3630 - val_loss: 0.4480\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3627 - val_loss: 0.4478\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3623 - val_loss: 0.4475\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3619 - val_loss: 0.4473\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3616 - val_loss: 0.4470\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(28, 67), test_y.shape=(28, 67)\n",
      "average MASE = 329.8443195642471, my average MASE = 91063731.05477783\n",
      "Cluster 3, 329.8443195642471\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6262 - val_loss: 0.5214\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6239 - val_loss: 0.5202\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6216 - val_loss: 0.5190\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6193 - val_loss: 0.5179\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6170 - val_loss: 0.5167\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6148 - val_loss: 0.5156\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6125 - val_loss: 0.5145\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6102 - val_loss: 0.5134\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6080 - val_loss: 0.5123\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6058 - val_loss: 0.5112\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6036 - val_loss: 0.5101\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6015 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5994 - val_loss: 0.5080\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5973 - val_loss: 0.5070\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5953 - val_loss: 0.5060\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5932 - val_loss: 0.5051\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5912 - val_loss: 0.5041\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5892 - val_loss: 0.5032\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5872 - val_loss: 0.5023\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5853 - val_loss: 0.5015\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5834 - val_loss: 0.5006\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5816 - val_loss: 0.4999\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5799 - val_loss: 0.4991\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5782 - val_loss: 0.4984\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5765 - val_loss: 0.4977\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5749 - val_loss: 0.4970\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5732 - val_loss: 0.4963\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5716 - val_loss: 0.4957\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5699 - val_loss: 0.4951\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5683 - val_loss: 0.4946\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5667 - val_loss: 0.4941\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5651 - val_loss: 0.4936\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5635 - val_loss: 0.4931\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5619 - val_loss: 0.4927\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5604 - val_loss: 0.4922\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5588 - val_loss: 0.4917\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5573 - val_loss: 0.4913\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5557 - val_loss: 0.4909\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5542 - val_loss: 0.4906\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5526 - val_loss: 0.4902\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32309710873507563, my average MASE = 0.5656513264705396\n",
      "Cluster 4, 0.32309710873507563\n",
      "Before prediction: train_X.shape=(43, 10, 67), train_y.shape=(43, 67), test_X.shape=(14, 10, 67), test_y.shape=(14, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5119 - val_loss: 0.6850\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5101 - val_loss: 0.6839\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5083 - val_loss: 0.6829\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5066 - val_loss: 0.6819\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5048 - val_loss: 0.6808\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5031 - val_loss: 0.6798\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5014 - val_loss: 0.6788\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4997 - val_loss: 0.6778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4980 - val_loss: 0.6769\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4964 - val_loss: 0.6759\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4948 - val_loss: 0.6749\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4931 - val_loss: 0.6740\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4915 - val_loss: 0.6730\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4900 - val_loss: 0.6721\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4884 - val_loss: 0.6711\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4869 - val_loss: 0.6702\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4853 - val_loss: 0.6693\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4838 - val_loss: 0.6683\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4823 - val_loss: 0.6674\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4808 - val_loss: 0.6665\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4794 - val_loss: 0.6656\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4779 - val_loss: 0.6647\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4765 - val_loss: 0.6639\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4751 - val_loss: 0.6630\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4737 - val_loss: 0.6622\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4723 - val_loss: 0.6613\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4710 - val_loss: 0.6605\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4697 - val_loss: 0.6596\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4683 - val_loss: 0.6588\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4670 - val_loss: 0.6580\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4657 - val_loss: 0.6572\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4644 - val_loss: 0.6564\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4631 - val_loss: 0.6556\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4619 - val_loss: 0.6548\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4606 - val_loss: 0.6540\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4594 - val_loss: 0.6532\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4581 - val_loss: 0.6525\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4569 - val_loss: 0.6517\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4557 - val_loss: 0.6510\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4545 - val_loss: 0.6502\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(14, 67), test_y.shape=(14, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 2340337256.388025, my average MASE = 7806499481.251814\n",
      "Cluster 5, 2340337256.388025\n",
      "Before prediction: train_X.shape=(181, 10, 67), train_y.shape=(181, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6846 - val_loss: 0.5744\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6833 - val_loss: 0.5737\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6820 - val_loss: 0.5730\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6807 - val_loss: 0.5723\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6795 - val_loss: 0.5716\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6783 - val_loss: 0.5709\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6771 - val_loss: 0.5703\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6760 - val_loss: 0.5696\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6749 - val_loss: 0.5690\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6737 - val_loss: 0.5683\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6727 - val_loss: 0.5677\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6716 - val_loss: 0.5671\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6705 - val_loss: 0.5666\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6695 - val_loss: 0.5660\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6685 - val_loss: 0.5654\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6675 - val_loss: 0.5648\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6664 - val_loss: 0.5643\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6654 - val_loss: 0.5637\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6645 - val_loss: 0.5632\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6635 - val_loss: 0.5626\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6626 - val_loss: 0.5621\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.6616 - val_loss: 0.5615\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6607 - val_loss: 0.5610\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6597 - val_loss: 0.5605\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6588 - val_loss: 0.5600\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6579 - val_loss: 0.5594\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6570 - val_loss: 0.5589\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6561 - val_loss: 0.5584\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6553 - val_loss: 0.5579\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6544 - val_loss: 0.5574\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6536 - val_loss: 0.5569\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6527 - val_loss: 0.5563\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6519 - val_loss: 0.5558\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6510 - val_loss: 0.5553\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6502 - val_loss: 0.5548\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6493 - val_loss: 0.5543\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6485 - val_loss: 0.5538\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6477 - val_loss: 0.5533\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6468 - val_loss: 0.5528\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6460 - val_loss: 0.5523\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 153.88341287865387, my average MASE = 335532064.75560737\n",
      "Cluster 6, 153.88341287865387\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=9, 9, 3, (61, 67)\n",
      "Before prediction: train_X.shape=(30, 10, 67), train_y.shape=(30, 67), test_X.shape=(10, 10, 67), test_y.shape=(10, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5800 - val_loss: 0.4525\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5784 - val_loss: 0.4515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5768 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5753 - val_loss: 0.4496\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5738 - val_loss: 0.4487\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5722 - val_loss: 0.4477\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5707 - val_loss: 0.4468\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5692 - val_loss: 0.4459\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5678 - val_loss: 0.4450\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5663 - val_loss: 0.4441\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5648 - val_loss: 0.4433\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5634 - val_loss: 0.4424\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5619 - val_loss: 0.4415\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5605 - val_loss: 0.4407\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5590 - val_loss: 0.4398\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5576 - val_loss: 0.4390\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5562 - val_loss: 0.4382\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5548 - val_loss: 0.4374\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5534 - val_loss: 0.4367\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5520 - val_loss: 0.4359\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5507 - val_loss: 0.4352\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5493 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5480 - val_loss: 0.4337\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5467 - val_loss: 0.4329\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - val_loss: 0.4322\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5441 - val_loss: 0.4315\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5428 - val_loss: 0.4308\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5415 - val_loss: 0.4301\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5403 - val_loss: 0.4294\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5390 - val_loss: 0.4287\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5378 - val_loss: 0.4280\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5366 - val_loss: 0.4273\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5354 - val_loss: 0.4266\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5342 - val_loss: 0.4260\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5330 - val_loss: 0.4253\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5318 - val_loss: 0.4246\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5307 - val_loss: 0.4240\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5295 - val_loss: 0.4234\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5284 - val_loss: 0.4227\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5273 - val_loss: 0.4221\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "predicted_original.shape=(10, 67), test_y.shape=(10, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 35650627.66244785, my average MASE = 4899168813.139491\n",
      "Cluster 0, 35650627.66244785\n",
      "Before prediction: train_X.shape=(179, 10, 67), train_y.shape=(179, 67), test_X.shape=(60, 10, 67), test_y.shape=(60, 67)\n",
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7142 - val_loss: 0.5624\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7129 - val_loss: 0.5618\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7116 - val_loss: 0.5612\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7104 - val_loss: 0.5605\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7092 - val_loss: 0.5599\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7080 - val_loss: 0.5593\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7069 - val_loss: 0.5588\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7057 - val_loss: 0.5582\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.7046 - val_loss: 0.5576\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7035 - val_loss: 0.5571\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7024 - val_loss: 0.5565\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.7013 - val_loss: 0.5560\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7002 - val_loss: 0.5555\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6993 - val_loss: 0.5550\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6982 - val_loss: 0.5545\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6972 - val_loss: 0.5540\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6962 - val_loss: 0.5535\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6952 - val_loss: 0.5530\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6942 - val_loss: 0.5525\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6932 - val_loss: 0.5520\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6922 - val_loss: 0.5516\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6913 - val_loss: 0.5511\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6903 - val_loss: 0.5506\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6894 - val_loss: 0.5502\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6885 - val_loss: 0.5498\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6875 - val_loss: 0.5493\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6866 - val_loss: 0.5489\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6857 - val_loss: 0.5485\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6848 - val_loss: 0.5481\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6839 - val_loss: 0.5477\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6830 - val_loss: 0.5472\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6821 - val_loss: 0.5468\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6812 - val_loss: 0.5464\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6803 - val_loss: 0.5460\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6794 - val_loss: 0.5456\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6786 - val_loss: 0.5452\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6777 - val_loss: 0.5449\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6768 - val_loss: 0.5445\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6759 - val_loss: 0.5441\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6751 - val_loss: 0.5437\n",
      "2/2 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(60, 67), test_y.shape=(60, 67)\n",
      "average MASE = 167.81473432422789, my average MASE = 220460085.3598021\n",
      "Cluster 1, 167.81473432422789\n",
      "Before prediction: train_X.shape=(15, 10, 67), train_y.shape=(15, 67), test_X.shape=(5, 10, 67), test_y.shape=(5, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4267 - val_loss: 0.6677\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4246 - val_loss: 0.6662\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4226 - val_loss: 0.6647\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4205 - val_loss: 0.6632\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4185 - val_loss: 0.6618\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4166 - val_loss: 0.6605\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4146 - val_loss: 0.6592\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4127 - val_loss: 0.6578\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4107 - val_loss: 0.6565\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4088 - val_loss: 0.6552\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4070 - val_loss: 0.6539\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4051 - val_loss: 0.6527\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4033 - val_loss: 0.6514\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4014 - val_loss: 0.6502\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3997 - val_loss: 0.6490\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3979 - val_loss: 0.6478\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3961 - val_loss: 0.6466\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3944 - val_loss: 0.6455\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3927 - val_loss: 0.6444\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3910 - val_loss: 0.6433\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3893 - val_loss: 0.6423\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3877 - val_loss: 0.6412\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3861 - val_loss: 0.6402\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3845 - val_loss: 0.6392\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3829 - val_loss: 0.6383\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3814 - val_loss: 0.6374\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3799 - val_loss: 0.6364\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3784 - val_loss: 0.6356\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3769 - val_loss: 0.6347\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3754 - val_loss: 0.6338\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3740 - val_loss: 0.6330\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3725 - val_loss: 0.6322\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3711 - val_loss: 0.6314\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3697 - val_loss: 0.6305\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3683 - val_loss: 0.6297\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3669 - val_loss: 0.6289\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.6281\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3642 - val_loss: 0.6273\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3629 - val_loss: 0.6264\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3616 - val_loss: 0.6256\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "predicted_original.shape=(5, 67), test_y.shape=(5, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1967377505.4498963, my average MASE = 5262000054.755049\n",
      "Cluster 2, 1967377505.4498963\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6328 - val_loss: 0.7373\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6300 - val_loss: 0.7359\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6272 - val_loss: 0.7344\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6245 - val_loss: 0.7330\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6218 - val_loss: 0.7316\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6191 - val_loss: 0.7301\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6164 - val_loss: 0.7287\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6137 - val_loss: 0.7273\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6111 - val_loss: 0.7259\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6085 - val_loss: 0.7245\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6058 - val_loss: 0.7230\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6033 - val_loss: 0.7216\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6009 - val_loss: 0.7202\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5985 - val_loss: 0.7188\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5961 - val_loss: 0.7174\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5938 - val_loss: 0.7159\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5915 - val_loss: 0.7146\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5892 - val_loss: 0.7133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5869 - val_loss: 0.7119\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5847 - val_loss: 0.7106\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5825 - val_loss: 0.7092\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5803 - val_loss: 0.7078\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5781 - val_loss: 0.7064\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5759 - val_loss: 0.7050\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5738 - val_loss: 0.7036\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5716 - val_loss: 0.7022\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5695 - val_loss: 0.7009\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5674 - val_loss: 0.6996\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5653 - val_loss: 0.6983\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5632 - val_loss: 0.6971\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5611 - val_loss: 0.6959\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5590 - val_loss: 0.6946\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5569 - val_loss: 0.6934\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5549 - val_loss: 0.6922\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5528 - val_loss: 0.6910\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5509 - val_loss: 0.6898\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5490 - val_loss: 0.6886\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5472 - val_loss: 0.6874\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5454 - val_loss: 0.6862\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5436 - val_loss: 0.6850\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.27232041656941225, my average MASE = 0.501167640234202\n",
      "Cluster 3, 0.27232041656941225\n",
      "Before prediction: train_X.shape=(7, 10, 67), train_y.shape=(7, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4602 - val_loss: 0.3734\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4580 - val_loss: 0.3723\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4558 - val_loss: 0.3714\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4536 - val_loss: 0.3704\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4515 - val_loss: 0.3694\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4494 - val_loss: 0.3685\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4474 - val_loss: 0.3675\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4454 - val_loss: 0.3666\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4435 - val_loss: 0.3657\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4416 - val_loss: 0.3648\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4397 - val_loss: 0.3640\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4379 - val_loss: 0.3631\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4361 - val_loss: 0.3623\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4344 - val_loss: 0.3616\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4328 - val_loss: 0.3608\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4312 - val_loss: 0.3601\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4296 - val_loss: 0.3594\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4279 - val_loss: 0.3587\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4263 - val_loss: 0.3581\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4247 - val_loss: 0.3575\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4231 - val_loss: 0.3569\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4216 - val_loss: 0.3564\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4200 - val_loss: 0.3558\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4184 - val_loss: 0.3553\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4169 - val_loss: 0.3547\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4154 - val_loss: 0.3542\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4138 - val_loss: 0.3537\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4123 - val_loss: 0.3533\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4109 - val_loss: 0.3528\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4094 - val_loss: 0.3524\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4080 - val_loss: 0.3520\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4066 - val_loss: 0.3516\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4053 - val_loss: 0.3512\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4039 - val_loss: 0.3508\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4026 - val_loss: 0.3505\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4013 - val_loss: 0.3502\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4000 - val_loss: 0.3498\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3987 - val_loss: 0.3495\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3974 - val_loss: 0.3492\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3961 - val_loss: 0.3490\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 363.8540679781247, my average MASE = 17706113.36217601\n",
      "Cluster 4, 363.8540679781247\n",
      "Before prediction: train_X.shape=(88, 10, 67), train_y.shape=(88, 67), test_X.shape=(29, 10, 67), test_y.shape=(29, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4172 - val_loss: 0.5128\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4165 - val_loss: 0.5124\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4158 - val_loss: 0.5121\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4151 - val_loss: 0.5117\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4145 - val_loss: 0.5113\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4139 - val_loss: 0.5110\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4132 - val_loss: 0.5107\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4126 - val_loss: 0.5103\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4120 - val_loss: 0.5100\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4114 - val_loss: 0.5096\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4108 - val_loss: 0.5093\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4102 - val_loss: 0.5090\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4097 - val_loss: 0.5086\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4091 - val_loss: 0.5083\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4085 - val_loss: 0.5080\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4080 - val_loss: 0.5077\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4074 - val_loss: 0.5074\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4069 - val_loss: 0.5071\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4064 - val_loss: 0.5068\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4059 - val_loss: 0.5065\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4053 - val_loss: 0.5062\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4048 - val_loss: 0.5059\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4043 - val_loss: 0.5056\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4038 - val_loss: 0.5053\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4034 - val_loss: 0.5051\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4029 - val_loss: 0.5048\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4024 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4019 - val_loss: 0.5042\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4014 - val_loss: 0.5039\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4010 - val_loss: 0.5036\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4005 - val_loss: 0.5033\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4000 - val_loss: 0.5030\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3996 - val_loss: 0.5028\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3991 - val_loss: 0.5025\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3987 - val_loss: 0.5022\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3983 - val_loss: 0.5019\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3978 - val_loss: 0.5016\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3974 - val_loss: 0.5013\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3969 - val_loss: 0.5011\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3965 - val_loss: 0.5008\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(29, 67), test_y.shape=(29, 67)\n",
      "average MASE = 210.04101539413423, my average MASE = 60624707.44207928\n",
      "Cluster 5, 210.04101539413423\n",
      "Before prediction: train_X.shape=(104, 10, 67), train_y.shape=(104, 67), test_X.shape=(35, 10, 67), test_y.shape=(35, 67)\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3090 - val_loss: 0.2755\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3084 - val_loss: 0.2752\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3078 - val_loss: 0.2749\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3072 - val_loss: 0.2745\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3066 - val_loss: 0.2742\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3061 - val_loss: 0.2739\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3055 - val_loss: 0.2736\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3049 - val_loss: 0.2733\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3044 - val_loss: 0.2730\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3039 - val_loss: 0.2727\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3033 - val_loss: 0.2724\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3028 - val_loss: 0.2722\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3023 - val_loss: 0.2719\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3018 - val_loss: 0.2716\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3013 - val_loss: 0.2713\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3008 - val_loss: 0.2711\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3003 - val_loss: 0.2708\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2998 - val_loss: 0.2705\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2994 - val_loss: 0.2703\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2989 - val_loss: 0.2700\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2984 - val_loss: 0.2698\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2980 - val_loss: 0.2695\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2975 - val_loss: 0.2693\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2971 - val_loss: 0.2690\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2966 - val_loss: 0.2688\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2962 - val_loss: 0.2686\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2958 - val_loss: 0.2683\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2953 - val_loss: 0.2681\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.2949 - val_loss: 0.2678\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2945 - val_loss: 0.2676\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2941 - val_loss: 0.2674\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2937 - val_loss: 0.2671\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2933 - val_loss: 0.2669\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2929 - val_loss: 0.2667\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2925 - val_loss: 0.2664\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2921 - val_loss: 0.2662\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.2917 - val_loss: 0.2660\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2913 - val_loss: 0.2658\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.2909 - val_loss: 0.2656\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2906 - val_loss: 0.2654\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "predicted_original.shape=(35, 67), test_y.shape=(35, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 554.2347835476104, my average MASE = 43885073.200175166\n",
      "Cluster 6, 554.2347835476104\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6507 - val_loss: 0.5207\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6481 - val_loss: 0.5200\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6456 - val_loss: 0.5192\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6431 - val_loss: 0.5184\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6407 - val_loss: 0.5176\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6383 - val_loss: 0.5169\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6360 - val_loss: 0.5161\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6338 - val_loss: 0.5154\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6316 - val_loss: 0.5147\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6293 - val_loss: 0.5140\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6271 - val_loss: 0.5133\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6249 - val_loss: 0.5126\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6227 - val_loss: 0.5119\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6206 - val_loss: 0.5112\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6185 - val_loss: 0.5105\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6164 - val_loss: 0.5099\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6145 - val_loss: 0.5093\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6125 - val_loss: 0.5087\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6107 - val_loss: 0.5082\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6088 - val_loss: 0.5076\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6069 - val_loss: 0.5071\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6051 - val_loss: 0.5067\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6032 - val_loss: 0.5062\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6014 - val_loss: 0.5058\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5996 - val_loss: 0.5053\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5978 - val_loss: 0.5049\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5959 - val_loss: 0.5045\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5941 - val_loss: 0.5040\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5923 - val_loss: 0.5036\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5905 - val_loss: 0.5033\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5888 - val_loss: 0.5030\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5871 - val_loss: 0.5027\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5853 - val_loss: 0.5024\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5837 - val_loss: 0.5021\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5822 - val_loss: 0.5017\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5806 - val_loss: 0.5014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5791 - val_loss: 0.5011\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5775 - val_loss: 0.5009\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5760 - val_loss: 0.5006\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5745 - val_loss: 0.5004\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2390672605525707, my average MASE = 0.4689912396588464\n",
      "Cluster 7, 0.2390672605525707\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1191 - val_loss: 0.0992\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1138 - val_loss: 0.0972\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1096 - val_loss: 0.0959\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.1060 - val_loss: 0.0949\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1029 - val_loss: 0.0942\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.1002 - val_loss: 0.0935\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0977 - val_loss: 0.0930\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0955 - val_loss: 0.0925\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0916 - val_loss: 0.0917\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0899 - val_loss: 0.0913\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0884 - val_loss: 0.0909\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0870 - val_loss: 0.0906\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0856 - val_loss: 0.0903\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0844 - val_loss: 0.0900\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0833 - val_loss: 0.0898\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0822 - val_loss: 0.0896\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0812 - val_loss: 0.0894\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0803 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0778 - val_loss: 0.0887\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0771 - val_loss: 0.0886\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0764 - val_loss: 0.0885\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0757 - val_loss: 0.0884\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0751 - val_loss: 0.0883\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0745 - val_loss: 0.0882\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0739 - val_loss: 0.0881\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0880\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0879\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0723 - val_loss: 0.0879\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0719 - val_loss: 0.0878\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0715 - val_loss: 0.0877\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0711 - val_loss: 0.0876\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.0707 - val_loss: 0.0876\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0703 - val_loss: 0.0875\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0700 - val_loss: 0.0874\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0697 - val_loss: 0.0873\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0694 - val_loss: 0.0872\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0692 - val_loss: 0.0872\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 1385618831.00148, my average MASE = 22365614226.60064\n",
      "Cluster 8, 1385618831.00148\n",
      "clusters_labels.shape=(408081,)\n",
      "N_clusters=11, 11, 68, (49, 67)\n",
      "Before prediction: train_X.shape=(23, 10, 67), train_y.shape=(23, 67), test_X.shape=(8, 10, 67), test_y.shape=(8, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5560 - val_loss: 0.4967\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5553 - val_loss: 0.4965\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5546 - val_loss: 0.4963\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5538 - val_loss: 0.4961\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5531 - val_loss: 0.4960\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5524 - val_loss: 0.4958\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5517 - val_loss: 0.4956\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5510 - val_loss: 0.4955\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5503 - val_loss: 0.4953\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5496 - val_loss: 0.4952\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5489 - val_loss: 0.4950\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5482 - val_loss: 0.4949\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5476 - val_loss: 0.4947\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5469 - val_loss: 0.4946\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5463 - val_loss: 0.4945\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5456 - val_loss: 0.4943\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5450 - val_loss: 0.4942\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5443 - val_loss: 0.4940\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5437 - val_loss: 0.4939\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5431 - val_loss: 0.4938\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5425 - val_loss: 0.4936\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5419 - val_loss: 0.4935\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5413 - val_loss: 0.4934\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5407 - val_loss: 0.4933\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5401 - val_loss: 0.4932\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5395 - val_loss: 0.4930\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5389 - val_loss: 0.4929\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5384 - val_loss: 0.4928\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5378 - val_loss: 0.4927\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5372 - val_loss: 0.4926\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5367 - val_loss: 0.4925\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5361 - val_loss: 0.4923\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5356 - val_loss: 0.4922\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5351 - val_loss: 0.4921\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5345 - val_loss: 0.4920\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5340 - val_loss: 0.4919\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5335 - val_loss: 0.4918\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5329 - val_loss: 0.4917\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5324 - val_loss: 0.4915\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5319 - val_loss: 0.4914\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(8, 67), test_y.shape=(8, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 62.874751666083846, my average MASE = 63681940.89448814\n",
      "Cluster 0, 62.874751666083846\n",
      "Before prediction: train_X.shape=(10, 10, 67), train_y.shape=(10, 67), test_X.shape=(3, 10, 67), test_y.shape=(3, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3794 - val_loss: 0.4534\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3770 - val_loss: 0.4520\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3747 - val_loss: 0.4506\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3724 - val_loss: 0.4494\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3701 - val_loss: 0.4481\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3678 - val_loss: 0.4468\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3656 - val_loss: 0.4455\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3634 - val_loss: 0.4443\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3612 - val_loss: 0.4430\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3591 - val_loss: 0.4418\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3571 - val_loss: 0.4406\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3551 - val_loss: 0.4394\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3531 - val_loss: 0.4382\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3511 - val_loss: 0.4371\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3492 - val_loss: 0.4359\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3473 - val_loss: 0.4348\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3454 - val_loss: 0.4337\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3436 - val_loss: 0.4326\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3418 - val_loss: 0.4315\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3400 - val_loss: 0.4305\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3382 - val_loss: 0.4294\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3365 - val_loss: 0.4284\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3349 - val_loss: 0.4273\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3332 - val_loss: 0.4263\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3316 - val_loss: 0.4253\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3300 - val_loss: 0.4243\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3285 - val_loss: 0.4233\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3269 - val_loss: 0.4224\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3254 - val_loss: 0.4214\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3239 - val_loss: 0.4205\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3224 - val_loss: 0.4196\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3209 - val_loss: 0.4186\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3195 - val_loss: 0.4177\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3181 - val_loss: 0.4168\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3166 - val_loss: 0.4159\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3153 - val_loss: 0.4151\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3139 - val_loss: 0.4142\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3125 - val_loss: 0.4134\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3112 - val_loss: 0.4125\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3098 - val_loss: 0.4117\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(3, 67), test_y.shape=(3, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1188796320.3185039, my average MASE = 2779981174.701244\n",
      "Cluster 1, 1188796320.3185039\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6283 - val_loss: 0.6105\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6261 - val_loss: 0.6091\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6239 - val_loss: 0.6076\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6218 - val_loss: 0.6062\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6196 - val_loss: 0.6047\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6175 - val_loss: 0.6033\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6153 - val_loss: 0.6018\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6132 - val_loss: 0.6004\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6110 - val_loss: 0.5990\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6089 - val_loss: 0.5976\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6067 - val_loss: 0.5961\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6046 - val_loss: 0.5947\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6026 - val_loss: 0.5933\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6005 - val_loss: 0.5919\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5985 - val_loss: 0.5905\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5964 - val_loss: 0.5891\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5944 - val_loss: 0.5877\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5923 - val_loss: 0.5866\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5903 - val_loss: 0.5854\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5882 - val_loss: 0.5842\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5861 - val_loss: 0.5831\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5841 - val_loss: 0.5819\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5820 - val_loss: 0.5808\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5799 - val_loss: 0.5796\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5778 - val_loss: 0.5784\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5758 - val_loss: 0.5773\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5737 - val_loss: 0.5762\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5717 - val_loss: 0.5751\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5697 - val_loss: 0.5740\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5676 - val_loss: 0.5731\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5656 - val_loss: 0.5721\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5636 - val_loss: 0.5712\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5616 - val_loss: 0.5703\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5597 - val_loss: 0.5694\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5577 - val_loss: 0.5686\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5558 - val_loss: 0.5678\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5538 - val_loss: 0.5670\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5519 - val_loss: 0.5663\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5499 - val_loss: 0.5655\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5480 - val_loss: 0.5647\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.32481366416229096, my average MASE = 0.6312112420260654\n",
      "Cluster 2, 0.32481366416229096\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4564 - val_loss: 0.4796\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4555 - val_loss: 0.4793\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4547 - val_loss: 0.4791\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4538 - val_loss: 0.4788\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4529 - val_loss: 0.4786\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4521 - val_loss: 0.4783\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4512 - val_loss: 0.4781\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4504 - val_loss: 0.4778\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4496 - val_loss: 0.4776\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4487 - val_loss: 0.4773\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4479 - val_loss: 0.4771\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4471 - val_loss: 0.4768\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4463 - val_loss: 0.4766\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4455 - val_loss: 0.4763\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4447 - val_loss: 0.4760\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4439 - val_loss: 0.4758\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4431 - val_loss: 0.4755\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4423 - val_loss: 0.4753\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4415 - val_loss: 0.4750\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4407 - val_loss: 0.4747\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4400 - val_loss: 0.4745\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4392 - val_loss: 0.4742\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4385 - val_loss: 0.4739\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4377 - val_loss: 0.4736\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4370 - val_loss: 0.4733\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4362 - val_loss: 0.4730\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4355 - val_loss: 0.4727\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4348 - val_loss: 0.4724\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4341 - val_loss: 0.4721\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4334 - val_loss: 0.4717\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4327 - val_loss: 0.4714\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4320 - val_loss: 0.4711\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4313 - val_loss: 0.4708\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4307 - val_loss: 0.4705\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4300 - val_loss: 0.4701\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4293 - val_loss: 0.4698\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4286 - val_loss: 0.4694\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4280 - val_loss: 0.4691\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4273 - val_loss: 0.4688\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4266 - val_loss: 0.4684\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 1418783.6078857174, my average MASE = 35875462.94910899\n",
      "Cluster 3, 1418783.6078857174\n",
      "Before prediction: train_X.shape=(27, 10, 67), train_y.shape=(27, 67), test_X.shape=(9, 10, 67), test_y.shape=(9, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3810 - val_loss: 0.3926\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3805 - val_loss: 0.3924\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3799 - val_loss: 0.3923\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3794 - val_loss: 0.3921\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3789 - val_loss: 0.3920\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3784 - val_loss: 0.3918\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3779 - val_loss: 0.3917\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3774 - val_loss: 0.3916\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3769 - val_loss: 0.3914\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3764 - val_loss: 0.3913\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3759 - val_loss: 0.3911\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3754 - val_loss: 0.3910\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3749 - val_loss: 0.3909\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3744 - val_loss: 0.3907\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3739 - val_loss: 0.3906\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3734 - val_loss: 0.3905\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3729 - val_loss: 0.3903\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3725 - val_loss: 0.3902\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3720 - val_loss: 0.3901\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3715 - val_loss: 0.3900\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3711 - val_loss: 0.3899\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3706 - val_loss: 0.3898\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3701 - val_loss: 0.3896\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3697 - val_loss: 0.3895\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3692 - val_loss: 0.3894\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3688 - val_loss: 0.3893\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3683 - val_loss: 0.3892\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3679 - val_loss: 0.3891\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3674 - val_loss: 0.3890\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3670 - val_loss: 0.3889\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3666 - val_loss: 0.3888\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3661 - val_loss: 0.3887\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3657 - val_loss: 0.3886\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3653 - val_loss: 0.3885\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3648 - val_loss: 0.3884\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3644 - val_loss: 0.3883\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3640 - val_loss: 0.3882\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3636 - val_loss: 0.3881\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3632 - val_loss: 0.3880\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3627 - val_loss: 0.3879\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(9, 67), test_y.shape=(9, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 73.99923698083529, my average MASE = 28273926.299095076\n",
      "Cluster 4, 73.99923698083529\n",
      "Before prediction: train_X.shape=(1948, 10, 67), train_y.shape=(1948, 67), test_X.shape=(649, 10, 67), test_y.shape=(649, 67)\n",
      "Epoch 1/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1188 - val_loss: 0.0994\n",
      "Epoch 2/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1133 - val_loss: 0.0973\n",
      "Epoch 3/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.1090 - val_loss: 0.0957\n",
      "Epoch 4/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1053 - val_loss: 0.0945\n",
      "Epoch 5/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1021 - val_loss: 0.0936\n",
      "Epoch 6/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0993 - val_loss: 0.0929\n",
      "Epoch 7/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0969 - val_loss: 0.0924\n",
      "Epoch 8/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0946 - val_loss: 0.0919\n",
      "Epoch 9/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 10/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0909 - val_loss: 0.0911\n",
      "Epoch 11/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0893 - val_loss: 0.0908\n",
      "Epoch 12/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0878 - val_loss: 0.0906\n",
      "Epoch 13/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0864 - val_loss: 0.0903\n",
      "Epoch 14/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0852 - val_loss: 0.0901\n",
      "Epoch 15/40\n",
      "31/31 [==============================] - 1s 35ms/step - loss: 0.0841 - val_loss: 0.0898\n",
      "Epoch 16/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0830 - val_loss: 0.0897\n",
      "Epoch 17/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0820 - val_loss: 0.0895\n",
      "Epoch 18/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0811 - val_loss: 0.0893\n",
      "Epoch 19/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0802 - val_loss: 0.0892\n",
      "Epoch 20/40\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 21/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0786 - val_loss: 0.0889\n",
      "Epoch 22/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0779 - val_loss: 0.0888\n",
      "Epoch 23/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0772 - val_loss: 0.0887\n",
      "Epoch 24/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0765 - val_loss: 0.0886\n",
      "Epoch 25/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0759 - val_loss: 0.0885\n",
      "Epoch 26/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0753 - val_loss: 0.0884\n",
      "Epoch 27/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0747 - val_loss: 0.0884\n",
      "Epoch 28/40\n",
      "31/31 [==============================] - 1s 34ms/step - loss: 0.0742 - val_loss: 0.0883\n",
      "Epoch 29/40\n",
      "31/31 [==============================] - 1s 33ms/step - loss: 0.0737 - val_loss: 0.0882\n",
      "Epoch 30/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0733 - val_loss: 0.0881\n",
      "Epoch 31/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0728 - val_loss: 0.0881\n",
      "Epoch 32/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0724 - val_loss: 0.0880\n",
      "Epoch 33/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0720 - val_loss: 0.0880\n",
      "Epoch 34/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0716 - val_loss: 0.0879\n",
      "Epoch 35/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0712 - val_loss: 0.0879\n",
      "Epoch 36/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0709 - val_loss: 0.0879\n",
      "Epoch 37/40\n",
      "31/31 [==============================] - 1s 30ms/step - loss: 0.0705 - val_loss: 0.0878\n",
      "Epoch 38/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0702 - val_loss: 0.0877\n",
      "Epoch 39/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0699 - val_loss: 0.0877\n",
      "Epoch 40/40\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.0696 - val_loss: 0.0877\n",
      "21/21 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_original.shape=(649, 67), test_y.shape=(649, 67)\n",
      "average MASE = 772933595.2163092, my average MASE = 33112652144.926693\n",
      "Cluster 5, 772933595.2163092\n",
      "Before prediction: train_X.shape=(3, 10, 67), train_y.shape=(3, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6742 - val_loss: 0.5426\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6711 - val_loss: 0.5410\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6680 - val_loss: 0.5395\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6649 - val_loss: 0.5381\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6619 - val_loss: 0.5366\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6589 - val_loss: 0.5352\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6560 - val_loss: 0.5338\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6532 - val_loss: 0.5324\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6503 - val_loss: 0.5310\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6475 - val_loss: 0.5296\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6447 - val_loss: 0.5282\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6420 - val_loss: 0.5269\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6393 - val_loss: 0.5255\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6367 - val_loss: 0.5242\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6340 - val_loss: 0.5229\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6314 - val_loss: 0.5216\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6289 - val_loss: 0.5203\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6264 - val_loss: 0.5190\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6240 - val_loss: 0.5178\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6215 - val_loss: 0.5165\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6191 - val_loss: 0.5153\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6168 - val_loss: 0.5141\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6145 - val_loss: 0.5128\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6122 - val_loss: 0.5115\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6098 - val_loss: 0.5102\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6076 - val_loss: 0.5089\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6054 - val_loss: 0.5076\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6033 - val_loss: 0.5062\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6011 - val_loss: 0.5049\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5989 - val_loss: 0.5035\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5968 - val_loss: 0.5022\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5947 - val_loss: 0.5009\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5928 - val_loss: 0.4996\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5908 - val_loss: 0.4982\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5889 - val_loss: 0.4969\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5869 - val_loss: 0.4956\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5850 - val_loss: 0.4944\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5831 - val_loss: 0.4932\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5812 - val_loss: 0.4921\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5794 - val_loss: 0.4911\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.24234404135098125, my average MASE = 0.42071116848846357\n",
      "Cluster 6, 0.24234404135098125\n",
      "Before prediction: train_X.shape=(50, 10, 67), train_y.shape=(50, 67), test_X.shape=(17, 10, 67), test_y.shape=(17, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4441 - val_loss: 0.4379\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4435 - val_loss: 0.4378\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4430 - val_loss: 0.4376\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4425 - val_loss: 0.4374\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4419 - val_loss: 0.4372\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4414 - val_loss: 0.4371\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4409 - val_loss: 0.4369\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4404 - val_loss: 0.4367\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4398 - val_loss: 0.4366\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4393 - val_loss: 0.4364\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4388 - val_loss: 0.4362\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4383 - val_loss: 0.4361\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4378 - val_loss: 0.4359\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4373 - val_loss: 0.4357\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4368 - val_loss: 0.4356\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4363 - val_loss: 0.4354\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4358 - val_loss: 0.4352\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4353 - val_loss: 0.4351\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4348 - val_loss: 0.4349\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4343 - val_loss: 0.4348\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4339 - val_loss: 0.4346\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4334 - val_loss: 0.4344\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4329 - val_loss: 0.4343\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4324 - val_loss: 0.4341\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4320 - val_loss: 0.4340\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4315 - val_loss: 0.4338\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4310 - val_loss: 0.4337\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4306 - val_loss: 0.4335\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4301 - val_loss: 0.4334\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4296 - val_loss: 0.4332\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4292 - val_loss: 0.4331\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4287 - val_loss: 0.4329\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4283 - val_loss: 0.4328\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4278 - val_loss: 0.4326\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4274 - val_loss: 0.4325\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4269 - val_loss: 0.4323\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4265 - val_loss: 0.4322\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4261 - val_loss: 0.4320\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4256 - val_loss: 0.4319\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4252 - val_loss: 0.4317\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "predicted_original.shape=(17, 67), test_y.shape=(17, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 191.2474349797922, my average MASE = 74799483.45709221\n",
      "Cluster 7, 191.2474349797922\n",
      "Before prediction: train_X.shape=(2, 10, 67), train_y.shape=(2, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2212 - val_loss: 0.1239\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2202 - val_loss: 0.1236\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2192 - val_loss: 0.1233\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2183 - val_loss: 0.1230\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2174 - val_loss: 0.1228\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2165 - val_loss: 0.1225\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2156 - val_loss: 0.1223\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2147 - val_loss: 0.1221\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2138 - val_loss: 0.1219\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2129 - val_loss: 0.1217\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2120 - val_loss: 0.1215\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2111 - val_loss: 0.1213\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2102 - val_loss: 0.1212\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2093 - val_loss: 0.1211\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2085 - val_loss: 0.1210\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2076 - val_loss: 0.1209\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2068 - val_loss: 0.1208\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2059 - val_loss: 0.1207\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2051 - val_loss: 0.1207\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2042 - val_loss: 0.1206\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2034 - val_loss: 0.1206\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2026 - val_loss: 0.1205\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2018 - val_loss: 0.1204\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2010 - val_loss: 0.1204\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2002 - val_loss: 0.1203\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1995 - val_loss: 0.1203\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1987 - val_loss: 0.1203\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1980 - val_loss: 0.1203\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1973 - val_loss: 0.1203\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1965 - val_loss: 0.1203\n",
      "Epoch 30: early stopping\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.15391611936993946, my average MASE = 0.29566028544300293\n",
      "Cluster 8, 0.15391611936993946\n",
      "Before prediction: train_X.shape=(4, 10, 67), train_y.shape=(4, 67), test_X.shape=(1, 10, 67), test_y.shape=(1, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5076 - val_loss: 0.4286\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5055 - val_loss: 0.4276\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5036 - val_loss: 0.4266\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5017 - val_loss: 0.4256\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4998 - val_loss: 0.4246\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4980 - val_loss: 0.4236\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4962 - val_loss: 0.4226\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4944 - val_loss: 0.4217\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4926 - val_loss: 0.4208\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4908 - val_loss: 0.4199\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4890 - val_loss: 0.4191\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4871 - val_loss: 0.4182\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4853 - val_loss: 0.4173\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4835 - val_loss: 0.4164\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4817 - val_loss: 0.4156\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4799 - val_loss: 0.4148\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4782 - val_loss: 0.4140\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4765 - val_loss: 0.4133\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4749 - val_loss: 0.4126\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4732 - val_loss: 0.4118\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4717 - val_loss: 0.4111\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4701 - val_loss: 0.4104\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4686 - val_loss: 0.4097\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4671 - val_loss: 0.4089\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4656 - val_loss: 0.4082\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4641 - val_loss: 0.4075\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4627 - val_loss: 0.4068\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4613 - val_loss: 0.4061\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4600 - val_loss: 0.4054\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4587 - val_loss: 0.4048\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4573 - val_loss: 0.4042\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4560 - val_loss: 0.4036\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4546 - val_loss: 0.4030\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4533 - val_loss: 0.4025\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4520 - val_loss: 0.4019\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4506 - val_loss: 0.4014\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4493 - val_loss: 0.4009\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4480 - val_loss: 0.4004\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4467 - val_loss: 0.3999\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4454 - val_loss: 0.3994\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(1, 67), test_y.shape=(1, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 0.2425229695624874, my average MASE = 0.5232189989788755\n",
      "Cluster 9, 0.2425229695624874\n",
      "Before prediction: train_X.shape=(6, 10, 67), train_y.shape=(6, 67), test_X.shape=(2, 10, 67), test_y.shape=(2, 67)\n",
      "Epoch 1/40\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4116 - val_loss: 0.3522\n",
      "Epoch 2/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4095 - val_loss: 0.3515\n",
      "Epoch 3/40\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4075 - val_loss: 0.3508\n",
      "Epoch 4/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4055 - val_loss: 0.3501\n",
      "Epoch 5/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4035 - val_loss: 0.3494\n",
      "Epoch 6/40\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4016 - val_loss: 0.3488\n",
      "Epoch 7/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3996 - val_loss: 0.3481\n",
      "Epoch 8/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3977 - val_loss: 0.3475\n",
      "Epoch 9/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3958 - val_loss: 0.3468\n",
      "Epoch 10/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3939 - val_loss: 0.3462\n",
      "Epoch 11/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3920 - val_loss: 0.3456\n",
      "Epoch 12/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3902 - val_loss: 0.3450\n",
      "Epoch 13/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3884 - val_loss: 0.3445\n",
      "Epoch 14/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3865 - val_loss: 0.3439\n",
      "Epoch 15/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3847 - val_loss: 0.3434\n",
      "Epoch 16/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3829 - val_loss: 0.3430\n",
      "Epoch 17/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3811 - val_loss: 0.3425\n",
      "Epoch 18/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3793 - val_loss: 0.3420\n",
      "Epoch 19/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3776 - val_loss: 0.3416\n",
      "Epoch 20/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3759 - val_loss: 0.3411\n",
      "Epoch 21/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3742 - val_loss: 0.3407\n",
      "Epoch 22/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3725 - val_loss: 0.3402\n",
      "Epoch 23/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3708 - val_loss: 0.3398\n",
      "Epoch 24/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3692 - val_loss: 0.3394\n",
      "Epoch 25/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3675 - val_loss: 0.3390\n",
      "Epoch 26/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3659 - val_loss: 0.3386\n",
      "Epoch 27/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3644 - val_loss: 0.3382\n",
      "Epoch 28/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3628 - val_loss: 0.3379\n",
      "Epoch 29/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3612 - val_loss: 0.3376\n",
      "Epoch 30/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3597 - val_loss: 0.3373\n",
      "Epoch 31/40\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3583 - val_loss: 0.3370\n",
      "Epoch 32/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3568 - val_loss: 0.3367\n",
      "Epoch 33/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3554 - val_loss: 0.3364\n",
      "Epoch 34/40\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3540 - val_loss: 0.3361\n",
      "Epoch 35/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3526 - val_loss: 0.3358\n",
      "Epoch 36/40\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3512 - val_loss: 0.3355\n",
      "Epoch 37/40\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3498 - val_loss: 0.3352\n",
      "Epoch 38/40\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3484 - val_loss: 0.3350\n",
      "Epoch 39/40\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3471 - val_loss: 0.3347\n",
      "Epoch 40/40\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3457 - val_loss: 0.3344\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "predicted_original.shape=(2, 67), test_y.shape=(2, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average MASE = 624.4867423423187, my average MASE = 18127046.32229549\n",
      "Cluster 10, 624.4867423423187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maes = defaultdict(lambda: [])\n",
    "mases = defaultdict(lambda: [])\n",
    "mapes = defaultdict(lambda: [])\n",
    "answers = {}\n",
    "bad_values = np.zeros(dataset.shape[1])\n",
    "\n",
    "dif=True\n",
    "\n",
    "for window_size in window_sizes_for_clustering:\n",
    "    for N_clusters in Ns_clusters:\n",
    "        dataset_windows, dataset_y = Forecasting.create_windows(dataset, window_size=window_size)\n",
    "        clusters_labels = Clustering.KMeans_for_windows(dataset_windows, W=window_size, N_clusters=N_clusters, max_iter=50)\n",
    "        print(f\"{clusters_labels.shape=}\")\n",
    "        datasets_clusters = Clustering.flatten_from_interceting_windows(dataset_windows, clusters_labels, W=window_size, \\\n",
    "                N_clusters=N_clusters)\n",
    "        # list of list of ndarrays [N_i, Q], dataset_clusters[cluster_num][i] - i-th part of dataset for cluster_num\n",
    "\n",
    "        print(f\"{N_clusters=}, {len(datasets_clusters)}, {len(datasets_clusters[0])}, {datasets_clusters[0][0].shape}\")\n",
    "        ###window_size for model\n",
    "        errors = [1] * N_clusters\n",
    "        for cluster_num in range(N_clusters):\n",
    "            sc = Forecasting.MyStandardScaler(dif=dif)\n",
    "            #datasets_clusters[cluster_num] - list of [N_i, Q] ndarrays\n",
    "            sc.fit(datasets_clusters[cluster_num])\n",
    "            prepared_data = sc.transform(datasets_clusters[cluster_num])\n",
    "            data_X, data_y = Forecasting.create_windows(prepared_data, window_size=10)\n",
    "            #data_X - list of [N_i-W, W, Q] ndarrays\n",
    "            train_X, train_y, valid_X, valid_y, test_X, test_y, ind = Forecasting.split_to_train_test(data_X, data_y, part_of_test=0.2, part_of_valid=0.2)\n",
    "            #ndarrays [N_i, W, Q] or [N_i, Q]\n",
    "            ind = np.array(ind) + window_size\n",
    "            print(f\"Before prediction: {train_X.shape=}, {train_y.shape=}, {test_X.shape=}, {test_y.shape=}\")\n",
    "            try:\n",
    "                assert(len(test_X.shape) == 3 and test_X.shape[0] > 0)\n",
    "                assert(len(valid_X.shape) == 3 and valid_X.shape[0] > 0)\n",
    "                assert(len(train_X.shape) == 3 and train_X.shape[0] > 0)\n",
    "            except AssertionError:\n",
    "                print(f\"FAIL - {test_X.shape=}, {valid_X.shape=}, {train_X.shape=}\")\n",
    "                errors[cluster_num] = np.Inf\n",
    "                continue\n",
    "            model, history = Forecasting.learn(train_X, train_y, valid_X=valid_X, valid_y=valid_y)\n",
    "            predicted = model.predict(test_X)\n",
    "            predicted_original = sc.inverse_transform(predicted)[0]\n",
    "            #inverse_trasform returns list of ndarrays \n",
    "            # if dif:\n",
    "                #константа при дифференцировании\n",
    "                # predicted_original = sc.add_first_element(predicted_original, ind)[0]\n",
    "            print(f\"{predicted_original.shape=}, {test_y.shape=}\")\n",
    "\n",
    "            #calc all metrics\n",
    "            cur_mae = mae(test_y, predicted_original, multioutput='raw_values')\n",
    "#             error_out = mase(test_y, predicted_original, y_train=test_y)\n",
    "#             error_in = mase(test_y, predicted_original, y_train=train_y)\n",
    "            # cur_mase = mase(test_y, predicted_original, y_train=test_y)\n",
    "            cur_mape = mape(test_y, predicted_original)\n",
    "            cur_mase = Forecasting.my_mase(test_y, predicted_original, multioutput='raw_values')\n",
    "            maes[(window_size, N_clusters)].append(cur_mae)\n",
    "#             mases[(window_size, N_clusters)].append((error_in, error_out))\n",
    "            mapes[(window_size, N_clusters)].append(cur_mape)\n",
    "#             errors[cluster_num] = mase_uni(test_y, predicted_original, y_train=test_y)\n",
    "            tmp_bad = cur_mase > np.percentile(cur_mase, 90)\n",
    "            bad_values += tmp_bad\n",
    "            cur_mase[tmp_bad] = -1\n",
    "#             errors[cluster_num] = Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')\n",
    "            errors[cluster_num] = np.mean(cur_mase[~tmp_bad])\n",
    "            \n",
    "            #show all metrics\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.suptitle(f\"K={N_clusters}, W={window_size}, C={cluster_num}\")\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.plot(cur_mae, color=\"green\", label=\"library\")\n",
    "            plt.plot(Forecasting.my_mae(test_y, predicted_original, multioutput='raw_values'), color=\"red\", label=\"custom\")\n",
    "            plt.title(\"MAE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "#             plt.plot(error_in, label=\"library, in\")\n",
    "#             plt.plot(error_out, label=\"library, out\")\n",
    "            plt.plot(cur_mase, label=\"custom, out\")\n",
    "            plt.title(\"MASE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.plot(cur_mape)\n",
    "            plt.title(\"MAPE\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f\"plots/Dataset2/K={N_clusters}  W={window_size} C={cluster_num}.png\")\n",
    "#             plt.show()    \n",
    "            plt.clf()\n",
    "            # print(f\"{cur_mae=}, {cur_mase=}, {cur_mape=}\")\n",
    "            # my_mase = mase()\n",
    "            # print(f\"MASE in_sample = {error_in}, MASE out_sample = {error_out}\")\n",
    "            print(f\"average MASE = {errors[cluster_num]}, my average MASE = {Forecasting.my_mase(test_y, predicted_original, multioutput='uniform_average')}\")\n",
    "            print(f\"Cluster {cluster_num}, {errors[cluster_num]}\")\n",
    "        answers[(window_size, N_clusters)] = errors\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.suptitle(f\"K={N_clusters}, W={window_size}\")\n",
    "        plt.subplot(2, 2, 1)\n",
    "\n",
    "        plt.bar(np.arange(N_clusters), [np.sum(clusters_labels == i) for i in range(N_clusters)], color='blue')\n",
    "        plt.title(\"Размеры кластеров\")\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.bar(np.arange(N_clusters), [len(datasets_clusters[i]) for i in range(N_clusters)], color=\"green\")\n",
    "        plt.title(\"Количество непрерывных отрезков\")\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.bar(np.arange(N_clusters), errors, color=\"red\")\n",
    "        plt.title(\"MASE на тесте каждого из кластеров\")\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        plt.table(cellText= [[f\"{x:.2f}\"] for x in errors],\n",
    "                      rowLabels=list(range(N_clusters)),\n",
    "                      loc='center')\n",
    "#         plt.show()\n",
    "        plt.savefig(f\"plots/Dataset2/method1: {N_clusters=}  W={window_size}.png\")\n",
    "        #         plt.show()\n",
    "        plt.clf()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.bar(np.arange(bad_values.shape[0]), bad_values)\n",
    "plt.title(\"Количество раз, когда переменная имела максимум MASE\")\n",
    "plt.savefig(f\"plots/Dataset2/bad_values.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([ 2,  4,  7,  8, 11, 14, 18, 21, 23, 25, 28, 30, 33, 37, 39, 43, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 5)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33,\n",
      "       39, 48, 50, 53, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 28, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 33, 37, 39,\n",
      "       41, 43, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 9)\n",
      "     (array([ 2,  4,  9, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 30, 31, 33, 35, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(1, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 12, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 11, 14, 18, 20, 21, 23, 25, 26, 28, 30, 39, 41, 42, 48,\n",
      "       51, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(3, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 13, 14, 15, 18, 21, 23, 25, 26, 28, 30, 33,\n",
      "       37, 39, 41, 42, 44, 48, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 5)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 26, 28, 30, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 7)\n",
      "     (array([ 2, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 22, 23, 25, 26, 28, 30, 35, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(3, 9)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 20, 21, 23, 25, 28, 30, 31, 33, 35, 39,\n",
      "       41, 43, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(3, 11)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 37, 39, 44, 48,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 12, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 2)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 12, 14, 18, 21, 23, 25, 30, 31, 33, 37, 39,\n",
      "       60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(5, 5)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 23, 25, 26, 28, 30, 31, 39, 60, 61,\n",
      "       62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(5, 7)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 16, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 23, 25, 28, 30, 33, 35, 39, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "(5, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 10, 11, 14, 15, 16, 18, 19, 21, 23, 25, 27, 28, 30,\n",
      "       39, 42, 44, 47, 48, 52, 58, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 15, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35,\n",
      "       37, 39, 60, 61, 62, 63, 65]),)\n",
      "(5, 11)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 39, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 21, 22, 23, 25, 28, 30, 31, 33, 39,\n",
      "       41, 42, 49, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62]),)\n",
      "(10, 2)\n",
      "     (array([ 2,  4,  7,  8,  9, 10, 11, 13, 14, 18, 21, 23, 25, 28, 30, 31, 33,\n",
      "       35, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 5)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 22, 23, 25, 28, 30, 31, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "(10, 7)\n",
      "     (array([ 2,  4,  8,  9, 14, 16, 18, 19, 30, 58, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 14, 18, 21, 22, 23, 25, 26, 28, 30, 33, 35, 37,\n",
      "       39, 60, 61, 62, 63, 65]),)\n",
      "(10, 9)\n",
      "     (array([ 2,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 13, 14, 18, 20, 21, 23, 24, 25, 26, 28, 30, 31,\n",
      "       33, 37, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "(10, 11)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  8,  9, 11, 12, 14, 18, 21, 22, 23, 25, 28, 30, 39, 56, 60,\n",
      "       61, 62, 63, 65]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62]),)\n",
      "     (array([ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22,\n",
      "       23, 24, 25, 26, 27, 28, 29, 30, 39, 60, 61, 62, 63, 65]),)\n",
      "     (array([ 2,  4, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8,  9, 14, 18, 19, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n",
      "     (array([ 2,  4,  8, 14, 18, 30, 60, 61, 62, 63]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in maes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in mases.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c[0] < 1)}, {np.where(val_c[1] < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "     (array([14, 18, 25, 30, 31, 33, 35, 37, 43]),)\n",
      "     (array([14, 30]),)\n",
      "(1, 5)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(1, 7)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 11, 14]),)\n",
      "     (array([14]),)\n",
      "(1, 9)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 4,  8, 14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14, 60, 61]),)\n",
      "(1, 11)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([ 8, 14, 65]),)\n",
      "     (array([14]),)\n",
      "(3, 2)\n",
      "     (array([ 4, 14, 18, 30, 31, 33, 35, 37, 42, 62]),)\n",
      "     (array([14, 30]),)\n",
      "(3, 5)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(3, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61]),)\n",
      "(3, 9)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 28, 39, 62]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 19, 30]),)\n",
      "(3, 11)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 23, 28, 39, 62, 65]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "(5, 2)\n",
      "     (array([12, 14, 18, 30, 31, 33, 35, 37, 60, 62, 65]),)\n",
      "     (array([14, 30]),)\n",
      "(5, 5)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "(5, 7)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([ 9, 11, 14, 18, 19, 21, 23, 25, 30, 39, 42, 44, 47, 52, 60, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "(5, 11)\n",
      "     (array([14, 18, 30, 60]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([ 8, 14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 21, 23, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14, 18, 30, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "(10, 2)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "(10, 5)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 7)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 61, 62]),)\n",
      "     (array([ 8, 14]),)\n",
      "(10, 9)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14, 60, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([ 8, 14]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n",
      "(10, 11)\n",
      "     (array([14, 61]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 60]),)\n",
      "     (array([14]),)\n",
      "     (array([ 4,  5,  6,  7, 10, 11, 14, 25, 28, 39, 62, 65]),)\n",
      "     (array([14]),)\n",
      "     (array([14, 18, 30]),)\n",
      "     (array([14]),)\n",
      "     (array([14]),)\n"
     ]
    }
   ],
   "source": [
    "for key, val in mapes.items():\n",
    "    print(key)\n",
    "    for val_c in val:\n",
    "        print(f\"     {np.where(val_c < 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anna",
   "language": "python",
   "name": "anna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
